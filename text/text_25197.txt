BACKGROUND
the comparative analysis of dna sequence variation within species  and between species  is a powerful approach to understand the evolutionary process , and represents an insight into the functional significance of genomic regions . particularly, the detection of both positive and negative purifying selection at the molecular level is of major interest. since positive darwinian selection is ultimately responsible for evolutionary adaptations, the detection of genomic regions driven by positive selection has profound implications in evolutionary biology as well as in understanding the gene function. the identification of regions evolving by negative selection is also very important as conserved regions are most likely to be functionally significant. the inference of such evolutionary process requires knowing how within-species dna sequences change under neutrality  <cit> . in this context, the coalescent theory  <cit>  has become the primary framework for the analysis of dna polymorphism data.

currently, there are few convincing studies on the action of recent -or ongoing- positive selection at the intraspecific level . apparently, the most important difficulty is that demographic events such as migration, population expansions or bottlenecks can mimic the signature of selective processes; therefore, it is not easy to detect the specific imprint of positive selection on individual genes or on short stretches of dna. the distinction between natural selection and other demographic events requires the surveys of large genome regions . the detection of negative purifying selection on dna sequences, on the contrary, has been much easier  <cit> ; in fact negative selection is acting continuously while positive selection is much more episodic. indeed, there are many surveys where the action of negative purifying selection has been detected even at non-coding dna regions . undoubtedly, such studies will provide fundamental insights into the functional significance of non-coding dna. even so, there are very few studies analysing the within and between-species patterns of nucleotide variation at the genome-wide scale.

recent genome projects efforts, as the hapmap  <cit> , encode  <cit> , simyak  <cit> , dpgp  <cit>  and the mouse genome resequencing project  <cit>  will change radically our capabilities to detect specific genomic regions shaped by natural selection. although with different goals, these projects will generate snps  data from many whole-genome copies. a limiting critical point has been the absence of adequate bioinformatic tools for such analysis. although there are powerful programs for molecular population genetic analyses , they are not completely satisfactory for the high-throughput kind of data released by these projects.

here, we describe version  <dig> of the variscan software  <cit> . in this new version we implemented new methods and features for an exhaustive analysis of dna sequence polymorphisms at the genome-wide scale, using a graphical user-friendly interface. in particular, the current version of the software allows i) reading several informative-rich genome-wide data files; ii) estimating many population-genetic parameters including coalescent-based statistics; iii) a separate analysis for different genomic regions, functional categories, chromosome locations, etc; iv) adapted analysis for shallow data generated by high-throughput genome projects; v) the identification of relevant genomic regions by using the sliding-window  and wavelet-multiresolution approaches  <cit> ; vi) the visualization of the results integrated with current genome annotations in the most commonly available genome browsers.

implementation
variscan main algorithms are written in ansi c. the software also includes a number of scripts written in perl, and a gui front-end developed in java. variscan currently runs on a wide variety of platforms, such as linux, macos x and win <dig>  variscan also uses the lastwave version  <dig>  software  <cit>  that is invoked from the java front-end.

RESULTS
new features
variscan version  <dig> incorporates substantial improvements over version 1: it implements many new methods and features and also includes a graphical user-friendly interface. specifically, variscan  <dig> allows handling input data files with dna sequence information from  outgroup species. this feature allows the current version of variscan conducting divergence estimates, neutrality tests and other parameters requiring such information. the second major improvement is the possibility to conduct separate analysis of different genomic regions , functional categories  and chromosome locations. in addition, variscan version  <dig> implements new features to visualize the results of the sliding-window, as well of the wavelet-multiresolution approaches, integrated with current genome annotations in the most commonly available genome browsers. since the data analysis by using such methods is complicated, we have incorporated an easy-to-use graphical user interface which allows conducting all needed computing steps, including those of the wavelet-multiresolution methods.

overview
variscan can read multiple alignment formats as maf, mga, phylip, xmga as those used in the hapmap project  <cit> , with dna sequence polymorphism data , and also with interspecific nucleotide variation . the software allows conducting exhaustive population-genetic analyses using genome annotations, and permits the visualization of the results integrated in the most commonly available genome browsers. the analysis can be performed using the available gui   or under a command-line mode.

molecular population genetics analysis
variscan computes state-of-the-art population genetic parameters and coalescent-based statistics including those requiring outgroup nucleotide information  <cit> . in particular, variscan calculates  the standard summary statistics of nucleotide polymorphism and divergence levels  <cit> , such as the population mutational parameter , nucleotide diversity , haplotype diversity or the number of nucleotide substitutions per site ;  linkage disequilibrium based-statistics: d'  <cit> , r <dig>  <cit> , and zns  <cit> ;  neutrality-based tests: tajima's d  <cit> , fu and li's d*, f*, d and f  <cit> , fu's fs  <cit> , and fay and wu's h  <cit> . all parameters and statistics can be conducted by means of the sliding window   <cit> , or the multiresolution analysis  approaches  <cit> .

missing data
previous statistics are commonly estimated after excluding all sites with alignment gaps or missing data . however, current genome sequencing projects are generating high-throughput data with a large number of sites with missing information. for example, only ~10% of the polymorphic sites identified in patil et al.  <cit>  study were typed in all  <dig> chromosomes. therefore, it is clearly convenient to develop and implement statistics that could capture relevant information included from sites with missing data . here, we have implemented a version of π  dealing with missing data. we define πm  as



where l is the net number of positions surveyed , and k is the average number of nucleotide differences that is given by



where m is the total number of positions , and hi is heterozygosity at site i, that is defined as



where ni is the total number of chromosomes  excluding those with missing data at site i , and xij is the relative frequency of nucleotide variant j  at site i. we denote as l  the total number of positions excluding those sites with ni ≤  <dig>  in estimating πm, all sites with alignment gaps should be excluded from the analysis. the rationale for this criterion is that while missing data are likely accumulated at random, alignment gaps are not; indeed, two  sequences with gaps in a given position likely correspond to a single insertion/deletion event occurred in a common ancestor.

analysis of different functional regions
variscan allows a fine and detailed analysis of the pattern and levels of nucleotide variation at different functional regions. more precisely, it allows a separate analysis of different genomic regions , functional categories , or chromosome locations . for the analysis variscan uses current genome annotations available in public databases. this task is accomplished by a perl script  that parses the appropriate genome information contained in a gff  file  <cit> , and returns a bdf  file directly used by variscan. the bdf format, which is very similar to that used in vista server  <cit> , consists of a tab-delimited list of the relevant positions  to be analysed. gff2bdf.pl incorporates several pre-defined filter options; the script, nevertheless, can be easily adapted to accommodate specific or more complex analyses.

wavelet transform and multiresolution analysis
variscan incorporates both the standard sw and the wavelet-based methods to identify particular genome features along the dna sequence. the wavelet transform , like fourier transform, is a mathematical transformation widely used to extract information from signals. a signal can be resolved simultaneously in time  and frequency domain by wt. the fourier transform, on the contrary, only contains frequency information and, therefore, fails to detect spectral components localized in the time  domain. therefore, wavelet-based analysis provides a method to decompose the signal into high and low frequencies and therefore it is useful in extracting feature information at different scales. for the present analysis, time/space and frequency should be regarded as the position of the nucleotide sequence  and the relevant parameter intensity , respectively. in this context, the signal is the profile of the relevant statistic along the dna sequence. here, we used the wt to decompose the signal into high and low frequencies for detecting global and local relevant features from genome-scale dna polymorphism data.

there are two basic kinds of wt, continuous  and discrete . the cwt of a signal x is defined as



where τ represents translation , s represents scale , ψ is the transforming function or mother wavelet, and the asterisk denotes a complex conjugate. there are a number of suitable mother wavelet functions; the choice of the particular mother wavelet to be used, nevertheless, should be adapted to the actual information to be extracted from the signal. signals are analysed by cwt, which is obtained by scaling and translating  the mother wavelet along the signal. this process generates the wavelet coefficients  that capture relevant information from a signal.

here, we used the dwt , which is just the discrete version of cwt, because of the discrete nature of the signal to be analysed . the signal, which can be envisaged as a one-dimensional vector , is analysed by the wtrans1d module of lastwave v <dig>  software  <cit>  using daubechies' d <dig>  <cit>  as the default wavelet filter since it is adequate for locating features, such as peaks and valleys, from a signal  <cit> . the dwt analysis requires a signal to have a number of points equal to some power of two. for this purpose, and to avoid the boundary effect problem, we used the mirror padding method. with this approach the signal is extended by mirroring both ends at the boundaries, to achieve a total length  as a power of two. after the wt analysis, the padding tags are discarded and the original signal  is recovered. dwt can be conducted by means of the mra  <cit> . this method uses a fast algorithm based on orthogonal wavelets, leading to the decomposition of a signal into different resolution levels; consequently, it enables the extraction of valuable information at different scales. under this method, the original signal is decomposed by two complementary filters . as a result, the signal is split into two equal parts: one including the high-frequency components , and the other with low frequency components  . while details are not further analysed, the approximation component is successively decomposed, split into two new high and low frequency components. the decomposition process can continue hierarchically until the detail component consists of a single coefficient. orthogonal wavelets allow for the further reconstruction of the signal, which can be used for an easy location of features along the dna sequence.

in the context of dna polymorphism analysis, the signal is the raw profile of the statistic  obtained along the dna sequence. the signal is further decomposed to all analysed levels  using the orthogonal wavelet decomposition method. the orthogonal property of daubechies' wavelets allows for reconstruction of the signal. the outcome is the reconstructed wavelet-transform profiles of the population genetic parameter along the sequence, which can be used for detecting global and local relevant features  on genome-wide dna polymorphism data.

output visualization
the sw and mra results can easily be visualized in available genome browsers , such as the human genome web browser at ucsc  <cit>  and any web browser using gbrowse  <cit> . this is accomplished by writing the relevant outcome in the so-called custom annotation track formats. in this way, the relevant results  can be visualized integrating available genome features .

data analysis
we tested the performance of the methods implemented in the variscan software by analysing two qualitatively different data sets: i) a computer-simulated data set generated by applying coalescent methods, and ii) snp data from the mouse genome resequencing project  <cit> , and from the patil et al.  <cit>  study in human. mra analysis conducted using windows of  <dig> bp captures all information of the data. small windows, however, increase the computational ram-time requirements, and in fact are not strictly necessary. however, we can use larger windows without losing interesting features. even so, unlike the sw analyses, the mra results are nearly independent of the chosen window length. moreover, the sw would likely fail in detecting small-size features at the whole genome scale. for the mra analysis, the optimal window size to detect most of the interesting features will depend on the current nucleotide diversity values and on of the sample size of the study. these values will be the input  for the mra. from a practical standpoint, analysis of 10– <dig> sequences may be conducted by using non-overlapping windows of 50– <dig> bp for per-site θ values of  <dig> , up to 500– <dig> bp for θ =  <dig> , as in drosophila and humans, respectively.

computer-simulated data set
we generated random data sets based on the simplest non-recombining coalescent model  <cit>  as follows: i) generation of evolutionary times and the gene genealogy ; ii) incorporation of poisson-randomly distributed mutations . subsequently, we modify this data set by changing  the applied θ value. in particular, we reduced nucleotide diversity values continuously and symmetrically. we made changes at two different levels: iii) one or more chromosome-wide nucleotide diversity reductions; iv) additional reductions at narrow regions. these changes were conducted by using different intensity  and stretch lengths  values. therefore, the simulated data set mimics the effects caused by partial selective sweeps upon different nucleotide diversity levels. the analysis of one of these simulated data files is given in figure  <dig>  it can be seen that the mra technique recovers the two different intensity types of distorted regions included in the data: nucleotide diversity reductions affecting small dna stretches are detected at lower mra levels while more genome-wide reductions are identified at higher levels.

.

dna polymorphism data from the mouse genome resequencing project
the mouse genome resequencing project is conducting a genome-wide dna resequencing survey in  <dig> inbred strains of mice using an array-based resequencing technology. in spite that the project in not finished yet, some chromosomes are quite well covered. here, we use variscan to analyse the levels of nucleotide diversity along the chromosome  <dig> . since the polymorphism data were determined in inbred strains  we will consider one sequence per strain . the mouse chromosome  <dig> data set contains  <dig>  snps; not all of these snps, nevertheless, were typed in all  <dig> strains because of experimental errors . estimates of nucleotide diversity  were πm =  <dig> . nonetheless, since many repetitive regions of the chromosome were not completely resequenced, current nucleotide diversity values likely are underestimated.

nucleotide diversity values along the chromosome, nevertheless, contain much more information than the global π values. for instance, the sw method allows identifying constrained regions, and it could facilitate the detection of the distinctive fingerprint of positive selection. the mra analysis is clearly a much more useful method for detecting specific genomic features at different scales. additionally, the results of these analyses can be visualized integrated with current genome annotations using available genome browsers . the mra analysis revealed a strong heterogeneous nucleotide diversity profile along the dna region, including a number of peaks and valleys. although it is premature to determine the evolutionary meaning of these regions, the joint visualization of the mra results with current annotated genomic features  is a comprehensive tool for their characterization and further understanding.

patil et al.  <cit>  data set
this data set contains the  <dig>  snps identified in the survey of  <dig>  mb  in  <dig> ethnically diverse individuals using high-density oligonucleotide arrays. however, for an easy and comprehensible interpretation of the results we do not use this raw data. first, we excluded all singletons variants because the used array-based technology had little power in their identification. second, we only analysed snps confirmed in the ncbi build  <dig> of the human genome . third, we focused the analysis on snps located in the longest contig  of patil et al.'s data, since there were missing regions between contigs. in total, we analyzed  <dig>  snps  in a region of  <dig>  mb long  in  <dig> individuals.

for the total nt_ <dig> contig data, only  <dig> snps  were typed in all  <dig> chromosomes, resulting on  <dig>  missing chromosomes per site. estimates of nucleotide diversity  was πm =  <dig> . this value is lower than that reported in patil et al.'s study  ; these estimates, however, are not completely comparable because we are using only a subset of patil's data. particularly, we have not taken into account singleton information, while the expected frequency of singletons  for a neutrally evolving region in a sample of  <dig> sequences is  <dig>  . thus, roughly 30% of the snps should be singletons, although the actual value is likely higher since many human regions have negative tajima's d values. considering this 30% as the true percentage of singletons in the sample, the πm estimates for the total contig would be  <dig> .

discussion
detecting the action of positive natural selection is critical to understand and identify the evolutionary forces that have shaped organismal traits and genomes. despite the profound implications in evolutionary biology and in medicine currently there are few convincing evidences of the action of positive selection. since purifying selection weeding out deleterious mutations operates continuously, their detection had been much easier. indeed, the detection of evolutionarily conserved regions has been proven to be a very effective method for the identification of functionally important regions, such as regulatory elements. the detection of the distinctive signature of natural selection can, nevertheless, be detected by analysing the spatial distribution of polymorphisms across the genome; essentially, positive natural selection causes a distinctive fingerprint on the pattern of nucleotide variation both in the target of selection but also in their surrounding regions. for instance, the selective sweep  produced when selection drives an advantageous mutation to fixation, will affect variation at relatively short dna sequence stretches   <cit> . on the other hand, demographic effects will have a genome-wide signature.

the identification of the specific regions evolving under natural selection at the genome scale requires, however, new analytical methods and bioinformatics tools. in spite of the impressive recent development of such methods  <cit> , nevertheless, they are not fully adequate for a genome-wide analysis. in this context, variscan software overcomes many limitations of current software and methods, and it is useful as an exploratory tool in the analysis of dna polymorphism at the genome scale. variscan can handle the vast amount of dna polymorphism data generated by large genome-based projects, and implements efficient methods, such as sw and mra, to determine the common patterns of nucleotide variation and to identify specific features, along large  dna fragments. the sw has been extensively used in dna polymorphism studies for exploratory data analysis  <cit> . this method allows obtaining a relevant parameter profile  along a dna region and, therefore, is instrumental in detecting the distinctive footprint of natural selection, mainly in genome wide-based analysis. unfortunately, the determination of the appropriate window size represents an important limitation of the method. this is a critical point because the accuracy of extracting features from dna sequence data  strongly depends on the window size. although there have been some statistical attempts to determine the window size  <cit> , the usual approach is by trial-and-error. the mra-based analysis, on the contrary, can be used to detect genomic features even at different resolution scales; for example, features in various nucleotide diversity backgrounds. therefore, the method can be helpful in detecting relevant features from dna polymorphism data at a genome-wide scale, such as conserved regions, peaks and valleys of nucleotide diversity, linkage disequilibrium clusters, etc. that, in turn, might reveal the distinctive footprint left by the action of natural selection.

CONCLUSIONS
in summary, the version  <dig> of the variscan software implements new methods and features for an exhaustive dna sequence polymorphism analysis at the genome-wide scale. we have tested the performance of the methods implemented in the software by analysing computer-simulated and real data sets.

availability and requirements
project name: variscan

project home page: . source code, executables and documentation are available from this site.

operating system: linux, macosx, windows

programming languages: ansi c, java, perl

other requirements: java  <dig>  or higher, perl  <dig>  or higher

license: gnu gpl

authors' contributions
sh and ajv developed and tested the software. jr conceived and led the project. jr wrote the manuscript. all authors read and approved the final manuscript. sh and ajv equally contributed to this work.

