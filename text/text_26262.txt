BACKGROUND
the cost of sequencing dna has decreased steeply since the introduction of next-generation short read technologies  <cit> . it is now at the point where cohorts of whole human genomes are sequenced for study. however, investigations of disease-causing variation continue to focus on the protein-coding exome, which is a small fraction of the whole genome. it contains fewer repetitive elements than non-coding regions and contains most of the causal disease variants identified to date  <cit> . additionally, experimental approaches to determine the function of candidate disease variants at protein coding or transcript splice sites are well developed and accepted by the research community.

for these reasons, exome centric analysis will remain common in research and is increasingly used in clinical genetic settings  <cit> . the targeted capture followed by sequencing of specific regions, such as the  <dig> mb human exome , has proven to be a cost-effective and productive strategy for the identification of single nucleotide polymorphisms  and small insertions and deletions in this rich vein of the genome. however, as sequencing technology rapidly improves and cost per sequenced nucleotide falls, there is likely to come a point where it is more economic to sequence a whole genome rather than target-capture and sequence, even if analysis is confined to just the exome. where that point lies depends both on the costs of the technologies but also on the uniformity of coverage and biases inherent in the data. in this work we set out to compare exome-seq with whole genome sequencing  in terms of their sensitivity to correctly detect known variants over the whole exome.

the process of exome-seq has known issues that impact negatively on snp detection sensitivity. these include pcr amplification, which tends towards lower coverage in gc-rich regions due to annealing during amplification , and the preferential capture of reference sequence alleles, which biases the allele distribution away from alternate alleles at heterozygous snp sites . exome-seq produces a relatively heterogeneous profile of read coverage over target regions when compared to the more homogeneous wgs  <cit> . better uniformity of coverage yields improved snp detection sensitivity across the regions of interest .

previous estimates of the amount of sequencing required to accurately identify snps in wgs and exome-seq are variable. bentley et al. estimated that 15x mapped read depth of wgs samples would be sufficient to detect almost all homozygous snps and 33x for almost all heterozygous snps  <cit> . 50x was estimated by ajay et al. for all snps and small indels  <cit> . depending on the capture kit, clark et al. calculated that exome-seq required 80x mean on-target depth to reach the common threshold of 10x per-site depth in 90% or more of all targeted regions  <cit> . our previous work on some of the original exome-seq target capture kits estimated between 20x and 46x mean on-target depth was required to successfully genotype 95% of heterozygous snps, with the commercially available kits at the higher end of that range.

we examine previously established measures of snp detection sensitivity  <cit>  in coding regions from exome-seq and wgs samples. snp detection sensitivity can be measured both at a site level, considering the number of reads mapped over a given position in the reference genome, or as an overall estimate based on the mapped read depth across a region or regions . we computed the per-site measure for different sequencing technologies and compared them directly when the per-site mapped depth is identical . because of the allele distribution bias in exome-seq, we expected that wgs would require fewer reads to successfully genotype heterozygous snps. the greater variability in coverage from exome-seq means that greater mean on-target depth should be required to identify the same proportion of snps in exome-seq as compared to wgs  <cit>  . we measured the estimated overall snp detection sensitivity across a given set of target regions by using the per-site snp detection sensitivity for the sequencing method combined with the coverage distribution for samples sequenced by the same method. this relates the overall sensitivity of a method to the mean on-target depth in the sample, which can be used to calculate the cost of sequencing to a given sensitivity.figure  <dig> 
snp detection sensitivity in exome and whole genome sequencing. exome and whole genome sequencing mapped read depth across the exons of an example gene. the grey vertical lines denote exon boundaries. at point a, the depth is equal and we can compare the per-site snp detection sensitivity. points b and c are examples of unequal depth, where per-site sensitivity cannot be directly compared, but the overall estimated sensitivity of the region can be calculated to account for the variability in coverage.



RESULTS
site level snp detection sensitivity
site level snp detection sensitivity is the mapped read depth directly over a polymorphic site that is required to reliably call that polymorphism  <cit> . ten human whole genome sequences  and matched whole exome sequences from the same patients, plus ten additional exome samples , were obtained from the cancer genome atlas . a further six human whole genome samples  were obtained from the  <dig> genomes project  <cit> , all aligned to the reference genome. an additional  <dig> exome samples were captured, sequenced, and aligned in house as part of two ongoing disease studies  . we randomly downsampled all  <dig> alignments to simulate shallower sequencing and called snps in the coding regions of the alignments as in our previous work  <cit> .

we defined a gold-standard set of snp calls for each sample, based on the full alignments  and confined to known hapmap  <dig>  variants . we validated the use of hapmap  <dig>  variants as the gold standard in sample na <dig> by comparing results to those obtained using the genome in a bottle  <dig>  highly confident variant call set  <cit>  as the gold standard . we measured sensitivity as a function of the per-site depth for heterozygous  and homozygous  snps. we focused on heterozygous snps as the more challenging problem: only 2-3x per-site depth was required to accurately detect at least 95% of homozygous snps in all four data sets.figure  <dig> 
site level heterozygous snp detection sensitivity for exome and whole genome sequencing samples. sensitivity is calculated from heterozygous hapmap  <dig>  positions  <cit>  located within coding sequence as determined by ensembl  <dig>  <cit> . 95% sensitivity is reached at per-site mapped depths of 9x for the tcga-wgs samples, 10x for the tcga-wxs and hgu-wxs samples, and 13x for the 1kg-wgs samples.



the oldest data set  had the worst performance for heterozygous snps, requiring at least 13x to reach 95% sensitivity. this could be due to shorter read lengths or higher sequencing error rates on older technologies. the difference in per-site snp detection sensitivity between this data set and the newer three data sets indicates that analysis of older data sets requires more stringent thresholds.

all of the newer three data sets, which are contemporary with each other, performed similarly. the tcga-wxs samples reached 95% sensitivity at 10x, while the hgu-wxs and tcga-wgs samples had a slight edge at 9x. there was a slight advantage in sensitivity for the newer tcga-wgs data set as opposed to the two exome-seq data sets, though this equalized at 12-13x per-site depth. given that read lengths are the same between these three data sets and most samples were sequenced on the same generation of machine, this difference was likely caused by reference bias from the capture step. low-depth exome sequencing projects may need to take this into consideration.

all the data sets converged at 99% sensitivity for sites with between  <dig> and 20x mapped depth. the recall curves were virtually identical for variants drawn from the ensembl  <dig> coding regions and each of the sets of targeted regions from the two exome sequencing data sets . specificity  reached 99% at 9x for the 1kg-wgs data set and 8x for the other three .

direct comparison of matched samples
the matched wgs and exome-seq samples from tcga were compared directly. considering only snps in the regions targeted by the exome capture kit,  <dig>  ±  <dig> % of variant sites were called as polymorphic by both methods with matched genotypes, and  <dig>  ±  <dig> % with mismatched genotypes. a further  <dig>  ±  <dig> % were called as polymorphic by whole genome sequencing only, and  <dig>  ±  <dig> % by exome sequencing only. 93% of the sites called as polymorphic only by whole genome sequencing had greater mapped per-site depth in the wgs sample than in the exome-seq sample . of these, 34% are at sites with no reads in the exome-seq sample, which could be due to probe failure or other technical problems.

the majority of mismatched genotypes were cases where the whole genome sample was genotyped as heterozygous and the exome sample was genotyped as homozygous . mismatches generally occurred at sites where the whole genome sample had higher per-site mapped depth than the exome sample . some sites with very high mapped depth in the exome sample also had mismatched genotypes with the whole genome sample. this could be caused by random accumulation of the same sequencing error at a given position if that position is sequenced to very high mapped depth. both of these results imply that improving uniformity of coverage will improve snp detection sensitivity.we took the subset of coding snps where the alleles and genotypes were identical in the full alignments between the tcga-wgs and tcga-wxs samples for the same individual, and compared the mapped depth of sequencing required to correctly identify the genotypes of both heterozygous and homozygous snps . to accurately genotype 95% of heterozygous snps, the tcga-wgs data set required a minimum per-site depth of 12x and the tcga-wxs data set required 34x. for homozygous sites, the minimum per-site depths were 8x and 33x respectively.figure  <dig> 
minimum per-site mapped depth required to correctly genotype a site in matched tcga exome and genome samples. coding snps at hapmap  <dig>  positions  <cit>  with identical genotypes and alleles between matched tcga exome and genome samples in the full alignments. a) the minimum per-site mapped depth required for a correct genotype call in tcga-wxs and tcga-wgs matchd samples. b) the number of extra reads required to correctly identify a snp in the tcga-wxs sample.



effect of grouped and single sample variant calling
the results in this paper are derived from calling variants for one sample at a time; however, it is standard practice to call variants in groups of samples  as this improves accuracy by allowing the use of reads across all samples at a position to determine the presence of a polymorphism. to investigate the relative benefits of pooled calling, we grouped our samples by data source, called variants on the full alignments for each group, and compared the results to the variants called on the full alignments by single sample calling .

for sites in hapmap  <dig> , there were very few cases of mismatched genotypes between the two calling methods; the main difference was in additional sites called as polymorphic when the samples were grouped. for all data sets, of the sites with mismatched genotypes or where only one method called the site as polymorphic, the mapped read depth was on average lower than for sites where genotypes were matched . the two exome capture data sets benefited significantly from grouped sample calling, with a mean of  <dig>  heterozygous and  <dig>  homozygous additional sites genotyped for the hgu-wxs  data set. these data sets had the most samples, which may have been the major cause of the improvement, or possibly the uneven coverage of the exomes was smoothed by the inclusion of multiple samples. the 1kg-wgs data set also benefited to the same degree as the exome capture data sets for heterozygous sites , but not for homozygous sites , perhaps because the 1kg-wgs data set comprises two family trios, which would help to resolve heterozygous positions.

the number of variants called from the tcga-wgs data set did not improve greatly with grouped sample calling , though there were a large number of mismatched genotypes between the group calling and the single-sample calling. this was observed in only  <dig> of the samples; the other  <dig> all had ≤  <dig> mismatched genotypes. the tcga-wgs samples had both excellent mean on-target depth and uniformity of coverage, which made them easy to accurately genotype using single-sample variant calling. grouped variant calling would therefore not provide the same boost as with the other data sets.

we also examined rare variants, as defined by absence from hapmap  <dig> , presence in the exome variant server esp <dig>  set at less than  <dig>  minor allele frequency, and minimum genotype quality at least  <dig> in each of the grouped and single sample call sets . the 1kg-wgs, hgu-wxs, tcga-wgs, and tcga-wxs data sets gained a mean of an additional  <dig> %,  <dig> %,  <dig> %, and  <dig> % respectively of these rare variants by grouped calling, while losing only  <dig> %,  <dig> %,  <dig> %, and  <dig> % that were only called in the single sample method. the tcga-wxs data set gained by far the most rare variants by use of the grouped calling, similar to the results for known common hapmap  <dig>  sites.

overall estimated sensitivity
using the depth of coverage distributions for every downsampled and full alignment on the regions targeted by each of the two exome capture kits, and the per-site snp detection sensitivity for each data set, we calculated the overall estimated sensitivity for each of the four data sets. we compared this measure to the mean on-target read depth across the targeted regions and found that the two whole genome data sets performed considerably better than each of the exome data sets . in order to reach an overall estimated 95% sensitivity for heterozygous snps in the targeted regions, the 1kg-wgs samples required at least 18x and the tcga-wgs 14x mean on-target depth. the hgu-wxs samples required 41x mean on-target depth, and the tcga-wxs samples 39x. this effect is almost entirely due to the lack of uniformity in coverage for the exome samples: the difference in per-site sensitivity is relatively slight between the two exome data sets and the tcga-wgs data set , and both of them perform better than the 1kg-wgs data set on that measure.figure  <dig> 
overall estimated sensitivity for targeted regions. calculated from the per-site sensitivity for each data set combined with the depth of coverage distributions for samples across the regions targeted by each of the two exome capture kits. a) hgu-wxs . b) tcga-wxs .



our estimates for wgs required mapped depth are lower than those from bentley et al.   <cit>  and ajay et al.   <cit> , though both were attempting to quantify detection of all or almost all snps rather than to a given percentage as here. it is unsurprising that the harder to sequence variants will require proportionally greater additional numbers of reads to accurately genotype. additionally, we are analysing only coding sequence variants, which are in the least repetitive portion of the human genome. the higher figures reported by the other wgs analyses will be influenced by the different qualities of non-coding sequence, especially repetitive regions. the tcga-wxs and hgu-wxs exome-seq data sets used in this analysis can update the figures provided by clark et al. of 80x mean on-target depth required for 10x mapped read depth in 90% of targeted regions  <cit> : a median of 59x mean on-target depth is needed for the same coverage in both of our more recent exome-seq data sets. the equivalent figure was 18x for the tcga-wgs data set and 20x for the 1kg-wgs data set.

sensitivity at sites in human gene mutation database 
overall estimated sensitivity is a useful measure that can be applied to more specific subsets of target regions. for instance, estimating how many known disease causing or disease associated snv sites can be recovered given a particular sequencing strategy. to demonstrate and at the same time discover if known disease causing mutations are preferentially located in easy or difficult to sequence regions of the genome: we obtained the locations of such coding and splice variants from hgmd  <cit> . from these we generated the coverage distributions for disease-causing and disease-associated snvs separately to compare their overall estimated sensitivity with coding regions in general for both whole genome and exome sequencing. for  <dig>  disease-causing and  <dig>  disease-associated sites, we found no difference in the measure across all four of our sample sets .

characteristics of difficult target regions
as has previously been noted for both whole genome and exome sequencing, regions of high g+c content and regions containing repetitive elements are generally harder to sequence to high depth  <cit> . we define difficult regions based on poor coverage  in at least half the samples from a given data set, and easy regions based on excellent coverage  in all the samples from that set. our samples show the expected characteristics, with the bulk of difficult regions occurring at g+c content above 60% , and with a significantly higher proportion of difficult regions overlapping repetitive elements compared to relatively easy target regions . the hgu-wxs data set also had a large number of difficult target regions that were of low g+c content. because the classification of a region as difficult is based on at least half the samples in a data set, this was not caused by capture failure of one or a few samples; however, a larger scale failure could be implicated. very few target regions were classed as difficult for the tcga-wgs data set for either of the two exome capture target region sets. however, approximately one third of all regions identified as difficult in any of the four data sets were classed that way for both the tcga-wxs and 1kg-wgs data set, and 15% for both the hgu-wxs and the 1kg-wgs data set .

to quantify the contributions of repetitive sequence and nucleotide composition to target difficulty, we identified targets meeting our criteria for difficult  in any of the samples for a data set. the number of samples in which that target was defined as difficult was multiply regressed against target g+c content, presence of annotated repeats and alignability  <cit> . all factors were significant to p< <dig> ; however, their predictive power was slight . the adjusted r-squareds were  <dig> ,  <dig> ,  <dig> , and  <dig>  for 1kg-wgs, hgu-wxs, tcga-wgs, and tcga-wxs respectively. as the analysis was run on the intersection of the target capture regions for the two exome-seq data sets; the particularly low r-squared for the hgu-wxs data set may be due to differences in probe design but is not due to a different set of targets.

cost of sequencing to a given level of sensitivity
we compared exome and whole genome sequencing costs on current standard technology  with an exome capture kit of the same size as the nimblegen seqcap ez exome v <dig>  used for the hgu-wxs samples, assuming 60% of exome reads on target  and holding the per sample cost of the exome capture kit constant. to achieve 93–94% overall estimated heterozygous sensitivity in the coding regions of the genome, exome sequencing is  <dig> x cheaper than whole genome sequencing . likewise, for 98–99% sensitivity, exome sequencing is  <dig> x cheaper .table  <dig> 
cost of sequencing to achieve a given level of heterozygous snv detection sensitivity


all costs have been normalised against the cheapest exome sequencing . estimated costs include library preparation, exome capture and multiplexing where applicable, and paired-end sequencing on illumina hiseq.



we estimate that the cost per lane of sequence would have to be 15–20% of the current cost for the two methods to reach cost parity, holding the cost of exome capture constant . the projected $ <dig> genome at 30x depth enabled by the illumina hiseq x ten  system reaches this cost point for 93–94% overall estimated heterozygous sensitivity in the coding regions of the genome. holding the per sample exome kit cost constant, the x <dig> system claims to sequence genomes to 12x depth at 77% the cost of sequencing exomes to 29x depth, with roughly equivalent sensitivity. however, for higher sensitivity of 98–99%, we estimate that wgs on the x <dig> system will still be 31% more expensive than exome-seq, and decreases in exome capture kit costs will likely keep the two methods at close to cost parity.

CONCLUSIONS
exome-seq target capture technology is clearly improving. our previous results from a solution-based target capture kit suggested a mean on-target depth of 46x was needed to obtain 95% overall estimated sensitivity for heterozygous snps  <cit> . the two data sets in this analysis from more recent capture kits  show 40x is required for the same level of sensitivity. this progressive improvement in technology could partially explain the difference between our results and the higher mean on-target depth of 80x suggested by other previous analyses such as clark et al.
 <cit> .

the mean on-target depth needed for 95% snp detection sensitivity shown by our analysis of wgs data from multiple sources is also lower than previous estimates  <cit> . the earlier of these two estimates describes reads from the first next-generation sequencing experiments, which were shorter than the reads used for our wgs samples, and additionally contained no paired-end reads. the second estimate is more comparable in terms of data, and we conclude that improvement in variant calling algorithms is likely to be a factor in the difference here.

uniformity of coverage is clearly still a major issue for exome sequencing in terms of capturing a reasonable number of reads across all of the targeted regions. pcr amplification-free library preparation can mitigate the issue somewhat for wgs samples  <cit>  but it is still required to provide a sufficiently large library for exome-seq samples. allele distribution biases introduced by the reference bias of exome-seq target probes could be minimised by the use of alternate probes containing common haplotypes, but the problem will remain for rare variants. the additional allele distribution bias introduced by treating the reference genome as truth during computational analysis affects both wgs and again exome-seq and is not easily fixed for rare variants.

the amount of raw sequencing is the main cost driver for both wgs and exome-seq, and the drop in cost to the $ <dig> human genome at 30x depth has brought the two methods roughly into parity. however, smaller sequencing centres relying on the previous generation of machines will continue to charge three to four times exome-seq costs for the same level of snp detection sensitivity across coding regions using wgs. when taking into account the considerably higher data storage requirements of wgs and the extra compute time required to perform alignment and subsequent bioinformatic analyses on wgs samples, the cost difference will be further amplified.

wgs provides a much richer data set, capturing information on polymorphisms over whole genome and potentially capturing genomic rearrangements. the dramatically improved uniformity of read coverage and reduced bias of allele ratios in wgs, both lend themselves to improved detection of copy number changes and measurement of sample heterogeneity. these are likely to be extremely useful measures in some settings, such as for the sequencing of primary tumours whose analysis, even when focused on the exome, is confounded by copy number change, sample heterogeneity and a desire to detect de novo mutations.

