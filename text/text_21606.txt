BACKGROUND
liquid chromatography-mass spectrometry/tandem mass spectrometry  is a powerful tool for protein identification and quantification  <cit> . one important task in lc-ms/ms processing is the identification of corresponding features  in multiple datasets, which is critical for the integration of quantification information to reduce measurement variation  <cit> .

before other discussions, we first introduce some definitions that are used throughout the paper. a feature is the two dimensional  signal registered by a single charge variant of a peptide. when we consider extracted-ion-chromatograms , a feature is represented by its lc elution peak in an lc-ms/ms run. if a peptide is picked up by tandem ms, then its lc elution peak can be located exactly in lc-ms. we refer to such lc peaks as "features with identity". if a peptide is not picked up by tandem ms, then its elution peak location would be unknown, and its lc peak is called "a feature with unknown identity".

if several datasets are collected in an experiment, then each dataset has an associated list of tandem ms identified peptides. we simply refer to the peptides associated with a dataset q <dig>  for example, as q <dig> peptides. the union of all peptides from all datasets is noted as the "union peptide set". when corresponding features of a peptide is found in all datasets, we say that the peptide is "completely identified for quantification", or simply "completely identified/quantified" in different context.

current alignment approaches focus on correcting the mean of elution time shifts between datasets using warping functions. warping function based methods can be categorized as profile- or feature-based. profile-based approaches align total-ion-chromatograms  or higher-resolution profiles based on the full, unprocessed data obtained in lc-ms experiments. the most basic profile-based methods compare the difference in the tics  <cit> . a method called correlation optimized warping  was proposed by nielsen  <cit> . bylund proposed many modifications to cow  <cit> . parametric time warping  was proposed by eilers  <cit> . van showed an extension of ptw called semi-parametric time warping   <cit> . prince generated the warping function based on dynamic time warping with a one-to-one  smooth warp-function called obi-warp  <cit> .

feature-based approaches focus on either aligning chromatogram peaks, aligning features or significant features in images  <cit> . in an initial feature detection step, these approaches try to distinguish relevant features of peptides and irrelevant noise in the data. among these methods, a very sophisticated algorithm called lcmswarp has been published by jaitly  <cit> . another paper  <cit>  compared six freely available alignment algorithms, and found that openms  <cit>  performs the best on both proteomics and metabolomics data. most recently, voss  <cit>  proposed a method which combines hierarchical pairwise correspondence estimation with simultaneous alignment and global retention time correction. voss's paper focuses on the alignment of multiple datasets at the same time. however, the performance is slightly worse than that of openms on proteomics data.

in lc-ms/ms, shorter elution time, which leads to crowded xics, is often desirable for increasing the throughput because it cuts down experimental time  <cit> . in such cases, there could be multiple elution peaks within a narrow elution time window after warping function correction, and it is ambiguous which peaks are corresponding. we have observed in some cases that the nearest lc peak to the warped time point is not the real corresponding one, and warping function based methods have a limitation in improving alignment accuracy. in addition, some popular alignment algorithms, such as openms  <cit>  or msinspect  <cit> , are designed to work in a procedure that results in low quantification coverage  <cit> , which can be summarized as the following:  <dig>  perform lc-ms peak identification in each dataset;  <dig>  perform alignment and corresponding feature identification;  <dig>  perform tandem ms peptide identification; and  <dig>  link tandem ms identified peptides to aligned corresponding features. generally, only a small overlap exists between them, and only a small portion of identified peptides can be completely quantified. maxquant  <cit>  improves quantification coverage greatly by performing an extra step that looks for the lc elution peaks of identified peptides in lc/ms. in this way, almost all identified peptides can be quantified at least once. but still, complete quantification coverage is limited to the intersection of tandem ms identified peptides, which is expected to be small since tandem ms picks up peptides randomly. this situation is shown in figure  <dig> 

given a small intersection between peptide lists, we know that the union of the lists must be significantly larger. if most peptides in the union set can be completely identified in all datasets, then complete quantification coverage can be improved significantly. to this goal, given a list of q <dig> peptides with identity, we consider the problem of finding their corresponding features in dataset q <dig>  this problem is illustrated in figure  <dig>  once this problem is solved, complete identification is possible for every peptide in the union set, which has identity in at least one dataset that can be treated as q <dig>  and any remaining dataset can be treated as q <dig> 

to address the proposed problem, we develop a statistical corresponding feature identification algorithm  which identifies corresponding features not only based on matching elution times but also elution peak shapes. we build statistical models which can be used to evaluate the probability of candidate feature pairs as corresponding ones. the identification of corresponding features can be applied to various lc-ms datasets under different experimental conditions without user supplied information. testing results show that scfia improves accuracy and complete quantification coverage significantly.

the proposed algorithm is designed for instruments with high mass resolution which have very few overlapping lc elution peaks within xics. for example, with a mass resolution of  <dig>  000fwhm on a orbitrap instrument, there are very few overlapping elution peaks using a mass window of  <dig> parts-per-million  for extracting xics, and the proposed algorithm can be applied. such a resolution and mass accuracy is routinely available nowadays.

datasets
we test and develop scfia based on freely available datasets, which can be downloaded from https://proteomecommons.org/dataset.jsp?i= <dig>  group <dig> datasets are

 <dig>  20090608_orbi6_tage_sa_tumor_5mix1_ <dig> raw 

 <dig>  20090608_orbi6_tage_sa_tumor_5mix1_ <dig> raw 

 <dig>  20090608_orbi6_tage_sa_tumor_5mix1_ <dig> raw 

group <dig> datasets are:

 <dig>  200090815_velos5_tage_sa_silacmix_top15_ <dig> raw

 <dig>  200090815_velos5_tage_sa_silacmix_top15_ <dig> raw

 <dig>  200090815_velos5_tage_sa_silacmix_top15_ <dig> raw

group <dig> represents data from three fractions of breast cancer tissue together with a super-silac mix collected on an orbitrap instrument. group <dig> represents three technical replicates without prior separation collected on a new generation ltq-orbitrap velos instrument. these two groups are representative of real biological datasets collected on different instruments, each of which contains hundreds of thousands of isotopically labeled peptides in appropriate amounts. for more information about super-silac data, please check the original paper  <cit> . we observe that

 <dig>  the warping function is non-linear; and

 <dig>  the elution peaks are crowded.

comparing to the simple protein mix datasets in  <cit> , where lc elution peaks are sparse, the super-silac datasets are more complex in protein composition, which lead to crowded xics because many peptides with similar masses are eluted out within a short period of time. if we only correct the mean of time shifts between corresponding features, many peaks will be wrongly matched because there are lc peaks in the close vicinity of the true corresponding ones.

methods
tandem peptide identification
we use x!tandem  <cit>  in trans-proteomic pipeline   <cit>  and maxquant for tandem ms identification. in both tpp and x!tandem, we select the international protein index-human database version  <dig>  as the source of protein sequences. in the tpp, x!tandem with kscore is applied as the search engine. parent mass and fragment ions are searched with maximal mass errors of 7ppm and  <dig>  dalton respectively. methionine oxidation and n-terminal acetylation are considered as variable modifications and cysteine carbamidomethylation is selected as the fixed modification. silac labeling is also considered as a variable modification. in the analysis, the minimum length of peptides is set to  <dig>  and the maximum number of missed cleavage sites is set to  <dig>  finally peptideprophet  <cit>  of tpp is used to validate the search results, and peptides are annotated with peptideprophet true positive probabilities . maxquant  is used with the same settings as that of the x!tandem, except that the validation step is done by the decoy method. the ipi human database is decoyed by andromeda  <cit> , and the false discovery rate is set to  <dig> .

ground truth list generation
to test scfia and train statistical models, we will need a ground truth list that contains peptide identification and elution time information in both q <dig> and q <dig>  the ground truth list shall contain truly existing peptides through reliable identification. however, it is impossible to get a "pure" ground truth list. tandem ms spectra are affected by interfering ions and thermal noise. there are some falsely identified ones in the reported peptide list. we can apply different peptideprophet probability thresholds to control the false positive rate of the ground truth list. with these considerations in mind, we select the ground truth list in the following procedure:

 <dig>  in each dataset, select one retention time for each unique peptide identification. sometimes, we find that a unique peptide is identified multiple times. in such cases, we pick the identification with the highest peptideprophet probability.

 <dig>  we filter peptides by applying a peptideprophet probability threshold.

 <dig>  we select peptides that are identified in both q <dig> and q <dig> to form the ground truth list with information of retention_time_sec, m/z value, and peptide sequence.

the ground truth list is further divided to a training and a testing set. the training set is used for statistical model training and the testing set is used for performance evaluation. since features with higher intensities are less corrupted by noise, features with top 20% intensities are selected to form the training set. in q <dig> and q <dig> datasets from group <dig>  the training set contains  <dig> peptides, and the testing set contains  <dig> peptides, which are annotated with their retention times in both q <dig> and q <dig> 

note that a pair of non-corresponding features can be obtained by replacing one of the features in a corresponding pair with a random feature from the same xic of the replaced one. in this way, we can construct a non-corresponding feature training set.

note that the higher the peptideprophet probability threshold is, the purer the ground truth list. the threshold will affect the calculated accuracy in corresponding feature identification. for example, at a threshold of 95%, at least around 5% of the testing peptides are false positives, which cannot be matched to their lc peak intervals recorded in the ground truth. consequently, the calculated corresponding feature identification accuracy can not exceed 95% significantly.

in contrast to the ground truth list selection process in  <cit> , we do not filter features based on retention time to avoid introducing bias to the training set. the "pureness" of the ground truth list is controlled by the threshold on peptideprophet probability. the threshold can be raised to reduce the number of outliers.

performance evaluation based on the testing set
before we describe the algorithm, we want to clarify the performance evaluation method used in this paper. after we get the testing set, we pretend that we know the identities of the testing peptides in q <dig>  but not in q <dig>  we then apply scfia. if an identified corresponding feature has an elution time that differs from what has been recorded in the ground truth of q <dig>  then an error is registered. finally, we calculate accuracy as the ratio between the total number of correctly identified corresponding pairs over the total number of peptides in the testing set. note that this accuracy measurement is equivalent to the precision rate in  <cit>  when considering pair-wise alignment.

in scfia, we first use the training set to construct the statistical models. we then evaluate the performance based on the testing set. finally, we compare the performance scfia to that of openms , and a warping function based method .

statistical corresponding feature identification algorithm 
scfia aims at evaluating the probability that a given pair of peptide features are corresponding. the algorithm has four processing steps:  <dig> ) pre-processing aims at identifying a set of initial lc elution peaks as corresponding feature candidates;  <dig> ) mean time shift correction between q <dig> and q <dig>  this is achieved by estimating a warping function based on the training set; 3). training of statistical models for corresponding feature identification; and 4). evaluating the likelihood probability of all candidate corresponding features in q <dig> given an lc peak in q <dig>  the candidate with the highest likelihood probability will be selected as the corresponding feature. the flow diagram of scfia is shown in figure  <dig>  the details of the algorithm is as the following:

step 1: pre-processing of lc/ms data
preprocessing aims at finding lc elution peaks of q <dig> peptides with known identity, and finding their corresponding feature candidates in q <dig> where their elution intervals are unknown. the following processing steps are performed.

 <dig>  to identify possible lc peak intervals for a given peptide in both q <dig> and q <dig>  we first calculate its xics at its mono- and first isotope m/z values in the charge state that it has been identified in tandem ms.

 <dig>  we use the xic at the higher isotope position to detect up to n high intensity regions by applying a threshold at three times the background noise standard deviation above the median noise level. only one interval corresponds to the elution interval of the peptide. in q <dig>  the exact interval is known by selecting the interval that includes the retention_time_sec recorded in the ground truth.

 <dig>  in q <dig>  we employ the same process as that in q <dig>  however, without identification information, the exact elution interval is unknown, and we treat all detected intervals as corresponding feature candidates, which should include the true corresponding one.

given an identified lc peak interval in q <dig>  there are the n candidates in q <dig>  which form n candidate corresponding feature pairs.

step 2: mean elution time shift correction
the mean time shifts between corresponding features can be corrected using a warping function. in the past, numerous algorithms have been developed for finding warping functions  <cit> . however, these algorithms seldom use elution time information reported by tandem ms for estimating the warping function except those in jaitly  <cit>  and palmblad  <cit> . however, nowadays, with much higher coverage in tandem ms, a list of true elution time shifts is almost always available. in our study, the training ground truth list is annotated with elution time values in both q <dig> and q <dig>  and we can simply use the matlab function polyfit to estimate the warping function by regressing the elution time points in q <dig> to those in q <dig>  this generates a very good estimation of the mean of time shifts as shown in figure  <dig>  note that this simple warping function can be non-linear, and it is referred as the ground-truth based warping  function. the gwarping function differs little if we use more than  <dig> time points.

to evaluate the performance of gwarping, we first use the gwarping function for mean time shift correction, then we assign the nearest features in q <dig> as corresponding ones. we find that the alignment performance of gwarping exceeds that of openms, which is considered as the best in  <cit> . this suggests that warping based on tandem ms identification is reliable. due to this reason, we use gwarping as a representative warping function based method to compare with scfia.

step 3: scfia models
in the third step, we build statistical models of corresponding features.

parameters considered in the model
after pre-processing both q <dig> and q <dig>  we obtain a training set of corresponding features, based on which, we can train our statistical models. the parameters considered are elution time shift and lc peak shape correlation between corresponding features. these two parameters are independent. elution time shift is mainly affected by varying experimental conditions, and lc peak shape depends on the physicochemical characteristics of a peptide.

elution time shift has been used as the most important parameter for lc peak alignment traditionally. in scfia, the time shift is assumed to have a gaussian distribution  <cit>  after mean correction, whose parameters can be estimated from the training set.

lc peak shape of peptides is another important parameter. under similar experimental conditions, identical peptides form similar lc peaks, while different peptides form different lc peak shapes. similarity between two lc peaks can be measured by the r <dig> statistics, which indicates how well a regression line approximates the observed data points. an r <dig> of  <dig>  means that the regression line perfectly fits the data, while  <dig> means the poorest fit. for details please see  <cit> . when we regress an lc peak in q <dig> to one in q <dig>  the resulted r <dig> statistic is noted as the alignment r <dig> statistics. ars can be calculated using the matlab function regress.

two statistical models can be built for these two parameters. suppose that at is the elution time shift between two peptide peaks, we can write

  p=pp, 

where p represents the probability that the considered feature pair with time shift at and peak shape correlation ar is corresponding. both p and p are given by the statistical models we constructed from the training set. our goal is to find the corresponding feature pair that maximizes the likelihood probability function in .

elution time shift model
in figure  <dig>  we plot the warping function estimated from elution time shifts of corresponding features from the training set of q <dig> and q <dig> from group <dig>  after applying the warping function, we calculate the remaining time shifts between corresponding features.

in the past, the time shifts are assumed as gaussian  <cit> , and we can write p ~ n, where μ represents the mean and σ <dig> the variance. we estimate  from the remaining time shifts between corresponding features using the matlab function normfit.

we plot the histogram of at  together with its estimated statistical model for corresponding features in figure  <dig>  we also plot the normalized histogram and the fitted model of non-corresponding features in figure  <dig>  in figure  <dig>  we plot the two statistical models together, and we can see that there is a big difference in the distribution of at, which allows us to differentiate corresponding and non-corresponding features. the fitted model of at between corresponding features is then substituted as p in .

ar statistic model
to find a suitable model for ar, we plot the normalized histogram of ar between corresponding features in the training set of q <dig> and q <dig> from group <dig>  in figure  <dig>  we can see that most ar values are around  <dig>  between corresponding features. let x =  <dig> - ar, and we model × as a random variable that follows the gamma distribution, x ~ gamma. we can write

  f=xk-1expθkΓ, 

where k and θ are parameters of the gamma distribution, which can be estimated using the matlab function gamfit. in figure  <dig>  we plot the fitted gamma distribution with the normalized histogram of ar for corresponding features. the normalized histogram and fitted model of ar for non-corresponding features are plotted in figure  <dig>  in figure  <dig>  we compare the difference in fitted distributions of ar between corresponding and non-corresponding features. we can see a notable difference in this example. note that group <dig> is composed of datasets from different peptide fractions, thus there exist significant concentration variations which do not lead to significant deterioration of peak shape correlations between corresponding features. this indicates that ar is a valuable parameter for corresponding feature detection. the fitted gamma distribution is then used as p in .

step 4: estimate probabilities of candidate corresponding feature pairs
in the fourth step, between any pair of candidate features, we first calculate its at and ar, which are plugged in  subsequently. the candidate pair with the highest likelihood probability will be reported as the corresponding one.

based on fitted distributions of at and ar for corresponding and non-corresponding features, we can plot their receiver operating characteristic  curves. in figure  <dig>  we plot the roc curves of at, ar, and the combined probability score as calculated in . we can see that the combined probability score is expected to give the best performance when the false positive rate is below 8%. this predicts that using both at and ar will provide performance gain.

RESULTS
accuracy in corresponding feature detection
to compare the performance of scfia with other methods, we use the testing ground truth list of q <dig> and q <dig> from group <dig>  we apply various algorithms for corresponding feature identification. when applying scfia, we use a peptideprophet probability threshold of 95% and a 10ppm mass window for calculating the xics. this mass window is selected based on the mass accuracy of the instrument, which should be adjusted for different instruments.

comparison with openms
openms is evaluated to have the best performance in  <cit> . the details of the simulation process of openms can be found in the . we set rt to two possible values,  <dig> and  <dig>  while mz is set as  <dig> . we try different settings to ensure the best result. openms achieves a  <dig> % and  <dig> % accuracy under two different settings which have little difference.

comparison with gwarping
to estimate the improvement of scfia over warping function based methods, we want to compare the performance of scfia to gwarping. after applying the gwarping function, the elution time of each peptide in q <dig> is mapped to q <dig>  then the lc peak which is the closest to the mapped time point is considered as the detected corresponding feature in q <dig>  by employing this simple method, the accuracy is  <dig> %, which is higher than that of openms. this result is not surprising because openms does not consider non-linear warping functions. there are a total of  <dig> peptides that are not aligned correctly out of  <dig> testing peptides. we inspect manually and find that these peptides have interfering lc peaks that are closer to the mapped time points than the true corresponding ones in q <dig>  the proportion of such peptides strongly depends on experimental settings. if shorter elution time is desired, then more peptides will have close neighbors, and warping function based methods will be less effective in finding corresponding features.

performance of scfia
in scfia, we detect corresponding features not only based on at but also on ar. the result of our algorithm is summarized in table  <dig>  scfia achieves the highest accuracy of  <dig> % among the three algorithms tested. out of  <dig> peptides that gwarping can not align,  <dig> are correctly aligned by scfia. in , we show an example of a peptide which is not aligned correctly by gwarping, but aligned correctly by scfia. in that example, there is a nearly  <dig> fold difference in lc peak height, yet the peak shape correlation is still high. this indicates that peak shape correlation stands up pretty well even when there are significant concentration variations.

we manually inspect the  <dig> peptides that are not aligned by scfia. we find that for these  <dig> peptides, their corresponding features specified by the ground truth do not agree in elution time and peak shape as well as interfering ones. we show an example in . we suspect that these peptides are false positives in tandem ms identification. if this assumption is true, we should be able to observe an increased accuracy rate as we raised the threshold on peptideprophet probability.

we test this hypothesis by increasing the peptideprophet probability threshold, and the results are summarized in table  <dig>  we can see that corresponding feature identification accuracy closely follows the threshold. this suggests that scfia can match nearly every true positives in the "ground truth" list, and its performance is near optimal.

we have also tested the accuracy of scfia between the remaining data pairs in group <dig> and group <dig>  the results are also summarized in table  <dig>  group <dig> is composed of lc/ms datasets from different fractions where the variations in concentration and elution time are larger than that between replicates in group <dig>  in table  <dig>  we can see that scfia consistently provides performance gain by using the combined probability score in group <dig>  in contrast, for group <dig>  the performance of using at alone is already very close to the optimal, and using the combined probability score provides a small gain in two out of the three cases. this phenomenon can be attributed to the smaller elution time variations between technical replicates. this shows that scfia is more effective in corresponding feature identification when there are high elution time and concentration variations.

complete quantification coverage
scfia is designed for the complete quantification of the union peptide set. we first investigate group <dig> datasets  from three fractions. after pre-processing of tandem ms scans using x!tandem and tpp, we obtain a list of tandem ms identified peptides. then we combine peptides with identical identifications, and filter out peptides with peptideprophet probability less than  <dig> . in figure  <dig>  we illustrate the venn-diagram of the sizes of tandem ms identified peptide lists. we can see that the overlap between any two fractions is quite small, and the size of the union  is significantly larger than that of the intersection .

we employ the following procedure for the complete identification of all peptides in the union set. we first select q <dig> peptides, and find their corresponding features in q <dig> if their identities are unknown. then the same procedure is repeated from q <dig> to q <dig>  subsequently, we focus on q <dig> peptides, and we find all corresponding features in q <dig> and q <dig> if their identities are not known yet. lastly, we focus on q <dig> peptides. this procedure is repeated for all peptides in all datasets with unknown identities until complete identification. using this procedure, a total of  <dig>  peptides are completely identified in all three datasets,  <dig> are identified in at least two datasets.

we then investigate group <dig> datasets  from three technical replicates. the peptideprophet probability threshold we choose is still  <dig> . in figure  <dig>  we show that the union has  <dig> peptides, and the intersection has  <dig>  for testing purposes, peptides detected in different charge states and different datasets are removed from the list, which leaves  <dig> peptides without complete identifications. using scfia, a total of  <dig>  peptides are completely identified in all three datasets, and  <dig> are identified in at least two datasets. since group <dig> datasets are from replicates, a higher complete identification rate is expected than that of group <dig> 

with complete identification, these peptides can be quantified completely. since peptide quantification is a lengthy topic, we leave it out of this paper.

comparison with maxquant
maxquant  <cit>  is a popular tool that provides both tandem ms identification and quantification. we want to compare the peak identification coverage of scfia with that of maxquant. to this end, we employ maxquant  to process super-silac datasets q <dig>  q <dig>  and q <dig> in group <dig> and group <dig>  the size of peptide identification results is summarized in the venn-diagram in figure  <dig>  we can see that the union set of group <dig> contains a total of  <dig> peptides, and the intersection between them is  <dig>  thus based on tandem ms identification information, only  <dig> peptides can be completely quantified in all three datasets. in contrast, after applying scfia, a total of  <dig> peptides are identified in all three datasets in the first group.

the same process is repeated in group <dig>  and the results are reported in in figure  <dig>  significant advantage of scfia is reported again.

the results on elution peak identification coverage using maxquant and x!tandem are summarized in table  <dig>  these results show that under different tandem ms search engines and different sample compositions, the intersection set is always pretty small comparing to the union set. scfia is very effective in improving complete identification coverage, based on which, accurate quantification can be performed for nearly all identified peptides.

q <dig> ∪ q <dig> ∪ q3-
q <dig> ∩ q <dig> ∩ q3
peptides analyzed
discussion
through testing, we can see that scfia can be applied in the alignment of both technical replicates and datasets collected from different lc/ms runs.

the accuracy results based on group <dig> and group <dig> data suggest that scfia is more effective when there are high elution time and concentration variations. in such cases, using peak shape correlation improves the performance. however, the improvement changes with experimental conditions. when elution time variation is small, and there exists long gaps between elution peaks, then alignment based on elution time is sufficient. however, when elution time variation is large, and gaps between lc peaks are small, peak shape correlation becomes useful in performance improvement. users can always decide if using peak shape correlation will provide performance gain by inspecting the roc curves estimated by scfia. in experiments where peak shape reproducibility is not strong, or when the xics are not crowded, then it may be sufficient or necessary to use at alone.

scfia requires a number of "common" identifications for training the statistical models. generally the more common identifications the better. preferably, there are around  <dig> common identifications. we observe no obvious difference in performance in our experiments when the size of the training set increases beyond this number.

CONCLUSIONS
in this paper, we propose a new statistical corresponding feature identification algorithm  for the identification of corresponding features in different lc-ms/ms datasets. the main innovation of the algorithm is the use of statistical models for both elution time shifts and peak shape correlations, which provides maximum likelihood estimates of corresponding features. the algorithm allows accurate corresponding feature identification with crowded elution profiles. we verify the algorithm on two groups of super-silac datasets, and the performance is shown to be better than warping function based methods including openms. scfia is shown to have very high accuracy in corresponding feature identification and the performance is near optimal.

scfia can be utilized for the complete identification of elution peak intervals of tandem ms identified peptides in multiple datasets. we have verified that scfia provides high coverage in complete identification which will lead to more accurate quantification in differential analysis for biomarker discovery.

availability and requirements
project name: scfia project; operating system: windows xp/vista/7; programming language: matlab; licence: gnu gpl; any restrictions to use by non-academics: licence needed. the related material including the testing dataset can be found at the project webpage http://compgenomics.utsa.edu/scfia.html.

authors' contributions
jc developed and tested the algorithm, wrote the paper. xm and lc provided assistance in data interpretation. jz conceived the idea, advised on the development of the algorithm and revised the paper. all authors have read and approved the final manuscript.

supplementary material
additional file 1
supplementary information. in this file we provide supplementary information.

click here for file

 acknowledgements
this work is supported by san antonio life sciences institute research enhancement, and a grant from national institute of health . we thank the computational biology initiative  for providing access and training to the analysis software used.
