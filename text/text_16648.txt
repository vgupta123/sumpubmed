BACKGROUND
accurate prediction of the regular elements of protein 3d structure is important for precise prediction of the whole 3d structure. a protein secondary structure prediction algorithm assigns to each amino acid a structural state from a 3-letter alphabet {h, e, l} representing the α-helix, β-strand and loop, respectively. prediction of function via sequence similarity search for new proteins  should be facilitated by a more accurate prediction of secondary structure since structure is more conserved than sequence.

algorithms of protein secondary structure prediction frequently employ neural networks  <cit> , support vector machines  <cit>  and hidden markov models  <cit> . parameters of the algorithm have to be defined by machine learning, therefore algorithm development and assessment usually contains four steps. the first one is a statistical analysis to identify the most informative correlations and patterns. the second one is the creation of a model that represents dependencies between structure and sequence elements. in the third step, the model parameters are derived from a training set. finally, in the fourth step, the algorithm prediction accuracy is assessed on test samples  with known structure.

there are two types of protein secondary structure prediction algorithms. a single-sequence algorithm does not use information about other  proteins. the algorithm should be suitable for a sequence with no similarity to any other protein sequence. algorithms of another type are explicitly using sequences of homologous proteins, which often have similar structures. the prediction accuracy of such an algorithm should be higher than one of a single-sequence algorithm due to incorporation of additional evolutionary information from multiple alignments  <cit> .

the estimated theoretical limit of the accuracy of secondary structure assignment from experimentally determined 3d structure is 88%  <cit> . the accuracy  of the best current single-sequence prediction methods is below 70%  <cit> .  bspss  <cit> , simpa  <cit> , sopm  <cit> , and gor v  <cit>  are examples of single-sequence prediction algorithms. among the current best methods that use evolutionary information , one can mention psipred  <cit> , porter  <cit> , sspro  <cit> , apssp <dig>  <cit> , svmpsi  <cit> , phdpsi  <cit> , jpred <dig>  <cit>  and prof  <cit> . for instance, the prediction accuracy of porter was shown to be as high as  <dig> %  <cit> . the joint utilization of methods that specialize on single-sequence prediction and methods using homology information will definitely improve the prediction performance.

single-sequence algorithms for protein secondary structure prediction are important because a significant percentage of the proteins identified in genome sequencing projects have no detectable sequence similarity to any known protein  <cit> . particularly in sequenced prokaryotic genomes, about a third of the protein coding genes are annotated as encoding hypothetical proteins lacking similarity to any protein with a known function  <cit> . also, out of the  <dig>  genes believed to be present in the human genome, no more than 40–60% can be assigned a functional role based on similarity to known proteins  <cit> . for a larger picture, the pfam database allows one to get information on the distribution of proteins with known functional domains in three domains of life .

from the structure prediction standpoint, it is important that two or more hypothetical proteins may bear similarity with each other, in which case it still would be possible to incorporate evolutionary information in a structure prediction algorithm. however, many hypothetical proteins would not have detectable similarity to any protein at all. such "orphan" proteins may represent a sizeable portion of a proteome, as it is shown in table  <dig> representing three newly sequenced genomes.

for an orphan protein, any method of secondary structure prediction performs as a single-sequence method. developing better methods of protein secondary structure prediction from single-sequence has a definite merit as it helps improving the functional annotation of orphan proteins. in this work, we describe a new algorithm for protein secondary structure prediction, which develops further the model suggested by schmidler et al.  <cit> . we consider the protein secondary structure prediction as a problem of maximization of a posteriori probability of a structure, given primary sequence, as defined by a hidden semi-markov model . to determine the architecture of this hsmm, we performed a statistical analysis identifying the most informative correlations between sequence and structure variables. we specifically considered correlations at proximal positions of structural segments and dependencies to upstream and downstream residues. finally, we proceeded with an iterative estimation of the hsmm parameters.

RESULTS
we first compared the performances of bspss  <cit>  and ipssp in strict jacknife conditions. in our computations, we used the eva set of "sequence-unique" proteins derived from the pdb database . we removed sequences shorter than  <dig> amino acids and arrived to a set of  <dig> proteins. the performances of ipssp and bspss were evaluated by a leave-one-out cross validation experiment  on this reduced set.

then we evaluated and compared the performances of bspss, ipssp and psipred on the set of  <dig> casp <dig> targets  that are available in the pdb. this evaluation is at the "single-sequence condition" implying no additional evolutionary information is available. we used the software "psipred_single", version  <dig> , which uses a set of fixed weight matrices in the neural network and does not employ psi-blast profiles. this program was downloaded from the psipred server  <cit>  with the available training data . we used the same training set to estimate the parameters of bspss and ipssp.

to reduce eight secondary structure states used in the dssp notation to three, it is possible to use different conversion rules. here we considered the following three rules:  h, g and i to h; e, b to e; all other states to l,  h, g to h; e, b to e; all other states to l,  h to h; e to e; all other states to l. the first rule is also known as the 'ehl' mapping  <cit> , the second rule is the one used in psipred  <cit>  and earlier outlined by rost and sander  <cit> , while, finally, the third rule is the common 'ck' mapping, which is the one used in bspss and other methods  <cit> . we also analyzed the effect of making further adjustments after applying either of the three conversion rules. we used the adjustments proposed by frishman and argos  <cit>  that lead to a secondary structure sequence with the minimum β-strand length of  <dig> and the minimum α-helix length of  <dig>  in our simulations, we used d =  <dig> for the maximum allowed segment length. this value is sufficiently large to cover almost all observed uniform secondary structure segments . for the ipssp method, we performed  <dig> iterations and used a percentage threshold value of 35% in the dataset reduction step .

performance measures
we have compared the performances of the methods in terms of four measures: the sensitivity, specificity, matthew's correlation coefficient and segment overlap score. we use the three-state-per-residue accuracy , defined in eq.  <dig> as the overall sensitivity measure:

q3=ncn× <dig>      
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwgrbqudawgaawcbagaeg4mamdabeaakmaabmaabagaeiyjaucacagloagaayzkaagaeyypa0zaasaaaeaacqwgobgtdawgaawcbagaem4yamgabeaaaoqaaiabd6eaobaacqghxdatcqaixaqmcqaiwaamcqaiwaamcqgguaglcawljagaaczcamaabmaabagaegymaedacagloagaayzkaaaaaa@3fc5@

here, nc is the total number of residues with correctly predicted secondary structure, n is the total number of observed amino acids. the same measure can be used for each type of secondary structure, qα, qβ and ql :

qi=ncini× <dig>      
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwgrbqudawgaawcbagaemyaakgabeaakmaabmaabagaeiyjaucacagloagaayzkaagaeyypa0zaasaaaeaacqwgobgtdaqhaawcbagaem4yamgabagaemyaakgaaagcbagaemota40aawbaasqabeaacqwgpbqaaaaaaogaey41aqraegymaejaegimaajaegimaajaeiilawiaaczcaiaaxmaadaqadaqaaiabikdayagaayjkaiaawmcaaaaa@4318@

where nci
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwgobgtdaqhaawcbagaem4yamgabagaemyaakgaaaaa@30a8@ is the total number of residues with correctly predicted secondary structure of type i, and ni is the total number of amino acids observed in conformation of type i. the distribution of ipssp predictions evaluated on the eva set with respect to the sensitivity measure is shown in fig.  <dig> 

we first compared the performances of bspss and ipssp on the eva set. from the results shown in table  <dig>  there is a  <dig> % increase in the overall 3-state prediction accuracy in comparison with bspss, when the third conversion rule was used with the length adjustments.

the prediction accuracy of the structural conformation of the residues situated close to structural segment borders  is measured by sensitivity values computed as overall q3_sb as well as structure type specific qα_sb, qβ_sb, ql_sb. we observed that, the accuracy of ipssp is better than bspss in proximal positions by  <dig> % .

the specificity measure spi is defined for individual types of secondary structure as follows:

spi=ncinpi,     
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwgtbwucqwgqbaudawgaawcbagaemyaakgabeaakmaabmaabagaeiyjaucacagloagaayzkaagaeyypa0zaasaaaeaacqwgobgtdaqhaawcbagaem4yamgabagaemyaakgaaagcbagaemota40aa0baasqaaiabdchawbqaaiabdmgapbaaaagccqggsaalcawljagaaczcamaabmaabagaeg4mamdacagloagaayzkaaaaaa@40cd@

where npi
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwgobgtdaqhaawcbagaemicaahabagaemyaakgaaaaa@30c2@ is the total number of amino acids predicted to be in conformation of type i. note that, we do not consider the overall specificity measure sp <dig>  since its numeric value is the same as q <dig>  it was observed in table  <dig> that values of spα and spl are higher for ipssp, while spβ value is higher for bspss.

the matthew's correlation coefficient  <cit>  is a single parameter characterizing the extent of a match between the observed and predicted secondary structure. matthew's correlation is defined for each type of secondary structure as follows:

mcc=tp*tn−fp*fn1/2     
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwgnbqtcqwgdbwqcqwgdbwqcqgh9aqpdawcaaqaaiabdsfaujabdcfaqjabcqcaqiabdsfaujabd6eaojabgkhitiabdaeagjabdcfaqjabcqcaqiabdaeagjabd6eaobqaamaadmaabawaaewaaeaacqwgubavcqwgobgtcqghrawkcqwggbgrcqwgobgtaiaawicacaglpaaadaqadaqaaiabdsfaujabd6eaojabgucariabdaeagjabdcfaqbgaayjkaiaawmcaamaabmaabagaemivaqlaemiuaalaey4kasiaemoraykaemota4eacagloagaayzkaawaaewaaeaacqwgubavcqwgqbaucqghrawkcqwggbgrcqwgqbauaiaawicacaglpaaaaiaawufacagldbaadaahaawcbeqaaiabigdaxiabc+caviabikdayaaaaagccawljagaaczcamaabmaabagaeginaqdacagloagaayzkaaaaaa@6180@

for instance, for the α-helix, tp  is the number of α-helix residues that are correctly predicted. tn  is the number of residues observed in β-strands and loops that are not predicted as α-helix. fp  is the number of residues incorrectly predicted in α-helix conformation, and finally fn  is the number of residues observed in α-helices but predicted to be either in β-strands or loops. all the mcc values shown in table  <dig> are higher for ipssp.

in terms of the segment overlap scores, ipssp performs uniformly better than bspss . we also assessed the reliability of predictions  produced by the methods bspss and ipssp . the results lead us to the conclusion that ipssp is better than bspss in terms of the reliability measures.

to investigate the effect of length adjustments, we converted short α-helices and β-strands to loops so that the α-helix and β-strand segments had at least  <dig> and  <dig> residues, respectively  <cit> . we also compared ipssp and bspss using different conversion rules and length adjustments . it is seen that ipssp performs better than bspss for each set of rules.

next, we compared the performances of the three methods bspss, ipssp and, psipred_v <dig>  on  <dig> casp <dig> targets that are available in pdb. from the results shown in table  <dig>  and table  <dig>  ipssp is comparable to psipred and is more accurate than bspss.

improvements over the bspss method
in summary, the differences with the bspss algorithm proposed by schmidler et al.  <cit>  are as follows. we introduced three residue dependency models  incorporating the statistically significant amino acid correlation patterns at structural segment borders. in these models, we allowed dependencies to positions outside the segments to relax the condition of segment independence. another novelty of the models is the dependency to downstream positions, which we believe is necessary due to asymmetric correlation patterns observed uniformly in structural segments. to assess the individual performances of the dependency models, we evaluated ipssp using ℳ
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbamrthrhal1wy0l2yhvtyaehbnfgdovwbhrxajfwnaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabawaaegaeaaakeaaimaacqwfzestaaa@3790@ <dig>  ℳ
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbamrthrhal1wy0l2yhvtyaehbnfgdovwbhrxajfwnaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabawaaegaeaaakeaaimaacqwfzestaaa@3790@ <dig>  ℳ
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbamrthrhal1wy0l2yhvtyaehbnfgdovwbhrxajfwnaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabawaaegaeaaakeaaimaacqwfzestaaa@3790@ <dig>  and ℳ
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbamrthrhal1wy0l2yhvtyaehbnfgdovwbhrxajfwnaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabawaaegaeaaakeaaimaacqwfzestaaa@3790@c, where ℳ
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbamrthrhal1wy0l2yhvtyaehbnfgdovwbhrxajfwnaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabawaaegaeaaakeaaimaacqwfzestaaa@3790@c is the combination of the three models obtained using an averaging filter. the results in table  <dig> show that the combined models improve the overall accuracy by more than 1% when the second conversion rule  is used without length adjustments. note that, all three models use a five letter alphabet for positions with significantly high correlation measures. the performance obtained when all the hydrophobicity groupings are defined using the three letter alphabet is  <dig> % lower .

apart from the more elaborate dependency structure, we introduced an iterative training strategy to refine estimates of model parameters. the individual contributions of the dependency model and the iterative training is given in table  <dig>  in this table, the method pssp refers to the ipssp method without iterative training. to reduce  <dig> states to  <dig>  the second conversion rule is used without length adjustments. under this setting, the dependency model improves the overall sensitivity measure by  <dig> % as compared to the bspss method. the inclusion of the iterative training further improves the results by  <dig> %.

single-sequence vs. sequence-unique condition
we would like to emphasize that throughout the paper, we use the term single-sequence prediction in its strict meaning, i.e. the prediction method does not exploit information about any protein sequence similar to the sequence in question as for a true single-sequence such information does not exist. the "single-sequence" concept should be distinguished from the concept of the "sequence-unique" category. the "sequence-unique" condition requires the absence of significant similarity between proteins in the test and in the training set. however, this condition leaves an opportunity to use the sequence profile information that typically improves the prediction accuracy by several percentage points in comparison with the single-sequence condition, in which such profiles are not available. indeed, methods such as apssp <dig>  <cit>  and svmpsi  <cit>  achieved values around 78% in the "sequence-unique" category of casp  <cit>  and cafasp  <cit>  experiments. similarly, the sspal method  <cit>  was cited  <cit>  to have 71% accuracy in terms of q <dig> again in the "sequence-unique" category. single-sequence condition, as defined, is more stringent. this condition is common for "orphan" proteins, which have no detectable homologs. improvement of structural prediction under the single-sequence condition should contribute to the improvement of function prediction for orphan proteins, which are not easy targets for functional characterization.

CONCLUSIONS
we have shown that new dependency models and training methods bring further improvements to single-sequence protein secondary structure prediction. the results are obtained under cross-validation conditions using a dataset with no pair of sequences having significant sequence similarity. as new sequences are added to the database it is possible to augment the dependency structure and obtain even higher accuracy.

typically protein secondary structure prediction methods suffer from low accuracy in predicting β-strands, in which non-local correlations have a significant role. in this work, we did not specifically address this problem, but showed that improvements are possible when higher order dependency models are used and significant correlations outside the segments are considered. to achieve substantial improvements in the prediction accuracy, it is necessary to develop models that incorporate long-range interactions in β-sheets. the advances in secondary structure prediction should contribute to the improvement of function prediction for orphan proteins inscrutable to current similarity search methods.

