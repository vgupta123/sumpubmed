BACKGROUND
methods for the experimental or theoretical determination of protein structures often output their results as an ensemble. in the case of experimental data like x-ray crystallography data, the ensemble represents both the conformational diversity and the inability to resolve the time and spatial aspects of the experiment, whereas in the case of computational experiments, the ensemble in part represents the uncertainty of interpreting the data <cit> . however, often, there is a requirement for a single consensus structure. one way to generate this 'consensus' or 'representative structure' is to calculate the centroid structure by averaging the cartesian coordinates of the ensemble of superimposed structures.

a series of computational and experimental studies have been performed to rationalize the averaging methodology. zagrovic et al.  <cit>  proposed the "mean-structure hypothesis" which states that the geometry of the collapsed unfolded state of small peptides and proteins in an average sense corresponds to the geometry of the native structure at equilibrium. huang et al <cit>  have shown that finding the "averaged structure" from a set of decoys yield structures that are closer to the native structure than most individual structures. moreover, zagrovic et al <cit>  have shown mathematically that the rmsd between the "averaged structure" and the native structure is more similar than the most individual structures to the native structure. furthermore, it was also argued that finding average distance matrices and using distance based root mean square deviation as a metric may be one way to capture the relevant features of ensembles of structure and compare them with other reference structures.

unlike point based averaging where each member is a point, in averaging of structures, the "averaged model" often has unrealistic local geometry, including unphysical bond lengths and angles. in this regard, several methods have been developed to remove averaging artifacts. due to the process of protein structure prediction, methods to remove averaging artifacts are most commonly developed in this context. the 'regularize' function of refmac  <cit>  can be used to regularize the bonds and angles. furthermore, betancourt and skolnick  <cit>  developed a clustering approach, called scar, that uses a harmonic potential to refine centroid structures. however, structure prediction results indicate that spicker  <cit>  outperforms scar in terms of model selection. furthermore, it has been shown  <cit>  that 'the models generated by tasser  <cit>  have incorrect side-chain conformations and poor hydrogen bonding patterns partly because of the on-lattice modelling and the unphysical geometry of the spicker <cit>  cluster centroid structure'. pulchra  <cit> , which combines a conjugant gradient search with a harmonic potential, supersedes both scar and spicker. similarly, kolinski and bujnicki  <cit>  have introduced an elegant approach using a combination of template-based and de novo modelling followed by hierarchical clustering that employed averaging of very diverse models from threading, that results in consensus structures with improved local and global quality.

in general, averaging artifacts become more pronounced when members of the ensemble are more divergent. this artifact is exacerbated in tasser due to the fact that it begins with a lattice model and averaging is performed across clusters of dissimilar structures. consequently, the averaged structure is often not suitable for detailed atomic model building due to unrealistic bond lengths and angles and unphysical local geometry. in the same vein, the community wide experiment on the critical assessment of techniques for protein structure prediction  also penalizes structures with unphysical bond lengths and unrealistic geometries. casp defines two types of clashes for bond length. the first type of clash involves atoms that are less than  <dig>  Å apart, and the other type of clash involves atoms that are less than  <dig>  Å apart. we adopt these criteria in what follows.

herein, we apply the proposed algorithm for removing averaging artifacts from clusters of structures generated by the tasser  algorithm  <cit> . within tasser, generated structures are clustered using spicker  <cit>  and the cluster with the highest structural density is selected . subsequently, the centroid model  that is obtained by averaging all the cluster members of the most densely populated cluster is selected as the predicted structure. in various benchmarks of the tasser algorithm  <cit> , the averaged structure  is generally closest to the native in terms of global rmsd. it is closer to the native structure than all the individual cluster members, including the medoid . hence, tasser outputs the cluster centroid  as its final model. in this regard, averaged models have also been shown to outperform minimum free energy structures in the context of rna secondary structure prediction  <cit> .

our goal is to generate a structure that is as close as possible to the 'averaged structure' while maintaining realistic bond lengths and angles and local geometry. unless otherwise stated, the term bond length refers to 'virtual bond length' between two cα atoms throughout this report, and bond angle refers to 'virtual bond angle' between any three consecutive cα atoms. to address this issue, we have developed a new algorithm, mcore  that is designed to generate such structures by minimizing the difference between the 'averaged' and the physically reasonable structure using a monte carlo minimization procedure. we show that our approach is robust and general and can overcome averaging artifacts with minimal reduction of structure quality as assessed by the rmsd of the resulting model from the native structure. once the refined cα model is obtained, then approaches like the one based on backbone building from quadrilaterals proposed by gront et al.  <cit>  can be used to complete backbone reconstruction.

methods
the central idea behind our approach is to start from a structure that has physically allowed bond lengths and then minimize the difference between this starting structure and the averaged structure. in this respect, our methodology consists of two basic components:  generation of the starting structure and  minimization of this starting structure in the presence of the averaged structure.

starting structure
we explore two types of starting structures:  a fully extended structure with bond length corresponding to the average bond length obtained from the pdb and all ψ and ψ = 180°,  a model that is close to the 'averaged structure' but has physically reasonable bond length and angles, which we call the 'close-by model'. a typical model of this type can be the structure that is closest  to the 'averaged structure' in an ensemble of proteins. in case of tasser, closc models fall in this category. in case, when two structures have the same rmsd to the averaged structure, one of them is chosen at random. extended structures will be required when no 'close-by model' is available.

energy function
the pseudo energy potential, v, in our algorithm is presented in equation . the potential, v, consists of three components: a harmonic term for excluded volume violations, a harmonic term for virtual bond angle violations and a third term that drives the conformation towards the target structure. thus, v is given by

  v=kexcl∑k=1n−2∑l=k+2n2+kang∑k=1n−22+kclos∑k=1n <dig> 

where n is the number of cα atoms; kexcl, kang, kclos are the weights of corresponding contributions to v. rkl is the distance between the kth and lth cα atoms, r0_excl is the cutoff parameter for excluded volume violations and is set to  <dig> Å if rkl <  <dig>  Å, otherwise r0_excl is set to be equal to rkl. that is, this contribution to the potential is turned off. θi, i+ <dig>  i+ <dig> is the virtual bond angle formed by the ith, i+1st, and i+2nd cα atom θ0_ang is the cut-off angle, and is set to be 70° if θi, i+ <dig>  i+ <dig> < 70°, 150° if θi, i+ <dig>  i+ <dig> > 150°, or θ0_ang = θi, i+ <dig>  i+ <dig> otherwise; dkkt is the distance between the corresponding cα atoms of the target structure and the current conformation, and d0_clo is the maximum allowed displacement between the corresponding cα atoms and is set to be equal to  <dig>  if dkkt >  <dig>  Å or is set equal to dkkt otherwise. the values for these parameters are chosen such that they are close to those by oldfield et al.  <cit>  the values of kclos, kexcl, and kangare chosen to be  <dig> ,  <dig>  and  <dig> , respectively, on the basis of optimization of the parameters using minuit  <cit>  to maximize the correlation between the energy function and the rmsd to the native structure and manual adjustment based on empirical observation for a set of  <dig> proteins that are used for training parameters as described in the data set. the rmsd values are measured on the cα atoms for all the cases except those where specified.

move sets
another important aspect of a monte carlo simulation is the move set that moves the structure from the current conformation to the next one. selection of move sets is very critical to the performance of the simulation itself. we have designed two types of move sets, one of which is global and another is local. both sets preserve initial bond lengths. a schematic overview of both is depicted in figure  <dig>  there are two types of local moves: i) one to five bead moves that preserve the geometry of the chain outside the fragment whose conformation is changed and ii) one to four bead moves at both ends of the chain. in both the cases, the geometry of the chain outside the targeted fragment is preserved. the global move involves a global rotation of the entire chain, which for the ith residue involves a rotation about the i- <dig> to ith bond. a given monte carlo step consists of n-k- <dig> attempts at a k-bead move , plus k  attempts at each of l-bead n-terminal and l-bead c-terminal moves , and one attempt at a global reorientation move. of course, attempt locations are randomly chosen.

we performed computational experiments on the set of  <dig> proteins described below where an extended structure  was driven towards the corresponding average structure using the algorithm described above. the snapshot of energy vs. number of steps for this set of experiments is shown in figure  <dig>  the average cα rmsd of the proteins to their respective native structure for a relatively short  run was  <dig>  Å.

convergency criteria
there are no straightforward convergence criteria for monte carlo simulations . however, two obvious convergence criteria are:  allowing for a pre-specified total number of steps and  allowing the algorithm to proceed until it ceases to make progress. herein, we use both types of convergency criteria. starting from the  <dig> extended structures, the average final rmsd for a  <dig> steps run was  <dig>  Å. hence, we choose  <dig> steps as the specified steps for our simulation. furthermore, we also devised a mechanism to stop the algorithm when it ceases to make progress. we define that the algorithm ceases to make progress after step j if following criteria is satisfied for every i, where  <dig> <i <n:

  ∀i <t 

where rmsdj is the rmsd of the conformation after j steps and rmdsj-i is the rmsd of the conformation after j-i steps. the value of i goes from  <dig> through n and t is the tolerance cutoff. once the step j  is obtained, the simulation is run for extra x steps. in other words, the simulation is stopped after j+x number of steps if the value of rmsd of the last n steps is within the tolerance region compared to the value of the step j. the values of n, x and t were chosen empirically and were chosen to be  <dig>   <dig> and  <dig>  respectively. monte carlo simulations were performed using the above move set and the standard metropolis criteria at a temperature of  <dig> k  <cit> .

data set
to verify the application of mcore algorithm, we use it to remove the averaging artifacts in the output of tasser algorithm. the data set used for this study consists of  <dig> non-homologous single domain proteins with less than  <dig> residues with a maximum of 35% pairwise sequence identity to each other that cover the protein data bank. all of these proteins have an initial rmsd of combo model  against the native protein to be less than  <dig>  Å. this is from the fact that the predicted models that are about  <dig>  Å to the native structures are likely to have the same fold as the native structure  <cit> . in addition, from the tasser outputs we have corresponding combo structure and closc structures for each of these proteins. out of the  <dig> proteins,  <dig> proteins are used for training of model parameters, whereas the remaining  <dig> proteins are used for validation. all root mean square deviation  values refer to cα atom comparisons unless otherwise stated.

RESULTS
comparison of two types of starting structures
for the comparison between the two types of starting structure schemes: extended structure and 'close-by' model, we performed computational experiments on the set of  <dig> test set of proteins as described in the data set. for each type of starting structure scheme, we run our algorithm for  <dig>   <dig> and  <dig> steps . it can be observed from the table that starting from close-by models produce better results in all three regimes  relative to the extended models. hence, for the comparison of our method with closc and combo models, we use the close-by starting scheme. the algorithm with close-by starting scheme that uses convergency criteria as described in equation  <dig> is termed mcore, whereas the version of the algorithm with fixed number of steps  using the same close-by starting scheme is termed mcore-l.

1extended and 'close-by model' for  <dig> steps,  <dig> steps and  <dig> steps for the same set of  <dig> proteins. the numbers x/y/z denote time required  for the respective runs, rmsd to the native and the percentage of atoms that are involved in clashes less than  <dig>  Å respectively.

refinement of combo models
before comparing the results of the refined models, we also take an opportunity to analyze the rmsd to native of the  <dig> combo and closc models. across the dataset, only  <dig> closc models had lower rmsd values relative to the native structure compared to the combo models, reiterating the advantage of averaged structures in this regard. the average rmsd of combo model to the native structure is  <dig>  Å, whereas the average rmsd of closc model to the corresponding native structure is  <dig>  Å.

upon application of the mcore algorithm to the refine the combo models, it is found that the refined representative structures have similar rmsd values to native structures, but with far fewer unphysical characteristics. figure  <dig> plots the rmsd values of the mcore to native comparisons versus the combo to native comparisons, which demonstrates a strong linear correlation between the two methods. the rmsd values of the combo models are only slightly better than those from mcore. this point is reinforced by figure  <dig>  which plots the density of rmsd differences between the methods. the majority of rmsd differences are slightly less than  <dig>  Å. in addition,  <dig> mcore refined structures had even better rmsd than their corresponding combo model. figure  <dig> plots fraction of clashes within the mcore vs. combo models. clearly, the mcore models have far fewer clashes than their combo counterparts. the average percentage of clashes in mcore refined models is  <dig> %, whereas the average percentage of clashes in combo models is  <dig> %.

we also compared the rmsd  of the mcore refined combo models to that of the unrefined closc models. here, it was observed that only  <dig> of  <dig> mcore refined models had poorer rmsd values than the corresponding closc models. the average rmsd for mcore models was  <dig>  Å. in addition, for mcore-l, we were able to obtain an average rmsd of  <dig>  Å. based on the much reduced compute time of the mcore algorithm , it is satisfying to note that the average rmsd of mcore-l models and mcore models are virtually the same. these results are summarized in table  <dig> 

 <dig> the corresponding standard deviation values are also provided.

overall, it is found that mcore produces models better in terms of rmsd and tm-score  <cit>  versus the corresponding closc models. moreover, the mcore models are only slightly worse than the averaged combo models, which is consistent with our initial problem statement. note that the larger tm-score, the better the model. moreover, if we discriminate clashes into the two casp types, then it is more evident that our refined models are much better in terms of clashes as they do not have any atoms involved in clashes that are less than  <dig>  Å, whereas combo models have  <dig> % of the atoms involved in this regime of clashes.

we also investigated the average number of steps and time for the mcore and mcore-l algorithms. it was observed that for mcore the number of average monte carlo steps is less than  <dig>  and the average running time is  <dig>  minutes. moreover, for mcore-l, the average running time is  <dig> minutes. hence, mcore can be applied to a wide variety of problems concerning the averaging of macromolecular structures due to its fast execution time.

we also analyzed some representative proteins that have higher rmsd deviation compared to the combo structure. in figure  <dig> we present the combo and native model and in figure  <dig> we present the mcore and native model of protein 1qle  which had the largest rmsd deviation compared to the combo structure. furthermore, to highlight the differences, we magnify the n-terminus region of figures  <dig> in  <dig> and  <dig> in  <dig> respectively. as can be seen in the figure, the n-terminus region of the cytochrome c oxidase of the protein in the combo model is totally unphysical and hence, the large rmsd deviation between the mcore models and combo models. we also analyzed the virtual bond distance in the model and found that there were two bonds less than  <dig>  Å and  <dig> bonds less than  <dig>  Å. we also analyzed other representative structures. as suspected, we found that in most of the cases where there was a large deviation between the combo rmsd and mcore rmsd, there was involvement of unphysical bond lengths which reiterates the fact that there is trade-off between local geometric correctness and deviation from the target structure.

comparison with pulchra
for the comparison of mcore algorithm with existing approaches, we also compared our results with pulchra  <cit>  refinement. pulchra is an all atom reconstruction method that has an optimization of cα carbon position using steepest descent minimization procedure. figure  <dig> plots the rmsd values of the pulchra to native comparisons versus mcore to native comparison. figure  <dig> plots the fraction of atoms involved in clashes less than  <dig>  Å in pulchra models versus the mcore models. the average rmsd of mcore refined combo models was found to be  <dig>  Å as compared to  <dig>  Å for pulchra. however, in terms of clashes mcore models on average only have  <dig> %, whereas  <dig> % of the atoms from the pulchra models are involved in clashes. this difference in clashes is statistically significant as shown in table  <dig> using a standard z-test. moreover, if we break down the clashes into clashes less than  <dig>  Å and clashes less than  <dig>  Å, it is found that mcore models do not have any clashes less than  <dig>  Å, whereas pulchra does . the clashes less than  <dig>  Å are severe for further refinement of the models. while the mcore models are slightly worse than those from pulchra in terms of rmsd to native by  <dig>  Å, they have a statistically significant improvement in terms of clashes. moreover,  <dig>  of the mcore models resulted in better refinement of the combo model versus pulchra. in addition, for long runs of mcore , we were able to obtain an average rmsd of  <dig>  Å, which is exactly same as obtained by pulchra. moreover, the mcore-l models had far fewer clashes than the pulchra models .

3p-values are given where available using the z-test. significant p-values are in bold.

furthermore, mcore algorithm is comparable to pulchra in terms of efficiency also, as on average the computation time is around a minute. one of the major advantages of our approach compared to pulchra is that if the input structure is heavily distorted, pulchra might fail to converge where mcore will always converge.

all-atom model reconstruction
it is essential to have a model with physical bond lengths and bond angles if further analysis is to be performed on the model. since structure prediction methods often produce cα-only models, all-atom models must be constructed from the cα descriptions. in this regard, we built all-atom representations of the mcore refined cα atom models. the initial backbone reconstruction method applied is the backbone reconstruction method of an algorithm proposed by milik et al  <cit> . once the backbone atoms are reconstructed, any side-chain packing methods  <cit>  can be utilized to build the side-chains. we performed the side-chain reconstruction using one of the most widely used side-chain packing algorithms scwrl  <dig>   <cit> . the mcore refined models for the set of  <dig> proteins had an average all-atom rmsd of  <dig>  Å . the pulchra refined all-atom models on the same dataset had a comparable average value of  <dig>  Å.

CONCLUSIONS
in this paper, we presented mcore, a monte-carlo based algorithm for removing averaging artifacts of the averaged structure to improve the quality of the consensus structure. we verified the application of the proposed algorithm by applying the algorithm to refine the combo models of a set of  <dig> proteins generated by tasser algorithm, refining and correcting unphysical bond length and bond angles. on average, the rmsd to native of the refined model is  <dig>  Å; where as rmsd of the combo model to the native is  <dig>  Å, which is a mere  <dig>  Å poorer than the rmsd of the combo model . on the other hand, the average percentage of atoms involved in the clashes in the refined mcore models is reduced from 63%  to only  <dig> %. moreover, slight rmsd gains were obtained by using a version of the mcore algorithm that samples longer. however, the difference between mcore-l  and mcore  is not statistically significant, emphasizing that our convergence criterion is robust.

we have also generated a framework for producing all-atom models from the cα only atom models by first reconstructing the backbone and then doing the side-chain reconstruction using existing methodologies. an obvious extension of the work is to refine not only cα models, but also to apply mcore to all-atom models. in essence, the new refinement algorithm helps in attaining structures with more physical bond lengths and bond angles by overcoming averaging artifacts produced due to averaging of structures. it has to be noted that there is always a trade-off between local geometric correctness and the deviation from the target structure. generating averaged structures that are not heavily distorted can minimize this trade-off. these results provide a genuine model for the subsequent analysis of the respective protein structure using molecular mechanics force field. in addition, this algorithm does not have convergence problems like pulchra . although the algorithm was tested for tasser models only, the presented approach is general and can be applied to remove averaging artifacts arising from averaging over any ensemble of molecular conformations.

abbreviations
rmsd: root mean square deviation; tasser: threading/assembly/refinement; casp: critical assessment of techniques for protein structure prediction; nmr: nuclear magnetic resonance; mcore : monte carlo based refinement; combo model: centroid model; closc model: model which is closest to the centroid model.

authors' contributions
dbkc wrote the program and carried out the experiments and authored the manuscript. all authors read and approved the final manuscript.

