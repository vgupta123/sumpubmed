BACKGROUND
large scale gene expression monitoring technology is changing our view of the biological processes, including their dynamics. hence, microarrays have emerged as the primary tool for studying the expression patterns of thousands of genes from a single experiment. as this technology matures, the ability to generate a large volume of data is accelerating; it is now perfectly normal to use tens or even hundreds of microarrays in a single study.

microarray data are rich and complex but experimental biases, as well as variations introduced along the various steps in measuring gene expression levels, tend to make them unaffordable as is  <cit> . therefore, data pre-processing is highly recommendable for reproducibility, reliability, compatibility and standardization of microarray analysis and results  <cit> , even if it does not seem so necessary with affymetrix chips  <cit> . microarray data pre-processing, mainly normalization, is used to remove biases within each array by local regression. many normalization methods often make the assumption that the majority of genes are not differentially regulated or that the number of up-regulated genes roughly equals the number of down-regulated genes. although these assumptions are not applicable to every case, they do not seem to cause a serious effect on most microarray experiments. alternatively, several methods have been proposed to normalize microarrays that do not fulfil the previous assumptions  <cit>  for both affymetrix genechip and two-colour array data. in any case, pre-processed data is usually more reliable in order to identify biologically meaningful patterns, since statistical tests to discover differentially expressed genes tend to depend on the experimental design.

an increasing number of academic and commercial solutions have been developed to tackle the pre-processing, each one with particular strengths and weaknesses. the most widely used and comprehensive packages currently belong to the open source software environment: bioconductor for r  <cit> , tm <dig>  <cit>  and gepas  <cit> .

bioconductor is a collection of extensible open source libraries for r, whose main focus is to deliver a high quality infrastructure and end user tools for expression analysis. object-oriented programming with well-defined classes is the basis for overcoming data complexity, and a command line interface is the preferred way to access libraries. this makes it very powerful but its use requires skills in statistics and programming capabilities. data objects generated by r microarray processing packages can be saved in flat text being assimilated by the user, but the reconversion into the original object for further analysis is not always trivial. tm <dig> is a series of java based tools that provide users with a well designed, easy to use interface. it consists of four major applications, as well as a mysql database for maintaining experimental results, that are mainly focused on two-colour microarrays. in spite of its graphical interface, its use is not always intuitive and it also requires statistical skills to pipeline the pre-processing algorithms; it also presents certain computing inefficiency for intensive calculations. unfortunately, only mev is actually kept updated  <cit> . gepas is a nice and very used web based tool that allows the use of r packages without any programming skills. however, as most of the web based applications, it faces technological problems: poor interactive interfaces, not suitable for uploading and downloading huge amounts of data, lack on interactivity and data privacy problems, etc. hence even if gepas deals with affymetrix and two-colour experiments, its implementation presents some limitations.

laboratory scientists are often challenged by large quantities of data produced by their microarray experiments, the statistics underlying the analysis of their own data, and the usability of applications that contain such statistical treatments. pre-processing microarray data requires some background in statistics that most users lack or have a very vague notion of. this gap even includes the knowledge of which statistical approaches to use and the correct order in which statistical calculations have to be performed. in such a context, prep has been in the front line of public software for two-colour microarray analysis  <cit> , since it helps statistics-unskilled users to manage and analyze data effectively from their microarray experiments. it provides  an integrated gallery of techniques to deal with the many sources of measurement errors, including two new algorithms not available in any other tool;  an interactive user friendly interface for the visualization of data in an appropriate representation;  a standalone application for data privacy; and  highly customizable statistical tools to build up a simple error removal pipeline procedure. in spite of being designed as a tool for the analysis of two-colour chips, the data pre-processing of affymetrix chips is possible through a slight initial preparation of data which consists of assigning one treatment to cy <dig> channel and another treatment to the cy <dig> channel; data can be thus processed and m and a values can be calculated. automatic procedures will be soon added to prep+ <dig> to perform this data preparation. the improvements described here have turned prep+ <dig> into a user friendly environment that meets microarray pre-processing requirements for users that are not skilled in statistics or programming, but know how to perform a right experimental design concerning microarrays.

pre-processing methods available in prep+07
background correction and filtering
to enable comparison between arrays and experiments, data must be normalized and then replicates need to be resolved before differential expression analysis. data treatment starts with background subtraction; this can be performed by prep+ <dig> or obtained from the microarray reading system. when data are supposed to be of high quality, subtraction can be enough; in any other case, background correction may need more artificial adjustments that are not available in prep+ <dig>  otherwise, prep+ <dig> has the option to start the normalization without background subtraction. prep+ <dig> also provides a data filtering tool to remove, for example, low quality spots, taking into account several criteria, such as foreground and background intensity, spot shape, saturation, etc.

normalization
typically, normalization is the first transformation applied to expression data. it aims to adjust the individual hybridization intensities to balance them appropriately so that meaningful biological comparisons can be made  <cit> . there are many approaches to normalizing expression levels, but the locally weighted linear regression  normalization  <cit>  has become the standard since it takes into account systematic biases and intensity specific artefacts that may appear in the data. prep+ <dig> implements both full parametric global and print-tip lowess normalization procedure. since normalised slides might not be comparable, scaling procedure is also provided for inter-slide normalization  <cit> . as a rule of thumb, no scaling must be performed unless box plots indicate that means of each slide are significantly different. however, some of the proposed methods are not supported by a model. these methods are called non-parametric and they offer, when properly used, a flexible approach to normalization.

replication
replication deals with the data merging from several repetitions of the same experiment and repeated spots in a single slide. usually, errors cause data to be dissimilar from one repetition to another, but more knowledge about them is available as the number of replications grows. this information about error effects is collected by statistical procedures. prep+ <dig> can deal with biological and technical replicates by average , or by median calculations . however, current proposals recommend using a noise  model  <cit>  and then extracting estimators  <cit> , quality filters  <cit> , thresholds  <cit> , etc from it, to be taken into account in solving replications.

double scan
this advanced correction method that improves data quality is uniquely implemented in prep+ <dig>  devices used for measuring intensities are neither perfect nor without limitations. saturation and quantization, which compromise the high and low spot intensity reads respectively, appear in the scanned images, and are hard to be removed. the double scan method  <cit>  combines two readings: a low intensity acquisition to avoid saturated spots and a high intensity second reading to avoid quantization, providing as a result a data set without saturation or quantization, so all slide spots become informative.

supervised lowess
array based comparative genome hybridization  is applied frequently to study the genomic content of closely related microorganisms, microbial taxonomy and species determination, as well as the presence of microbial pathogenicity factors. with acgh a difference in signal arises, not only because of the absence or presence of genomic dna, but also due to differences in sequence identity. this problem in particular plays an important role in bacterial acgh experiments, since prokaryotes generally show lower genomic conservation than eukaryotes  <cit> . the supervised lowess  normalization method only uses genes that are conserved  in both samples hybridized for normalization. in a first step, the sl method performs lowess normalization over the lhg subset of genes, computing the initial log ratios ), followed by lowess normalization, generating a set of corrected ratios rc i  and correction factors for the subset of conserved genes used: αi = rc i - ri. subsequently, the lowess correction factors belonging to the subset of conserved genes  are extrapolated to determine the correction factors βj  for the remaining genes. the correction factors are then used to adjust the log ratios of the remaining genes. the spot set used for sl can be selected by hand or using the filtering capabilities of prep+ <dig> 

differential expression
finally, differential analysis serves to identify outlier spots  whose outlying behaviour is not due to experimental error but biological expression. the differential expression based on a fixed fold change cut-off has been identified as insufficient. therefore, methods involving calculation of the mean and standard deviations  <cit>  of the spot distribution of log <dig> values, and also defining a global fold change difference and confidence  <cit> , equivalent to a z-test, have been included for a preliminary analysis.

a typical protocol
a typical normalization procedure  using prep+ <dig> starts loading data to which column-functionality is assigned . frequently, a row filtering step is needed to remove low quality and empty spots. several options are available for filtering, such as spot quality, signal presence/absence, fold change, etc. when applicable, a  <dig> scan resolution can be performed to extend dynamic range of intensity values. data normality can be visually evaluated using normality graphs and then data normalization can be chosen to correct the deviation . statistical tests can be used to identify differentially expressed genes. finally, results can be saved in several formats for further processing.

implementation
the methods described above have been implemented in prep+ <dig> . among them: merging intensities by double scan method*; adjusting by lowess or supervised lowess regression*; scaling for inter-slide normalization; filtering* and thresholds; random error removal by replicates resolution; global and local statistical descriptors such as z-test, t-test, p-values; etc. . the general setup of prep+ <dig> offers a certain degree of freedom when running pre-processing methods. a remarkable feature in this version are the normality plots , that help the user to visualize the normality of the data. when the observed data nearly follows the expected distribution, a diagonal line will be drawn and in this way outliers will be easily observed on these graphs as points both ends of the diagonal.

prep+ <dig> input/output
special attention has been paid to improve input-output functionality in prep+ <dig>  input and output files in prep+ <dig> are tab-delimited text files, which can be readily imported, for instance into microsoft excel. in addition, prep+ <dig> manages its own data format , and compatibility with genepix , arraypro and text-tabulated output files are also provided. additionaly to data loading, the meaning of each column must be specified . manual or file configuration can be used for this purpose, including the description  of slide structure .

prep+ <dig> also supplies a broad range of alternative output formats, from simply a text tabulated table to gene expression matrixes including statistical characterization. an important and useful feature is the ability to store intermediate results as a prep project that can later be recovered for further processing.

double scan
double scan implementation is based on a robust mathematical model described in  <cit>  and requires the identification of the saturation model . adjustments can be visualized with the 'intensity-intensity' plot. it shows the spots according to the intensity measured in a low sensitivity scan and a high sensitivity scan for both the green and red channels. this plot can also be used for the comparison of two replicated slides or scans. if the replication is properly done, the spots must show a linear relation; otherwise, when the scans have different calibrations, the data will follow a non linear curve due to saturation or calibration effects .

supervised lowess
supervised lowess  can be advantageously used when data follow a non normal distribution due to differences in gene sequence identity, as demonstrated in  <cit> , suggesting that it is appropriate for any microbial acgh comparison. in any case, sl assesses a normalizing estimate using a subset of genes  and then uses this estimation to remove the error in the rest of genes. this procedure has been successfully applied to spiked-in dual dye dna microarray data.

visualization tools
there are many ways to represent microarray data , many of which have been implemented in prep+ <dig>  in order to help in data interpretation as well as to detect any kind of systematic error in the dataset. in a first instance it provides a synthetic image built from the image processing software output that gives a general overview of the data quality and can be compared to the original scanner images, not only to validate the reading of data but to aid in the discovery of any unnoticed artefact or incoherent values due to noise of bad background estimation. the ma plot  <cit> , which represents the intensity  against log <dig> of expression  is nowadays an indispensable tool in microarray representations. it can help locate outliers, detect any kind of quantization at low intensity or saturation at high intensities. in prep+ <dig> the lowess normalization curves are drawn on these plots in order to assess the degree of adjustment that the normalization will introduce.

replicated data can be visualized, and the quality estimated, by dispersion, deviation and correlation diagrams that expose these statistical values and their dependence on the average of the replicated spot intensities. for the dispersion graph, the data points should be located along the diagonal, and the more noise, the more blurred they will appear, in other words, a lot of spread spots suggests low data quality.

to assess the replication normality, qq plot compares quantiles of the expected normal distribution with quantiles of the observed data distribution . these plots are drawn for every step in the project stack.

to emphasize prep+07's user friendliness most of the graphs have interactive visualizations: tooltips with the data associated to each spot, colours that help the user differentiate genes with differential expression, etc. clearly, prep+ <dig> outperforms existing implementations of gene expression graphical representations .

local normalization
prep+ <dig> implements a local deviation procedure to get a preliminary set of differential expressed genes for this issue with three different estimators:  windowed local deviation that takes a fraction of spots near the spot whose deviation is to be found, and then it uses those local spots for the estimation;  lowess absolute deviation, that uses a lowess curve, given a fraction and a number of steps, for absolute deviation fitting, and  lowess standard deviation, similar to  but for standard deviation fitting  <cit>  negative ratios can be managed as symmetric, forcing the deviation to be the same for positive and negative values, or as asymmetric, to allow different deviations for positive and negative values.

architecture implementation
prep+ <dig> is implemented in visual c++ for the ms-windows xp os. it is designed in an object oriented way for robustness and scalability. the code is intended to ease the use of the application. an important goal was making the user interface friendly. this is achieved by extensive visual information, using the operative system's gui libraries and a high degree of interactivity. the installation of prep+ <dig> is extremely simple, just downloading the software from the web site and launching it. a comprehensive user-friendly manual is also available, giving more details about the methods used, and a pertinent guided tour allows a step by step discovery of the software.

a prep+ <dig> project
conceptually speaking, a prep+ <dig> project is a collection of states. each state is the result of applying a given process over the previous state. the different prep+ <dig> states are stored in a stack, meaning states are pushed into the stack and only the last state can be removed  from the top of the stack. the last state is the current state, this is to say, the state over which the procedures are applied . each state is self-contained so that it holds all the necessary information to produce a new state .

each state consists of a collection of slides. the slides represent and contain the information obtained by the scan of a given dna chip. the slide has an associated name and, when necessary, a set of pre-computed values to be used in a new step. in general, the slide name resumes the experimental conditions. finally, a slide is a collection of points . each spot has a set of values that correspond to light intensities, position in the chip, labels, etc. .

the first state is produced by a special step named the "load step". in this step the slide files are loaded and identified to translate the original data tags into prep+ <dig> understandable tags. options available for the "load step" are particular to this stage . some of the different procedures implemented in prep+ <dig> can be applied in any context  while others require specific conditions .

RESULTS
since bioconductor packages are considered a standard in microarray analysis, prep+ <dig> results were compared with it. the comparison rationale has been to obtain normalized log-ratios by applying r and prep+ <dig> procedures, then use these log-ratios to perform a two-class t-test and detect the differential expressed genes in both datasets using the multi expression viewer  program from the tm <dig>  <cit> .

a complete set of experimental data obtained in the framework of espsol spanish project  <cit>  with solanum lycopersicum has been used to obtain a set of differentially expressed genes, following the typical protocol described previously. the set was composed of  <dig> tomato microarrays hybridized to samples representing two different conditions, . to keep data confidentially, random gene ids were assigned for the tomato sequences. the experimental design includes a dye-swap and images were obtained with the genepix technology. these chips are organized in  <dig> ×  <dig> blocks  and each block contains  <dig> rows and  <dig> columns , including  <dig> empty and intra-slide replicates for some tomato ests and negative controls, identified by the same id. in particular  <dig> different spots contain  <dig> different negative controls  and  <dig> spots contain replicates for  <dig> ests. so finally,  <dig> spots correspond to tomato sequences in the chip . all scan acquisitions were performed at normal intensity  with a minimal number of saturated signals .

once empty spots were removed , data were pre-processed to obtain log-ratios following two protocols in order to allow for software comparison. they are fl  and fls . both protocols were applied to microarray data using prep+ <dig> and using the bioconductor package limma.

filtering step is designed to remove low quality spots  and resulted in  <dig> filtered spots with detectable signal in all  <dig> samples. the log-ratios produced by limma and prep+ <dig> were used as input for mev to perform a two conditions t-test. this test provides a p-value that ranks genes whose mean expression level in group a is significantly different from the mean expression level in group b. the complete set of genes was classified in  <dig>  wide ranges following their p-values. the number of differentially expressed genes for p-values coming from prep+ <dig> and limma were nearly coincident  considering ±  <dig>  fluctuations. it should be noted that the fls protocol produces a smaller correspondence, which supports the idea that scaling introduces more noise than benefit.

in order to learn more about the correlation between results, genes coming from prep+ <dig> pre-processing with a t-test p-value <  <dig>  were selected and sorted according to their p-value and then compared with their counterparts as calculated with limma . this procedure allows knowing what differences would be obtained if prep+ <dig> or limma were used for gene selection. the main result differences correspond to genes  <dig> and  <dig>  so they were analyzed in detail from their log-ratios to the final p-values to better understand these differences . as can be seen on the table, differences in log-ratios in the t-test p-value are produced by slight differences in the means and their deviation values, which result in higher differences between groups and low intra-group variability.

columns correspond to:  <cit>  gene id;  <cit>  and  <cit>  t-test p-value for data processed by prep  and limma;  <cit>  and  <cit>  position in the list of significant genes in prep+ <dig> and limma;  <cit>  differences in p-value: |  <cit>  –  <cit>  |. t-test p-values were obtained using mev from tm <dig> package.

for these genes, log-ratios  for the  <dig> analyzed chips are shown including mean and standard deviation for conditions a and b, from which the p-value was estimated.

an additional experiment with no proprietary dataset has been performed using a public dataset from geo . samples belong to nk cells of c57bl/ <dig> mice either mock-infected or infected with p. chabaudi with id codes from gsm <dig> to gsm <dig>  . the object is to identify differentially expressed genes by the infection with p. chabaudi. the protocol used for the analysis was the same but empty or low quality spots were not removed. this data set also shows a significant agreement between r and prep results .

CONCLUSIONS
pre-processing is a necessary step when preparing gene expression data for analysis since raw data carry instrumental and operator errors. moreover, these biases are not constant across experiments, rendering the data inconsistent. furthermore, the preprocessing methods should keep real differential values  still identifiable, and this must be achieved by using outlier detection and robust statistical methods.

prep+ <dig> is an attempt to reduce the barriers between scientists that hybridize microarrays and statisticians that analyze microarray results in depth. in other words, prep+ <dig> enables scientists to prepare their data and conducts a basic analysis of differential expression which is ready for closer and more specialised inspection. hence, prep+ <dig> has been designed a standalone interactive graphical suite to integrate widely used pre-processing methods for gene expression data that aims to minimize sources of systematic and random variation in the acquired data, other than those directly related to differential expression. prep+ <dig> includes a variety of analytical tools for reducing dependencies of intensity and, when available, allowing the resolution of replicated data sets. in some cases these can be applied in any context . in other cases, some specific conditions have to be met . once the error has been minimized, prep+ <dig> allows extracting the individual control, target signals and their ratio since most of the techniques available on prep+ <dig> are based on robust statistical procedures, thus being respectful to outliers and differentiated values.

statistical microarray analyses  require a collection of biological and technical replicates in order to obtain information about what genes are differentially expressed. in addition to this, prep+ <dig> also provides the opportunity of analysing differentially expressed genes slide-by-slide by means of a t-test or z-scores statistics. slide-by-slide analysis can be very helpful for researchers unskilled in statistical methods that want to obtain an overview of their results. these advantages are strengthened by the interactive interface of prep+ <dig>  which allows the identification of values and quality of every spot on the slide in each plot. the available plot set enables data visualization using different criteria to assess data reliability.

among the multiple advantages of using prep+ <dig>  the most remarkable characteristics are  the visualizations tools are completely interactive, with optional tooltips for each coloured spot in the graph to display complete information aimed to identify outliers spots and obtain their information visually ;  new and unique methods such as supervised lowess and double scan regression;  intuitive and powerful replication resolution that allows users to combine inter- and intra-slide replicates;  comparable results with most used related software allowing non-bioinformaticians to do the same pre-processing procedures using a graphical and intuitive interface, ensuring data privacy and high quality images; and  data results and inputs are interchangeable between programs .

the learning curve in prep+ <dig> can be expected to be smoother than the learning curve in r bioconductor, with prep+ <dig> the biologist does not need to have prior knowledge about scripting and simple steps such as loading the data and applying filtering or lowess could be done intuitively the first time the user runs the program.

prep+ <dig> is intended for preliminary microarray analysis for users unskilled in statistical microarray treatments or without scripting languages' capabilities. this is why it is an integrated application that contains only well-known and widely used methods  such as print-tip-lowess, lowess or scale. the idea is not to open a wide range of opportunities, but to offer a small collection of reliable workflows with the necessary options to reach normalised data and even a set of differentially expressed genes.

prep+ <dig> has been exhaustively tested in various research projects, like acgh with spiked-in dual dye  <cit> , express fingerprints  <cit> , gene expression pattern and protein profile in pigs infected by circovirus  <cit>  and esp-sol project  <cit> .

availability and requirements
▪ project name: prep+ <dig> 

▪ project home page: 

▪ operating system: windows xp.

▪ programming language: visual c++.

▪ other requirements: none.

▪ license: free software.

▪ any restriction to use by non-academics: none.

authors' contributions
vmr designed and programmed the new methods and improvements of windows prep+ <dig> program. amm carried out the transcriptomic analysis and exhaustibly tested the application. mgc tested the application and helped with the manuscript. ots conceived of the study, participated in its design and coordination and helped to draft the manuscript. all authors have read, participated in, and approved the final manuscript.

supplementary material
additional file 1
supplementary material. this document contains the different sources of error on microarray data analysis, a full table with the existing applications in gene expression data analysis, a typical prep+07's protocol of use, an alternative experiment comparing prep+ <dig> and r, technical details of prep+ <dig> code and the manuscript's figures in full resolution.

click here for file

 acknowledgements
this work has been partially financed by the espsol project conducted by the national institute for bioinformatics , a platform of genoma españa and the eu project "advancing clinico genomic trials on cancer" .

the authors would like to make a special mention to antonio granell, asuncion fernandez and sophie mirabel from the esp-sol project for their contribution in the laboratory work. the authors acknowledge the initial work of sacha v. hijum and jorge garcia de la nava in the first versions of prep.
