BACKGROUND
maintaining databases that contain the most up-to-date, high quality models of the protein structures for entire proteomes is becoming increasingly difficult. structural annotation databases such as 3d-genomics <cit> , gene3d <cit> , superfamily <cit>  and the genomic threading database <cit>  contain predicted models for all of the proteins encoded within key genomes. the quality of the models deposited in these databases relies on obtaining the closest templates for each target sequence and constructing the best possible sequence to structure alignment. most of the methods used to construct models currently rely on sequence-profile based searches; however keeping these models up-to-date is problematic for several reasons. the proteome sequences of key organisms are often updated on a monthly basis, the protein structures within the protein data bank  <cit>  are updated every week and many of the non redundant protein sequence databases  <cit> , used to construct psi-blast  <cit>  profiles for example, are updated every single day. it is clear from the livebench experiments  <cit>  that the reliability of fold recognition methods is greatly affected by the templates that are available in a fold library. a hard target sequence, regarded as having an analogous or novel fold one day, may have a homologous template available the next. it is also clear that the quality of sequence profiles is likely to increase with the availability of closer homologues.

currently the best fold recognition methods are those which employ profile-profile based searching. a number of studies have shown that these methods greatly outperform the sequence-profile based methods which are often used to populate structural annotation databases   <cit> . clearly the most comprehensive structural annotation for a given proteome would be achieved through more rigorous profile-profile based searches. however, the trade-off for the increased coverage of high confidence annotations is the speed at which predictions can be made. the main added computational overhead is due to the required construction of profiles for every unique target sequence within a proteome.

in this paper we describe our jyde  system, a meta scheduler designed to be run above cluster schedulers such as sun grid engine  <cit>  and condor  <cit>  . we demonstrate that jyde is able to distribute large numbers of intensive fold recognition jobs on demand running across several computer clusters within independent grid domains. we use the most recent profile-profile version of our mgenthreader software  <cit>  in order to annotate the latest ensembl  <cit>  version of the human proteome as quickly as possible. using our jyde system to harness over  <dig> cpus from  <dig> independent grid domains we have been able to annotate  <dig> % of the protein sequences within the human proteome in less than  <dig> hours. this study demonstrates that the prospect of carrying out on demand snapshots of the structural annotations for key eukaryotic organisms is now entirely feasible.

implementation
profile-profile based fold recognition using mgenthreader
the most recent mgenthreader protocol  <cit>  was followed for profile-profile based fold recognition. the comparison method used was designed to directly compare psi-blast position-specific scoring matrix  scores, and makes use of an optimized heuristic comparison metric. the target pssm was built using  <dig> iterations of psi-blast , searching the uniref <dig> sequence data bank with low complexity regions, coiled coil regions and transmembrane segments filtered out. the profile-profile scoring scheme we use is essentially based on the dot product of two pssm vectors x  and y , though where any negative values in the target pssm are set to zero:

s=∑i=120max⁡{0xi}yi∑i=120max⁡{0xi}
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwgtbwucqggoaakcqwgybawcqggsaalcqwgzbqwcqggpaqkcqgh9aqpdawcaaqaamaaqahabagagiyba0maeiyyaemaeiieag3aaiwaaeaafaqabegabaaabagaegimaadabagaemiwag1aasbaasqaaiabdmgapbqabaaaaagccagl7bgaayzfaagaemywak1aasbaasqaaiabdmgapbqabaaabagaemyaakmaeyypa0jaegymaedabagaegomaijaegimaadaniabgghildaakeaadaaewbqaaigbc2gatjabcggahjabciha4naacmaabaqbaeqabiqaaaqaaiabicdawaqaaiabdifaynaabaaaleaacqwgpbqaaeqaaaaaaogaay5eaiaaw2haaawcbagaemyaakmaeyypa0jaegymaedabagaegomaijaegimaadaniabgghildaaaaaa@59d6@

to find the correct alignment parameters  for this scoring function, the parameters were optimized using a grid search to maximize the sum of model quality for each top hit across a benchmark set of  <dig> difficult fold recognition targets. using a standard affine gap penalty term, a gap-opening penalty of  <dig>  and extension penalty of  <dig>  were found to be optimal.

a non-redundant template fold library for mgenthreader was constructed from  <dig> representatives from the pdb. all pairs of proteins within the fold library had low sequence homology to one another . the profile-profile version of mgenthreader was run on the human proteome sequences downloaded from the ensembl website  <cit>   using the jyde pipeline described below. the method was also run on the sequences from the fold library itself in order to estimate the reliability of the output scores .

sequence-profile based fold recognition using genthreader
the genthreader protocol  <cit>  was used for sequence-profile based fold recognition. the same procedure was carried out as for mgenthreader above using the identical fold library and target sequences.

calculation of p-values for genthreader and mgenthreader fold assignments
it is essential to provide a quantitative measure of the confidence we have in any particular fold assignment from both methods. for this we used an approach similar to that used in a previous study  <cit>  based on hypothesis testing. we determined the statistical significance of obtaining a fold match with a given score or better when compared to a null model. our null model is based on the criteria that a match of this score or better has occurred by chance and does not actually signify that the sequence has the specified fold. clearly the alternative model is that the match score is due to the sequence actually having the given fold.

in more detail, we generated random pairings of sequences which are known not to have the same fold. this was carried out by comparing the tm-score of pairs of proteins within the fold library, using the tm-align method and recommended parameters  <cit> . applying genthreader and mgenthreader to these sequences provided a score distribution for the null model. unlike our previous study  <cit> , which assumed an extreme value distribution for the null distribution, in this study we fitted a generic density model based on a gaussian kernel using the r software  <cit> . this was found to more accurately reflect particular features of our current data. we were then able to determine the statistical significance of any score using a one-sided test based on this distribution. the p-value gives the proportion of non-matching folds which, on average, would be incorrectly assigned as matches. the coverage of sequences with assigned structures was determined within the human proteomes using standard p-value cut-offs .

the jyde pipeline for high throughput structural annotation
the jyde  software package was developed as part of the e-protein project  in order to distribute structural annotation jobs across multiple co-operating processing clusters at independent grid domains. jyde consists of a meta-scheduler that works above cluster schedulers, such as sge or condor, and supports multiple submission front-ends. the software currently in use at ucl has a bioinformatics tailored web interface which is powered by a tomcat servlet. the servlet allows authenticated users to upload a proteome sequence file via a web form and then prepares the data for processing by bioinformatics software such as mgenthreader. the proteome sequence files are subdivided into smaller files which are then passed through to the portal. the portal maintains the job queues with different priorities for different users and projects.

the portal requests permission for job execution from the distribution manager . the distribution manager on the submission server is part of a peer-to-peer network with the dms at other grid sites and attempts to balance the load across them. the dm issues permits to the portal which instructs the portal to execute a particular job at a particular site. the portal has different modules to support communication with different kinds of clusters, e.g. a specific pluggable module talks to sites which are running sge <dig> or condor. this module submits the jobs to the cluster, reports on their status and returns the results when they finish.

jyde hardware setup
three clusters were used within three independent grid domains at ucl and imperial. at the peak of the experiment  <dig> pentium iiis  were available at the ucl computer science domain ,  <dig> opterons  were available at the imperial lesc domain  and  <dig> xeons  were available at the ucl information systems domain . in total  <dig> cpus were available to carry out the structural annotations.

we arranged to have increased access to each of the clusters between the 2nd and 4th december  <dig>  exclusive access to the cluster at the ucl computer science domain was obtained throughout the experiment. we had increased priority to the cluster at the imperial lesc domain and restrictions were imposed on the job lengths of other users. at the ucl information systems domain restrictions were put in place to prevent any other users from submitting jobs during the experiment.

jyde software setup
three components of jyde were installed on the submission web server including: the bioinformatics front end to the portal , the portal itself and the distribution manager.

installing our software on the clusters was relatively straightforward and merely required a standard user account to be setup on the front end machine. a tar file containing the binaries for our mgenthreader software was uploaded into the nfs-shared home directory on each cluster. java was also installed in the home directory where it was found to be unavailable. public keys were setup in order to enable the submission web server to ssh into each clusters and submit jobs. this ssh connection also enabled the clusters to transfer results files back to the main data store on the file server. finally we configured the mgenthreader shell scripts for each cluster. these scripts were run by sge on each node, which in turn called the mgenthreader binaries. the sge 'qsub' command was run on the front end machine with the shell script and input parameters.

the mgenthreader program required read-access to large database files containing up-to-date sequence and structure data. an rsync through ssh was setup to keep these files updated on each cluster.

data flow during rapid annotation of the human proteome
we downloaded the latest available human proteome sequence file from ensembl  and submitted it for annotation using mgenthreader via the web interface.

the human proteome sequence file contained  <dig> unique sequences. for reasons of efficiency, we chose to allocate  <dig> sequences to each job so that jyde would run a total of  <dig> jobs. the parameters were passed to the portal, the input file was pre-processed and subdivided into  <dig> smaller files.

the portal queried the distribution manager  for permits to run  <dig> jobs. the dm initially issued a few hundred permits to the portal in order to fill each cluster with jobs. each permit specified the identity of a cluster where the portal was allowed to run a job. for each of the  <dig> waiting jobs, the portal matched the job up to a permit and then submitted a permit to a specified cluster. for each job the input data file, containing  <dig> protein sequences, was then uploaded to the cluster via ssh. since the clusters in this experiment were all running sge, the job was then submitted using the 'qsub' command via an ssh connection to the cluster front end.

as each of the jobs ran, log files were written containing information about the job status. the log files were then transferred back to the central data store on the file server. the status of each run could then be queried using the web interface on the web server. the tomcat servlet was able to read the log files and display which jobs were queued, running or completed on each of the clusters.

the dm worked by constantly checking the lengths of the wait queues at each site. when a queue on a particular site fell below a certain threshold, new permits were issued for that site, the portal would then submit more jobs to that site. the aim of this strategy was to keep every cpu at every site running jobs and to keep a few jobs waiting at each site at any time, but not so many that it would hinder the dm's ability to make scheduling decisions. prior to running, the majority of jobs were queued in portal's queue on submission web server and not in the sge cluster queues on the grid sites.

RESULTS
throughput of human proteome annotation
the cumulative throughput per hour is shown in figure  <dig>  where the proportion of annotated sequences in the human proteome is plotted against the hour. the plot remains linear for over  <dig> hours, which again indicates the constant rate of throughput that was achieved. approximately  <dig> % of sequences within the human proteome were structurally annotated in under  <dig> hours. the expected tailing off phase takes the overall time to just over  <dig> hours for completion of every single sequence.

cpu usage at independent grid domains
the tailing-off phase in cpu usage is clearly indicated on the plot . this occurs when the number of cpus exceeds the number of jobs left to run. towards the end of the run the last remaining jobs were redirected to the fastest cluster  in attempt to minimize the tailing-off effect.

comparison of genthreader and mgenthreader: estimated coverage of the human proteome
comparison of genthreader and mgenthreader: processing benchmarks
analysis of latest available templates
the pdb  <cit>  is updated on a weekly basis. during the week that the fold library was constructed ,  <dig> new structures became available which had no detectable sequence homology to known templates within the fold library. these structures have the following pdb codes and chain identifiers: 2esna, 2es7a, 2brya, 2beia, 2bdua, 2bdqa, 2axwa, 2auaa, 2anea, 2ahua, 1z7aa, 1ytla, 1ys4a, 1ylqa, 1on1a, 1wp7a.

these latest template structures were assigned to  <dig> protein sequences within the human proteome using mgenthreader. of these  <dig> sequences,  <dig> had new assignments which were estimated to be significant .

discussion
in this study we have provided a proof of concept for carrying out on demand profile-profile fold recognition for large eukaryotic proteomes. we have developed and benchmarked grid middleware in the form of a meta-scheduler called jyde . this first version of jyde has been designed specifically for distributing fold recognition software such as mgenthreader for large-scale structural annotations but it is also easily extensible to other bioinformatics applications.

profile-profile based methods for fold recognition are able to detect more remote homologues with higher confidence than can be found with sequence-profile based methods  <cit> . figure  <dig> clearly demonstrates the advantage of using the profile-profile version of mgenthreader for annotation of the human proteome over the sequence-profile method genthreader. there have been many studies on the advantages of profile-profile methods over sequence-profile methods since the first method developed by rychlewski and colleagues  <cit> . in a recent review, ohlson et al.  <cit>  observed that profile-profile methods performed at least 30% better than standard sequence-profile methods both in alignment quality and in their ability to recognize distantly related proteins. this observation is reflected in the difference in estimated coverage of significant fold assignments obtained by mgenthreader over genthreader .

it is important that structural annotation of whole proteomes can be updated on demand in order to ensure that the most accurate models are obtained for every sequence. new fold templates are released on a weekly basis and new sequences appear daily. the example model in figure  <dig> was constructed from one of  <dig> new templates which were only made available during the week that the fold library was constructed. this fold was assigned to a domain of a human protein where no structural template was previously available. so why not just align sequences to the new structures incrementally, as and when they come out? on the surface this may appear to be a pragmatic approach; however the sequence databases from which profiles are constructed are also updated frequently. this means that the ranking of models may change as more accurate sequence to structure alignments can be made. this would, in turn, mean that model rankings from week-to-week could not be accurately compared against one another. additionally, versions of proteome sequences are often updated on a monthly basis which would further complicate updates, were they to be carried out incrementally. finally, other structure prediction applications which make use of sequence profiles would also benefit from continual updates. for example przybylski et al.  <cit>  observed that secondary structure prediction improves as sequence databases increase in size. secondary structure alignment scores using predicted secondary structures have been an important feature of many fold recognition methods  <cit> . it is clear from the livebench  <cit>  assessments that the highest quality fold recognition models are produced by profile-profile based methods which maintain both continually updated fold libraries and sequence databases.

the trade off for increased accuracy is the speed at which predictions can be made. the profile-profile methods such as mgenthreader are significantly more cpu intensive than the sequence-profile methods such as genthreader . however, through the development of jyde we have provided a grid platform to enable proteome wide profile-profile fold recognition to be carried out on demand. the system could be easily scaled up to include more clusters and is extensible to other high throughput cpu intensive bioinformatics applications.

while it may not be necessarily economic to carry out a complete update of the structures for just the human proteome every  <dig> hours, it is perhaps necessary to carry out an update at least every month in order to maintain accurate models for the latest sequence versions. this could be carried out in line with the new release cycle of the proteome sequence. if we were to use the jyde system in its current setup to run mgenthreader predictions  <dig> hours a day, it would be possible  to carry out complete structural annotations for up to  <dig> or so large eukaryotic proteomes per month, in line with their ensembl release versions.

the jyde system is not restricted to protein fold recognition and could be applied to any bioinformatics applications where there is a need to regularly distribute intensive methods on large-scale data sets. the system could also be deployed in situations where the performance of a stand-alone prediction server would have insufficient power, for example serving ab initio/new fold predictions for individual sequences on demand.

although the current version of the jyde system has proved to be robust and efficient there are some aspects which could be further improved. for instance, we are aware that the current method initialises a large number of ssh sessions, and the distribution manager is not yet optimally configured for job allocation. we are hoping to address these issues in the next version of the software.

it is clear that the tailing off phase could be further reduced in order to decrease the total time taken. one option would be to reduce the number of sequences per job to one at the end of the run, as the number of sequences left to run equals the total number of cpus available. it is impractical to initially set the number of sequences per job to one. this is because of the inefficiencies of handling  <dig> jobs in the initial submission, which hinders performance at the start of the run. however, it should be possible to build in dynamically configurable job sizes in future versions of jyde.

another consideration for reducing the tailing off phase would be to redirect all final jobs to the fastest cluster when the number of sequences left to run equals the number of nodes available in the fastest cluster. this was attempted at the end of the second run where we redirected the last remaining jobs to the imperial-lesc cluster  . it is difficult to accurately predict how long a fold recognition job will need to run based on the sequence information alone. however, it would be possible to monitor long running jobs and resubmit them to faster nodes in the early stages of the run. each of these performance improvements can be carried out automatically and will be added to future versions of jyde, indeed it is our priority to minimize the tailing off phase as far as possible.

CONCLUSIONS
we succeeded in annotating  <dig> % of the human proteome in under  <dig> hours. the jyde system was able to effectively schedule jobs dynamically across three different grid domains, achieving a maximum throughput of  <dig> sequences per hour and using  <dig> cpus at the peak of the run. this study clearly demonstrates the feasibility of on demand high-throughput structural annotations of the proteomes of major eukaryotic organisms. the use of grid middleware such as jyde software should allow us to maintain continually updated structural annotation databases containing the highest possible quality models of protein structures for key eukaryotic organisms.

availability and requirements
• project names: e-protein, jyde

• project home pages: , 

• operating system: platform independent 

• programming language: java  <dig> 

• other requirements: ant

• license: freely available for academic use

• any restrictions to use by non-academics: license required

authors' contributions
ljm and rts conceived, designed and carried out the experiment. ljm drafted the paper and developed the structural annotation pipeline and web portal. rts contributed text to the manuscript, developed the distribution manager and maintained the hardware. kb performed the statistical analysis. ss conceived of the jyde system and participated in the design and coordination of the study. dtj developed and contributed the key protein structure prediction software and carried out final editing of the manuscript. all authors have read and approved the final manuscript.

supplementary material
additional file 1
jyde software. job yield distribution environment software, see readme file for installation instructions.

click here for file

 acknowledgements
we are very grateful to keith sephton at lesc and william hay at ucl for arranging priority access to their clusters for this experiment. this work was supported by the uk biotechnology and biological sciences research council and the uk department of trade and industry  along with the biosapiens network of excellence .

figures and tables
