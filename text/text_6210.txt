BACKGROUND
most biological processes, including metabolism and signal transduction, involve large numbers of proteins and are usually regulated through protein-protein interactions . it is therefore important to understand not only the functional roles of the involved individual proteins but also the overall organization of each biological process  <cit> .

several experimental methods can be employed to determine whether a protein interacts with another protein. experimental results are published and then stored in protein-protein interaction databases such as bind  <cit>  and dip  <cit> . these ppi databases are now essential for biologists to design their experiments or verify their results since they provide a global and systematic view of the large and complex interaction networks in various organisms.

initially, the results were mainly verified and added to the databases manually. since  <dig>  the development of large-scale and high-throughput experimental technologies such as immunoprecipitation and the yeast two-hybrid model has boosted the output of new experimental ppi data exponentially  <cit> . it becomes impossible to perform the relying curation task on the formidable number of existing and emerging publications if it relies solely on human effort. therefore, information retrieval and extraction tools are being developed to help curators. these tools should be able to examine enormous volumes of unstructured texts to extract potential ppi information. they usually adopt one of two general approaches:  extracting ppi information directly from the literature  <cit> ;  finding articles relevant to ppi first, and then extracting the relevant information from them.

the second approach is more efficient than the first. it extracts fewer false positive ppis because the total number of biomedical articles is very large and most of them are not directly relevant to ppi. therefore, in this paper, we focus on the first step of the second approach: finding articles relevant to ppi.

most methods in this approach formulate the article-finding step as a text classification  task, in which articles relevant to ppi are denoted as positive instances while irrelevant ones are denoted negative. we refer to this task as the ppi-tc task from now on. one advantage of this formulation is that the methods commonly used in general tc systems can be modified and applied to the problem of identifying ppi-relevant articles.

in general tc tasks, machine-learning approaches are state-of-the-art. support vector machines  <cit>  or bayesian approaches  <cit>  are two popular examples. these approaches can achieve very high accuracy but they also require a sufficient number of training data, including both positive and negative instances.

in ppi-tc, the definition of 'ppi-relevant' varies with the database for which we curate. most ppi databases define their standard according to gene ontology, a taxonomy that classifies all kinds of protein-protein interactions. each ppi database may only annotate a subset of ppi types; therefore, only some of these types will overlap with a different ppi database. in ppi databases, each existing ppi record is associated with its literature source . figure  <dig> shows a ppi record of the mint  <cit>  database. it shows that the article with pubmed id: <dig> contains information about the interaction between p <dig> and o <dig>  where p <dig> and o <dig> are the primary accession numbers of two proteins in the uniprot database. these articles can be treated as ppi-relevant and as true positive data. however, to employ mainstream machine-learning algorithms and improve their efficacy in ppi-tc, there are still two major challenges. the first is how to exploit the articles recorded in other ppi databases. since other databases may partially annotate the same ppi types as the target database, articles recorded in them can be treated as likely-positive data. if more effective training data are included, the feature space will be enlarged and the number of unseen dimensions reduced. considering these articles may increase the generality of the original model. the second challenge is a consequence of the first: to use likely-positive data we must collect corresponding likely-negative data or the ratio of positive to negative data will become unbalanced.

in this paper, our primary goal is to develop a method for the selection and exploitation of likely-positive and likely-negative data. in addition, since term-weighting is an important issue in general tc tasks and usually depends on the corpus and domain, we also investigate the secondary issue of which scheme is best suited to ppi-tc. ppi-tc systems have two possible uses for database curators. one is merely as filters to remove irrelevant articles. the other is to rank articles according to their relevance to ppi. we will first describe our experience of building our ppi-tc system in the "system overview" section. we will then use different evaluation metrics to measure system performance and discuss different configurations in the remaining sections.

system overview
step 1: dataset preparation
we use the training  and likely positive  datasets from biocreative-ii interaction abstract subtask  <cit>  and the unlabeled datasets  from pubmed. the treatment applied on lp and u will be described in step <dig>  the preparation of these datasets is detailed in the datasets subsection of the methods section. the size of each dataset is shown in table  <dig> 

their source databases are depicted in figure  <dig>  for each abstract, we remove all punctuation marks, numbers and stop words in the pre-processing step.

step 2: feature extraction and term weighting
the most typical feature representation in tc systems is bag-of-word  features, in which a term in document is converted into a feature vector. this feature vector is calculated by a term-weighting function. then the classification of these feature vectors can be modeled with existing classifiers such as support vector machines .

it is very important for svm-based tc to select a suitable term-weighting function to construct the feature vector because svm models are sensitive to the data scale, i.e. they are dominated by some very wide dimensions. a feasible term-weighting function emphasizes informative or discriminating words by allowing their feature values to occupy a larger range, increasing their influence in the statistical model. in addition to the simplest binary feature, which only indicates the existence of a word in a document, there are currently numerous term-weighting schemes that utilize term frequency , inverse document frequency  or statistical metrics information. lan et al.  <cit>  pointed out that the popularly-used tf-idf method has not performed uniformly well with respect to different data corpora. the traditional idf factor and its variants were introduced to improve the discriminating power of terms in the traditional information-retrieval field. however, in text categorization, this may not be the case. hence, they proposed a new supervised weighting scheme, tfrf, to improve the term's discriminating power. another popular supervised weighting scheme bm <dig>  <cit>  has been shown to be efficient in recent studies and tasks on ir  <cit> . we have not seen any previous attempt to apply bm <dig> to tc, perhaps because it was originally designed for applications with input query, such as searching or question answering.

inspired by the idea of lan et al. and by bm <dig>  we propose a new supervised weighting scheme, tfbrf, which avoids some biases in ppi-tc problem. the details of tfbrf will be illustrated in the "methods" section. we will compare it with other popular general-tc term weighting schemes mentioned above in "result" section.

step 3: selecting likely-positive and negative data
the base training set  contains only limited numbers of tp and tn data. to increase the generality of the classification model, more external resources should be introduced, such as the lp provided by biocreative-ii and external unlabelled dataset proposed by this work. for likely positive dataset, one important resource is other ppi databases; abundant ppi articles are recorded in various such databases. however, most of them only annotate a selection of all the ppi types defined in gene ontology. therefore, some annotations may match the criteria of the target ppi database while others may not. this means that abstracts annotated in that database can only be treated as likely-positive examples, some of which may need to be filtered out.

another problem is that there are no negative data or even likely-negative data in any curation. because most machine-learning-based classifiers tend to explicitly or implicitly record the prior distribution of positive/negative labels in the training data, we will obtain a model with a bias toward positive prediction if only those instances in the ppi databases are used. an imbalance in training data can cause serious problems. however, a large proportion of the biomedical literature is negative, which is exactly the opposite. more likely-negative  instances should be incorporated to balance the training data, and this can be carried out in a manner similar to filtering out lp instances. here, we introduce the external unlabelled dataset to deal with this problem.

since there may be noisy examples in the lp and unlabeled data, we have to select reliable instances from them in order to use these data to augment our classifier. the detailed filtration is described in the "method" section. we list the selected instances including 'selected likely positive' and 'selected likely negative' instances in table  <dig> 

step 4: exploiting likely-positive and negative data
the next step is to integrate the selected likely data into the training set to build the final model. here, we employ and compare two integration strategies: 1) directly mixing the selected likely data with the original training data, called a 'mixed model'; or 2) building an ancillary model with these likely data and encoding their prediction as features in the final model, called a 'hierarchical model'. the details of these two strategies can be found in the "methods" section.

evaluation metrics
in this paper, we employ the official evaluation metrics of biocreative ii, which assess not only the accuracy of classification but also the quality of ranking of relevant abstracts.

evaluation metrics for classification
the classification metrics examine the prediction outcome from the perspective of binary classification. the value terms used in the following formulas are defined as follows: true positive  represents the number of correctly classified relevant instances, false positive  the number of incorrectly classified irrelevant instances, true negative  the number of correctly classified irrelevant instances, and finally, false negative  the number of incorrectly classified relevant instances.

the classification metrics used in our experiments were precision, recall and f-measure. the f-measure is a harmonic average of precision and recall. these three metrics are defined as follows:

 precision=tptp+fn,recall=tptp+fnf-measure=2⋅precision⋅recallprecision+recall 

evaluation metrics for ranking
curation of ppi databases requires a classifier to output a ranked list of all testing instances based on the likelihood that they will be in the positive class, as opposed to only a binary decision. the curators can then either specify a cutoff to filter out some articles on the basis of their experience, or give higher priority to more highly ranked instances.

the ranking metric used in our experiments is auc, the area under the receiver operating characteristic curve . the roc curve is a graph of the fraction of true positives  vs. the fraction of false positives  for a classification system given various cutoffs for output likelihoods, where

 tpr=tptp+fn,fpr=fpfp+tn 

when the cutoff is lowered, more instances are considered positive. hence, both tpr and fpr are increased since their numerators become larger but their denominator, denoting the total number of positive instances, remains constant. the more positive instances are ranked above the negative ones by the classification system, the faster tpr grows in relation to fpr as the cutoff descends. consequently, higher auc values indicate more reliable ranking results.

difference between f-measure and auc
f-measure measures a classifier's best classification performance. on the other hand, auc measures the probability of a threshold classifier that it rates a randomly chosen positive sample higher than a randomly chosen negative sample.  <cit>  auc is more suitable for applications that require ranking as it provides a measure of classifier performance that is independent of a cutoff threshold. therefore, f-measure tends to measure the classifier's performance on a specific threshold while auc tends to measure a classifier's overall ranking ability. the importance of f-measure and auc depends on the application. for filtering, f-measure is more important. for ranking, auc is more suitable.

RESULTS
exploiting likely-positive and negative data
in this section, we examine the performance improvement brought by exploiting unlabeled and likely labeled data. we use the initial model, which is only trained on tp+tn data , as the baseline configuration. to exploit unlabeled data and likely labeled data, we construct two different models – the mixed model and the hierarchical model. the construction procedures of these two models are detailed in the "methods" section.

figures  <dig> and  <dig> compares the f-measures and auc scores of the three models. in order to focus on a comparison of how to exploit likely-positive and negative data, we only use the most common weighting schemes: binary, bm <dig> and tfidf. these figures show that irrespective of the weighting scheme used, the hierarchical model generally has higher f-measures while the mixed model has higher aucs. also, regardless the weighting scheme, the initial model always has the worst auc value, meaning that its ranking quality is also the worst. these results suggest that exploiting lp*+ln* data can refine the ranking quality effectively, which is critical for database curation.

employing variant term weighing schemes
in this section, we demonstrate the efficacy of the bm <dig> weighting scheme by comparing it with others. we also compare it with biocreative's rank  <dig> system <cit> . as shown in figure  <dig>  bm <dig> outperforms other weighting schemes in terms of f-measure within the hierarchical model. however, in terms of auc , tfbrf generally performs best. therefore, we can conclude that if the classification model only serves as a filter, the hierarchical model with bm <dig> is the best choice. however, to be used as an assistant tool to help database curators, the mixed model with tfbrf is most appropriate.

another notable result is that tfidf, which is considered an effective term-weighting scheme in many tc and ir systems  <cit>  does not significantly outperform others in this ppi-tc task. this is not surprising. there are many infrequent terms in the biomedical literature such as the names of chemical compounds, species and some proteins. these proper nouns appear rarely in publications, which gives them undue emphasis in the tfidf weighting. however, these proper nouns, especially non-protein names, are not directly related to ppi, raising the risk of over-fitting.

discussion
tfrf vs. tfbrf
traditional term weighting schemes such as tfrf ignore term frequencies other than target terms in positive or negative documents and emphasize terms that are more frequent in the positive than the negative documents because of their hypothesis that those ignored terms are always much greater; that is, the proportion of positive instances in the training set is very small. however, this is not the case in our ppi-tc problem. we have a large number of reliable and likely positive training instances, and a nearly equivalent number of negative instances. hence, we create a new weighting function that considers all four values. this new function is called balanced relative frequency  because it is similar to the relative frequency  of lan et al. in our formula, brf takes into account the number of documents that do not contain the target word while rf does not. detailed formulas are described in the "method" section.

mixed vs. hierarchical models
as we described in the previous section, mixed models are suitable for ranking purposes whereas hierarchical models are better for filtering. here, we discuss the reason why these two models have divergent behaviors.

for the svms of linear kernels, the hierarchical model is indeed equivalent to finding two separating hyperplanes:

 y=w′⋅xy=w0⋅w′⋅x+w1⋅x=⋅x 

such that the criteria of the svms are optimized, where the former is trained with lp* and ln* and the latter is trained with tp and tn. notice that the notions of the intercepts can be simplified by merging the term b into the weight vector w and appending a constant, say - <dig>  to the feature vector x. we can see that the strategy of using the ancillary model's output as an additional feature is an effective way to increase its influence.

unlike in the hierarchical model, in the mixed model, all instances, whether from the true datasets or the noisy ones, are mixed together to train a separating hyperplane. in other words, the training errors on the noisy datasets are taken into consideration, so the hyperplane is more robust than that of the hierarchical model, leading to higher overall ranking ability. however, its f-measure is lower due a bias for positive data, which results from the asymmetry in the filtration thresholds applied in selecting likely negative and positive instances.

CONCLUSIONS
the main purpose of this paper is to find a useful strategy for integrating likely positive data from multiple ppi databases with likely negative data from unlabeled sources. our secondary intent is to compare term-weighing schemes and select that most suitable for converting documents into feature vectors. both these issues are essential for constructing an effective ppi text classifier, which is crucial for curating databases because a good ranking can effectively reduce the total number of articles that should be reviewed given the same number of relevant articles curated.

in targeting an annotation standard of a specific ppi database, all other resources can be regarded as likely-positive. in this case, the complicated dataset integration problem can be converted into an easy filtration. also, we can extract abundant likely-negative instances from unlimited unlabeled data to balance the training data. we demonstrate that the mixed model is suitable for ranking purposes whereas the hierarchical model is appropriate for filtering.

different term-weighting schemes can have very different impacts on the same text classification algorithm. being aware of the potential weakness of unsupervised term-weighting schemes such as tfidf, we turn to some popular supervised weighting schemes and derived a novel one, tfbrf. the experimental results suggest that tfbrf and its predecessor, bm <dig>  are favorable for ranking and filtering, respectively. this may be because they consider not only the frequencies and class labels of the documents containing the target word, but also those documents that do not contain it.

with these two strategies, our system has higher f-score and auc than the rank  <dig> system of these metrics in the biocreative-ii ias challenge, which suggests that our system can serve as an efficient preprocessing tool for curating modern ppi databases.

