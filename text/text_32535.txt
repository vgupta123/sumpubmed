BACKGROUND
a sizable genomics study such as microarray often involves the use of multiple batches  of experiment due to practical complication. the systematic, non-biological differences between batches in genomics experiment are referred as batch effects. batch effects are wide-spread occurrences in genomic studies, and it has been shown that noticeable variation between different batch runs can be a real concern, sometimes even larger than the biological differences  <cit> . without sound experiment designs and statistical analysis methods to handle batch effects, misleading or even erroneous conclusions could be made. this especially important issue is unfortunately often overlooked, partially due to the complexity and multiple steps involved in genomics studies.

to minimize the impact of batch effects, a careful experiment design should ensure the even distribution of biological groups and confounding factors across batches. it would be problematic if one batch run contains most samples of a particular biological group. in an ideal genomics design, the groups of the main interest, as well as important confounding variables should be balanced and replicated across the batches to form a randomized complete block design   <cit> . it makes the separation of the real biological effect of our interests and effects by other confounding factors statistically more powerful.

however, despite all best effort, it is often than not that the collected samples are not complying with the original ideal rcbd design. this is due to the fact that these studies are mostly observational or quasi-experimental since we usually do not have full control over sample availability  <cit> . in clinical genomics study, samples may be rare, difficult or expensive to collect, irreplaceable or fail qc before profiling. the resulted unbalance and incompleteness nature of sample availability in genomics study, without appropriate attention in sample-to-batch allocation, could lead to drastic batch effects. therefore, it is necessary to develop effective and handy tool to assign collected samples across batches in an appropriate way in order to minimize the impact of batch effects.

we developed osat to facilitate the allocation of collected samples into different batches in genomics studies. osat is not aimed to be a software for experimental design carried out before sample collection, rather, it is developed to fulfill the needs arise from some practical limitations occurring in the genomics experiments. specifically, osta is developed to address one practical issue in genomics studies – when the available experimental samples ready to be profiled in the genomics instruments are collected, how should one allocate these samples to different batches in a proper way to achieve an optimal setup minimizing the impact of batch effects at the genomic profiling stage? with a block randomization step followed by an optimization step, it produces setup that optimizes the even distribution of samples in groups of biological interest into different batches, reducing the confounding or correlation between batches and the biological variables of interest. it can also optimize the even distribution of confounding factors across batches. osat can handle challenging instances where incomplete and unbalanced sample collections are involved as well as ideal balanced rcbd.

RESULTS
datasets
an exemplary data is used for demonstration. it represents samples from a study where the primary interest is to investigate the expression differentiation in case versus control groups . two additional variables, race and agegrp, are clinically important variables that may have impact on final outcome. we consider them as confounding variables. a total of  <dig> samples are included in the study, with one sample per row in the example file. as shown in additional file 1: table s1–s <dig>  none of the three variables are characterized by balanced distribution.

comparison of different sample assignment algorithms
the default algorithm implemented in osat will first block three variables considered  to generate a single initial assignment setup, and then identify the optimal one with most homogeneous cross-batch strata distribution through shuffling the initial setup. alternatively, if blocking the primary variable  is the most important and the optimization of the other two variables is less important , a different algorithm implemented in osatcan be used. it works by first blocking sampletype only to generate a pool of assignment setups, and then select the optimal one with most homogeneous cross-batch strata  distribution.

as shown in figure 1a-c, the final setup produced by the default algorithm is characterized by relatively uniform distribution of all three variables across the batches. pearson’s χ <dig> test examining the association between batches and each of the variables considered indicate that all there variables considered are highly uncorrelated with batches . on the other hand, as shown in figure 2a-c, the final setup produced by the alternative algorithm is characterized by almost perfectly uniform distribution of sampletype variable , with the uniformity of the other two variables not included in block randomization step decreased. pearson's χ <dig> test  shows that the resulting chi-square for sampletype decreases while those for race and agegrp increase, indicating the tradeoff in prioritizing variable of primary interest for block randomization. nevertheless, as shown in figure 1d and figure 2d, both algorithms produce final setups which show more homogeneous cross-batch strata distribution than the corresponding starting ones.

simply performing complete randomizations might lead to undesired sample-to-batch assignment, especially for unbalanced and/or incomplete sample sets. in fact, there is substantial chance that variables will be statistically dependent on batches if a complete randomization is carried out, especially for incomplete and/or unbalanced sample collections. as shown in figure  <dig>  an undesired setup can be produced through complete randomization of sample-to-batch assignment. the pearson's χ <dig> tests indicate all three variables are statistically dependent on batches with p-values <  <dig>  .

CONCLUSIONS
genomics experiments are often driven by the availability of the final collection of samples which might be unbalanced and incomplete. the unbalance and incompleteness nature of sample availability thus calls for the development of effective tools to assign collected samples across batches in an appropriate way in order to minimize the impact of batch effects at the genomics experiment stage. osat is developed to facilitate the allocation of collected samples to different batches in genomics study. with a block randomization step followed by an optimization step, it produces setup that optimizes the even distribution of samples in groups of biological interest into different batches, reducing the confounding or correlation between batches and the biological variables of interest. it can also optimize the homogeneous distribution of confounding factors across batches. while motivated to handle challenging instances where incomplete and unbalanced sample collections are involved, osat can also handle ideal balanced rcbd.

partly due to its simplicity in implementation, complete randomization has been frequently used in the sample assignment step of experiment practice. when sample size is large enough, randomized design will be close to a balanced design. however, simple randomization could lead to undesirable imbalanced design where efficiency and confounding might be an issue after the data collection. as we demonstrated in the manuscript, simply performing randomizations might lead to undesired sample-to-batch setup showing batch dependence, especially for unbalanced and/or incomplete sample sets which doesn’t comply with the original ideal design. osat package is designed to avoid such scenario, by providing a simple pipeline to create sample assignment that minimizes the association between sample characteristics and batches. the software was implemented in a flexible way so that it can be adopted by genomics practitioner who might not be specialized in experiment design.

it should be emphasized that although the impact of batch effect on genomics study might be minimized through proper design and sample allocation, it may not be completely eliminated. even with perfect design and best effort in all stages of experiment including sample-to-batch assignment, it is impossible to define or control all potential batch effects. many statistical methods have been developed to estimate and reduce the impact of batch effect at the data analysis stage   <cit> . it would be helpful that analytic methods handling batch effects are employed in all stages of a genomics study, from experiment design to data analysis.

experimental design has been applied in many areas, with methods being tailored to the needs of various fields. a collection of r packages for experimental design is available at http://cran.r-project.org/web/views/experimentaldesign.html. many of these existing experiment design software work for ideal situation  where the sample size is fixed and/or model is specified. for example, the software in above link includes optimal design , orthogonal arrays for main effects experiments , factorial 2-level designs , and etc. we developed osat to facilitate the allocation of collected samples into different batches in genomics studies. our software implements the general experiment design methodology to achieve the optimal sample-to-batch assignment in order to minimize the impact of batch effects. it is specifically used in the profiling stage of a genomics study when the available experimental samples ready to be profiled in the genomics instruments are collected. it provides predefined batch layout for some of the most commonly used genomics platforms. written in a modularized style in the open source r environment, it provides the flexibility for users to define the batch layout of their own experiment platform, as well as optimization objective function for their specific needs, in sample-to-batch assignment in order to minimize the impact of batch effects. to our best knowledge, there is no other tool for this important utility within the framework of bioconductor.

