BACKGROUND
the immense complexity in biological structures and processes such as intracellular signal transduction networks is one of the obstacles to fully understanding how these systems function. as understanding of these biochemical pathways increases, it is clear that they form networks of astonishing complexity and diversity. this means that the complex pathways involved in regulation of one area of the cell  are so interconnected to other, equally complex areas that all of the different pathway systems must be studied together, as a whole, if any of the individual components are to be understood. however, the large scale and minute intricacy of each of the individual networks makes it difficult for cell biologists or biochemists working in one area of a cell’s biochemistry to be aware of, let alone relate their results to, findings obtained from the various different areas. so how will all of these individually complex systems be possible to study in an integrated biochemical “mega-system?”

in order to address this problem, the concept of systems biology study has emerged  <cit> . however, with i) data being generated by laboratory scientists at a staggering rate in the course of studying the individual systems, ii) the fact that these individual systems are so complicated that scientists rarely have detailed knowledge about areas outside those that they study, there is a huge impediment to implementing a systems approach in cellular biochemistry, and iii) for laboratory scientists to fully embrace systems biology computational tools must lend themselves to usage without requiring advanced mathematical entry or programming.

several significant advancements in the systems biology field have been made as a response to the sea of data being generated at ever increasing rates. for example, in the area of biochemical signal transduction, several community-based projects to organize information about signal transduction systems such as the alliance for cellular signaling  <cit> , the former signal transduction knowledge environment  <cit> , uniprot  <cit> , or the wikipathways project  <cit>  have been created. these resources provide a way to organize and store important laboratory-generated data and information such as gene sequences, protein characteristics, interaction partners, etc.; these are then easily accessible via the internet to the scientific community. building on these resources and advancements has been the development of tools to visualize and analyze these data and, specifically, the entities that make up the complex, network-like structures of biological processes. amongst the most widely used tools to visualize biological networks is the open-source software, cytoscape  <cit> .

the information contained in the above database resources  is limited in that it is mostly static; biological systems however are dynamic in nature. hence to fully understand the underlying mechanisms , the dynamics of these processes need to be considered.

computational modeling and simulation has been successfully adopted in a number of fields to dramatically reduce development costs. the use of these modern tools to organize and probe biological structure and function has a high potential to provide the basis for new breakthroughs in both basic understanding of cell function and the development of disease therapies. the ability to observe the actual dynamics of large scale biological systems increases the probability that, out of the tens of thousands of combinations of interactions, unexpected points of intervention might be deciphered. the cell collective aims at providing an environment and resource where the biomedical community, as a whole, can more effectively bring these exciting new computational approaches to bear on cellular systems. the integration of computational and laboratory research has the potential to lead to improved understanding of biological processes, mechanisms of disease, and drug development.

if a “systems approach” is to be successful, then there must be a “system” into which the thousands of laboratory scientists all over the world can incorporate their detailed local knowledge of the pathways to create a global model of biochemical pathways. with such a systems platform, all local information would be far more accurate if laboratory scientists would contribute their specialized expertise into a system that enables the integration of the currently dispersed knowledge. hence, a collaborative modeling platform has the potential to substantially impact and move forward biomedical research.

this is precisely the purpose of the cell collective. the cell collective is an environment to model biological processes. the platform allows scientists to deposit and track dynamical information about biological processes and integrate and interrogate this knowledge in the context of the biological process as a whole. laboratory scientists can directly simulate large-scale models in real time to not only help test and form new hypotheses for their laboratory research, but also to make research more easily reproducible . furthermore, the creation and simulation of models in the cell collective doesn’t require direct use of mathematics or programming – a substantial advancement in the field  <cit> ; this tool has been developed to bring modeling into the hands of mainstream laboratory scientists.

the role of the cell collective in the current landscape of systems biology technology
as a result of the constant flow of data from laboratories, the success of biomedical research relies now, more than ever, on computational and computer technologies. while a number of different technologies have already been developed and succeeded in their purpose, the cell collective further builds on the successes of these efforts to provide a novel technology to exploit the full potential of systems biology. in this section, a discussion of some of these technologies follows. note that, the following is not an extensive review, rather we aim to illustrate how the cell collective fits within the landscape of systems biology resources. for better understanding, these resources have been categorized according to their function. 

a) biological databases  were developed as one of the first steps to deal with the sea of biological data being produced with high-throughput technologies. the information contained in these biological databases focuses on static cell “parts lists.” in other words, the data focuses on the description of the individual entities rather than the dynamical relationship between the individual parts. conversely, the cell collective, and specifically its knowledge base component  extends static knowledge and data into dynamical models; hence the information contained in the knowledge base  is dynamical in nature; it takes into account the dynamical relationship between all of the interacting partners.

b) software for dynamical models  also already exist . these tools have been built and used mainly for individual groups to study networks of a confined size. they also rely on the users’ training in computer programming and/or mathematics ; this makes it difficult for laboratory scientists to incorporate these tools into their experimental studies. the cell collective provides a novel tool in the area of large-scale, whole cell models, while extending the use of computational modeling to laboratory scientists.

c) model repositories such as the cellml repository  <cit>  or the biomodels database provide a central location to store models developed by the community. these models are then available to others for download and further analyses using other tools. the biomodels database is primarily a model repository, however, it does provide simulation capabilities via the jws simulator  <cit> . in addition, the pathcase systems biology tool  <cit>  provides a central place for kinetic models from the biomodels database and kegg pathways to be queried, visualized, and simulated side-by-side. similar to these resources, the cell collective provides the first repository  for models based on a qualitative mathematical formalism.

d) model exchange standards such as the systems biology markup language  or cellml  <cit>  make it easier for models to be exchanged between different groups and simulated/analyzed by different simulation tools. for example, when a research group wants to simulate a model deposited to the biomodels database, the model’s description in sbml or cellml ensures that the model truly corresponds to the same model used by a different group, and hence the generated data can be easily reproduced. while users can share their models with other users of the cell collective directly, without the need to import/export model files, the platform currently provides sbml export features based on the most recent version of sbml l <dig> qualitative package  <cit> .

e) visualization and analysis tools for static interaction networks, such as the aforementioned cytoscape  <cit> , but also others including visant  <cit>  or gephi , have been used extensively to visualize and analyze the graph properties of networks of various types and sizes. as a complement to existing graph analyses, the cell collective deals with dynamical models – ones that can be put in motion via computer simulations – and hence focuses on the visualization of the dynamics of these models via simulations, and susbsequent analyses . together, the cell collective is a platform that not only provides a unique combination of successful systems biology and modeling approaches, but also offers significant innovations to these technologies. in this manuscript, discussed are the various components and features of the platform, and exemplified on a previously published large-scale network model of signal transduction  <cit> .

implementation
the cell collective is a server-based software implemented in java and powered by mysql database. the simulation engine is based on chemchains which was implemented in c++  <cit> . the user interface of the cell collective was implemented primarily using javaserver faces  and primefaces .

computational framework and simulations
models in the cell collective are based on a qualitative, rule-based mathematical framework. in this framework, each species can assume either an active or inactive state. which state a species assumes at any given time point depends on a set of rules that take into account the activation state of all immediate upstream regulators.

the bio-logic builder provides the user interface for users to enter qualitative information about the regulatory mechanism of each species in a model, and subsequently converts this information into an appropriate mathematical  expression . before the simulation engine  can simulate a model, the mathematical expressions of individual species are converted into c++  files, which are subsequently compiled into a single dynamical library . this dynamical library encodes the entire model which is subsequently simulated by chemchains .

though a discrete  mathematical framework is used to represent the modeled biological processes, chemchains has been developed to enable simulations of discrete models while using continuous input/output data. in general, the activity levels of the models’ individual constituents is measured as %on. depending on the context of the biological process being simulated, this measure corresponds, for example, to concentration or the fraction of biological species being active at any given time.

in the case of real-time simulations, %on of a species represents its moving average activity, and is calculated as the fraction of the active/inactive states over a sliding window. for simulations using the dynamical analysis feature, the activity levels of the individual species  also corresponds to the ratio of active/inactive states, but is calculated once the dynamics of the model settle in a steady behavior . in both the real time simulations and dynamical analysis, %on is used as a semi-quantitative way to measure the dynamics of the modeled biological processes.

simulation performace
we analyzed the perfomance of individual simulations for randomly generated models of different sizes and different complexities . specifically, we considered models with  <dig>   <dig>   <dig>  and  <dig>  nodes and network connectivities of  <dig>   <dig>   <dig>   <dig>  and  <dig>  note that for biological application, relatively small  connectivity is most realistic  <cit> . as can be seen table  <dig>  simulations in the cell collective are relatively efficient as the required computational resources are in a linear relationship with the increasing parameters of the generated networks.

simulations consisted of  <dig>  time steps and were performed on a computer with a single core, 2ghz processor and 2gb of ram.

RESULTS
the cell collective is a web-based platform  in which laboratory scientists can collaboratively build mathematical models of biological processes by utilizing existing laboratory data, and subsequently simulate the models to further guide their laboratory experiments. conceptually, the platform can be broken up into three parts  that form the basis for the core functionality of the software: 1) integrated knowledge base of protein dynamics generated from laboratory research in a single repository, 2) integration of this knowledge into mathematical representation that allows visualization of the dynamics of the data , and 3) simulations and analyses of the model dynamics. as can also be seen in the figure, these three parts form a loop that is closed by laboratory experimentation. the first model in the cell collective  is one of the largest models of intracellular signal transduction  <cit> . features available in the current version of the cell collective are described in more detail in the following sections.

knowledge base of interaction dynamics
when laboratory scientists produce new results, for example regarding the role of one protein interacting with another protein, these results are usually published along with thousands of other results generated by the scientific community. the publication of individual results in isolation means that separate findings are not necessarily absorbed, verified, analyzed, and integrated into the existing knowledge. with the invention of various high-throughput technologies, the gap between the amount of knowledge produced and the ability of the scientific community to fully utilize this knowledge has grown  <cit> .

the first major component of the cell collective  is a knowledge base which enables laboratory scientists to contribute to the integration of knowledge about individual biological processes at the most local level which includes, for example, the identification of direct protein-protein interactions. however, the goal of the cell collective is not to duplicate other well-established resources by providing extensive parts lists that make up various biological processes and cells. instead, the aim of the platform is to extend static knowledge and data into dynamical models; hence the information provided in the knowledge base needs to be dynamical in nature. this means that the information  contained in the cell collective knowledge base takes into account the dynamical relationship between all of the interacting partners. for example, let’s assume, there are two positive regulators  of a hypothetical species z. while in the context of a parts list, information about the above species and interactions would be sufficient, in order to abstract the biological process to a dynamical model, one needs to know the dynamical relationship between the interacting partners. for instance, are both x and y  necessary for the activation, or is either one of them sufficient to activate z? this is the type of information that is used to construct dynamical models in the cell collective.

based on a widely known wiki-like concept, the knowledge base module of the platform was developed to allow laboratory scientists to contribute – collaboratively – their knowledge to the complete regulatory mechanisms of individual biological species. because all of the regulatory information forms the basis of the modeled biological/biochemical process, and hence has to be correct for the model to exhibit similar behaviors as seen in the laboratory, this process of aggregating all known information about a species into one place can also serve as a mechanism to identify possible contradictions or holes in the current knowledge about the regulatory mechanism of a particular species. using the previous hypothetical example, let’s assume laboratory scientist a discovers that proteins x and y  are both necessary to activate species z, but scientist b’s laboratory results suggest either protein xory  can sufficiently activate z . the process of integrating all known information on species z becomes crucial in discovering such discrepancies , which may have not been found otherwise. because the goal of the cell collective is to also integrate this information into dynamical models, simulations of the large-scale model  can suggest whose data is more likely to be correct. assume that scientist a adds his information into the model and the model exhibits phenomena similar to the ones seen in the laboratory, whereas when the model is built with the data from scientist b’s experiments, the simulation dynamics of the overall model fails to resemble the known actions of the real system. in such a case, new laboratory experiments would be warranted, with a potential to produce more insights into the regulatory mechanism of protein z .

the sea of biological information has made it difficult for the data to be verified on such an integrated basis. we fully understand how some of the most complex biological systems work only when the experimental data is re-integrated into and seen in the context of the entire system; a platform for integration of data is exactly what the cell collective provides.

dynamical information
each species in the cell collective’s knowledge base has a dedicated page where laboratory scientists can directly deposit their knowledge regarding the species’ regulatory mechanisms. while the wiki-like format of the knowledge base gives users the ability to input their data in a free form which can be also interactively discussed, each page is structured to help users organize and review their data more efficiently. because the wiki format is an easy medium for collecting knowledge from a large number of individuals, a number of scientific efforts have successfully adopted a variation of this technology .

first, the regulation mechanism summary section describes the general mechanism of the activation/deactivation of the species. this section, found at the top of the page of a given species, is most important from a systems perspective as the information therein takes into an account the role of all immediate upstream regulators .

the upstream regulators section contains the list of key players that have a role in the regulation of the species, as well as any evidence  supporting those roles. using the earlier example involving the regulatory mechanism of species z, this section would include proteins x and y  as upstream regulators, and the findings of laboratory scientists a and b suggesting the role of these regulators in the activation of the species . on the other hand, the regulation mechanism summary section  would contain the overall dynamical information as to how z is regulated in the context of both x and y  .

model-specific information section: because a number of molecular species can be regulated differently based on the type of the cell, this section allows users to enter such cell type-specific information. for example, an intracellular species can be regulated either by different players, or the same players but with different dynamical relationships in, say, a t cell and a mammary epithelial cell. this section enables users to differentiate between the regulatory mechanisms of the species in the two  different types of cells . hence, this section can be utilized by users to define upstream regulators and the regulation mechanism summary that is specific to users’ different models. for example, the regulation mechanism summary of species z in scientist a’s model would describe his findings that both upstream regulators of z are necessary for its activation, whereas scientist b’s regulation mechanism summary on wiki page for z would indicate that either one of the upstream regulators can activate z .

finally, references is a section that users can use to record any published works that support information entered in any of the above sections. users can enter references by simply entering the pubmed id  of the article of interest and the cell collective will automatically import all of the bibliographical information about the works.

as a starting point, we have deposited all biological knowledge describing one of the largest dynamical models of signal transduction built and published as part of our previous research  <cit> . this model consists of around  <dig> biochemical interactions between  <dig> species, comprising a number of main signaling pathways such as the epidermal growth factor, integrin, and g-protein coupled receptor pathways. the dynamical information about the hundreds of local interactions, collected manually from published biochemical literature, is available in the knowledge base module. expert scientists in the field may begin contributing to it, as well as discovering discrepancies and gaps in the biological knowledge that might have been included in the model.

once the dynamical information about the individual interactions is added in the platform knowledge base, the next step is to convert this knowledge into a dynamical model; a discussion on where this piece fits into the overall concept of the cell collective follows in the next section.

building computational models
while the knowledge base component of the cell collective serves as the knowledge aggregator for the dynamical regulatory mechanisms of individual biological species, the next step  is to convert this knowledge into a dynamical computational model that can be simulated and analyzed on the computer.

perhaps one of the biggest challenges in transforming biological knowledge into a computational model is the conceptual gap between the mathematical and biological sciences. thus far, the creation of mathematical models has been limited to scientists who are well versed in computer science and mathematics. to address this issue, we have developed bio-logic builder , a component of the cell collective, which allows laboratory scientists to build computational models based purely on the logic of the species’ regulatory mechanisms as discovered in the laboratory.

the step of transforming biological knowledge into its model representation is aided by the information provided in the knowledge base component of the software platform . specifically, as discussed above, the information recorded for the corresponding local interactions by individual scientists amounts to the overall regulation mechanism which represents the blueprint of each species’ bio-logic. while the local interactions  are discovered in the laboratory by individual scientists , the species overall regulation mechanism should take into an account all of the local knowledge . bio-logic builder was developed in such a way that all that is necessary to construct the computational representation of the regulatory mechanism of each species is the same qualitative data provided in the knowledge base component. scientists define each species’ bio-logic in a modular fashion by simply defining activators and inhibitors  of the species of interest, as well as the logical relationship between the upstream regulators . because models in the cell collective utilize a qualitative, rule-based mathematical framework, no kinetic parameters are necessary to construct the models. 

once the bio-logic is defined for all species in a given model, in silico simulations and analyses can be conducted . how this can be done with the cell collective is the focus of the next section.

simulations and analyses of model dynamics
the idea behind abstracting biological processes as computational models is to be able to visualize the dynamics of these processes on the computer, and to conduct in silico experiments that can provide i) new insights into laboratory experiments and ii) additional basis for theoretical computational research to further elucidate the complexity governing these biological processes. with its simulation and analysis component, the cell collective has been designed to provide exactly these features. specifically, in the current version of the platform, two tools for simulations and analyses  are available.

real-time simulations
perhaps the most unique and novel innovation to computational modeling is the real-time simulation feature in the platform, which allows users to visualize the dynamics of any model interactively and in real time. similar to the rest of the platform, the simulation features have been designed with simplicity and intuitiveness in mind.

all modeled biological/biochemical processes in the cell collective, represented by species that make up the internal machinery of the cell, are simulated in external environments which drive the dynamics of the system. in our example of signal transduction, this environment is represented by external species corresponding to various extracellular signals such as growth hormones, stress, etc. using a simple slider, users can change the amount of each extracellular signal  and visualize the effects of the changes on the dynamics of the cell while the simulation is running. similarly, users can introduce biological mutations to simulate loss-of-function and gain-of-function experiments while watching the dynamics of the cell change as a result of the mutations. for users’ convenience, real time simulations can be also paused and resumed at any time. figure  <dig> shows a screen-shot of the real time simulation tool. a short video demonstration of real time simulations using the previously mentioned large-scale model of signal transduction is also available as a additional file  <dig> 

dynamic analysis
laboratory studies to identify functional relationships between extracellular stimuli and various components of the cell involve a number of experiments that can be both time consuming and resource demanding. for example, a laboratory study  <cit>  that suggests that akt  is activated in response to the epidermal growth factor , the activity of akt is measured and compared in untreated cells and cells treated with egf. such studies usually involve the construction of a number of protein constructs, cell cultures, assays, etc, amounting to the use of many resources.

while akt has been known for many years to be activated in response to egf, there are many areas of the cell that are not as well understood. laboratory experiments in such areas can be sometimes based on less sound hypotheses that may lead to the waste of many resources. but what if one had the ability to pre-test laboratory hypotheses on the computer, using a computational model, in a matter of minutes? this would allow laboratory scientists to weed out weak hypotheses while focusing on the ones that have a better chance of being proven correct, and hence resulting in more efficient studies.

this is where the dynamic analysis simulation feature of the cell collective plays an important role. this tool allows users to conduct in silico experiments that closely resemble the way laboratory experiments are performed, with the advantage that in these computational studies researchers can perform more simulations and experiments in a much shorter time-frame. for example, models in the cell collective can be simulated and their dynamics visualized and analyzed in hundreds or thousands of extracellular environments  in a manner of minutes.

as an example, we will demonstrate how the software can be used to study the relationship between egf and akt. the dynamical analysis studies are done in two parts. first, on the main page of the simulation tool , users define the extracellular environment under which the study will be done. this is analogous to the preparation of cell media in the laboratory. similar to laboratory experiments with real cells, different studies using computational models  also require the set up of optimal extracellular conditions. as visualized in the figure, this can be done easily by setting the ranges of the activity  of the individual extracellular  species via the dual sliders . because in this example experiment, we are interested in the effects of egf on the network model, the activity of egf  is set to range on the full scale between  <dig> and 100% on. on the other hand, the activity ranges of the remaining external species are selected for optimal results based on our previous research  <cit> , and supported by laboratory-generated data. for example, the extracellular matrix  is set to higher activity levels, varying between  <dig> and 100% ; this corresponds to a biological finding that egf-induced growth  is dependent on cell anchorage via ecm  <cit> . 

while in this example,  <dig> simulations are performed, users can specify the number of simulations to be run within the study . during each simulation, an activity level for each extracellular species is selected randomly by the software such that the activity falls into the specified range. as a result, the user is able to simulate what would amount to  <dig> different laboratory experiments, with each experiment corresponding to a different external condition.

once the in silico experiment has completed, users can analyze the dynamics of the model. currently, the dynamic analysis tool allows users to generate dose-response curves to investigate qualitative  relationships between external cellular signals and various components of the model, such as the one between egf and akt as visualized in figure  <dig>  as can be seen in the graph, there is indeed a positive correlation between egf and akt, similar to the phenomenon seen in the laboratory. an additional significant advantage of computational experiments using this tool is that users can generate a number of analyses without re-running the entire experiment. for instance, in addition to examining the functional relationship of akt and growth, one can generate similar dose-response curves for any species in the model using a single 100-simulation experiment. this is done by specifying the appropriate extracellular signal and output species  from drop-down menus available on the page. on the generated graph, the selected external species is represented on the x-axis whereas the output species is represented on the y-axis. furthermore, similar to the real time simulation feature, mutations to any of the cellular species can easily be specified which allows users to simulate gain/loss-of-function in an intuitive fashion. in the current version of the software, users can generate the dose-response graphs for all species in the model by selecting the appropriate input-output species. while we are in the course of adding additional means of visualizing the simulation results, users can also download all generated  simulation data, which can subsequently be analyzed by users according to their needs.

the dynamical analysis feature can be used not only to generate new hypotheses, but also to test the correctness of the model. because the models are built using local knowledge of the individual interactions, how do we know that all of this local information adds up to a system that represents what is seen in the laboratory? hence the correctness of the model needs to be tested on global phenomena of the system. the above example demonstrates how the model of signal transduction in a fibroblast cell can be tested to ensure that species associated with apoptosis and growth  appropriately respond to a growth signal . if, for example, the dose-response curve for akt and egf suggested a negative correlation, one would have to go back and investigate which of the local interaction data resulted in the contradictory result.

seed models
in addition to the signal transduction model of a fibroblast cell created and previously published by our group  <cit> , as part of our most recent research efforts, we have constructed additional models of the budding yeast cell cycle  <cit>  and host cell infection by influenza a, including the viral replication cycle . we have also re-created a model of erbb signaling and regulation of the g1/s transition in the cell cycle during breast cancer. this model was initially created by the authors to study trastuzumab resistance and predict possible drug targets in breast cancer  <cit> . all of these models are now available and published in the cell collective, hence available to the scientific community as seed models for further contributions and/or simulations and analyses.

collaboration and accessibility
as discussed in the background section, collaboration amongst laboratory scientists working in different areas of complex biological processes and the accessibility to modeling frameworks is key to new discoveries using the systems approach. these two properties were strictly kept in mind when designing the software, and provide the main framework for the cell collective.

first, motivated by this framework was the use a wiki-like format to keep track of the knowledge concerning the dynamical properties of biological process. this framework was also applied to the way users interact with the actual computational models.

perhaps the most important feature in the context of accessibility is the concept of “published models” . these models created by the community are freely accessible to all registered users, fostering the idea of open science. all users can view the bio-logic as well as the information in the knowledge base, and perform real time simulations on these models directly. to make changes to these models and see how these modifications affect the dynamics of the model, users can create personal copies of published models. once a copy of a published model is created, the copy will be available and visible only to the one user until shared under “my models” as seen in figure  <dig>  

my models is a collection of models created by any given user. users have an additional ability to share and collaborate on any of these models with a select group of colleagues. the degree to which such a collaboration can take place is guided with the choice of three types of permission a user can specify when sharing his/her model. first, models can be shared such that other users can simulate the shared models and view the model’s bio-logic. a second way of model sharing also allows other users to contribute to the models and directly edit them. finally, models can be also shared so that other users become model administrators and have the same rights as the creator of the model, including the ability to share the model with additional collaborators.

many biomedical research software tools  tend to limit users in such a way that once the user commits to the tool, it becomes difficult to move their data to a different platform. this is exactly the opposite with the cell collective. in addition to being able to share models with any and every user of the platform, features to export models in formats that can work with other modeling tools are also available. in the most recent version, users can export all mathematical expressions for each model  in the form of flat text files as well as sbml .

finally, a forum is available as part of the cell collective modeling suite. this will afford users additional means of communication with the scientific community as well as with the platform’s development team.

CONCLUSIONS
because of the inherent size and complexity of biochemical networks, it is extremely difficult for a single person or group to efficiently transfer the vast amount of laboratory data into a mathematical representation; this fact applies to any modeling technique. one way to address this issue is to engage the community of laboratory scientists that have generated these data and, hence, have first-hand knowledge of the local protein-protein regulatory mechanisms. if the community of laboratory scientists had a mechanism by which they could collaborate and contribute their intimate knowledge of local interactions into a large-scale global model, the creation of these models would be greatly enhanced in terms of both size and accuracy. as most laboratory scientists communicate their data in qualitative terms, rule-based models which utilize such qualitative information provide an ideal candidate for that platform.

although qualitative models do not require an understanding of high level mathematics, it does assume that users dealing with these models are familiar with rule-based  formalisms. at first, this may seem a subtle issue , however, the boolean truth tables  get more complex as the size of the model increases. this complexity effectively creates another challenge in building large-scale models. the cell collective and its major component, bio-logic builder , aims at bridging this gap by enabling users to create these dynamical models without having to directly interact with the model’s mathematical complexities.

the collaborative nature of the cell collective also opens doors to more open and reproducible science. by integrating biological knowledge, currently dispersed across hundreds of scientific papers, scientists will be able to test the integrity of this knowledge in the context of the b/iological processes as a whole. the model building process will make it easier to identify published results that contradict each other, as well as find gaps in current knowledge that may have not been realized. using a modeling platform such as the cell collective has the potential to generate new hypotheses that can be further verified in the laboratory.

furthermore, the non-technical and easy-to-use nature of building and simulating computational models in the cell collective, the platform has a potential as a great educational tool for undergraduate and graduate biology students with diverse mathematical/computer science skills. rather than studying biochemical pathways presented in current textbooks as “static” and isolated components of the cell, students can easily visualize and start understanding cells as complex, dynamical systems – precisely as is the case with real cells. large models available in the cell collective allow for the instruction of experimental design – because modeled biological processes have  properties of the real counterparts, students can learn how to design experimental studies, including the concepts of controls. students can also create simple cellular models and study the dynamical properties of a wide range of molecular subsystems such as positive and negative feedback loops.

we are actively developing new features and making the cell collective even more intuitive for users to interact with it. we are also working on implementing a plug-in system to allow the community to be directly involved in the development of additional features.

availability and requirements
the cell collective is platform independent, and can be accessed through any modern web browser . data made public in the cell collective are governed with gnu gpl v. <dig>  the platform is free for academic use.

competing interests
the authors declare that they have no competing interests.

authors contributions
th and jar conceived the platform. th designed the software and led the development. bk, ms, sm, and kl developed the software. th, jar, kb, ms, sm, kl, and am tested the software. th and jar wrote the manuscript. all authors read and approved the final manuscript.

supplementary material
additional file 1:
real time simulation example. video example of a real time simulation of a large-scale model of intracellular signal transduction.

click here for file

 acknowledgements
this project was supported and funded by the college of arts and sciences at the university of nebraska at omaha, the university of nebraska foundation, and patrick j. kerrigan and donald f. dillon foundations.
