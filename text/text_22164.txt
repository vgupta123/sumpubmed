BACKGROUND
next generation sequencing technologies  have drastically accelerated the generation of sequenced genomes. however, these technologies remain unable to provide a single sequence per chromosome. instead, they produce a large and redundant set of reads, with each read being a piece of the whole genome. because of this redundancy, it is possible to detect overlaps between reads and to assemble them together in order to reconstruct the target genome sequence.

even today, assembling reads remains a complex task for which no single piece of software performs consistently well  <cit> . the assembly problem itself has been shown to be computationally difficult, more precisely np-hard  <cit> . practical limitations arise both from the structure of genomes  and from the sequencing biases . applied solutions represent the sequence of the reads in an assembly graph: the labels along a path of the graph encode a sequence. currently, most assemblers rely on two types of graphs: either the de bruijn graph  for the short reads produced by the second generation of sequencing technologies  <cit> , or for long reads the overlap graph  and variants thereof, like the string graph  <cit> . then, the assembly algorithm explores the graph using heuristics, selects some paths and outputs their sequences. due to these heuristics, the set of sequences obtained, called contigs, is biased and fragmented because of complex patterns in the graph that are generated by sequencing errors, and genomic variants and repeats. the set of contigs is rarely satisfactory and is usually post-processed, for instance, by discarding short contigs.

the most frequent computational task for analyzing a set of reads is mapping them on a reference genome. numerous tools are available to map reads when the reference genome has the form of a set of sequences . the goal of mapping on a finished genome sequence is to say whether a sequence can be aligned to this genome, and in this case, at which location. this is mostly done with a heuristic  alignment procedure that authorizes a small edit or hamming distance between the read and genome sequences. read mapping process suffers from regions of low mappability  <cit> . repeated genomic regions may not be mapped precisely since the reads mapping on these regions have multiple matches. when a genome is represented as a graph, the mappability issue is reduced, as occurrences of each repeated region are factorized, limiting the problem of multiple matches of reads.

when the reference is not a finished genome sequence, but a redundant set of contigs, the situation differs. the mapping may correctly determine whether the read is found in the genome, but multiple locations may for instance not be sufficient to conclude whether several true locations exist. conversely, an unfruitful mapping of a read may be due to an incomplete assembly or to the removal of some contigs during post-processing. in such cases, we argue it may be interesting to consider the assembly graph as a  reference instead of the set of contigs. then mapping on the paths of this graph is needed to complement mapping on set of contigs. this motivates the design and implementation of bgreat.

in this context, we explore the problem of mapping reads on a graph. aligning or mapping sequences on sequence graphs  has already been explored in the literature in different application contexts: assembly, read correction, or metagenomics.

in the context of assembly, once a dbg has been built, mapping the reads back to the graph can help in eliminating unsupported paths or in computing the coverage of edges. to our knowledge, no practical solution has been designed for this task. cerulean assembler  <cit>  mentions this possibility, but only uses regular alignment on assembled sequences. allpaths-lg  <cit>  also performs a similar task to resolve repeats using long noisy reads from third generation sequencing techniques. its procedure is not generic enough to suit the mapping of any read set on a dbg. from the theoretical view point, the question is related to the np-hard read-threading problem , which consists in finding a read coherent path in the dbg . the assembler called spades  <cit>  threads the reads against the dbg by keeping track of the paths used during construction, which requires a substantial amount of memory. here, we propose a more general problem, termed de bruijn graph read mapping problem , as we aim at mapping to a graph any source of ngs reads, either those reads used for building the graph or other reads.

recently, the hybrid error correction of long reads using short reads has become a critical step to leverage the third generation of sequencing technologies. the error corrector lordec  <cit>  builds the dbg of the short reads, and then aligns each long read against the paths of the dbg by computing their edit distance using a dynamic programming algorithm . for shorts reads correction, several tools that evaluate the k-mer spectrum of reads to correct the sequencing errors use a probabilistic or an exact representation of a dbg as a reference  <cit> .

in the context of metagenomics, wang et al.  <cit>  have estimated the taxonomic composition of a metagenomics sample by mapping reads on a dbg representing several genomes of closely-related bacterial species. in fact, the graph collapses similar regions of these genomes and avoids redundant mapping. their tool maps the read using bwa on the sequence resulting from the random concatenation of unitigs of the dbg. hence, a read cannot align over several successive nodes of the graph . similarly, several authors have proposed to store related genomes into a single, less repetitive, dbg . however, most of these tools are efficient only when applied to very closely related sequences that result in flat graphs. the blastgraph tool  <cit> , is specifically dedicated to the mapping of reads on graphs, but is unusable on real world graphs .

here, we formalize the mapping of reads on a de bruijn graph and show that it is np-complete. then we present the pipeline ggmap and dwell on bgreat, a new tool which enables to map reads on branching paths of the dbg . for the sake of efficiency, bgreat adopts a heuristic algorithm that scales up to huge sequencing data sets. in section results, we evaluate ggmap in terms of mapping capacity and of efficiency, and compare it to mapping on assembled contigs. finally, we discuss the limitations and advantages the of ggmap and give some directions of future work .

methods
we formally define the problem of mapping reads on a dbg and investigate its complexity . besides, we propose a pipeline called ggmap to map short reads on a representation of a dbg . this pipeline includes bgreat, a new algorithm mapping sequences on branching paths of the graph .

complexity of mapping reads on the paths of a dbg
in this section, we present the formal problem we aim to solve and prove its intractability. first, we introduce preliminary definitions, then formalize the problem of mapping reads on paths of a dbg, called the de bruijn graph read mapping problem , and finally prove it is np-complete. our starting point is the well-known hamiltonian path problem ; we apply several reductions to prove the hardness of dbgrmp.

definition <dig> .
given a set of strings s={r <dig> r <dig> …,rn} on an alphabet Σand an integer k≥ <dig>  the de bruijn graph of order k of s ) is a directed graph  where: 
 v={d∈Σk|∃i∈{ <dig> …,n}suchthatdisasubstringofri∈s},anda={∣ifthesuffixoflengthk−1ofdisaprefixofd′}. 

definition <dig> .
let g be a directed graph. 
a walk of g is an alternating sequence of nodes and connecting edges of g.

a path of g is a walk of g without repeated node.

a hamiltonian path is a path that that visits each node of g exactly once.



definition <dig> .
let g be a de bruijn graph of order k. a walk of g composed of l nodes  generates a sequence of length k+l− <dig> obtained by the concatenation of v <dig> with the last character of v <dig>  of v <dig> …, of vl.

we define the de bruijn graph read mapping problem  as follows:

definition <dig> .
given 
s, a set of strings over Σ,

k, an integer such that k≥ <dig> 

q:=q1…q|q| a word of Σ∗ such that |q|≥k,

a cost function f:Σ×Σ→ℕ, and

a threshold t∈ℕ,



decide whether there exists a path of the dbgk composed of |q|−k+ <dig> nodes  such that the cost c:=∑i=1|q|f≤t.

we recall the definition of the hamiltonian path problem , which is np-complete  <cit> .

definition <dig> ).
given a directed graph g, the hpp consists in deciding whether there exists a hamiltonian path of g.

to prove the np-completeness of dbgrmp we introduce two intermediate problems. the first problem is a variant of the asymmetrical travelling salesman problem.

definition <dig> ).
let 
l be an integer,

g:= be a directed graph whose edges are labeled with a non-negative integer cost ,

t∈ℕ be a threshold.



flatsp consists in deciding whether there exists a path p:= of g composed of l nodes whose cost c:=∑j=1l−1c) satisfies c≤t.

we consider the restriction of flatsp to instances having a unit cost function = <dig> for any a∈a) and where l equals both the threshold and the number of nodes in v. this restriction makes flatsp very similar to hpp, and the hardness result quite natural.

proposition <dig> 
flatsp is np-complete even when restricted to instances with a unit cost function and satisfying l=|v|=t.

proof.
we reduce hpp to an instance of flatsp where the cost function c simply counts the edges in the path, and where the path length l equals the threshold t and the number of nodes in v.

let g= be a directed graph, which is an instance of hpp. let h=, and l:=|v| and t:=l. thus  is an instance of flatsp.

let us now show that there is an equivalence between the existence of a hamiltonian path in g and the existence of a path p= of h such that c≤t. assume that g has a hamiltonian path p. in this case, p is also a path in h of length |v|, and then the cost of p equals its length, i.e. c=∑i=1|v|1=|v|. hence, there exists a path p of h such that c≤t=|v|.

assume that there exists a path p= of h such that c≤t. as p is a path it has no repeated nodes, and as by assumption l=|v|, one gets that p is a hamiltonian path of h, and thus also a hamiltonian path of g, since g and h share the same set of nodes and edges.

the second intermediate problem is called the read graph mapping problem  and is defined below. it formalizes the mapping on a general sequence graph. hence, dbgrmp is a specialization of grmp, since it considers the case of the de bruijn graph.

definition <dig> .
given 
a directed graph g=, whose edges are labeled by symbols of the alphabet ,

q:=q1…q|q| a word of Σ∗,

a cost function f:Σ×Σ→ℕ,

a threshold t∈ℕ,



grmp consists in deciding whether there exists a path p:= of g composed of |q|+ <dig> nodes, which generates a word m:=m1…m|q|∈Σ|q| such that mi:=x), and which satisfies ∑i=1|q|f≤t. here, m is called the word generated by p.

proposition <dig> 
grmp is np-complete.

proof.
we reduce flatsp to grmp.

let ,l∈ℕ,t∈ℕ) be an instance of flatsp. let Σ={y <dig> …,y|Σ|} an alphabet larger than the largest value of c, and let s be the application such that s:{ <dig> …,|Σ|}→Σ and such that for each i in { <dig> …,|Σ|}, s=yi. let h= and let α be a letter that does not belong to Σ, let q=αl− <dig> and f such that for each i in { <dig> …,|Σ|}, f=i. thus, we obtain |q|=l− <dig> 

now, let us show that there is an equivalence between the existence of a path p= of g such that c≤t and the existence of a path p′= of h composed of |q|+ <dig> nodes, which generates a word m=m1…m|q| of Σ|q|, where each mj=x), and such that ∑j=1|q|fmj,qj≤t. assume that there exists a path p= of g such that c≤t. by definition, p is a path in h. let m be the word generated by p. thus we have ∑j=1|q|fmj,qj=∑j=1l−1f=∑j=1l−1c)≤t.

now, suppose that there exists a path p′= of h composed of |q|+ <dig> nodes, which generates a word m=m1…m|q| of Σ|q|, where each mj=x), and such that ∑j=1|q|fmj,qj≤t. by the construction of h, p′ is a path in g of length |q|+1=l. hence, we obtain ∑j=1l−1c)=∑j=1|q|f=∑j=1l−1fmj,qj≤t.

theorem <dig> 
dbgrmp is np-complete.
fig.  <dig> illustration of the gadget used in the proof of theorem  <dig>  encoding a directed graph into a dbg of order  <dig>  the directed graph g  admits the same words than the 2-dbg g
′ , if we ignore the numbers



proof.
let us now reduce grmp to dbgrmp.

let ,q∈Σ∗,f:Σ×Σ→ℕ,t∈ℕ) be an instance of grmp. let $ and Δ be two distinct letters that do not belong to Σ, and let Σ′:=Σ∪{$,Δ}. let v′ be a set of words of length  <dig> defined by 
  <dig> v′:=αiβj∣x=αand∃l∈vsuch thatx=βset1⋃Δi$i∣∃j∈v,such thatx=αand∄l∈vsuch that∈aset2⋃$iαi∣∃j∈v,such thatx=αand∄l∈vsuch that∈a.set <dig> 

any letter of a word in v′ is a symbol of Σ′ numbered by a node of v. moreover, if that symbol is taken from v then it labels an edge of a that goes out a node, say i, of v, and the number associated to that symbol is i. in fact, v′ is the union of three sets :

set  <dig> considers the cases of an edge of a labeled α followed by an edge labeled β, sets  <dig> and  <dig> contain the cases of an edge of a labeled α that is not preceded by another edge of a; for each such edge one creates two words: Δi$i in set  <dig> and $iαi in set  <dig> 

let h be the 2-dbg of v′; note that Σ′ is the alphabet of the words of v′. now let z be the application from v′ to Σ that for any αi of v′ satisfies z=α. . let f′:Σ′×Σ→ℕ be the application such that ∀∈Σ′×Σ, f′=f,β)=f.

let us show that this reduction is a bijection that transforms a positive instance of grmp into a positive instance of dbgrmp. assume there exists a path p:= of g which generates a word m=m1…m|q|∈Σ|q| satisfying mi=x) and such that ∑i=1|q|f≤t. we show that there exists a path p′ of g′ which generates a word m′=m1′…m|q|′∈Σ′|q| such that ∑i=1|q|f′≤t.

we build the path p′ as the “concatenation” of two paths, denoted pstart′ and pend′, that we define below. let γj:=x)vj=vj for all j between  <dig> and |q|. one has that γj∈Σ′. now, let 
 pstart′:=x)vl′x)vl,x)vlx)v1if∃l,l′∈vsuch that∈aand∈a$vlx)vl,x)vlx)v1if∃l∈vsuch that∈aand∄l′∈vsuch that∈aΔv1$v <dig> $v1x)v1otherwise.  and let 
 pend′:=γ1γ <dig> …,γ|q|−1γ|q|. 

let m′ denote the word generated by p′. clearly, one sees that m′=v1…v|q|, and since mi=zvi), one gets that z=m and ∑i=1|q|f′mi′,qi=∑i=1|q|fmi,qi≤t.

in the other direction, the proof is similar since our construction is a bijection.

ggmap: a method to map reads on de bruijn graph
we propose a practical solution for solving dbgrmp. we consider the case of short  reads with a low error rate , which is a good approximation of widely used ngs reads. since errors are mostly substitutions, mapping is computed using the hamming distance.

our solution is designed for mapping on a compacted de bruijn graph  any set of short reads, either those used to build the graph or reads from another individual or species. we recall that a cdbg is representation of a dbg in which each non branching path is merged into a single node. the sequence of each node is called a unitig. figure  <dig> shows a dbg and the associated cdbg.
fig.  <dig> a toy example of a dbg of order k with k= <dig>  and its compacted version 



in a cdbg, the nodes are not necessarily k-mers, words of length k, but unitigs, with some unitigs being longer than reads. thus, while mapping on a cdbg, one distinguishes between two mapping situations: i/ the reads mapping completely on a unitig of the graph, and ii/ the reads whose mapping spans two or more unitigs. for the latter, we say that the read maps on a branching path of the graph.

taking advantage of the extensive research carried out for mapping reads on flat strings, ggmap uses bowtie <dig>  <cit>  to map the reads on the unitigs. in addition, ggmap integrates our proposed new tool, called bgreat, for mapping reads on branching paths of the cdbg. figure  <dig> provides an overview of the pipeline.
fig.  <dig> unitig construction, as used in the proposed experiments  and ggmap pipeline. reads to be mapped can be distinct from reads used for building the graph. long unitigs are unitigs longer than the reads. we remind that tools bcalm and bowtie <dig> are respectively published in  <cit> 



ggmap takes as inputs a query set of reads and a reference dbg. to avoid including sequencing errors in the dbg, we construct the reference dbg after filtering out all k-mers whose coverage lies below a user-defined threshold c. this error removal step is a classical preprocessing step that is performed in k-mer based assemblers. the unitigs of the cdbg are computed using bcalm <dig> , using the k-mers having a coverage ≥c. ggmap uses such a set of unitigs as dbg.

we now propose a detailed description of bgreat.

bgreat: mapping reads on branching paths of the cdbg
as previously mentioned, bgreat is designed for mapping reads on branching paths of a cdbg, using reasonable resources both in terms of time and memory. our approach follows the usual “seed and extend” paradigm. more generally, the proposed implementation applies heuristic schemes, both regarding the indexing and the alignment phases.

indexing heuristic
we remind that our algorithm maps reads that span at least two distinct unitigs. such mapped reads inevitably traverse one or more dbg edge. in a cdbg, edges are represented by the prefix and suffix of size k− <dig> of each unitig. we call such sequences the overlaps. in order to limit the index size and the computation time, our algorithm indexes only overlaps that are later used as seeds. those overlaps are good anchors for several reasons: they are long enough  to be selective, they cannot be shared by more than eight unitigs , and a cdbg usually has a reasonable number of unitigs and then of overlaps. for instance, the cdbg in our experiment with human data has  <dig> million unitigs and  <dig> million overlaps for  <dig> billion k-mers). in our implementation, the index is a minimal perfect hash table indicating for each overlap the unitig starting or ending with this -mer. using a minimal perfect hash function limits the memory footprint, while keeping efficient query times .




read alignment
given a read, each of its k−1-mers is used to query the index. the index detects which k−1-mers represent an overlap of the cdbg. an example of a read together with the matched unitigs are displayed on fig.  <dig>  once the overlaps and their corresponding unitigs have been computed, the alignment of the read is performed from left to right as presented in algorithm  <dig>  given an overlap position i on the read, the unitigs starting with this overlap are aligned to the sequence of the read starting from position i. the best alignment is recorded. in addition, to improve speed, if one of the at most four unitigs ending with the same overlap is the next overlap detected on the read, then this unitig is tested first, and if the alignment contains less mismatch than the user defined threshold, the other unitigs are not considered. note that this optimization does not apply for the first and last overlaps of a read.
fig.  <dig> representation of the mapping of a read  on a cdbg, whose nodes are represented on lines  <dig>   <dig>  and  <dig>   the overlaps of the graph that are also present in the read are found .  unitigs that map the beginning and the end of the read are found .  cover the rest of the read, guided by the overlaps 



this mapping procedure is performed only if the two extremities of the read are mapped by two unitigs. the extreme overlaps of the read enables bgreat to quickly filter out unmappable reads. for doing this, the first  overlap of the read is used to align the read to the first  unitig. note that, as polymorphism exists between the read and the graph, some of the overlaps present on the read may be spurious. in this case the alignment fails, and the algorithm continues with the next  overlap. at most n alignment failures are authorized in each direction. if a read cannot be anchored neither on the left, nor on the right, it is considered as not aligned to the graph.

note that the whole approach is greedy: given two or more possible choices, the best one is chosen and backtracking is excluded. this results in a linear time mapping process, since each position in the read can lead to a maximum of four comparisons, and the algorithm continues as long as the cumulated number of mismatches remains below the user defined threshold. because of heuristics, a read may be unmapped or wrongly mapped for any of the following reasons. 
all overlaps on which the read should map contain errors, in this case the read is not anchored or only badly anchored and thus not mapped.

the n first or n last overlaps of the read are spurious, in this case the begin or end is not found and the read is not mapped. by default and in all experiments n= <dig> 

the greedy choices made during the path selection are wrong.



we implemented bgreat as a dependence-free tool in c++ available at github.com/malfoy/bgreat.

RESULTS
beforehand we give details about the data sets , then we perform several evaluations of ggmap and of bgreat. first, we compare graph mapping to mapping on the contigs resulting from an assembly . second, we assess how many reads are mapped on branching paths vs on unitigs . third, we evaluate the efficiency of bgreat in both terms of throughput and scalability , then assess the quality of the mapping itself . all bgreat alignments were performed authorizing up to two mismatches.

there are very few published tools to compare ggmap with. indeed, we found only one published tool, called blastgraph  <cit> , which was designed for mapping reads on a dbg. however, on our simplest data set coming from the e.coli genome , blastgraph crashed after ≈  <dig> h of computation. thus, blastgraph was not further investigated here.
k
c

e.coli



c.elegans_cpx and c.elegans_norm are two distinct graphs, constructed using the same read set from c.elegans genome. the suffixes norm and cpx respectively stand for “normal”  and for “complex” 



data sets and cdbg construction
for our experiments we used publicly available illumina read data sets from species of increasing complexity: from the bacterium e.coli, the worm c.elegans, and from human. detailed information about the data sets are given in additional file 1: table s <dig> .

for each of these three data sets, we generated a cdbg using bcalm. from the c.elegans read set, we additionally generated an artificially complex graph, by using small k and c values . this particular graph, called c.elegans_cpx, contains lot of small unitigs. we used it to assess situations of highly complex and/or low quality sequencing data. the characteristics of the cdbg obtained on each of these data sets are given in table  <dig> 

graph mapping vs assembly mapping
we compared ggmap to the popular approach consisting in mapping the reads to the reference contigs computed by an assembler. for testing this approach, for each of the three sets used, we first assembled them and then we mapped back the reads on the obtained set of contigs. we used two different assemblers, the widely used velvet  <cit> , and minia  <cit> , a memory efficient assembler based on bloom filters. finally, we used bowtie <dig> for mapping the reads on the obtained contigs.

the results reported in table  <dig> show that the number of reads mapped on assembled contigs is smaller than the one obtained with ggmap. we obtained similar results in terms of number of reads mapped on the assemblies yielded by velvet and minia . let us emphasize that on the human dataset, ggmap maps  <dig> additional percents of reads on the graph than bowtie <dig> does on the assembly.


e.coli

c.elegans_norm

c.elegans_cpx


we notice that the more complex the graph, the higher the advantage of mapping on the cdbg. this is due to the inherent difficulty of assembling with huge and highly branching graphs. this is particularly prominent in the results obtained on the artificially complex c.elegans_cpx cdbg.

we also highlight that our approach is resource efficient compared to most assembly processes. for instance, velvet used more than  <dig> gigabytes of memory to compute the contigs for the c. elegans data set with k= <dig>  on this data set, our workflow used at most  <dig> gb memory . in terms of throughput, using bgreat and then bowtie <dig> on long unitigs is comparable to using bowtie <dig> on contigs alone. see section ggmap performances for more details about ggmap performances.

mapping on branching paths usefulness
mapping the reads on branching paths of the graph is not equivalent to simply mapping the reads on unitigs. indeed, at least  <dig> % of reads  and up to  <dig> % of reads  map on the branching paths of the graph . these reads cannot be mapped when using only the set of unitigs as a reference. as expected, the more complex the graph, the larger the benefit of bgreat’s approach. on the complex c.elegans_cpx graph, only  <dig> % of reads can be fully mapped on unitigs, while  <dig> % of them are mapped by additionally using bgreat. on a simpler graph as c.elegans_norm the gap is smaller, but remains significant . complete mapping results are shown in additional file 1: table s <dig> 
fig.  <dig> 
ggmap mapping results for the different read sets. in the “c.elegans_norm ” case, reads from srr <dig> are mapped on the cdbg obtained using reads from read set srr <dig>  for all other results, the same read set was used both for constructing the cdbg and during the mapping



non reflexive mapping on a cdbg
the ggmap approach is also suitable for mapping a distinct read set from the one used for constructing the dbg. we mapped another read set from c.elegans  on the c.elegans_norm cdbg. results in this situation are similar to those observed when performing reflexive mapping : among  <dig> % of mapped reads,  <dig> % were mapped on branching paths of the graph .

ggmap performancestable  <dig> time and memory footprints of bgreat and bowtie2

bgreat

e.coli

c.elegans_cpx

c.elegans_norm

c.elegans_norm
indicated wall clock times use four cores, except for the human samples for which  <dig> cores were used



ggmap accuracy
to measure the impact of the read alignment heuristics, we forced the tool to explore exhaustively all potential alignment paths once a read is anchored on the graph. results on the e.coli dataset show that the greedy approach is much faster than the exhaustive one , while the mapping capacity is little impacted: the overall number of mapped reads increases by only  <dig>  % with the exhaustive approach. we thus claim that the choice of the greedy strategy is a satisfying trade-off.

to further evaluate the ggmap accuracy, we assess the recall and mapping quality in the following experiment. we created a cdbg from human chromosome  <dig> . thus, each k-mer of the chromosome appears in the graph. furthermore, from the same sequence, we simulated reads with distinct error rates . for each error rate value, we generated one million reads. we evaluated the ggmap results by mapping the simulated reads on the graph. as the graph is error free, except in some rare cases due to repetitions, the differences between a correctly mapped read and the path it maps to in the graph occur at erroneous positions of the read. if this is not the case, we say that the read is not mapped at its optimal position. among the error free positions of a simulated read, the number of mismatches observed between this read and the mapped path is called the “distance to optimal”. results are reported in table  <dig> together with the obtained recall . those results show the limits of bgreat while mapping reads from divergent individuals. with  <dig> % of substitutions in reads, only  <dig>  % of the reads are perfectly mapped. nevertheless, with this divergence rate,  <dig>  % of reads are mapped at distance at most one from optimum. with over  <dig> % of perfectly mapped reads, these results show that with the current sequencing characteristics, i.e. a  <dig>  % error rate, the mapping accuracy of bgreat is suitable for most applications.ggmap mapping results on simulated reads from the reference of the human chromosome  <dig> with default parameters

results show the recall of ggmap and the quality of bgreat mapping, as represented by the “distance to optimum” value. for instance  <dig> % of the reads were mapped without error,  <dig> % were mapped with a distance to the optimum of one etc. due to approximate repeats in human chromosome  <dig>  the reported distance to optimum is an upper bound



discussion
we proposed a formal definition of the de bruijn graph read mapping problem  and proved its np-completeness. we proposed a heuristic algorithm offering a practical solution. we developed a tool called bgreat implementing this algorithm using a compacted de bruijn graph  as a reference.

from the theoretical viewpoint, the problem dbgrmp considers paths rather than walks in the graph. the current proof of its hardness does not seem to be adaptable to the cases of walks. a perspective is to extend the hardness result to that more general case.

we emphasize that our proposal does not enable genome annotation. it has been designed for applications aiming at a precise quantification of sequenced data, or a set of potential variations between the reads and the reference genome. in this context, it is essential to map as much reads as possible. experiments show that a significant proportion of the reads  can be only mapped on branching paths of the graph. hence, mapping only on the nodes of the graph or on assembled contigs is thus insufficient. this statement holds true when mapping the reads used for building the graph, but also with reads from a different experiment. moreover, our results show that a potentially large number of reads  that are mapped on a cdbg cannot be mapped on a classical assembly.

with ggmap, the mapping quality is very high: using human chromosome  <dig> as a reference and reads with a realistic error rate , over  <dig> % of the reads are correctly mapped. the same experiment also pointed out the limits of mapping reads on a divergent graph reference : approximately  <dig> % of the reads are mapped at a suboptimal position.

a weak point of bgreat lies in its anchoring technique. reads mapped with bgreat must contain at least one exact k−1-mer that is an arc of the cdbg, i.e., an overlap between two connected nodes. this may be a serious limitation when the original read set diverges greatly from the reads to be mapped. improving the mapping technique may be done by using not only unitig overlaps as anchors at the cost of higher computational resources. another solution may consist in using a smarter anchoring approach, like spaced seeds, which can accommodate errors in the anchor  <cit> .

a natural extension consists in adapting bgreat for mapping, on the cdbg obtained from short reads, the long  and noisy reads produced by the third generation of sequencers, whose error rate reaches up to  <dig> % . such adaptation is not straightforward because of our seeding strategy, which requires long exact matches. the anchoring process must be very sensitive and very specific, while the mapping itself must implement a blast-like heuristic or an alignment-free method. however, mapping such long reads on a dbg could be of interest for correcting these reads as in  <cit> , or for solving repeats, if long reads are mapped on the walks  of the dbg. our np-completeness proof only considers mapping on  paths. proving the hardness of the problem of mapping reads on walks of a dbg remains open.

incidentally, using the same read set for constructing the cdbg and for mapping opens the way to major applications. indeed, the graph and the exact location of each read on it may be used for i/ read correction as in  <cit> , by detecting differences between reads and the mapped area of the graph in which low support k-mers likely due to sequencing errors are absent, or for ii/ read compression by recording additionally the mapping errors, or for iii/ both correction and compression by conserving only for each read its mapping location on the graph.

having for each read  its location on the cdbg also provides the opportunity to design algorithms for enriching the graph, for instance enabling a quantification that is sensitive to local variations. this would be valuable for applications such as variant calling, analysis of rna-seq variants  <cit> , or of metagenomic reads  <cit> .

additionally, bgreat results provide pieces of information for distant k-mers in the cdbg, about their co-occurrences in the mapped read data sets. this offers a way for the resolution, in the de bruijn graph, of repeats larger than k. it could also allow to phase the polymorphisms and to reconstruct haplotypes.

CONCLUSIONS
a take home message is that read mapping can be significantly improved by mapping on the structure of an assembly graph rather than on a set of assembled contigs . this is mainly due to the fact that assembly graphs retains more genomic information than assembled contigs, which also suffer from errors induced by the complexity of assembly. moreover, mapping on a compacted de bruijn graph can be fast. the availability of bgreat opens the door to its application to fundamental tasks such as read error correction, read compression, variant quantification, or haplotype reconstruction.

abbreviations
cdbg, compacted de bruijn graph; dbg, de bruijn graph; dbgrmp, de bruijn graph read mapping problem; flatsp, fixed length assymetric travelling salesman problem; grmp, graph read mapping problem; hpp, hamiltonian path problem

additional file
additional file  <dig> read mapping on de bruijn graphs additional file. three complementary tables are presented. main characteristics of data sets used in this study. assembly and mapping approach comparison. results of bgreat on real read sets. 



