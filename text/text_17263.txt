BACKGROUND
the function of a protein is brought about by its three-dimensional structure the knowledge of which can be instrumental to several applications, ranging from function assignment to the prediction of its mode of interaction with its molecular partners to the interpretation and design of re-engineering experiments.

the obvious limiting step in exploiting the power of protein structures in many of these applications clearly lies on the availability of a relatively small number of experimentally determined protein structures, stored in the pdb  <cit> , compared to the number of known protein sequences  <cit> . this limitation can be partially overcome by the use of methods for inferring the structure of proteins from their sequences.

at present several methods are available to this end the most reliable of which remains comparative modeling, based on the observation that evolutionarily related proteins have similar structure and therefore that the knowledge of the structure of one member of a protein family  can be used as starting model for the others, provided that the evolutionary relationship can be detected at the sequence level. because functional relevant regions are better preserved in evolution, the method has the advantage that it will produce better results for the biologically relevant parts of the target protein.

comparative modeling has an additional advantage over other protein structure prediction methods: there is a known and well-studied relationship between the divergence between the sequences of two homologous proteins, indicative of their evolutionary distance, and the structural changes between the backbone atoms of their core  <cit> . this implies that, when a single template is used, it is possible to estimate beforehand the error affecting the model by measuring the percentage of identity between its sequence and that of the target protein.

the relationship has been validated several times, for example using the results of blind tests in the casp  series of initiatives  <cit> . the results of the experiments also repeatedly showed that the quality of models can be substantially improved when the whole set of sequences of the protein family are taken into account and this affects several steps of the modeling procedure, from the detection of the template to the quality of the alignment to the use of different regions from different templates in the final model. however, in this case and when multiple templates are used, the relationship between sequence and structure divergence is more difficult to estimate.

casp has also tested the ability of independent methods to estimate the quality of models demonstrating that they can achieve a significant accuracy in selecting the best model among a set of diverse predictions for the same proteins, while methods for assigning an estimated quality to single models still lag behind  <cit> .

it is obvious that the quality of a protein model dictates how effective it is for subsequent studies, however the identification of a precise and general relationship between the quality of a model and its usefulness for a specific application is still eluding the efforts of the community. the aim of the server described here is to allow developers of structure based methods to quickly test how well their method performs when models of different quality are used instead of experimental structures.

it has been shown that high-resolution models 1-2 Å rmsd away from the native counterpart can provide relevant functional information, such as the inference of enzyme reaction mechanisms  <cit>  and the interpretation of disease-causing mutations  <cit> . in some cases they have been shown to be useful in ligand-docking studies  <cit> , experimental structure determination aid  <cit>  and drug design  <cit> . as accuracy drops, the range of applications narrows.

we reasoned that the easiest and most straightforward way to help solving the issue is to provide method developers with a curated and annotated set of models at different level of accuracy for each known protein structure to rapidly test the level of accuracy required for a model to be used in place of an experimental protein structure.

we describe here how we obtained models at different levels of quality for each of the proteins of known structure and introduce a tool, modeldb, which allows easy access to them and to several relevant information about the modeled proteins.

the user can select entries on the basis of several annotations, structural and functional domains, gene ontology and enzyme commission numbers extracted directly from publicly available databases.

the server also includes a tool to build a homology model of a protein of unknown structure and to compare the model with the template used to build it.

methods
dataset
the initial dataset of proteins included proteins solved by x-ray crystallography alone or in complex with other molecules as available on january 3rd  <dig>  filtered not to contain any pair with more than 50% sequence identity , excluding those structures with only cα atoms, with a resolution worse than 2 Å, with a sequence length outside the range 20– <dig> residues, and with an r-factor higher than  <dig> . we were left with a total of  <dig>  pdb chains. we could detect suitable templates, and therefore build comparative models, for  <dig>  of them. of these  <dig>  have an ec number ,  <dig>  with a complete 4-digit ec number ;  <dig>  bind to ligands ,  <dig>  of them to more than one , and there are  <dig>  different ligands found binding to this subset of modeled chains ;  <dig>  have at least one annotated catalytic site ,  <dig> of them have more than one catalytic site ;  <dig>  are annotated in swiss-prot .

modeling strategy
the modeldb modeling pipeline, written in perl, relies on hhsearch  <cit>  for template identification and modeller  <cit>  for building the complete model.

the sequence of each pdb chain is used as query in hhsearch to search for templates in the 70% non-redundant pdb database. all target-single template alignments with 80% minimum sequence coverage and 10- <dig> maximum e-value were used as input for modeller to produce an all non-hydrogen atom single-template model for each of the selected sequences.

superposition of the models to the corresponding experimental structure
each model of each target protein was compared to the corresponding experimental structure using lga   <cit> . we record the gdt-ts and rmsd values and allow sorting the models according to these parameters  as well as to hhsearch probability, e-value, score and coverage.

functional annotation
each pdb structure in the input list  is annotated whenever possible at the residue level, using the credo database  <cit>  that collects protein-ligand interactions, the catalytic site atlas   <cit>  that includes information about enzyme catalytic sites, and swiss-prot.

model visualization
experimental structures and their models can be visualized and colored at the residue level according to solvent accessibility and secondary structure as computed by dssp  <cit> , cavity occurrences and average depth as defined by speedfill  <cit> , and protrusion and burial indexes obtained via psaia  <cit> .

this visualization is obtained using an in-house perl program named mappon. a stand-alone version of mappon is also available to visualize the parameters described above and also the disorder probability , evolutionary residue conservation and variability  on user provided structures. the tool is accessible via the modeldb site.

subsets of proteins can be selected on the basis of their functional and structural domains, go annotation and enzyme commission numbers.

model building
the user can build a homology model of a protein of unknown structure using modeller  <cit>  on the basis of templates identified using hhpred  <cit>  and compare its structure with those of the templates used to build it taking advantage of all the described visualization tools.

RESULTS
database composition
models for the  <dig>  proteins obtained as described in methods and annotated at the residue level with information about secondary structure, solvent accessibility, cavity occurrence, average depth and protrusion and burial indexes are stored in the modeldb relational database.

the average number of models per pdb chain in the database is  <dig>  the largest number of models being  <dig> for  chain a. the distribution of the number of models is shown in figure  <dig>  while figure  <dig> shows the distribution of the average gdt-ts and standard deviation values for the models in the database.

modeldb
the modeldb database can be accessed via the publicly available modeldb web server. both can also be downloaded and installed locally.

modeldb server
the modeldb pipeline was used to build the pre-calculated model sets stored in the database and can be used to build models for user-provided structures. in this case, input sequences are subjected to the same procedure described in methods for building the database.

the modeldb web interface  is conceived to be as user-friendly as possible and has several features. a user can either specify a pdb code or upload a protein structure of interest, in both cases the chain needs to be specified .

if the input protein is not present in the database or the user changed the default parameters for modeling, the modeling program is launched. this is followed by a blast search with stringent parameters  against pdb and swiss-prot, to retrieve information and functional annotations for the protein entry or for a very close homologue.

upon completion of these steps, the output page described next, which is directly displayed if the entry is already stored in the database, is shown.

the page contains a short description of the protein and a sortable table  where the models are listed and can be ranked. one or more models can be visualized using a jmol applet  and are shown superimposed to the experimental structure. different representations are possible  and solvent excluded and solvent accessible surfaces can be rendered. a state win-dow records what happens in the jmol applet . the user can also rotate the axes in the jmol window and create images.

there is the possibility to color the structures and surfaces according to different coloring schemes . collapsible boxes provide functional annotation . functional residues as well as the distance in Å between corresponding cαs of the experimental and modeled structure can be visualized in the structure. finally, the models of a given protein can be downloaded as a zip file.

some examples of application
we show here examples of how the modeldb server can be used to identify the level of accuracy required for simple structure-based computations.

for example, models are often used to identify suitable locations for modifications or functionalization of the protein. therefore one could ask to which extent the classification between exposed and buried residues can still be made using a model and which is the minimum level of model quality required to obtain meaningful results. we defined exposed residues as those with a solvent accessibility value above 70%  with respect to the maximum residue value, as defined by miller et al.  <cit> . as shown in figure  <dig>  one can correctly identify 75% of the exposed residues in more than 40% of models with a gdt-ts above  <dig>  and in almost 30% of those with a gdt-ts above  <dig>  below the latter threshold, the percentage of models where at least 75% of the exposed residues are correctly detected reaches 10%. this is relevant to keep in mind when using models as frameworks for experiments.

another common use of models concerns the identification of enzyme active sites. it is known that binding sites tend to occur in the largest cavity on the surface of proteins  <cit> , so the obvious question is how well this property is conserved in models of different quality. our data  show that only in a 20% of the models with a gdt-ts above  <dig> can at least 75% of the residues constituting the largest cavity be detected . it follows that this approach is not very suitable for medium to low quality models and perhaps it should be parameterized differently for these cases. the situation moderately improves when the subset of enzymes stored in csa is considered .

the last question we asked is whether the relative position of residues forming an active site, and therefore well conserved throughout evolution, can be reliably measured using models. this is relevant because in many cases the identification of specific residues at a given distance from each other are very good signs of the presence of an active site.

we measured the euclidean distance differences between every permutation of catalytic residue cαs constituting an active site  in the native structure and in its models of varying quality. averaging all the differences over each active site showed an increasing mean euclidean distance difference as model quality decreases in terms of gdt-ts . however, the maximum mean value of the difference per site  is never much higher than  <dig>  Å, implying that the catalytic residues relative positions can be effectively estimated also in models of relatively low quality .

CONCLUSIONS
since the gap between known protein sequences and structures continues to increase, researchers need to make use of protein structural models more routinely. models usually contain structural inaccuracies that vary in number and severity, but they can still provide important insights into a protein role. there is no general rule that relates model accuracy with its usefulness for different applications, therefore there is the need to test the model quality tolerance for each specific structure-based method. modeldb, the tool introduced here, serves this purpose by rapidly generating decoy sets for the proteins of interest. these decoys are intended to be used to test structure-based methods and decide to which extent each method can be applied to computed protein structure models. the tool allows the establishment of the quality threshold at which interpretable results, analogous to the ones that would be obtained with native structures, can be produced.

the project has involved the implementation of a pipeline divided in programs that work together, but also exist independently, either on-line or for local use when larger calculations are demanded. the modeldb modeling pipeline takes a protein structure as input to generate single-template decoy models; it makes use of an in-house program named mappon to visualize the structures and the models colored according to different descriptors . the on-line versions of both modeldb and mappon query a relational database that not only contains pre-calculated decoy models, but also functional annotations extracted from different sources.

modeldb contains decoy models created for a significant subset of the pdb, thereby covering a significant portion of the protein structural space compared to the other resources; this portion will increase as new decoy sets will be built and stored in the database. individual decoy sets themselves are expected to cover wider quality ranges in new releases as more structures are deposited in the pdb. last but not least, modeldb also provides a visualization window where any decoy in a set, colored according to different descriptors, can be loaded, inspected and compared with its native counterpart.

competing interests
the authors declare that they have no competing interests.

authors’ contributions
at designed the study. dc implemented the method. at and dc wrote the paper. both authors have read and approved the final manuscript.

