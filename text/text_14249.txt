BACKGROUND
the accurate delineation of protein domain boundaries is an important step for the prediction of protein structure, function, evolution and design. since a single domain spans an entire polypeptide chain or a subunit of such a chain, domains provide one of the most useful sources of information for understanding protein function, analysis based on domain families, and the study of individual proteins  <cit> .

proteins are composed of smaller building blocks, which are called "domains" or "modules". these building blocks are distinct regions in three-dimensional  structure resulting in protein architectures assembled from modular segments that have evolved independently  <cit> . the modular nature of proteins has many advantages, offering new cooperative functions and enhanced stability. for example, new proteins, such as chimeric proteins, can be created because they are composed of multi-functional domains  <cit> . the search method for templates used in comparative modelling can be optimised by delineating domain boundaries, since the templates are classified on the basis of domains  <cit> . domain boundary prediction can improve the performance of threading methods by enhancing their signal-to-noise ratio  <cit> , and for homologous domains plays a key role in reliable multiple sequence alignment  <cit> .

over the past three decades, a large number of methods using the 3d coordinates of protein structure have been proposed for more accurately delineating domain boundaries  <cit> . however, the demand for fully automated approaches to identify domains in globular proteins from one-dimensional  atomic coordinates has significantly grown over recent years  <cit> ; because, genome and other sequencing projects have produced a flux of dna and protein sequence data  <cit> . many automated systems have shown reasonable improvements since they have successfully captured the information of a single molecule or of neighbouring residues involving short-range  interactions. however, at the same time, their limitations in the exploitation of information from long-range  interactions have been observed  <cit> . these limitations are related to model overfitting, and the weak signal-to-noise ratio associated with non-local interactions, which lead to the problem of the "vanishing gradient".

in this paper, we introduce a novel inter-range interaction integrated approach for protein domain boundary prediction. it involves  the design of modular kernel algorithm, which is able to effectively exploit the information of non-local interactions, and  the development of a novel profile that can provide suitable information to the algorithm. one of the key features of this profiling technique is the use of multiple structural alignments of remote homologues to create extended sequence profiles and combines the structural information with suitable chemical information that plays an important role in protein stability. this profile can capture the sequence characteristics of an entire structural superfamily and extend a range of profiles generated from sequence similarity alone.

RESULTS
to see the suitability of our proposed approach in domain boundary prediction, we have chosen the most widely adopted machine-learning models and profiles for comparison. our experiment has three consecutive steps. first, we compare the performance of our modular neural network, hierarchical mixture of experts  with two other well-regarded machine-learning models in protein domain boundary prediction, transductive support vector machine  and multi-layered perceptron . second, in the model comparison, the effectiveness of hydrophobicity information presented in evolutionary and hydrophobicity profile  is thoroughly tested and compared with widely known evolutionary profile, position specific scoring matrix  generated by psi-blast  <cit> . last, the performance of our modular kernel approach  that consists of hme model and eh-profile is compared with three other protein domain boundary predictors on benchmark_ <dig> and casp <dig> datasets.

the performance of each model was measured by the fractions of true negative and true positive  and tpf: the proportion of true positive data correctly predicted), the sensitivity , the specificity , correlation-coefficient  and accuracy . cc reflects a situation in that a method, which predicts every residue to be positive, shows a prediction accuracy of 100% in detecting positive boundaries, but 0% accuracy for negative residues. hence, a high value of cc means that the model is regarded as a more robust prediction system.

we adopted a sevenfold cross-validation scheme for the model evaluation. cross validation effectively solves the potential problems caused by residual evaluations. because the residual uses the entire dataset in the training, it does not give an indication of how well the model will predict for unseen data. for this reason, we remove some of the data before training begins. when training is completed, the data that was removed can be used to test the performance of the learned model on new data. the advantage of this method is that it matters less how the data gets divided. every data point gets to be in one of the test sets , and gets to be in one of the training sets .

in this experiment, the dataset is divided into seven subsets, and the holdout method is repeated seven times. each time, one of the seven subsets is used as the test set and the other  subsets are put together to form a training set. the estimated prediction accuracy is the average of the prediction accuracy for the models, derived from the independently and randomly generated test divisions.

in our preliminary experiments  <cit> , we tested five different window sizes  for each model and found that the window size of  <dig> is the most suitable for our experiments. a window size of  <dig> means which contain  <dig> amino acids with  <dig> preceding and  <dig> following amino acids for the boundary residue .

mean testing data Â± standard deviation obtained using anova test using optimal settings for each model.

finally, our modular kernel approach  that comprises hme model and eh-profile, and three other well-known predictors, were evaluated on benchmark_ <dig> and casp <dig> datasets. dompro  <cit>  uses evolutionary information , secondary structure and solvent accessibility information with a recursive neural network. dompro is trained and tested on a curated dataset derived from the cath database. it achieved a sensitivity and specificity of 71% and 71%, respectively in the cafasp <dig> and was ranked among the top ab initio domain predictors. domnet  <cit>  is a recently introduced machine-learning algorithm that uses a novel compact domain profile . it outperformed nine other machine-learning methods on benchmark_ <dig> dataset. domnet is trained with an inter-domain linker-region index, secondary structure and relative solvent accessibility information with cd-profile. cd-profile uses additional structural information from conserved-domain database  <cit>  because conserved domains contain conserved sequence patterns or motifs, which allows for their detection in polypeptide sequences. hence, the pssms in conserved domain database can be useful to find remote homology. dompred  <cit>  uses a combined homology and fold-recognition based approach. the sequence homology approach simply attempts to distinguish boundaries from overlapping edges in psi-blast multiple sequence alignments using hidden markov models. the fold recognition approach relies on secondary structure element alignments, using domssea method  <cit>  to find domain boundaries in more distant homologs. the domssea has been shown to provide a rapid prediction of the fold for given sequences with no detectable homology to any known structure and have also been applied to the related problem of novel fold detection. the method has an accuracy of 49% at predicting the domain boundary location within  <dig> residues using a representative set of two domain chains.

benchmark_3: 1-domain , 2-domain , and 3-domain and more ; casp8: single-domain , and multi-domail .

mka correctly predicted  <dig> of all  <dig> targets for 1-domain chains and showed  <dig> % accuracy. the accuracy of mka was  <dig>  percentage points less than domnet in 1-domain prediction. in 2-domain prediction, domnet still performed better as it predicted  <dig> of all  <dig> chains correctly. however, with 3-domain and more chains, only mka correctly predicted with above 30% accuracy. its accuracy in this category was  <dig>  and  <dig>  percentage points higher than domnet and dompro respectively. again, mka showed the best performance  with the multi-domain proteins in casp <dig>  this means mka more consistently captures information from eh-profile and eventually leads to model stability and robustness. although it is well acknowledged that the model stability is a more important factor than the learning bias in predictive performance  <cit> , several important issues that should be taken into account in order to improve the performance of the proposed mka. this will be discussed in the next section.

two experiments performed in this study proved that hydrophobicity information presented in the eh-profile provides useful information. however, the pssms in the conserved domain database used by domnet can be of a central source, providing valuable structural/homology information. because, conserved sequence patterns in the pssms of conserved domain database are effectively recognised by its learning model. the computational learning model was also specially designed for processing high-dimensional data with the focus of the exploitation of local-interaction information. because of these capacities, the predictor showed even more powerful performance in the prediction of single-domain proteins and as demonstrated in the two above-mentioned experimental results.

discussion
although many machine-learning-based domain predictors have been developed, they have shown limited capability for multi-domain proteins. our approaches used in mka were shown to be effective for multi-domain proteins. the two experiments confirmed our hypothesis that mka efficiently captures non-local interaction information while preserving accurate data modelling in domain-boundary prediction. however, as its prediction accuracy reaches only about 40% for multi-domain and 82% for one-domain proteins, there is still much room for improvement. some areas of possible improvement are discussed in this section.

non-local interactions in amino acids
as historical summaries have shown  <cit> , many researchers have built successful secondary structure predictors using machine learners such as feed-forward neural networks and support vector machines with local input windows of 9- <dig> amino acids  <cit> . over the years, the performance has steadily improved by about one percent per year. this was possible because of increased training data and several additional techniques including  output filers to cleanup predictions,  input profiles - associated with homologous sequence alignments and  predictor ensembles. the main weakness of these approaches resides in the researchers' use of a local window that cannot capture non-local information such as that presented in Î²-sheets. this is partially corroborated because the Î²-sheet class always shows the weakest performance results. substantially increasing the input window's size, however, does not seem to improve the performance. as long as we cannot fully capture information about the interaction of remote sequence positions, efficient learning for the long-range dependencies does not appear possible. the learner is given only a set of inputs and a serial order relation for them and must solve a difficult credit assignment problem to identify the interacting positions.

our modular kernel approach using hme architecture consists of comparatively simple experts  and gating networks, organised in a tree structure . the basic functional principle behind this structure is the well-known technique called "divide and conquer". this technique solves complex problems by dividing them into simpler problems for which solutions can be obtained easily. these partial solutions are then integrated to yield an overall solution to the whole problem. its architecture enforces constant error flow  through internal states of units.

many gradient-based machine learners solve their classification problem  by explicitly hard splitting the input space into sub-regions, such that only one single "expert" is contributing to the overall output of the model. the "hard splits" of the input space make algorithms to be variance increasing, especially in the case of higher dimensional input spaces where data is very sparsely distributed. in contrast, hme architecture uses a soft splitting approach to partition the input space instead of hard splitting, as is the case in statistical models, allowing the input data to be present simultaneously in multiple sub-regions. in this case, many experts may contribute to the overall output of the network, which has a variance decreasing effect.

secondary structure information
in the literature, protein secondary-structure information has been widely used for domain-boundary prediction, as it was shown to be useful for increasing prediction accuracy. most inter-domain regions are composed of loops while Î²-strands tend to form sheets that constitute the core of protein domains. the Î±-helices and Î²-sheets in proteins are relatively rigid units and therefore domain boundaries rarely split these secondary structure elements. the mutations at the sequence level can obscure the similarity between homologs. however, their secondary-structure patterns remain more conserved because changes at the structural level are less tolerated. the secondary-structure-alignment methods used in this study aim to exploit these conserved features to locate domain regions within secondary-structure strings. we obtained the secondary-structure information by one of the widely known secondary-structure predictors called sspro  <cit> . however, there is one significant limitation: the best predictor still cannot reach the upper boundary of prediction accuracy. the best secondary-structure predictors show only about 75-80% accuracy. clearly, the incorrectly predicted secondary structures are highly likely to lead to the incorrect delineation of domain boundaries. although the predicted secondary information seems to be useful for current approaches, it may not be ideal if one attempts to reach better than 80% accuracy.

hydrophobicity and profiles
one of the existing powerful methods for rapidly shifting through protein data is homology modelling, which uses dynamic-programming-alignment methods to search evolutionarily related  sequences in the databases of known sequences. in the last decade, a number of machine-learning-based systems have used evolutionary profiles that contain homology information from sequence alignments and showed striking improvements  <cit> . this has been a major breakthrough in protein structure prediction literature  <cit> . this profiling technique that provides suitable information for the base algorithm opened a way on how to effectively incorporate valuable information into computational structure prediction models.

for prediction or classification tasks, it is well-known that finding the right features or information plays key roles in improving model performance. our profiling method based on the assumption that hydrophobicity, a major factor in protein stability with a suitable homology information can provide better information for its computational leaner proved to be successful. however, many more issues need to be investigated, as indicated in various alignments studies  <cit> . one of the examples is human intervention in the adjustment of automatic alignment. as widely believed, domain expert intervention at  fold identification and  readjustments multiple alignment levels can significantly improve its accuracy. in the literature, therefore, research to develop more biologically realistic profiles has been actively reported. this should prevent the current limitations of automated methods by allowing domain experts to interact with the computation to control the quality of analysis at processing stages.

domain assignment is more accurate for proteins with fewer domains
in general, the prediction accuracy of sequence-based methods has been far smaller  for multi-domain proteins. for example, liu and rost's  <cit>  experiments on cath and scop assigned domains to random subsets of  <dig> proteins of known high-resolution structure and less than 10% sequence homology; they showed correct prediction of the number of domains  in 69% of the cases. however, the accuracy for multi-domain cases alone was only 38%. for the two continuous-domain proteins, the average accuracy of dbp prediction in different validation runs was 46-51% considering a prediction to be correct if it were in Â±  <dig> residues interval of the cath- and scop-assigned boundaries.

joshi  <cit>  discussed the main reasons for the problems in deciphering the multi-domain-protein structures and his possible solutions. with experimental data, although the structure within a domain is fixed, the relative positioning of two domains within the same chain can vary. for this reason, and because protein structural domains are independent folding units, it is unusual to find single crystal structures containing more than one domain. similarly, protein modelling by database searching, sequence alignment and/or phylogenic analysis is better performed on a single domain rather than a multi-domain polypeptide. hence, in most cases, the number of domains in a protein should first be identified to determine the locations of such domains on the primary chain before embarking on a standard method of protein-structure/function determination. the identification of linker regions connecting two distinct domains is also useful in finding domain-boundary locations; accordingly, several domain-boundary predictors employing domain-linker information, such as domcut and domaindiscovery, showed reasonably better predictive performance in domain-boundary prediction.

continuous vs. discontinuous
since wetlaufer  <cit>  introduced the classification of domains into continuous and discontinuous, a large number of researches have been done in these separate fields. continuous domains form from a single-chain segment whereas discontinuous domains are composed of two or more chain segments. the boundary prediction for discontinuous domains remains very difficult, especially from ab initio approaches. the most current and successful ab initio method for predicting discontinuous domains is snapdragon  <cit> . it is comparably reliable and as it requires a set of homologous sequences, similar to the target sequence to generate a multiple sequence alignment as input. it showed the accuracy for continuous domains is  <dig> % while only  <dig> % for discontinuous domains, with an overall accuracy of  <dig> %.

the main reason for poor performance in case of discontinuous domains appears to be that use of secondary elements is not appropriate in such cases  <cit> . a component of  local organisation is partly an element in the domain but is not sufficient as some domains are formed from segments of the protein sequence that are distant in the primary chain. the Î²-sheet also influences the definition of a domain since Î²-sheets are rarely split into separate domains. however, although one sheet would not normally be in two domains, two or more sheets might be in one domain, so again this structural element does not provide a sufficient definition.

the partitioning of the structure into domains may result in domains consisting of continuous stretches of ploypeptide chain, one stretch per domain . frequently, however, regions of the polypeptide chain that are distant in sequence, are close together in 3d structure, thus a domain may consist of two or more segments of the chain, which are non-continuous in sequence . our method simply assigns each domain segment to a separate domain, ignoring at this time the relatively rare problem of non-continuous domains.

CONCLUSIONS
we have firstly used modular kernel approach  in protein domain boundary prediction as a novel method to effectively tackle the problem of non-local interaction. our approach adopted modular hme that leverages evolutionary and hydrophobicity information in the form of profiles and also used predicted secondary structure and relative solvent accessibility. this was demonstrated in the three consecutive experiments in this study. the novel eh-profile that combines homology information with hydrophobicity from the sarah <dig> scale was successful in providing more structural and chemical information. in addition, the modular approach adopted in hme proved to be effective in capturing information from non-local interactions. each memory-based model in hme  showed a learning ability to bridge time intervals at some level in the non-local interaction environment , without much loss of a short-time-lag capability . with benchmark_ <dig> and casp <dig> datasets, our approach showed its usefulness, especially in the case of multi-domain chains.

