BACKGROUND
the omics fields hold huge promises in the investigation of various diseases. multiple examples are available in the literature showing the potential of proteomics  <cit>  and metabolomics  <cit> . both domains carry valuable information about biological pathways involved in human diseases  <cit> . proteomics aims to provide a comprehensive identification and quantification of proteins present in tissues or biofluids. this information allows one to find networks of cellular mechanisms and to get more insight into molecular disease processes  <cit> . metabolomics aims to determine the small molecule fingerprints of cellular processes. similarly to proteomics, metabolomics relies on the detection and quantification of small biomolecules, here metabolites. the proteome and metabolome separately and in combination represent an instant picture of a biological system  <cit> .

the proteome and metabolome are not disjoint. protein levels obviously influence the metabolic profile, e.g. through enzymatic reactions. on the other hand, the metabolites concentrations may affect the expression of proteins  <cit> . therefore, the combination of this information in a systems biology approach is expected to provide a more comprehensive understanding of biological entities  <cit> . various studies have been proposed to analyse jointly different metabolomics or proteomics data in order to improve the overall understanding of the system  <cit> . our aim is here to propose a new statistical approach. the objective of this method is to perform data fusion of multiple types of measurements related to the same biological system. we chose a proteomics and metabolomics platform that measured the very same csf samples. this biofluid is in close interaction with the central nervous system . therefore, csf can be expected to reflect the status of the cns. this assumption has been used to study neurological diseases such as multiple sclerosis   <cit> . mscl is an autoimmune disease and the most common cause of neurological disability in young adults  <cit> . it manifests itself as an acute, focal, inflammatory demyelination and axonal loss with limited remyelination. the disease culminates in chronic multifocal sclerotic plaques. the associated symptoms are various and follow an unpredictable course. the csf samples are relatively accessible. however, collecting samples from large cohorts of mscl patients and healthy volunteer is still a complex and time consuming task. moreover, the analysis of such clinical samples often encounters challenges related to the variation linked to genetic and environmental background.

in the frame of biomarker discovery, it is therefore more straightforward and productive to initiate an investigation from an animal model of the disease. the experimental autoimmune encephalomyelitis  model is one of the most intensively studied model of autoimmune disease  <cit> . eae, like mscl is an inflammatory disorder of cns. it is mainly used to look at the neuroinflammatory mechanism, which is one of the key hallmarks of mscl. this animal model has been reproduced in many species, including rats  <cit> . depending on the species and antigen used, the resulting eae presents a specific disease course. the acute version of this model, as used in this study, is induced by the injection of complete freund adjuvant  and myelin basic protein . the initial symptom, paralysis of the tip of the rat's tail, appears after approximately  <dig> days. this ultimately culminates in paralysis extended up to the limbs. the 10th day can be considered as the onset of disease. our main interest in this study is to define the combined proteomic and metabolomic biomarker pattern corresponding to this onset. an experimental design has been constructed to characterize the disease at this time point. the aim is to establish whether these combined biomarkers and/or biomarker profiles can act as predictive indicators of the onset of disease.

the main objective from a data analysis point of view is to extract from both proteome and metabolome all the relevant information allowing a comprehensive definition of the disease profile. it is also of the utmost importance to extract information from both platforms. indeed a shared pattern would provide insights on interactions between proteins and metabolites. this information could greatly enhance our comprehension of the disease process. for this purpose, we propose a so-called mid level fusion architecture  <cit>  based on two layers. the first layer aims to extract all the information allowing for discrimination between control and disease samples per platform. this step is hampered by the usual "curse of dimensionality", as it will be shown in the next section. the second layer is designed to fuse the information of each platform. at this point, a new problem arises related to missing measurements from platform to platform. to solve these practical problems, we propose a solution based on two methods: extended canonical variates analysis   <cit>  and a modified version of principal component analysis   <cit> . these two methods and our data analysis strategy are described in the methods section. the fusion method is then applied to the analysis of metabolomics and proteomics data of the eae experiment. the outcome of this approach allows for a better description of the data of the joint platforms than the one achieved by using the data from the two platforms separately. the variables driving the model are then explored in term of biological meaning. this allows confirming the validity of our approach. in addition, it is possible to visualize the eae biomarker profile on the systems biology level.

methods
material
induction of acute eae in lewis rat
male lewis rats  kept under normal housing conditions with water and food ad libitum, weighing between  <dig> and  <dig> grams at the start of the experiment, were inoculated on day  <dig> as previously described  <cit> . briefly, a  <dig> μl saline based emulsion containing  <dig> μl complete freund adjuvant h <dig> ra ,  <dig> μg mycobacterium tuberculosis type h37ra  and  <dig> μg guinea pig myelin basic protein  was injected subcutaneously in the pad of the left hind paw of isoflurane anaesthetized animals. next to these mbp challenged rats, referred to as the eae group, two control groups were included: a group of animals receiving the same emulsion without mbp  and a healthy group undergoing anesthesia only . each group consisted of  <dig> animals. the animals present in one given cage were all belonging to the same group. the animals were sacrificed to collect csf on day  <dig> . the design is summarized in table  <dig> 

animals were housed per  <dig> and cages were randomized across treatments and disease duration. disease symptoms and weights of all animals were recorded daily. the animal experiments described were approved by the local institutional animal care and use committee.

csf sampling
on day  <dig>  animals were euthanized with co2/o <dig>  terminal csf samples were obtained by direct insertion of an insulin syringe needle  via the arachnoid membrane into the cisterna magna. for this purpose a skin incision was made followed by a horizontal incision in the musculus trapezius pars descendens to reveal the arachnoid membrane. a volume of maximum  <dig> μl was collected per animal. each sample was centrifuged within  <dig> min after sampling, for  <dig> min at  <dig> g at 4°c. after centrifugation the supernatants were stored at -80°c for further analysis. previous experiments have shown that collecting up to  <dig> μl using this technique and conditions provided hemoglobin-free csf samples measured by esi-orbitrap. as an additional check fresh samples, supernatant and pellet size were visually scored for hemolysis and samples were discarded if positive.

from the set of  <dig> samples,  <dig> of them  were contaminated with blood and were excluded from measurements.

measurements
ms-orbitrap: samples preparation and data acquisition
 <dig> μl of rat csf sample was put into a 96-microtiter-well plate , and  <dig> μl of  <dig> % rapigest  in  <dig> mm ammonium bicarbonate buffer was added to each well. after a  <dig> min incubation period with  <dig> -dithiothreitol  and, subsequently, iodoacetamide ,  <dig> μl of  <dig>  μg/μl gold-grade trypsin / <dig> mm tris-hcl  was added to each sample. the samples were incubated overnight at 37°c. to adjust the ph of the digest to ph <  <dig>  a high concentration of trifluoroacetic acid was added to the mixture prior to a final incubation step at 37°c for a duration of  <dig> minutes to stop the digestion reaction.

mass spectrometry measurements were carried out on a ultimate  <dig> nano lc system  online coupled to a hybrid linear ion trap/orbitrap ms .  <dig> μl digest were loaded onto a c <dig> trap column  and desalted for  <dig> minutes using a flow rate of  <dig> μl/min  <dig> % tfa. then the trap column was switched online with the analytical column  and peptides were eluted with the following binary gradient: 0%-25% solvent b for  <dig> min and 25%-50% solvent b for a further  <dig> minutes, where solvent a consist of 2% acetonitrile and  <dig> % formic in water and solvent b consists of 80% acetonitrile and  <dig> % formic acid in water. the column flow rate was set to  <dig> nl/min. for ms detection a data dependent acquisition method was used: high resolution survey scan from 400- <dig> th. was performed in the orbitrap 2o)6)  <cit> ). based on this survey scan the  <dig> most intensive ions were consecutively isolated  and fragmented by collision-activated dissociation  applying 35% normalized collision energy in the linear ion trap. after precursors were selected for ms/ms, they were excluded for further ms/ms spectra for  <dig> minutes.

following a standardized noise reduction procedure, the orbitrap raw files were preprocessed using the progenesis lc-ms software package . in this software package all peaks in the raw files are aligned according to their retention time by a graphical detection algorithm. this algorithm detects the peptide peaks in a gel-view representation of the mass spectrometry data and matches corresponding peaks  between samples. strict criteria for alignment acceptance were employed . following this, peptides were identified and assigned to proteins by exporting features, for which ms/ms spectra were recorded, using the bioworks software package . the resulting. mgf file was submitted to mascot  for identification to interrogate the uniprot-database :  <dig> sequences). only ions with charge states between + <dig> and + <dig> were considered and only proteins with at least two unique peptides  assigned to them were accepted as true identifications. carbamidomethylation of cysteine was set as fixed and oxidation of methionine as variable modification allowing a maximum of  <dig> missed cleavages. mass tolerance for precursor ions was set to  <dig> ppm and for fragment ions at  <dig>  da. the cut-off for mass differences between the measured and the theoretical mass of the identified peptides was set at  <dig> ppm. the mascot search results were imported back into the progenesis software to link the identified peptides to the detected abundances of these peptides. the data were exported subsequently in excel format. in this exported excel file an abundance  is listed for all features  in all individual samples. the abundance is used instead of the peak intensity to account for tailing of the peptide peaks during the lc-separation. the differences in abundance are subsequently used for analysis of the differences between the groups for all identified peptides and proteins.

nmr: samples preparation and data acquisition
 <dig> μl of rat csf were thawed at room temperature and  <dig> μl d2o were added to biofluid in order to obtain the sufficient amount of sample for nmr measurement. we used tsp-d <dig>  as an internal standard for chemical shift reference  and metabolite quantification. for the latter,  <dig> μl of  <dig>  mm tsp-d <dig> stock solution in d2o was added to  <dig> μl of rat csf to a final concentration of  <dig>  mm tsp. the tsp-d <dig> stock was prepared by weighing in dry tsp-d <dig>  the ph of the csf was adjusted to around  <dig>  by adding phosphate buffer . the final csf nmr sample  was then transferred to a shigemi microcell nmr tube for nmr measurements.

the 1d 1h nmr spectra of rat csf samples were acquired on an  <dig> mhz inova  system equipped with a  <dig> mm triple-resonance, z-gradient hcn cold-probe. suppression of water was achieved by using watergate . for each 1d 1h nmr spectrum  <dig> scans of  <dig> k data points were accumulated with a spectral width of  <dig> hz. the acquisition time for each scan was  <dig> s. between scans, a  <dig> s relaxation delay was employed. prior to spectral analysis, all acquired free induction decays  were zero-filled to  <dig> k data points, multiplied with a  <dig>  hz line broadening function, fourier transformed, manually phase and the tsp internal reference peak was set at  <dig> ppm - by using acd/specmanager software. the set of  <dig> rat csf spectra were acquired and preprocessed as described above. however due to high line broadening of internal standard  two spectra were not included in spectral analysis. in total  <dig> spectra were subsequently transferred to matlab, version  <dig>    for further analysis.

the nmr spectral data is then preprocessed, which typically involves baseline correction, alignment, binning, normalization and scaling. baseline correction of nmr spectra was performed by applying asymmetric least square method  <cit> . fluctuation in experimental conditions like sample temperature, ph and ionic strength can lead to chemical shift variations, therefore nmr spectra were aligned by using improved parametric time warping  <cit> . a further problem is the high dimensionality of the data . it is common to apply binning to this kind of data which reduces the number of variables. to perform proper spectral bucketing we used adaptive intelligent binning  <cit> . this binning procedure, more complex than the classical binning, ensures that peaks are not divided over multiple bins. moreover it allows excluding regions without signals from the analysis. the chemical shift range δ  <dig>  -  <dig>  was used for binning procedure because it contained most relevant information. this region was selected based on visual inspection of the spectra because it contains signals with high signal to noise ratio. next, spectral resonances corresponding to one identified metabolite were summed and regrouped in one bin. this procedure was applied to the resonances were no overlapping was present and it led to  <dig> bins in total. the identification of the metabolites was performed using chenomx . for the purpose of making spectra comparable as the final step of the preprocessing approach integral normalization was applied to the binned data.

the analysis proposed in this work is initiated by an exploratory analysis. the objective here is to assess the quality of the two data sets and detect outliers. the fusion itself is performed afterwards. both steps are detailed below, respectively.

exploratory method
the different data sets have been analyzed using exploratory methods in order to detect outliers. this also provides some insights on the information content of the data sets and eventually their ability to provide relevant information related to the separation of the groups. for this purpose, principal component analysis   <cit>  and robust pca  <cit>  have been used. the outliers detection has been based on cut off values on both orthogonal and mahalanobis distances, as proposed in  <cit> .

mid-level fusion
the purpose of data fusion is to extract the information spread across the different platforms. conclusions based on multiple independent types of measurement are more reliable than from one platform alone . more importantly it may provide new scientific insights on relations between compounds such as protein-metabolite interactions. the simplest approach is to concatenate the different data sets in a low-level fusion approach  <cit> . however this strategy is greatly affected by the variability between the two platforms. therefore we designed a mid-level architecture capable to discriminate between a number of beforehand defined groups. the mid-level fusion analysis contains two steps as presented in figure  <dig> 

two problems have to be faced during the analysis of the two -omics data set. the first one has to deal with a dimensionality problem. indeed both metabolomics and proteomics studies measured a large number of variables on relatively few samples. the second challenge is related to the missing values. each instrumental platform received the same samples. however, some measurements had to be excluded from the study because of instrumental artifacts or technical issues during the measurement. therefore the algorithm has to deal with two different problems. in the two following sections we provide answers for each challenge. finally, we discuss how to integrate these two steps and how to interpret the final results.

first step: extended canonical variate analysis
the first step consists of extracting and compressing the information contained in each data set. pca  <cit>  is the most usual way to compress data  <cit> . however, biological data are often affected by multiple sources of variance. therefore, we opted for a "lda-like"  method. the advantage of this approach is to focus only on the information related to the defined classes . yet such methods are confronted with the "curse of dimensionality". indeed lda requires more samples than the variables, otherwise the inversion of the within-group covariance matrix becomes impossible. a recently proposed algorithm provides a solution. extended canonical variate analysis   <cit>  has been developed to cope with multi-collinear data. the concept of this method very much resembles fisher lda. assuming a data matrix x  where g groups of ni samples are present, the within-group covariance matrix swithin is defined as:   

and the between-group sbetween is:   

where xij is the jth sample in the ith group,  is the mean vector in the ith group, and  is the overall mean vector. the best discrimination between the groups is obtained by defining a direction w maximizing the ratio of the between-group on thewithin-group covariances  <cit> :   

when swithin is non-singular, the equation  can be rewritten in the form of an eigenvalue problem:   

where a represents the number of directions, λa are the eigenvalues and wa the eigenvectors. equation  has a maximum dimensionality of a = min. therefore even in the case of high dimensional data, the number of canonical variables extracted is equal to the number of groups minus one . it can be shown that this problem ) can be turned into a regression problem  <cit> . partial least squares  method is then used to solve the equation  corresponding to this regression problem:   

where y contains the differences , the columns of b are wa and f is a residual matrix. the scores t can then be calculated projecting them along the directions wa i.e. the canonical variates . the classification model is then constructed using these scores. note that the best results where obtained on vast scaled data  <cit>  .

the two data sets here have very different dimensions. the proteomics data set contains almost  <dig> times more variables than the metabolomics data. therefore an additional variable selection step was introduced for the proteomics platform. the ecva model was constructed on  <dig> variables. the  <dig> most important variables were selected and used to reconstruct the ecva model. the latter is then used in the rest on the analysis.

second step: principal component analysis for missing values
the information related to groups has been compressed by ecva into a small set of  canonical variates. therefore, the problem of dimensionality does not apply anymore in the second step. the experimental design is such that the same samples should be measured by all platforms. in practice some samples were either missing or the obtained measurements were detected as outliers during the exploratory analysis. as a consequence, some data points are missing in the concatenation of t <dig> and t <dig>  it is important to note that this problem does not arise in the previous step because the different ecva models are constructed per platform. therefore, if a sample is missing it is simply excluded from the construction of the ecva model. one should note that the quantity of missing data should not unbalance dramatically the number of samples per group . however, if this strategy is applied in the second step a considerable amount of information would remain unused . a method able to deal with missing values must therefore be used. we propose an adaptation of the pca based on the missing toolbox from claus andersson  <cit> . the missing elements are replaced by model estimates of these elements. the estimates are iteratively improved until a convergence criterion is fulfilled and the estimates do not change significantly. the influence of the missing values on the model is then limited  <cit> .

validation - interpretation
the method proposed here explicitly uses class information. a risk of overfitting exists; therefore a validation procedure has to be implemented. a test set is constructed using 20% of the samples. the test samples must be representative of the whole set. they are selected using kennard and stone algorithm  <cit> . the test samples are then inputted in the ecva model and then projected in the pc space. the prediction can be obtained using an approach similar to principal component discriminant analysis. once validated, the model is reconstructed using all available samples.

the biological interpretation is performed by assessing the importance of the original variables. it is calculated by multiplying the canonical variates from the first step by the loadings of the pca . for example the weights of the original variables from the first platform are calculated as follow:   

where w <dig> contains the weights of the original variables for the global model  p:,1:g- <dig> contains the importance of the g- <dig> first latent variables. the same operation can be done for the second platform using the corresponding g- <dig> latent variables. the model can be inspected using a score plot and/or biplot.

the most important variables are then put into context by projecting them into a correlation network. this network is constructed by calculating all pair-wise pearson correlations  in the different classes:   

where ni is the number of samples,  and  are the sample means of x <dig> and x <dig> while and are the standard deviations of x <dig> and x <dig>  the complete network is too large and complex to be used. therefore a sub-network is represented using the most important variable as a seed which is expanded to all variables with a correlation superior to  <dig>   to them. the network is visualized using graphviz  <cit>  where each node represents one variable. the node is a square if it represents a variable seen as important by the fusion method, otherwise as an ellipse.

RESULTS
explorative analysis
the analysis of the data can be performed first per platform. this is particularly relevant during the exploratory analysis. pca was used to visualize each dataset and detect eventual outliers. in figure  <dig> score plots obtained for both platforms are presented. the samples are colored in accordance to their group memberships. one can observe that the separation is clearer for the proteomic platform than for the metabolomics. indeed in figure 2a the main source of variance  allows one to separate most of the disease group  from the control samples . interestingly, the pc <dig> also shows separation of two groups of points. this source of variation represents 15% of the variance. however, it does not correspond to the experimental design. this separation is then certainly due to either biological or instrumental variations. in this case the separations in two subgroups correspond to two series of measurements. this effect could be corrected for with dedicated method  <cit> . however the proposed fusion method should be generic enough to deal with this issue. therefore we did not investigate further batch effects. the equivalent plot for the metabolomics platform is presented in figure 2b. here no instrumental variations are observed but the disease group is also strongly overlapping with the control samples.

the most straightforward approach for data fusion is to analyze the two data sets together. this is called low-level fusion  <cit> . it is expected that the two types of information should complete each other and improve the class separation. this low level fusion provides disappointing results, as can be seen in figure  <dig>  the two data sets are analyzed together, using pca for missing values. the three classes are overlapping in the plane defined by pc <dig> and pc <dig> .

both instrumental analyses provide different information about the group separation. however, in both cases the biological or instrumental variations distort the picture. the explorative analysis of both sets as one unique data matrix does not provide a better but actually a worse separation of the groups. in that respect it is relevant to use a supervised method in order to extract the relevant information from each data set. this can be performed using mid-level fusion as described in the methods section.

mid-level fusion
our approach is based on two steps. the first one consists of a supervised analysis of each platform. after the first step, each submodel  can be assessed in terms of complexity and prediction, based on a cross validation included in ecva. here the inner pls loop of the ecva models for the proteomics and metabolomics platforms are using respectively  <dig> and  <dig> latent variables. as additional check, we perform the prediction of the test samples left out during the construction of the ecva models. they were correctly predicted in 78% of the cases by the proteomic platform and in 78% by the metabolomics platform. the latent variables constructed by ecva are inspected in order to determine whether the variability spanned by the latent variables from one model is comparable to the one spanned by the other model. the latent variables obtained for each platform are then concatenated. the newly formed matrix can be analyzed using pca. the test samples groups can be predicted using a method similar to principal component discriminant analysis   <cit> . the fusion leads to 89% of correct classification on the validation set.

since the model shows good predictive ability we consider it as statistically validated. the model is reconstructed using all available samples before starting interpretation. the resulting model can be graphically assessed using a score plot as shown in figure  <dig> where each sample is color coded according to the groups' label. the separation of the healthy control  from the two other groups can be seen along pc <dig>  the disease and inflammation groups are mostly separated from each other along pc <dig> with some overlap. it is interesting to note that the spread of the disease group is larger than the other groups. it suggests that this group is more heterogeneous. part of the neuroinflammation group is overlapping with the peripheral inflammation group. this would suggest that the neurological symptoms are delayed for the corresponding animals.

the most significant metabolites and proteins linked to the disease group are then studied. the selection rules for proteins were that at least three peptides must show similar behavior . their importance is then averaged. the importance is a relative measure of the influence of the variable on the definition of the group considered . in table  <dig> a selection of the names of main variables, the corresponding uniprot/cas numbers and their relative importance to define this group is listed. the sign of these values indicates whether the metabolite/protein concentration is up or down regulated in the disease group in comparison to the controls. the values have been normalized in such way that the most important variable  has a value of  <dig> 

unidentified signals are reported using chemical shift .

the interpretation can obviously be based on an univariate approach i.e. considering each selected variable separately. however, the interest of fusion is to make a connection between the two types of information and to evaluate the link between proteins and metabolites. to facilitate the interpretation of the results we constructed a correlation network that embodies the interconnections between the protein and metabolite variations. the result is presented in figure  <dig>  each node corresponds to one metabolite or one protein. the links between nodes indicate that a correlation is superior to  <dig>  . the complete network is too complex to be reproduced in a single image. the figure  <dig> represents a portion of the complete correlation network centered on hemopexin and t-kininogen  <dig> i.e. the variable seen as most important . only the proteins and metabolites directly correlated to hemopexin or t-kininogen  <dig> or through one other variable are represented. the correlation network is clearly different between the disease and control groups. the correlations observed in the healthy control are represented by solid black line. the correlations observed in the disease group are represented by dotted lines.

discussion
a fingerprint of the eae onset is defined by our data analysis approach. the first aspect to be discussed is the statistical performance of our method. the obtained results show better prediction ability than individual analysis and low level fusion based on either ecva or partial least squares discriminant analysis  . the limitations of this approach are mostly related to the statistical aspects. firstly, the underlying concept of both ecva and pca is that the information is related to linear variations. in the cases of more complex signals , the obtained discrimination could be too low or based only on a part of the metabolites and proteins really involved. secondly, the number of samples measured by both platforms should be sufficiently high to ensure that the relations observed are not artifacts.

the second aspect to be discussed is the nature of the variables selected. one can glean from table  <dig> that both proteins and metabolites participate in the discrimination model. apparently the fingerprint of the eae onset is better defined using both proteomics and metabolomics knowledge i.e. using a systems biology approach.

in terms of biological interpretation, the obtained results are coherent with previous studies. indeed the proteins presented in table  <dig> have been previously linked to eae and/or mscl. increased levels of hemopexin and t-kininogen  <dig> have been previously reported in neurological disorders  <cit> . the expression level of the kininogen  <dig> receptor has been proposed as a non-specific index of disease activity in mscl by prat et al.  <cit> . serum albumin  <cit>  is known to cross the blood brain barrier after administration of cfa and, in absence of inflammatory cells in the cns, albumin is not triggering any neuroinflammation  <cit> . however, we observed reduced level of albumin in the disease group. this suggests a relation between the neuroinflammation process and the serum albumin present in the cns. however this observation needs to be validated. complement c <dig>  <cit>  and complement c <dig>  <cit>  have been related to mscl. in addition the complement c <dig> and its derived fragments have been marked as a central player in the pathophysiology of eae  <cit> . increased concentration of haptoglobin has been found in mscl  <cit> . it has been suggested that haptoglobin plays a modulatory and protective role on autoimmune inflammation of the cns  <cit> . ceruloplasmin  <cit>  and citrate  <cit>  are known to rise in concentration during the inflammation phase. similarly some of the selected metabolites have been ascribed to mscl. increased lysine level is known to have an impact on the entry of arginine in leucocytes and thus on the no synthesis  <cit> . the complete biological interpretation of this multivariate model requires larger discussion and validation. these aspects are not in scope of this manuscript and will not be discussed for brevity reasons.

CONCLUSIONS
the feasibility of fusion of multiple omics platforms was discussed in this work. the study of the onset of eae was chosen as a case study. from the point of view of data analysis multiple challenges had to be addressed. the first one had to do with the biological variation usually encountered in omics experiments. the method proposed here focuses on the information of interest through a training procedure. however, the high dimensionality of the data is problematic for discriminant methods. this explains why it is necessary to use ecva, since this method is able to handle highly collinear multivariate data. the second difficulty is linked to the multiplatform aspect of this work: the same samples have been measured by two platforms. in the process some measurements were either lost or discarded for multiples reasons . we propose to apply in the last step of the fusion a version of pca which is able to cope with missing values.

overall the results of the fusion show a significantly better discrimination of the three classes  compared to individual analysis of the two data sets. a second advantage here is the possibility of studying the correlation between proteomics and metabolomics without having to assume any model . for that purpose, we propose the use of correlation networks. the variables seen as important for any discriminant model can be put in context using this approach. the obtained networks give an insight about the modification of the metabolic pathways by the disease.

from a biological point of view the selected variables appears to make sense. the proteins and metabolites described in this study were previously found in relationship to the eae and mscl and therefore provide a biological validation for the fusion of data from two different platforms. performing a fusion of several platforms can further confirm the role of the described pathways and potentially highlight new pathways involved in the eae disease process. future work will focus on the search and interpretation of newly detected metabolites and proteins. the pattern defined by these variables must also be studied by itself and put into the context of system biology.

list of abbreviations
cfa: complete freund adjuvant; cns: central nervous system; csf: cerebrospinal fluid; ecva: extended canonical variates analysis; lda: linear discriminant analysis; mscl: multiple sclerosis; mbp: myelin based protein; nmr: nuclear magnetic resonance; pca: principal component analysis.

competing interests
the authors declare that they have no competing interests.

authors' contributions
this study was designed by aa, tt, tl, ssw, and lmcb. the protocol related to the eae experiment was designed by aa and tt. the animal experiments were carried out by aa, hva and es. the nmr measurement protocol was designed by as, ka and ssw. the sample preparation, nmr measurements and data processing were made by as. the orbitrap measurement protocol was designed by ms and tl. the sample preparations, orbitrap measurements, and data preprocessing were made by ms. the fusion method presented here was developed and applied by lb. the redaction of this manuscript was done by lb, as and ms. lmcb, aa, ssw and tl have been involved in the critical revision of the manuscript. all authors read and approved the final manuscript.

supplementary material
additional file 1
supplementary material. the low level fusion has been investigated and is presented in the additional file  <dig> together with the effect of block scaling. the comparison between results of ecva and partial least squares - discriminant analysis is also provided in this document.

click here for file

 acknowledgements and funding
this work was performed within the framework of dutch top institute pharma, project "the csf proteome/metabolome as primary biomarker compartment for cns disorders" .
