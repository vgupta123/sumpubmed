BACKGROUND
through the use of information retrieval  technologies, information systems retrieve information to index data based on all kinds of pre-defined searching techniques/functions. each information system has its own models to rank the output. a metasearch system will get access to multiple ir systems and combine their ranking results into a single ranking output generated by the metasearch system. metasearch systems do not crawl the raw data or maintain a database as most ir systems do, but instead they search several ir systems simultaneously, which act as an agent to pass the query to the search systems and then return the results. since there are different results retrieved by ir systems/models, metasearch systems provide a quick way to determine which systems are retrieving the best match for information needs. the major goal of the trec genomics tracks is to create test collections for evaluation of ir and its related tasks in the genomics domain. the users desire to be provided short, specific answers to questions and put them in context by providing linking to original sources from the biomedical literature. this motivates the trec genomics track to implement a new task in  <dig> that focuses on passage retrieval using full-text documents from the biomedical literature  <cit> . for the trec  <dig> and  <dig> genomics track, systems are tasked with extracting out relevant passages of text that answer topic questions and focus on retrieval of short passages  that specifically address an information need, along with linkage to the location in the original source document  <cit> . here a passage is defined to be a string of characters within a natural paragraph  <cit> . systems are not only tasked to return passages of text, but also measured on how well they retrieve relevant information at the document-level, aspect-level and passage2-level, which will be presented in the results and discussion section.

in the trec  <dig> genomics track, there are a total of  <dig> runs submitted, in which  <dig> are classified as automatic. among the  <dig> submitted runs, submissions have employed multiple approaches for retrieval processes, such as query expansion, various levels of passage retrieval granularity, and varying ir models with many different scoring schemes. therefore, meta-features are distilled from the submissions as high-level categories, which are shown in table  <dig> <cit> . for example, “tfidfir” uses passage retrieval by a vector space model with any variant of tf-idf  <cit> , “okapiir” indicates passage retrieval using an okapi bm <dig> model  <cit> , “lmir” means passage retrieval using a language model, and “fusionir” combines results from two or more systems regardless of fusion operator usage. this motives us to consider a multi-source fusion approach in a metasearch system to utilize these meta-features. in addition, the performance of nlmfusion, the top scoring automatic run for all three measures  in  <dig>  <cit> , suggests that combining results from different ir models may improve the final results  <cit> .

in the trec  <dig> genomics track, submissions have employed multiple approaches for retrieval processes, such as query expansion, various levels of passage retrieval granularity, and varying ir models with many different scoring schemes. this table presents five typical and popular meta-features as follows.

in this paper, we propose a robust approach to combining multiple ir baselines from multiple sources in the genomics domain. first, the proposed approach employs three modified fusion methods, reciprocal, combmnz and combsum, where combmnz is generated into three versions to deeply evaluate this popular combination method. second, considering the diversity of baselines, we assume the proposed approach in the metasearch system has access to the baselines from three kind of individual models, dfr, bm <dig> and language model. therefore, we select five baselines from the official submissions of the trec  <dig> genomics track for combination as the main part of our experiments. third, in order to evaluate the superiority of the proposed approach, we conduct the experiments not only on the base runs from different sources, but also on the baselines from a single source of okapi bm <dig> with different indices, using the  <dig> and  <dig> genomics data sets. fourth, the experimental results demonstrate the viability and superiority of the propose approach with reciprocal to better performance fusion. in addition, as an extension of our preliminary work  <cit> , we employ combsum as the third combination method and further evaluate combmnz by considering its normalization, assigned weights and multiple times application.

the paper is organized as follows. first, we briefly present the experimental results and discussions in the results and discussion section, where the ir environment is introduced with the descriptions of the data sets, queries and evaluation measures. the comprehensive empirical study includes the analysis for the baselines, the proposed approach, the comparisons of combmnz and combsum to reciprocal, and the influence of the proposed approach on the single model bm <dig>  second, we show our contributions in the conclusion section. third, in the methods section, we propose our methods systematically and consistently. a robust approach to optimizing multi-source ir systems is proposed, followed by the introductions of reciprocal, combmnz and combsum, the descriptions of ir models as dfr, bm <dig> and language model. the related work is also presented in this section.

RESULTS
in this section, we conduct a series of pilot experiments using reciprocal, combmnz and combsum on the  <dig> and  <dig> genomics data sets.

ir environment
data sets and queries
we evaluated our model and algorithms on the  <dig> and  <dig> trec data sets. the trec  <dig> and  <dig> genomics data sets provide a test collection of  <dig>  full-text documents assembled with  <dig> queries in  <dig> and  <dig> queries in  <dig>  the trec  <dig> queries are in the form of questions asking for lists of specific entities. the definitions for these entity types are based on controlled terminologies from different sources, with the source of the terms depending on the entity type  <cit> . the trec  <dig> queries are derived from the set of biologically relevant questions based on the generic topic types   <cit> . there is a sample query as query  <dig> as “what serum  change expression in association with high disease activity in lupus?”. more information is available on the official genomics website at: http://ir.ohsu.edu/genomics.

evaluation measures
the trec genomics track has three evaluation measures that are the document-level, the aspect-level and the passage2-level   <cit> . each of these provides insight into the overall performance for a user trying to answer the given queries and measured by some variant of mean average precision , which are briefly described as follows.

document-level
this is a standard ir measure. the precision is measured at every point where a relevant document is obtained and then averaged over all relevant documents to obtain the average precision for a given query. for a set of queries, the mean of the average precision for all queries is the mean average passage precision of that ir system.

aspect-level
a question could be addressed from different aspects. for example, the question “what is the role of gene prnp in the mad cow disease?” could be answered from aspects like “diagnosis”, “neurologic manifestations”, or “prions/genetics”. this measure indicates how comprehensive the question is answered  <cit> .

passage2-level
this is a new character-based map measure which is added to compare the accuracy of the extracted answers and modified from the original measure passage map. passage <dig> treats each individually retrieved character in published order as relevant or not, in a sort of “every character is a mini relevance-judged document” approach  <cit> . this is done to increase the stability of the passage map measure against arbitrary passage splitting techniques.

performance of official baselines
the performance of five selected baselines is presented in the following table. the baselines are the official submissions in the trec  <dig> genomics track. the model applied in each baseline is specified in the parentheses as “dfr”, “bm25” and “lm”. here “lm” stands for “language model”.

influence of reciprocal
corresponding to the baselines, we evaluate the combinations applying the reciprocal method. due to three kind of ir models, there are four combinations as listed in table  <dig>  each combination contains a dfr baseline, a bm <dig> baseline and a lm baseline. the values in the parentheses are the relative rates of improvement over the best results of the baselines.

corresponding to the baselines, we evaluate the combinations using the reciprocal method in this table. in total, there are four combinations generated from three different ir models. each combination contains a dfr baseline, a bm <dig> baseline and a lm baseline. the values in the parentheses are the relative rates of improvement over the best results of the baselines. one of the conclusions is that the alliance of giants with boldface is the winner on all the measures.

first, the reciprocal method works very well on the passage2-level and the aspect-level, while it does not contribute a lot on the document-level. second, “unine1+mumshfd+ubexp1” achieves the best performance, especially in terms of the passage2-level. as we note in table  <dig>  “mumshfd” and “ubexp1” have better performance than “york07ga2” and “kyoto1”. we can see that the alliance of giants is the winner on all the measures. in addition, for the overall performance on the passage2-level, the performance generated by the alliance of giants “unine1+mumshfd+ubexp1”, almost catches up with the top official automatic run, “nlmfusion”  <cit> . note that “nlmfusion” is an automatic run obtained by five baselines, instead of three in our experiments.

in table  <dig>  both “unine1+mumshfd+ubexp1” and “unine1+york07ga2+ubexp1” make improvements in terms of the passage2-level and the aspect-level. focusing on the passage2-level, we can see that the different components of these two combinations are the bm <dig> baselines, “york07ga2” and “mumshfd”. then we can argue that the language model “ubexp1” contributes more than the bm <dig> model “mumshfd” in the proposed approach. this conclusion can also be confirmed by comparing “unine1+york07ga2+ubexp1” with “unine1+mumshfd+kyoto1”, in which the latter one has better performance than the preceding one.

furthermore, a common conclusion can also be drawn that the baselines who have better performance effect the combination results more significantly. for example, the alliance of giants “unine1+mumshfd+ubexp1”, which has the best dfr run, the best bm <dig> run and the best language model run, achieves the best fusion result. “unine1+mumshfd+kyoto1” is better than “unine1+york07ga2+kyoto1”, because “mumshfd” is better than “york07ga2”.

comparison to combmnz
in order to deeply evaluate the benefits of combmnz, we generate combmnz-with-normalization, combmnz-with-assigned-weight and combmnz-with-multiple respectively. for combmnz-with-normalization, we employ the standard zero-one normalization method in which all the base weights are scaled between zero being the lowest value and one being the absolute highest value. for combmnz-with-assigned-weight, the baselines earn their weights depending on their models. only the optimal results are presented. for combmnz-with-multiple, we apply the combmnz method for multiple times . no normalization and no additional weights has been given to the baselines. only the optimal results are presented as well. the values in the parentheses are the relative rates of improvement over the best results of the baselines. note that “w/” stands for “with”.

in combmnz-with-normalization, we employ the standard zero-one normalization method in which all base weights are scaled between zero being the lowest value and one being the absolute highest value. combmnz-with-normalization is the most popular version such that we generate another two versions of combmnz to check its effectiveness.

in combmnz-with-assigned-weight, the baselines earn their weights depending on their models. for n baselines, different weights are assigned to them linearly, in which the sum of the weights equals to one always. in this paper, we conduct the experiments with tuning the assigned weights. only the optimal results are presented in table  <dig> 

in combmnz-with-multiple, we apply the combmnz method for multiple times. in the experiments, we try m times  on the baselines. no normalization and additional weights has been given to the baselines. only the optimal results are presented in table  <dig> as well.

although combmnz has been confirmed by lee  <cit> , fox and shaw  <cit>  as an effective method. however, in our experiments in the biomedicine domain, combmnz does not show any advantage at all, although three different versions have been generated. in table  <dig>  all the combinations get worse compared with the best results of the baselines, especially in terms of the passage2-level and the aspect-level. on the genomics data, reciprocal outperforms combmnz thoroughly.

comparison to combsum
fox and shaw  <cit>  proved that the combsum method can achieve good performance on the trec- <dig> data set. in this paper, we apply combsum as a second comparison to reciprocal, since combmnz doesn’t work on the genomics data set.

in table  <dig>  combsum does not work very well on the baselines. however, the alliance of giants “unine1+mumshfd+ubexp1” outperforms the best baseline on the passage2-level. we can say that the combsum method has great potential to improve the retrieval performance on multi-source baselines in the genomics domain. compared to reciprocal, reciprocal outperforms combsum on all the measures as well. although both combsum and combmnz do not work as well as reciprocal, combsum provides its effectiveness better than combmnz with the evidence of the improved passage2-level performance.

we evaluate the combinations applying the combsum method in this table. the values in the parentheses are the relative rates of improvement over the best results of the baselines.

furthermore, the application of combsum repeatedly confirms that the alliance of giants achieves the best results over the other combinations. in addition, comparing “unine1+mumshfd+kyoto1” with “unine1+mumshfd+ubexp1”, we can see the evidences as no big performance gap on all the measures and only a different component between them. then a conclusion can be drawn that “ubexp1” doesn’t contribute much more than “kyoto1”, although “ubexp1” outperforms “kyoto1” much. on the other hand, comparing “unine1+york07ga2+ubexp1” with “unine1+mumshfd+ubexp1”, we also get the evidences as big performance gap existing especially on the passage2-level and only a different component between them. then another conclusion can be drawn that “mushmshfd” contributes much more than “york07ga2”, since “mushmshfd” has much better performance than “york07ga2”.

influence of the proposed approach on the single source
in the previous sections, we evaluate our proposed approach on the official multi-source submissions of the rec  <dig> genomics track. among three different models, the reciprocal method obtains nice performance as a good combination method. in this section, we will examine how our proposed approach works based on the single source of okapi bm <dig> 

first of all, the baselines are from three different indices under the same ir model, bm <dig>  instead of those from three kind of ir models. second, three indices are built on the  <dig> and  <dig> genomics data sets according to three passage extraction methods  <cit> . here “word” stands for “word-base”, “sentence” for “sentence-base” and “paragraph” for “paragraph-base”. third, the okapi tuning parameters of the selected runs are  = . similarly, reciprocal, combmnz and combsum are applied as the same way in the previous experiments. table  <dig> shows the performance of baselines and combinations in  <dig> and  <dig> respectively.

we examine the proposed robust approach on the single model with okapi bm <dig>  first of all, the baselines are from three different indices under the same ir model, bm <dig>  instead of those from three kind of ir models. second, three indices are built on the  <dig> and  <dig> genomics data sets according to three passage extraction methods  <cit> . here “word” stands for “word-base”, “sentence” for “sentence-base” and “paragraph” for “paragraph-base”. third, the okapi tuning parameters of the selected runs are  = . the values in the parentheses are the relative rates of improvement over the best results of the baselines.

in the trec  <dig> genomics track overview  <cit> , the measure correlation of the four measures shows that the passage2-level is highly correlated with the aspect-level. therefore, on the  <dig> data set, we choose the aspect-level as our main measure, since there is no passag2-level in  <dig>  focusing on the passage2-level and the aspect-level, we can observe the reciprocal method outperforms combmnz and combsum obviously in table  <dig>  the reciprocal method achieves great improvements on the passage2-level, the aspect-level and the document-level on both  <dig> and  <dig> genomics data sets. the standard normalization method, tuning the assigned weights and using multiple times combmnz can not help combmnz to make progress on the  <dig> and  <dig> data sets respectively. combsum does not work well on both  <dig> and  <dig> data sets. however, the consistent conclusion can be drawn that the combsum method works slightly well than the combmnz method, although both of them are not as good as reciprocal.

CONCLUSIONS
in this paper, we propose a robust approach with multi-source information for improving ir performance in the genomics domain. the proposed approach employs a reciprocal method, a combmnz method and a combsum method respectively, with evaluation on the trec  <dig> and  <dig> genomics data sets. empirical study on three different ir models demonstrates the utility of our proposed approach.

compared to the combmnz and combsum methods, the reciprocal method provides notable improvements using the baselines from a dfr model, a bm <dig> model and a language model respectively. the improvements are significant for both trec  <dig> and  <dig> genomics data set, in which the improved result in terms of the passage2-level in  <dig> almost catches up with the highest official result “nlmfusion”  <cit> . while combmnz does not achieve good performance, we conduct three versions as combmnz-with-normalization, combmnz-with-assigned-weight and combmnz-with-multiple to further improve and evaluate the combmnz method. although the combsum method does not work as well as reciprocal, combsum makes progress on the passage2-level, also works better than combmnz on all the three versions.

we select five baselines from three kind of ir models as dfr, bm <dig> and language model. the experimental results implement the following conclusions: 1) the alliance of giants achieves the best result; 2) under the same combination, the better the baseline performance is, the more contribution the baseline provides.

furthermore, the proposed robust approach makes improvements not only for combining the baselines from different sources, but also for combining the baselines from the single source such as okapi bm <dig> 

