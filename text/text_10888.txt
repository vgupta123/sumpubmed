BACKGROUND
music is omnipresent, and many people listen to music because of the emotional richness it adds to their lives  <cit> . music can be used to experimentally induce emotional states  <cit>  including peak experiences, such as "chills" and "shivers down the spine"  <cit> . frequently, such music can be remembered even years later, possibly due to the strong emotions it first elicited. since music unfolds over time  <cit> , music recognition requires that incoming sounds be mapped onto a stored long-term representation which contains invariant properties of the piece. indeed, listeners seem to retain much information about the music they know and are very accurate in reproducing familiar music  <cit> . while some evidence has been found in favour of a dedicated memory store for music  <cit> , this is still under debate.

emotional verbal and pictorial stimuli are remembered better than non-emotional ones  <cit> . this is probably due to the interaction of emotional and memory processes in limbic structures  <cit>  and can be explained by the semantic associative network model of memory by bower  <cit>  which proposes that emotions are used as contextual information linked to the to-be-remembered item. the semantic associative network model assumes that emotions are represented in a network of nodes together with words, pictures or music. stimulation of emotion nodes creates spreading activation that lowers the threshold of excitation of all associatively linked nodes and thus helps to retrieve an emotional item from memory. similar evidence for an effect of emotions on memory for musical stimuli is still lacking.

to fill this gap, we conducted a study investigating the influence of emotional properties of musical pieces on subsequent recognition performance for these pieces in a second session a few days later. this study is a prelude to a brain imaging experiment. in a previous pilot study we used piano music by j.s. bach as stimuli to test the effect of emotions on musical memory  <cit> . the stimuli yielded neither a sufficient recognition nor sufficient emotional contrasts. therefore, in the present study we used symphonic film music as a stimulus with more emotional impact which we expected to be remembered better. in the present study we also changed the design of the study in some points  and used a larger number of participants. we changed to a 5-point-rating scale because the rougher scaling can be answered more clearly and easily by the participants and leads to more reliable answers.

in keeping with the literature and our previous study, we used a dimensional model for measuring emotions with the dimensions "valence" and "arousal"  <cit>  and asked to rate the respective dimensions on a 5-point-rating scale which resulted in five categories for each dimension.

"arousal" refers to the excitation level elicited by the music . previous studies have shown that emotionally arousing stimuli are elaborated more deeply and thus are remembered better  <cit> . we therefore hypothesized that highly arousing musical excerpts should be remembered better.

finally, "valence" is understood here as the emotional value on a continuum from negative to positive  elicited by a musical stimulus. some studies have shown better memory performance for stimuli with positive valence  <cit>  others for negative valence  <cit> . music elicits predominantly pleasant feelings  <cit> , and emotion induction by music is strongest for happy and peaceful music  <cit> . we therefore restricted the stimuli to a valence range of neutral to strongly positive according to a preassessment, and hypothesized that the latter should be associated with better recognition memory.

in this experiment we focused on felt emotion. therefore, participants were asked to rate arousal, valence, and emotional intensity elicited in them by the music and not to indicate emotions they detected in the music. several recent studies have shown that feeling emotion and the judgement of expressed emotion are different parts of emotions and are evaluated differently in music listening  <cit> .

inspired by memory research using the levels of processing framework  <cit> , we also manipulated the participants' tasks during encoding: an "emotion group" was asked to rate the musical pieces with regard to valence, intensity and arousal during the encoding phase , while the second "time-estimation group" only performed a more superficial task . we hypothesized that the "emotion group" would show a better recognition performance than the "time-estimation group".

RESULTS
overall recognition performance
the rates of correctly recognized targets  and false alarms were calculated for each participant. the total number of targets was  <dig>  the number of hits differed among participants from  <dig> to  <dig> with a median of  <dig> correct answers to targets and the rate of false alarms differed between  <dig> and  <dig> with a median of  <dig> incorrect answers to targets  .

in addition, d' values were computed per participant. the d' values ranged from  <dig>  to  <dig>  with a mean of  <dig>  .

according to a reliability analysis the consistency of arousal ratings was very high . valence rating  was also rather reliable.

recognition performance  and emotional ratings  did not differ significantly between the emotion group and the time estimation group.

overall, the selected music pieces were not familiar to the participants before the experiment. some of the participants had a feeling of familiarity in various music excerpts: three of the participants in eight, seven, and six pieces, respectively; two participants in five pieces; one knew four pieces; two in three pieces, and three in one piece. except for three pieces which were familiar to two participants, the familiar pieces were all different for the different participants,. even if the participants had indicated that the excerpt was familiar to them, they did not necessarily recognize this piece in the recognition session . familiar pieces did also not receive higher valence ratings. we therefore decided to include all pieces of music in the analysis.

a reliability analysis was conducted to determine the consistency of the arousal and valence ratings for all stimuli and participants. for arousal ratings, reliability was very high . valence ratings were also rather consistent . to test whether emotional ratings in the emotion group would change from the first session to the second session, a wilcoxon test was calculated. for each excerpt of music, the median values of arousal, valence, and emotional intensity ratings of the emotion group members was compared between the two sessions. there was no significant difference between the arousal and valence ratings given in session  <dig> and those in session  <dig> 

recognition memory and emotional rating
the following analysis was based on all  <dig> participants from the emotion and time estimation groups. the emotion ratings of the felt/induced emotion from the third session were used.

there was a significant effect of valence on recognition performance . dunn's multiple comparison tests revealed significant differences between category  <dig> vs. category  <dig>  and category  <dig> vs. category  <dig>  .

recognition performance did not differ between the different arousal categories.

levels of processing: emotion group versus time-estimation group
even though a better recognition performance was expected in the emotion group, the overall d' values of both groups did not differ  =  <dig> , p =  <dig> , df = 18).

a  <dig> ×  <dig> anova  with the dependent variable d' per valence category revealed no significant effects – neither a main effect for valence  =  <dig> , p =  <dig> , n = 20) nor for the group  =  <dig> , p =  <dig> , n = 20). there was no interaction between group and valence levels.

discussion
in this study, an incidental episodic recognition task was used to investigate whether music pieces which induce high arousal and very positive valence are remembered better by nonmusicians than are excerpts that rate as low arousing and emotionally neutral. we also examined the influence of depth of processing during the encoding phase on memory performance.

despite the moderate recognition performance, clear-cut results concerning the relation between emotional ratings and musical long-term memory performance were obtained.

the results confirmed our hypothesis that music pieces which were rated more positively are positively related to the degree of recognition performance. some studies in other domains showed a similar valence effect supporting this result  <cit> .

however, some studies found negative valence  <cit>  to improve memory. these results do not contradict the results of our study as it is perfectly possible that either negative or positive emotional stimuli could enhance memory performance. in this study we only tested the effect of music with neutral to positive valence on recognition performance. it could be that music rated as very negative would have similar enhancing effects on recognition performance as does very positive music.

surprisingly, arousal ratings were not predictive for recognition performance. thus the hypothesis that stimuli which induce high arousal are remembered better was not confirmed. previous studies in other domains found that stimuli which induce higher arousal are remembered better independently of valence  <cit> . other studies suggest that arousing stimuli attract attention  <cit>  and are therefore processed more effectively and more elaborately  <cit> . experience with other types of material, such as the iaps pictures  <cit> , indicates that strongest arousal is seen for very negative events. the use of neutral and positive material in the present study, therefore, might have precluded an arousal effect.

in summary, this study showed that ratings of valence are positively associated with better recall. however, it is possible that the ratings of emotionality in the second session may in part be based on the person's belief how memorable an excerpt of music was. the fact that the emotion ratings of the stimuli in the emotion group in the first session were very similar to those in the second session might speak against this assumption. further studies are needed to ascertain on which aspect of the stimulus the emotion ratings were based.

a further manipulation of the study concerned the task during the first  session: an emotional rating task, thought to give rise to deep elaborate processing, was contrasted with a time-estimation task, which was believed to lead to a more shallow processing of the musical pieces. contrary to our hypothesis, as derived from the levels of processing framework, the recognition performance of the two groups did not differ. because the processing level during encoding has profound influence on memory performance using other types of stimuli , this lack of an effect was surprising. a likely reason for this negative finding is that due to our experimental conditions , the processing level was not dissimilar enough for both groups. our negative finding is not without precedence, however. none of the few studies using a level of processing manipulation in conjunction with musical material found an effect for  music compared to verbal stimuli  <cit> . thus, it has been assumed that musical memory differs from verbal memory  <cit> .

another possible explanation for the missing level of processing effect in music could be that music is not encoded in a fixed hierarchical manner as is language. the importance of different aspects of the music may change depending on the context of music processing or the setting. a further encoding task can therefore direct the attention of the listener to different aspects of the tune. thus, the depth of encoding the features might not differ  <cit> .

of particular interest was the finding that the time-estimation group, despite not concentrating on the emotions during the first session, showed the same pattern of answers as the emotion group. the missing difference in recognition performance between both groups could also be explained by the small sample size of only  <dig> people per task group. however, both groups showed a similar distribution of correct answers in relation to the emotion ratings in the second session. thus, the participants of the time-estimation group also implicitly processed the emotional content of the music and used it in the generation of a memory trace. in other words, emotion induced by the music is processed automatically and profoundly influences recognition.

CONCLUSIONS
the results of this study indicate that emotional information modulates musical memory similar to the influence of emotional factors on memory in other domains.

very positive valence ratings seem to be associated with better memory performance of music in a recognition task. arousal ratings were not significantly related to recognition performance. this contrasts with the majority of memory studies in other domains which found arousal to be the most important variable in recognition memory of emotional events  <cit> . the level of processing manipulation in conjunction with the incidental memory task confirms that emotional information in music is processed automatically and implicitly. the neural underpinnings of this emotional modulation of musical memory are currently under study using an event-related fmri design.

