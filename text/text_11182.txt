BACKGROUND
microarrays allow researchers to examine the expression of thousands of genes simultaneously. the primary goal of many microarray experiments is to identify a group of genes that is differentially expressed between two or more conditions. such "differentially expressed genes"  are identified through statistical testing. with tens of thousands of genes represented on an array and one or more hypotheses being tested for each gene, a multiple testing adjustment is certainly warranted. for expression studies involving microarrays, it has become common practice to focus on control of the false discovery rate . the false discovery rate is the expected proportion of incorrect rejections among the rejected hypotheses. let v be the number of truly null hypotheses that are rejected and r be the total number of hypotheses that are rejected. let q be defined as v/r when r >  <dig> and let q =  <dig> if r =  <dig>  fdr is then defined as fdr = e  <cit> .

many procedures are available for estimating or controlling fdr. benjamini and hochberg proposed an intuitive procedure for controlling fdr  <cit> . storey and tibshirani offer the q-value method to estimate the fdr  <cit> . the q-value is a measure of significance in terms of fdr. the q-value of a particular feature  is the expected proportion of false positives among all features as extreme or more extreme than the observed one. the q-value method uses an estimate of π <dig>  the proportion of p-values that correspond to tests in which the null hypothesis is true. both the benjamini-hochberg and q-value methods are based on the assumption that the distribution of p-values corresponding to truly null hypotheses  follows a uniform distribution between zero and one. additional fdr methods have been proposed by many authors, but we find the benjamini-hochberg and q-values methods to be the most commonly used methods.

fdr methods offer a substantial increase in power over methods that control family-wise error rate. however, low power can still be a problem when the proportion of differentially expressed genes is relatively low. in addition, researchers using standard manufactured arrays  have no control over the number of genes represented on the array. for example, the ath <dig>  genechip contains approximately  <dig>  probe sets, the mgu <dig>  genechip contains approximately  <dig>  probe sets and the wheat genechip contains roughly  <dig>  probe sets. hence, situations can arise where the number of tests is very large but the proportion of differentially expressed genes is relatively low, resulting in low power even when using an fdr method.

filtering methods can be used to reduce the number of tests and therefore increase the power to detect true differences. an ideal filtering method would remove tests which are truly null , while leaving those tests corresponding to genes which are truly differentially expressed. several methods for filtering have been suggested including filtering by variance, signal, and mas detection call.

all filtering methods discussed here can be applied without using information about treatment assignments. when filtering by variance, we remove genes with low variance across arrays . the rationale is that expression for equally expressed genes  should not differ greatly between treatment groups, hence leading to small overall variance. the goal of filtering by signal is to filter out genes that have signal close to background level. genes with low average signal  are removed. filtering by mas detection  call is a common choice of investigators using affymetrix genechips. the mas detection call algorithm is based on the use of the wilcoxon signed rank test to compare pm  and mm  probes within a probe pair. a "call" of present, absent or marginal is made for each probe set  <cit> . the idea of filtering by detection call is that if a transcript is not present in any sample, then clearly it cannot be differentially expressed. hence, we filter out probe sets that are called absent on all arrays.

RESULTS
in order to evaluate the effect of filtering, we use three case studies as well as a simulation study. all programming was done in r using bioconductor  <cit> .

for the three case studies, we examine the effect of three filtering methods  as well as the results when no filtering is done. in order to facilitate direct comparisons between the filtering methods, we selected the same number of probe sets to be filtered out for all filtering methods.

specifically, we found the number of probe sets not called present on any array in a given experiment and hence filtered out by the detection call method. we then fix this to be the number of probe sets filtered out by the variance and signal filtering methods as well. in addition to the various filtering and fdr methods, we consider the rma, mas <dig> and plier methods for preprocessing. we note that all testing was done using expression values on the log <dig> scale. however, we examined the effect of filtering by variance on both the log <dig> and "original" scales. a  <dig>  significance level was used for all methods.

for the simulation study, we start with simulated expression data and focus on the effect of filtering by variance. a  <dig>  significance level was used for all methods.

case study: wheat data
a study was conducted to examine gene expression of resistant and susceptible lines of wheat grown in the presence and absence of the russian wheat aphid. the affymetrix genechip wheat genome array  was used for this study. rna samples were collected from wheat plants in  <dig> ×  <dig> factorial design. the design was originally balanced, but one array was dropped due to concerns about array quality. each array represents a pooled sample from five seedlings. the data used here consists of  <dig> arrays:  <dig> arrays representing the resistant wheat variety in the absence of the russian wheat aphid,  <dig> arrays representing the resistant wheat variety in the presence of the russian wheat aphid,  <dig> arrays representing susceptible wheat variety in the absence of the russian wheat aphid, and  <dig> arrays representing the susceptible wheat variety in the presence of the russian wheat aphid.

for the purposes of this paper, we focus on two comparisons of interest:  comparison of gene expression of the resistant wheat line in the presence and absence of the russian wheat aphid and  comparison of gene expression of the resistant and susceptible wheat lines in the absence of the russian wheat aphid. these two comparisons were selected because the first is expected to yield a large number of degs while the second should yield fewer degs. testing for the two comparisons of interest was performed using an analysis of variance  model and contrasts of factor level means.

in order to facilitate direct comparisons between the filtering methods, we selected the same number of probe sets to be filtered out for all filtering methods. a total of  <dig>  probe sets  were not called present on any of the  <dig> arrays and were therefore filtered out by the detection call filtering method.

hence, when filtering by average signal , the probe sets with the smallest  <dig>  average signal values  were filtered out. figure 1a gives a histogram of p-values obtained from testing for degs for the first comparison with p-values corresponding to the filtered  probe sets overlaid in gray.

the number of probe sets corresponding to differentially expressed genes identified for each of the combinations of preprocessing , filtering  and fdr methods  are shown in table  <dig> for both wheat comparisons. we see that for a given preprocessing and fdr method, filtering by detection call, signal or variance  leads to an increase in the number of degs identified. in contrast, in some cases, filtering by variance on the log <dig> scale leads to a decrease in the number of degs identified  for mas <dig> and plier preprocessing methods.

table of number of probe sets identified as differentially expressed for each of the case studies. for each case study, we considered three preprocessing methods , two fdr methods  and three filtering methods  and signal). the stated significance level was  <dig>  for all methods.

case study: diabetes data
a study was conducted to examine gene expression in the cardiac left ventricle using a rodent model of diabetic cardiomyopathy  <cit> . the affymetrix rat genechip  <dig>  <dig>  array  was used for this investigation. rna samples were collected from the cardiac left ventricles of  <dig> diabetes induced rats and  <dig> controls. each sample was hybridized to a single array. the data can be obtained from the ncbi gene expression omnibus   <cit> . a two-sample t-test assuming equal variances was used to identify differentially expressed genes.

similar to the analysis for the wheat data, we selected the same number of probe sets to be filtered out for all filtering methods. a total of  <dig>  probe sets  were called absent on all  <dig> arrays and were therefore filtered out by the mas detection call filtering method. hence, the same number of probe sets were removed for the other filtering methods. the number of probe sets corresponding to differentially expressed genes for each of the combinations of preprocessing, filtering and fdr methods are found in table  <dig>  we see that for a given preprocessing and fdr method, filtering by detection call, signal or variance  leads to an increase in the number of degs identified. in contrast, filtering by variance on the log <dig> scale leads to a decrease in the number of degs identified  for mas <dig> and plier preprocessing methods.

case study: smoking data
a study was conducted to examine gene expression in the lungs of young mice exposed to  <dig> days of cigarette smoke  <cit> . the affymetrix mouse genome  <dig>  <dig>  array  was used for this investigation. rna samples were collected from the lungs of  <dig> mice exposed to cigarette smoke and  <dig> controls. each sample was hybridized to a single array. the data can be obtained from the ncbi gene expression omnibus   <cit> . a two-sample t-test assuming equal variances was used to identify differentially expressed genes.

a total of  <dig>  probe sets  were called absent on all  <dig> arrays and were therefore filtered out by the mas detection filtering method. hence, the same number of probe sets were removed for the other filtering methods. the number of probe sets corresponding to differentially expressed genes for each of the combinations of preprocessing, filtering and fdr methods are found in table  <dig>  we see that for a given preprocessing and fdr method, filtering by detection call or variance  leads to an increase in the number of degs identified. in contrast, filtering by variance on the log <dig> scale leads to a decrease in the number of degs identified for mas <dig> and plier preprocessing methods. we also observe a decrease in the number of degs identified when signal filtering is paired with rma preprocessing.

simulation study
we simulated expression data under two models: when signal values between genes are independent and when the signal values between genes follow a "clumpy dependence"  <cit> . the data was simulated to correspond to two groups of five samples  with signal values generated for  <dig>  genes for each sample. we considered true π <dig> values of  <dig> ,  <dig> ,  <dig> ,  <dig> , and  <dig> . a total of  <dig> runs were used for each simulation scenario.

the signal value for gene g in sample k in block j and group i, was generated according to the model

 yijkg = fig × ig + bjk + zijkg. 

a proportion, π <dig>  of genes were randomly selected to have indicator variable ig =  <dig>  and the rest of genes have ig =  <dig> . the term fig ~ n  for samples from one group only, thus giving the magnitude of the differential expression. to create the dependent simulation scenario , genes were randomly grouped into  <dig> blocks of  <dig> genes, indicated by the subscript j and with bjk ~ n . the variable zijkg ~ n  where σg <dig> ~ uniform was used to allow the variance to differ among genes. for the dependent case, σb <dig> =  <dig> , and for the distribution of σg <dig>  umin =  <dig> , and umax =  <dig> . for the independent case, σb <dig> =  <dig>  umin =  <dig> , umax =  <dig> . the values for σb <dig>  umin, and umax were chosen such that the distribution of the variance of yijkg is the same for both the dependent and independent models. moreover, the distributions of fig, bjk, and zijkg were selected so the distribution of p-values for the simulation study resembles the distribution of p-values seen in case studies. this is supported by the histogram of p-values shown in figure  <dig> 

for each run of the simulation, t-tests comparing the two groups were performed and the bh and q-value methods were applied, with and without filtering to the  <dig>  resulting p-values. the t-tests were performed assuming equal variances for the two groups. filtering was performed by variance, with the  <dig>  genes with the lowest variances  being filtered out. an α =  <dig>  level of significance was used for all fdr methods. a histograms of the p-values for a single run of the simulation with π <dig> =  <dig>  for the independent case is shown in figure 1b.

power
the observed power for each method and each run was calculated as the proportion of true positives that were detected at the stated significance level of α =  <dig> . the distribution of observed power for each of the fdr methods with and without filtering are shown in figure  <dig> and summarized in additional file  <dig> table s <dig>  as expected, the power for the two fdr methods increases as π <dig> decreases, demonstrating increased power as a higher proportion of genes are differentially expressed. more importantly, these results show that filtering by variance results in an overall gain in power for both fdr methods considered for both independent and dependent models. the gain in power due to filtering is fairly consistent across the range of π <dig> values. not surprisingly, the power under the independent model was less variable than the corresponding power under the dependent model. however, the median power for a given value of π <dig> is about the same for independent and dependent models. not unexpectedly  we find that q-value has higher power than the benjamini-hochberg method for a given simulation scenario.

false discovery rate
the observed fdr for each method and each run was calculated as the proportion of false positives among the rejected hypotheses. this observed fdr was compared to the nominal fdr level of  <dig> . the distribution of the observed false discovery rate for each of the simulation scenarios are shown in figure  <dig> and summarized in additional file  <dig> table s <dig>  the effect of filtering on the observed fdr is different for each of the fdr methods. for bh, the use of filtering actually leads to an overall decrease in observed fdr for lower values of π <dig>  for q-value, the use of filtering has little effect on the observed fdr, except for some decrease in the variability of the simulation runs. all methods  have median observed fdr less than or equal to the nominal level of α =  <dig> . similar to the results for power, the observed fdr of the simulation runs are more dispersed for the dependent model than for the independent model.

analysis of different filtering thresholds
we examined the effect of different thresholds when filtering by variance. the observed power and fdr for a simulation run of the independent model with π <dig> =  <dig>  across a range of variance quantiles  is shown in figure 4a and 4b. for instance, if the variance quantile is  <dig> , then 10% of genes  are filtered out for bh and q-value methods.

for both fdr methods, the power increases as an increasing proportion is filtered out  until the proportion  gets close to π <dig>  at the same time, the observed fdr for these methods stays close to or below the α level of  <dig> . as the quantile used for the threshold becomes close to π <dig>  the power begins to decrease. this suggests that we are starting to remove genes that are truly differentially expressed. hence both the bh and q-value methods have improved power  if filtering is done at a level somewhat close to, but well below, π <dig>  similar results were obtained for the dependent models.

we also examined the effect of filtering with different thresholds for the three case studies. the number of degs found when varying the proportion of genes filtered out for wheat comparison  <dig>  is also shown in figure 4c. for this comparison, the number of degs identified gradually increased for both benjamini-hochberg and q-value methods as the proportion filtered out increased until a threshold of about  <dig> . the quantile at which the number of degs began to decrease is close to the q-value estimate of π <dig> . similar results were seen for the other case studies and preprocessing methods, but these results are not shown here.

discussion
mcclintick and edenberg previously studied the effects of filtering by mas detection call and signal in combination with mas <dig> and rma preprocessing methods  <cit> . they recommend filtering out probe sets that are not called present in at least 50% of samples in at least one treatment group. when using signal as a filtering criteria, they filtered out probe sets that did not have average signal greater than some threshold in at least one treatment group. instead of filtering out probe sets that are not called present in at least 50% of samples for at least one treatment group, we filtered out probe sets that were not called present for any samples. a benefit of this method is that no knowledge of treatment assignments is used for filtering. in addition, in our experience, for moderately sized experiments  this method removes the vast majority of probe sets that would be removed using the 50% rule. however, as the number of arrays increases, it becomes more likely that a probe set corresponding to a truly unexpressed transcript will be called present on at least one array just by chance. hence we could see more dramatic differences between the two methods for larger experiments.

in their analysis, mcclintick and edenberg found filtering by mas detection call to be superior to filtering by signal because it results in decreased fdr. their logic for filtering out absent called genes is clear, "data for genes not actually expressed represent experimental noise and cannot increase true positives, but can  generate false positives." while this is true, we must bear in mind that the mas detection call is itself a statistical test and the truth of which genes are unexpressed is unknown. in addition, filtering by mas detection call is not an option for spotted cdna arrays or other types of manufactured arrays besides affymetrix genechips.

we consider three different filtering methods in combination with two fdr methods and three preprocessing methods. for all case studies, preprocessing methods and fdr methods examined, filtering by detection call and variance  increased the number of degs identified when compared to unfiltered data. in one case, filtering by signal  lead to a decrease in the number of degs identified. in most cases, filtering by variance on the log <dig> scale in combination with mas <dig> and plier methods actually lead to a decrease in the number of degs identified. this is surprising since testing was conducted on the log <dig> for all methods.

we believe that there are two factors contributing to this counterintuitive result. first of all, there is a relationship between average signal and variance and, for mas <dig> and plier, the direction of this relationship depends on the scale. based on the case studies considered, the correlation between average signal and variance for mas <dig> ranged between - <dig>  and - <dig>  on the log <dig> scale and between  <dig>  and  <dig>  on the original scale. for plier, the correlation ranged between - <dig>  and - <dig>  on the log <dig> scale and between  <dig>  and  <dig>  on the original scale. for rma, the correlation ranged between  <dig>  and  <dig>  on the log <dig> scale and between  <dig>  and  <dig>  on the original scale. one reason the log <dig> transformation is used is to stabilize the variance. however, it seems that for mas <dig> and plier, this transformation over corrects and leads to increased variance for low expression transcripts. the result is that on log <dig> scale, high expression genes tend to have relatively low variances.

in addition to the relationship between signal and variance, there is a tendency for high expression genes to be over-represented in the list of degs. to examine this, we calculated the proportion of degs  that had average signal in the top 50%. hence, if there was no relationship between average signal and significance, we would expect 50% of degs to have average signal in the top 50%. the actual proportions varied by case study and preprocessing method ranging between 45% and 84%. in only one case , was this percentage less than 50%.

these relationships between signal and variance and signal and significance lead to removal of high expression genes when using the mas <dig> or plier methods and filtering by variance on the log <dig> scale. since highly expressed genes are more likely to be identified as degs, then this filtering method tends to filter out genes that are likely to be differentially expressed. filtering by variance on the original scale works better for these methods, even when testing is done on the log <dig> scale. this can be seen by examining the histogram of p-values corresponding to those genes filtered out by variance . the distribution of p-values more closely approximates a uniform distribution when filtering by variance is done on the original scale for mas <dig> and plier. we suggest that whatever filtering method researchers choose, they examine the distribution of p-values corresponding to those genes filtered out.

filtering by detection call and variance  consistently led to an increase in the number of differentially expressed genes identified. this was true for both cases where a large proportion of genes are differentially expressed  and a small proportion of genes are differentially expressed . however, we note that for other data sets we examined we were not able to identify any degs  either with or without filtering. it is possible that some of these are cases where no genes are differentially expressed. on the other hand, it could be that even after filtering, the power was still too low. either way, if no degs were identified to begin with, there is certainly no harm in attempting filtering.

the simulation study focuses on filtering by variance. we note that the simulated data does not exactly mimic observed microarray results. specifically, we did not consider the relationships between signal and variance and signal and significance. in addition, the simulation study applies filtering by variance on the same scale as testing and does not represent a specific preprocessing method. because of these issues, there may be concerns about the generalizability of the simulation results. the key issues for extending the simulation results are the full distribution of p-values, the null distribution of p-values and the distribution of filtered out p-values. regarding the full distribution of p-values, we choose simulation parameters to generate realistic distributions. regarding the null distribution of p-values, we examined simulation scenarios that represented both dependent and independent cases. regarding the distribution of filtered out p-values, we note that for both the case studies and the simulation, there were significant departures from the uniform distribution based on the kolmogorov-smirnov test . specifically, for all case studies, preprocessing methods and filtering methods, the k-s test rejected the assumption of uniformity  at the  <dig>  significance level. for the simulations studies, the assumption of uniformity  was rejected more than 5% of the time at the  <dig>  significance level . however, the departures from the uniform distribution seemed to be larger for the observed data.

based on our simulation study, we find that filtering by variance results in increased power without an increase in the observed fdr when paired with bh or q-value methods. while only filtering by variance was used in the simulation study, it is expected that similar results could be found if filtering by detection call had been explored. this is supported by the large overlap in the number of probe sets identified by both the variance and detection call filtering methods for the case studies. based on the three case studies examined, the percentage overlap in degs identified using detection call and variance filtering was consistently above 80% for all preprocessing methods and fdr methods . this is based on variance filtering on the original scale for mas <dig> and plier, but on both the original and log <dig> scales for rma.

while filtering by mas detection call leads to some natural thresholds , it is not clear how to choose a threshold when filtering by variance. for the simulation, we removed 50% of the genes. as long as the majority of genes are not differentially expressed, then this seems like a reasonable choice. when we examined the effect of varying the proportion filtered out, we found that the power increased until the proportion filtered out approached π <dig>  a similar effect was observed for the case studies when using π^ <dig> from the q-value method. since a common assumption of microarray analysis is that the majority of genes will not be differentially expressed, filtering 50% of the values should be reasonable in most cases. as an example, when we filter out 50% of values by variance for the diabetes data  we see consistent gains in the number of degs identified as compared to the values presented in table  <dig> .

the filtering methods examined in this paper can be applied to data with any number of treatment groups. we note that in cases when there are three or more treatment groups, the global f-test could also be used for filtering. specifically, those genes which do not pass the f-test would be removed from further testing . a concern with this method is the need to control the overall error rate. since false rejections when performing the f-test will affect false rejections when performing further testing, the fdr of the whole procedure must be controlled. jiang and doerge suggest a two-step procedure to control the overall fdr  <cit> . though the two-step procedure is only appropriate for experiments involving three or more treatment groups, if there are more than three treatment groups, it becomes very complex because the possible configurations of means of the factor levels must be determined to apply the two-step procedure.

in this paper, we focus on the use of filtering to increase the number of differentially expressed genes identified in gene expression studies when using an fdr method. however, not all researchers use fdr to identify a group of differentially expressed genes. recently, the microarray quality control  project concluded "that a straightforward approach of fold-change ranking plus non stringent p cutoff can be successful in identifying reproducible gene lists"  <cit> . we believe that this method of identifying degs by using a p-value cutoff followed by ranking genes by absolute fold change can be improved by considering the false discovery rate. in particular, an estimate of the fdr can aid in the selection of an appropriate significance cutoff, one that will help control the number of false positives.

CONCLUSIONS
the need for the multiple testing adjustments to microarray data is well established. however, after applying an fdr method, the number of differentially expressed genes that are identified in the analysis is often greatly reduced and when the number of true degs is small relative to the number of tests, applying a multiple testing adjustment can result in a substantial loss in power. in this paper we examine the effect of filtering out probe sets in order to increase power. three filtering criteria were considered: mas detection call, variance, and average signal. our analysis also considered the performance of two fdr methods  and three preprocessing methods .

for the case studies considered, filtering by detection call and variance  consistently led to an increase in the number of degs identified. on the other hand, filtering by variance on the log <dig> scale had a detrimental effect when paired with mas <dig> and plier preprocessing methods, even when the testing was done on the log <dig> scale. for a fixed preprocessing and fdr method, the degs identified with filtering by detection call and variance filtering  were largely the same.

while we saw an increase in the number of degs identified for the case studies when filtering by variance was used in combination with an fdr method, we cannot determine whether this is due to an increase in power or false discovery rate. hence a simulation study was performed to examine the issues of power and false discovery rate. the simulation study demonstrates that filtering by variance  improves the power over a range of null proportions for the two fdr methods considered. the q-value method has higher power than bh in all the cases considered both with or without filtering. the observed fdr is maintained close to or below the stated level for both fdr procedures. overall, filtering by variance can effectively increase power while maintaining the stated fdr and performs especially well when paired with q-value method.

finally, we examined the effect of various thresholds for variance filtering. we found that filtering out 50% of probe sets seems reasonable as long as the majority of genes are expected to be equally expressed. this assumption can be checked based on the estimate of π <dig> provided by the q-value method.

