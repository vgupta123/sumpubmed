BACKGROUND
whole exome capture sequencing  represents a cost effective approach to identify the mutations of highest biomedical importance, generating hypotheses for downstream follow-up  <cit> . the cost of wecs is currently only ~1/ <dig> of the cost of whole genome sequencing performed on next-generation sequencing  platforms; it is a flexible approach designed to detect rare variants segregating in affected families, to follow up on already identified regions of interest in large scale association studies, and to produce more interpretable variant results  <cit> . in the past few years, wecs has rapidly gained popularity in disease studies and has even helped reveal many highly interesting causal loci  <cit> 

while capture sequencing technologies have matured and stabilized to a level appropriate for routine use, there are few generally available analysis tools specialized for dealing with exome capture data. wecs data introduces a set of biases and error patterns distinct from whole genome sequencing, such as heterogeneous depth coverage, and reference bias due to capture  <cit> . the coding regions of the human genome also modify the expectation of a number of quality metrics that are routinely used in variant calling such as transition/transversion ratio , and percentage of insertion-deletion polymorphisms introducing frameshifts. thus far, a few bioinformatics tools primarily developed for whole genome analysis have been utilized in wecs with some success, but extensive manual adjustments--such as setting stricter cutoffs and/or implementing several additional ad-hoc filters pertinent to coding regions--based on the user's own biomedical and informatic insights are required  <cit> .

here we present the atlas <dig> suite, a suite of tools specialized for calling variants in wecs on multiple sequencing platforms  which detects both snps and short range  insertion-deletions . ). the atlas <dig> suite makes use of logistic regression models trained on wecs data to identify snp and indel sites with high sensitivity and specificity, and to subsequently produce genotypes.

wide adoption of wecs in both research and clinical settings is currently limited by the data analysis bottleneck including the shortage of bioinformatics expertise and inadequate computational resources. small clinical laboratories are particularly affected by this limitation. to address this bottleneck, we made the atlas <dig> suite web-accessible via the genboree discovery system http://www.genboree.org , allowing researchers with a minimal level of bioinformatics training and computational resources, using only a web browser to carry out variant analysis, understand functional implications, and generate hypotheses for followup studies. in the context of a research study, the additional access control, role assignment, data protection, and collaborative features of genboree aids researchers in meeting many administrative, physical, and technical provisions of the hipaa privacy rule.

implementation
overview of atlas <dig> pipeline
the primary components of the atlas <dig> suite are atlas-snp <dig> and atlas-indel <dig> . each of these applications accepts single sample alignment data in binary sequence alignment/mapping format   <cit>  and produces snp or indel calls in the variant call format   <cit> . the initial single sample vcf files may be merged and annotated into a population vcf file using the 'vcfprinter' module within atlas <dig> 

to separate true variants from sequencing, mapping, and alignment errors, the atlas <dig> suite collects read depths for each allele, read quality scores, and other pertinent data at each variant locus and applies a trained logistic regression model to assess the quality of each potential variant . we exhaustively examined possible variables , and found the most significant variables were related to read depth ratio, base quality score, variant position in the read, and the read strand direction distribution. the logistic regression models return the probability  that the given variant is a true variant. to deal with the small number of edge cases which the model may misclassify, and for another layer of flexibility on the users' end, variant calls are subjected to a few basic heuristic filters such as minimum read depth and minimum variant read ratio. variants with a p greater than a default cutoff and which pass the heuristic filters are included in the final variant call set in vcf format. based on our initial evaluation results, we optimized the suite's cutoffs and options to balance sensitivity and precision. users are also able to tune the parameters to make a call set more suitable to their data and research context.

variables and interactions for both the snp and indel models along with the variable's wald z-statistic and p-value as estimated by the r environment's glm function. the z-values and p-values indicate the significance of the variables in the model, with the most significant variables having a z-value furthest from zero.

the atlas <dig> suite is currently specialized for variant detection within exonic regions on existing ngs platforms, but it also can easily be evolved to work with new technologies. in order to identify systematic sequencing and mapping errors on a wide variety of platforms, the model training procedure tests a series of variables on a training set of true positive  and false positive  variants. for example, there are  <dig> and  <dig> variables evaluated for snps and indels for solid, respectively . while variables that are significant for a specific platform may vary, we have established a semi-automated pipeline for re-training the regression models for different platforms. the atlas <dig> suite is written in a modularized manner that allows us to rebuild the regression models for new types of data and integrate it into the application in just a few days. this ability ensures that the atlas <dig> suite remains as an up-to-date and effective variant calling tool in the midst of rapidly evolving sequencing technologies.

statistical model in atlas2
in solid atlas-snp <dig>  we found five variables and two interactions to be most significant in regression model training: reference/variant reads ratio, mean variant base quality, mean neighboring base quality , mean variant distance to the 3' end, strand direction standard, the interaction between nbq and mean distance to 3' end, and the interaction between strand direction standard and mean distance to 3' end . the reference/variant reads ratio acts as a simple measure of the direct evidence for and against the variant. as expected, sequencing and mapping errors generally have a much higher reference/variant reads ratio than true snps . the mean variant base quality takes the mean of each variant read's base quality at the snp locus as reported by the sequencer. this provides a measure of the overall sequencing reliability of the variant bases. the nbq is defined as the mean base quality score of the variant base and its  <dig> flanking base pairs  on either side of the read. nbq is a quantitative variation of the neighboring quality standard which has already been established as an effective metric in the roche  <dig> version of atlas-snp <dig> and other variant calling pipelines  <cit> . the hypothesis behind this variable is that even bases with relatively high base qualities may be false positives if they are surrounded by bases of very low quality scores  <cit> ; also reads with multiple sequencing errors are more likely to be mismapped. the mean variant distance to the 3' end is the mean distance from the variant site to the 3' end of the read in all variant reads. sequencing quality generally diminishes towards the end of each read, so snps near the 3' end are often of lower quality . the strand direction standard is a boolean variable which is set to  <dig> when there is at least one variant read in each strand direction. for true variants, the variant read strand direction is expected to follow a binary distribution with a roughly 50% probability for each direction; however, false variants are often found in only a single strand direction even when there is a large number of variant reads. in our training data we found that only 14% of the false snps had evidence in both strand directions, compared 94% for the true snps .

by performing a simple cross-validation procedure within the training data , we were able to test the model for overfitting and provide an in silico estimate of its performance . the model was evaluated at all possible p cutoffs in terms of precision  and sensitivity . results estimate the model is able to achieve a 97% recall rate and a precision of no less than 90% . at the optimal cutoff of p â‰¥  <dig> , the average performance of all cross validation iterations almost exactly matches that of the actual model evaluated on all training data, indicating that the model is not overfit.

atlas-indel <dig> uses a similar logistic regression model to separate true-positive and false-positive indels. during model training we discovered the most significant variables for indel calling to be the normalized variant square , the mean nbq, the mean variation rate of the reads, and the read-end ratio . the nvs is the number of variant reads squared and divided by the total read depth. in our initial testing the variant read depth was found to be extremely significant while the variant read ratio  was not significant enough to be included in the model. this is partially due to the smaller indel training set which limited the number of variables we could include in the model without overfitting. we were concerned that using the variant read depth without any type of variant read ratio variable would introduce too much bias based on total coverage, which may vary considerably, especially from experiment to experiment. our solution was to square the variant reads in the variant read ratio to give the nvs, which retains the significance of the variant read depth, but is normalized by the total read depth to remove any bias. effectively, the nvs allows the model to consider both the variant read depth and the variant read ratio together in a single variable. the mean nbq variable is defined the same as for the atlas-snp <dig> model. the variation rate is calculated by counting the number of mismatches and gaps in a read and dividing by the read length. while the reported mapping quality was not found to be at all significant , the mean variation rate provides a simple indication of the mapping quality of the variant reads that was found to be highly significant. the read-end ratio variable is the number of reads where the indel is within  <dig> base-pairs of either read-end divided by the total number of variant reads. while visually inspecting fp indels, we noticed several were found primarily at the end of reads. this can be attributed to both the lower sequencing quality near the 3' end and the difficulty in mapping indels near read-ends. the read-end ratio variable was designed to identify these types of errors.

in silico cross-validation testing indicates that for indels that posses at least  <dig> variant reads  the regression model is capable of calling indels with ~95% sensitivity and ~96% precision . the regression model does not perform well in cases where only a single variant read is present. our testing results indicate that the indel model is not overfit, with the average performance of all cross validation iterations closely matching the actual model's performance.

the indel logistic regression model was trained on a validated call set from human sample sequencing data  for details). although the variables tested during the model training included the variables used in the atlas-snp <dig> model, only the mean nbq variable is included in both the snp and indel models. the difference in which variables are most significant may be attributed to the different nature of error patterns around snps and indels. for example, while the snp model uses the mean distance to the 3' end, the indel model uses the read end ratio variable. both variables measure a similar metric, but while the distance to 3' variable is primarily related to detecting sequencing errors, the read end ratio is also useful in identifying mapping errors, which are the primary cause of false indels. as a result, the read end ratio is more significant than the distance to 3' in the indel model. an example of a more practical difference is that while the variant base quality is a clearly significant variable for snps, such a variable cannot be used for deletions which have no sequenced base or base quality.

the atlas <dig> suite also includes models for variant calling data from the illumina platform. the illumina snp model is described in detail in our previous publication, where we have shown it to have high precision and sensitivity   <cit> . our indel illumina model is described in detail in the supplement , and is estimated to have high precision and sensitivity .

RESULTS
to evaluate the performance of the atlas <dig> suite, we processed  <dig> samples from the  <dig> genomes  phase  <dig> whole exome project http://www.1000genomes.org, which is an ongoing large scale population resequencing project aiming to provide the most comprehensive human variant call set  <cit> . these  <dig> samples were chosen because they are also included in the 1000g exon pilot project  <cit> . for indels, we additionally analyzed  <dig> samples from the 1000g whole exome project for comparison against other indel callers.

in the  <dig> samples a total of  <dig>  snps were discovered, with an average of  <dig>  snps per sample . previous studies have established an expected transition/transversion  ratio of 3- <dig> for coding regions  <cit> . the atlas-snp <dig> call set has a ts/tv ratio of  <dig>  and a dbsnp v129b re-discovery rate of  <dig> %. we also checked the snp density by normalizing the number of snps against each sample's callable region. the average snp density of the  <dig> exomes was  <dig>  snp per  <dig>  bp, which is consistent with previous results in the  <dig> g exon pilot data 

we compared the snp calls of atlas-snp <dig> to the latest official release of  <dig> g exon pilot snp calls  on a sample-by-sample basis . only snp calls on the consensus high coverage genomic region of the two data sets were compared. on average, atlas-snp <dig> re-discovered  <dig> % of the snps called in  <dig> g exon project on the consensus region.  <dig> % of the snps discovered in  <dig> g exome data by atlas-snp <dig> are confirmed by the  <dig> g exon project data. with a ts/tv ratio of  <dig>  and a dbsnp re-discovery rate of  <dig> %, the remaining  <dig> % of snps unique to the exome call set are likely to be true snps not discovered in the exon project, which resulted from the stringent calling procedure employed by the exon pilot project  <cit>  as well as the evolving nature of the capture sequencing technology.

in the  <dig> samples we ran through the atlas <dig> suite pipeline, we called a total of  <dig>  indels, with an average of  <dig> indels per sample . frameshift indels in coding dna nearly always render the resulting protein non-functional, and are expected to be significantly less common than in non-coding dna. previous studies have indicated that approximately 50% of coding indels cause frameshifts  <cit> . the samples analyzed by atlas-indel <dig> were found to have an average in-frame rate  of  <dig> %, indicating the call set may be of high quality.

for the purpose of comparison against other variant calling tools,  <dig> samples  were processed by atlas-indel <dig>  gatk  <cit> , and samtools mpileup  <cit>  . results were compared on the basis of total exome indels called and the percent of the indels that are in-frame . the comparison shows that the atlas-indel <dig> call set has a significantly higher average in-frame rate of  <dig> % compared to  <dig> % for gatk and  <dig> % for samtools mpileup . in these  <dig> samples, atlas-indel <dig> called an average of  <dig> indels per sample, while gatk called  <dig>  indels per sample and samtools called  <dig>  indels per sample.  <dig> indels per sample is much closer to the number found in previous exome indel studies  <cit> . the low in-frame rate and large call set size for gatk and samtools indicate a much higher false-positive rate compared to atlas-indel <dig> .

average indels/sample
summary of indels called by atlas-indel <dig>  gatk unified genotyper and samtools mpileup on  <dig> solid samples . the metrics compared are the average number of coding and non-coding indels per sample, the number of indel alleles merged across all  <dig> samples and the %  <dig> indels. the  <dig> indels refer to indels with a length of multiples of  <dig>  which do not cause a frameshift mutation in the coding region. previous studies have reported that coding regions tend to harbor less frameshift-causing indels. coding refers to the consensus exome target regions of the genome as defined by the  <dig> genomes consortium. non-coding refers to all the regions outside of the exome target regions. in the merged call sets, indels at the same site found in different samples are merged together in a population vcf file. individual sample results are shown in additional file  <dig> 

atlas-indel <dig> is also specifically tuned for the illumina platform in short indel calling and genotyping. the model is described in detail in the supplement . as with the solid data, we analyzed a small number of illumina samples and compared the results of atlas <dig> to a few other widely used indel callers including dindel  <cit>  and gatk  <cit> . the results show that all callers performed very similarly, calling between 221- <dig> average coding indels per sample with an average in-frame rate of 57-61% . 86% of the indel sites called by atlas-indel <dig> were also called by dindel and 89% were also called by gatk .

computational performance
the regular size of wecs bams is 10- <dig> gigabytes per bam. despite the enormous size of high coverage sequencing data, the atlas <dig> suite is engineered in a manner that allows it to process wecs data on a standard desktop computer or a small server in a reasonable amount of time. sequencing reads are processed one at a time, with a minimal number stored in memory. the result is that the run-time increases linearly with the bam file size and memory usage remains constant . memory usage is dependant on the reference genome used; for example, using the human reference genome the maximum memory usage is about  <dig> mb. a whole exome  <dig> gb bam file will take approximately  <dig> hours to be processed by atlas-snp <dig> and  <dig>  hours by atlas-indel <dig>  using one core of a  <dig>  ghz intel xeon processor. using  <dig> cpu cores on a computational cluster we are able to process all  <dig> samples in ~ <dig> hours for snps and ~ <dig> hours for indels, demonstrating that the atlas <dig> suite is well suited for population scale analysis.

using atlas <dig> in the genboree workbench for integrative genomic analysis
in order to make the atlas <dig> suite tools accessible to a wide range of researchers we integrated the tools into the genboree workbench . primarily aimed at collaborative genomics research, genboree provides web-based services for groups of researchers to share, visualize, and analyze genomic annotations and raw data files. using the graphical user interface at the workbench, researchers can run atlas <dig> suite tools on their bam and sam files . the interface provides help information, validation of parameters, and adds the ability to upload the snp and indel calls as annotation tracks. upon submission, the configured job is added to the genboree job queue and will execute on a modest compute cluster, after which the user is notified of job completion via email. the result files are also made available to the collaborating researchers via the workbench, and are organized in a directory structure using the study and job names provided by the researcher .

by running the atlas <dig> suite tools via the workbench, researchers benefit from integrative analysis. for example, if the snp calls are uploaded as an annotation track, they can be viewed visually in the internal genome browser . researchers can also configure genboree to export their snp tracks to the ucsc browser, and can use the tracks as inputs to other workbench tools. additionally, the workbench provides us with a framework for adding new altas <dig> suite models and additional external tools. because the workbench is implemented on top of the genboree http rest api, researchers can automate this kind of analysis. for example, bam file upload and launching an atlas <dig> suite tool can be done through the api, as can checking if result files are available and, if so, downloading them. using the apis, the researchers can also extend the analysis capabilities using their own software.

CONCLUSIONS
as exome capture continues to become an effective method for high coverage gene sequencing and mutation discovery in personalized diagnosis, there is strong demand for a complementary set of data analysis tools specialized for the unique error models and other challenges inherent to exome capture. the atlas <dig> suite provides an effective and flexible solution to exome variant detection and genotyping, using statistical methods trained on exon capture data. we have applied our method to  <dig> whole exome human samples and demonstrated the suite is capable of producing sensitive and accurate variant calls in a reasonable amount of time.

integration of the atlas <dig> suite into the genboree workbench provides the benefits of a visual interface, the easy sharing of access-controlled data, a hierarchy for organizing results of multiple analysis jobs, the potential for integrative analysis, and automation support. these additional resources provide a valuable online tool set to the wider research community.

the results of the atlas <dig> suite model development are beneficial not only for use in calling variants, but also for classifying variants and identifying error models for exon capture data that can be applied in a more general sense. for example, it was somewhat unexpected to discover that for snps the base quality score of the variant site is less significant than the base qualities of the surrounding bases in the mean nbq; the number of variant reads was not even significant enough to be included in the final model . we discovered that the most significant variable in snp calling was the reference/variant read ratio. almost all true snps had a reference/variant ratio less than  <dig>  while most false snps had a ratio greater than  <dig>  the most surprising discovery in the indel model training was that the mapping quality had almost no significance and could not be used to improve indel calls. we found, however, that the variation rate of the reads  provided a better surrogate to capture the alignment quality in a region that harbors an indel.

while highly accurate snp calling  has become a very achievable goal using current methods, such consistent results remain a serious challenge for indel calling. in our comparison of the different solid indel callers over 90% of the indel calls were unique to one of the callers . the overlap looks much better in illumina comparison, but there are still 20% of the indel calls which were unique to one of the callers . the short read length and high error rate of ngs technology makes indel calling inherently challenging . in order to gain significant improvement we will likely need to widen our approach to include other methods such as de novo or guided assembly.

we intend to continue maintenance and improvement of the atlas <dig> suite through a series of regular releases. atlas <dig> will be updated as training data becomes available on new sequencing platforms.

