BACKGROUND
aiming at high throughput plant phenotyping, one of the main challenges is the robust and automatic analysis of plant data  <cit> . in this context phenotyping implies the measurement of observable plant attributes, reflecting the biological function of gene variants as affected by the environment  <cit> . whereby modern phenotyping techniques are used to study growth and development of large sets of plant genotypes under different stress situations  <cit> . in this connection 3d laserscanning allows a non-destructive assessment of various plant parameters under controlled conditions. the plant architecture, the plant height and size, specific plant organs or the organ volume can be deduced from the 3d structure of plants. a detailed evaluation of these parameters through time will help to link alteration in plant growth to stress tolerance, or to predict the yield potential of different genotypes.

structural geometrical analysis of plants is an important technique to observe the development and growth of plants or the reaction of plants to abiotic and biotic stresses  <cit> . highly resolved analysis enables the establishment of 3d organ based architectural models, like functional structural plant models  <cit> . the observation of subtle changes can be used to link geometrical deviation and deformation to environmental effects  <cit> . 3d-measuring devices like 3d-cameras, photogrammetric methods or laserscanners  <cit>  provide non-contact and non-destructive 3d-measurements. however, only highly resolved and accurate 3d point clouds enable a valid description of the geometry of plant organs. laserscanning results in huge point clouds with more than hundred thousand data points for a whole plant or ten to thirty-thousand points per plant organ  <cit> . this technique has been used in various studies for plant analysis  <cit>  and stands out due to its quick, direct and automatic data collection  <cit> . thus, the requirements for an implementation in phenotyping process are fulfilled.

the automatic recognition of shapes from point clouds is a prerequisite for plant phenotyping. the recognition of geometrical standard shapes like cylinders, spheres, planes or cones as well as combinations and variations is well described in various fields of research  <cit> . for 3d plant analysis the most common approaches use 3d mesh processing  <cit> . paproki a,  <dig>  <cit>  used a 3d point cloud created out of  <dig> images of a cotton plant to detect single plant organs. aiming at a segmentation of leaves, main stem and petioles, a region growing algorithm sensitive for curvature, noise, sharp edges and smoothness constraints was applied to a pre-calculated mesh. furthermore primitive fitting algorithms were used to approximate organs like stems or petioles. the resulting regions were used for organ specific parameterization. this approach requires plant organs that can be abstracted by primitives and certain smoothness constraints e.g. of the leaf surface.

an entirely different approach that avoids mesh processing and uses more explicit properties to describe surfaces is the so called surface feature histogram  <cit> . furthermore it overcomes the demands of smoothness constraints and the abstraction of primitives. these histograms enable a direct point classification by using descriptors for surface curvature and pointnormal-properties; moreover they provide an invariance to translation and 3d rotation. this technique has been optimized for the recognition of geometrical standard shapes  <cit> , 3d point cloud registration  <cit> , pose recognition  <cit>  and for the recognition of kitchen objects like cupboards, tables and cups  <cit> . points were linked to classes with similar surface properties by using support vector machines  or conditional random field  classification  <cit> . with this approach regions of similar points can be determined and a following model fitting can be applied to extract geometrical and functional maps of the environment  <cit> . this technique can be directly applied to a point cloud without calculating an additional surface representation as it is necessary for mesh-based approaches. however, it has to be demonstrated whether the recognition of point classes due to their surface properties and the extraction of geometrical maps can be transferred to various situations in plant research. this task is of high importance for plant phenotyping, where high throughput laserscans of plants can be used to extract growth curves of specific plant organs  <cit> .

surface feature histograms have shown their applicability for online procession in robotics. the transfer of this method to plant phenotyping promises huge benefits to speed up phenotyping processes with high accuracy. especially the application to highly resolved close-up laserscans from plants has never been realized before. until now a descriptive representation of the local geometry of plant point clouds by surface feature histograms has not been applied to complex structures like plant organs . the establishment of 3d measuring devices for plant imaging during the past years and upcoming high precision laserscanning methods particularly evoke the demand of specified and adapted techniques and algorithms for point cloud processing  <cit> . certainly laserscanning provides euclidian xyz-data with device specific differences in the point to point distance , the amount of occlusion and in the accuracy. hence a fast and accurate data processing method is required for the implementation in an automatic measuring and classification workflow. previous experiments show the demand for algorithms aiming at an automated classification  <cit>  without specific requirements on the shape  <cit>  or on additional sensor data  <cit> .

in the present paper, we introduce an adapted surface feature based technique for an automated pointwise classification of plant organs from 3d laserscans. we show an automated separation of grapevine point clouds to the plant organs leaf and stem, as well as a separation of wheat ears and stems to extract yield parameters. furthermore, the impact of the point cloud resolution was evaluated with respect to the classification accuracy.

RESULTS
the main focus of this study is the processing of 3d point clouds, which do not provide any additional information for the classification like e.g. color. we aim at a geometry based labeling of single points, which can be used to define regions of similar geometry, describing underlying plant organs as it is important for parameterization. the three key outcomes of this methological study are i) the adaption of a low resolution algorithm on the demands of highly resolved point clouds for grapevine plant organ classification, ii) an empirical evaluation of different point resolutions to show the validity for different kinds of 3d-measuring devices and iii) the integration of the proposed method in a processing workflow for an automated yield calculation of wheat plants.

plant organ classification by feature based histograms
surface feature histograms show unique characteristics for point clouds that differ in the euclidean properties of their surface. figure  <dig> introduces the geometrical descriptions of the surface properties of two point clouds of a grapevine leaf  and a grapevine stem , visualized as surface feature histogram. the algorithm of  <cit>  calculates surface feature histograms using pointwise neighbor features. to increase the descriptive properties of surface feature histograms even with large histogram radii, we introduced a distance weight for the calculation. subsequently, these histograms were used as features for svm classification.

the classification results of a grapevine scan for different point cloud resolutions, from  <dig>  mm to  <dig>  mm, is shown in table  <dig>  the mean results of a repeated random sub-sample cross-validation using ten iterations are presented. 4% of the points were randomly chosen training data for each class. this approach provides a reasonable prediction as it is necessary for real applications. a resolution of e.g.  <dig>  mm implies that the point cloud shows minimal point to point distances of not less than  <dig>  mm. the normal for every point has to be calculated due to the output of laserscanners pure 3d point clouds. therefore the neighbors of a source point within the radius rnormal = rn were used. comparable to this, the calculation of the surface feature histogram only considered points within radius rhistogram = rh. each column of table  <dig> describes the results for the combination of different rn and rh varying from 13mm to  <dig> mm in steps of 13mm for both variables. best performing combinations of rn and rh, for each resolution, were evaluated. as initial values for rn, the value slightly bigger than the point cloud resolution was used and as maximum value the radius of the smallest object - here the stem diameter  was chosen. the histogram algorithm requires a rn that is smaller than rh, but bigger than the point cloud resolution. due to this restriction the amount of combinations decreases with increasing point resolution. thus resolutions above  <dig>  mm result only in one specific value or were not calculable. the best classification results were shown together with related rn and rh values. the classification results were validated using manually distinguished data, labeled by geomagic studio  <dig> 64bit .

satisfying classification accuracies of ≥90% were achieved for point cloud resolutions between  <dig>  mm and  <dig>  mm. the best classification results above 96% were constantly reached for resolutions smaller than  <dig>  mm. indeed the best classification accuracy of  <dig> % was found at a point cloud resolution of  <dig>  mm using rn =  <dig>  mm and rh =  <dig>  mm. furthermore, the classification results for different point cloud resolutions depends on the combination of rn and rh. for each point cloud resolution the best classification results can be reached by using a large radius rh. while this tendency is valid throughout all different resolutions, this can not be generalized for rn.

furthermore, we perceive a slow decrease in the classification accuracy with a decreasing resolution. this is strongly connected with a decreasing number of points providing the point cloud. at a resolution of e.g.  <dig>  mm  <dig> points were considered,  <dig> for a resolution of  <dig>  mm and  <dig> points at the lowest resolution of  <dig>  mm. considering the ground truth data, approximately 80% of all points belong to the grapevine leaves and 20% to grapevine stems for throughout the used point cloud resolutions. at the highest resolution of  <dig>  mm more than  <dig> thousand points were mislabeled. this amounts to only  <dig> % of the respective  <dig> considered points. a similar percentage of misclassified points were obtained at higher resolutions.

further analysis showed an influence of the parameters rn and rh to the classification accuracy. the variation in classification accuracy for rn,rh ≤  <dig> mm and a fix point cloud resolution of  <dig>  mm is shown in figure  <dig>  a resolution of  <dig>  mm was chosen exemplary for the visualization in figure  <dig>  due to its satisfying results regarding calculation time and classification accuracy. our aim is a deeper understanding of the impact of the used radii rn and rh to the classification result. the best classification accuracy of more than 99% can be found within a small radius of rn between  <dig>  mm and  <dig>  mm and a rh of  <dig>  mm to  <dig> mm.

in figure  <dig>  a detailed view on a classified grapevine point cloud with a point resolution of  <dig> mm is shown. using rn =  <dig>  mm and rh =  <dig> mm an accuracy of about 99% has been reached. unfortunately, this means that  <dig> of  <dig> points have a wrong classification label . figure  <dig>  and  show typical misclassification of the plant organ. points that belong to a grapevine stem  are misclassified in regions where we locate a surface geometry very similar to a leaf surface  geometry . vice versa parts of the leaf surface are classified as stem, especially at the transition between leaf and stem and in the border area of the leaf .

we have introduced surface feature histograms together with svm classification as a method for a highly accurate separation of plant organs of a grapevine plant. we determined r<rn<<rh with r represents the point clouds resolution. using histogram radii of  <dig> − <dig> mm leads to a satisfying covering of the points neighborhood. this results in a high classification accuracy of about 99%. the resolution should be choosen with respec to the expansion of the smallest object which has to be classified. thus, the resolution of the grapevine point cloud shouldn’t be bigger than the minimal diameter of the stems.

wheat yield estimation by online processing
previous results have shown histogram based classification for 3d point clouds of grapevine for an automated extraction of plant organs such as leaf and stem. in the following subsection we transfer previous findings to the classification of 3d point clouds of wheat plants, to determine stem and ear points automatically. this method was integrated in a workflow for an automated volume calculation of wheat ears, which is of importance for wheat yield estimation and prediction. it shows the applicability of 3d laserscanning in high throughput phenotyping.

a wheat point cloud with a resolution of  <dig>  mm was used for further processing, in accordance to our experience from grapevine plant organ classification. for normal- and histogram calculation rn =  <dig>  mm and rh =  <dig> mm were used. the processing pipeline is as follows 1) laserscanning, 2) pre-processing including cutting of pot points and leaf points, 3) normal calculation, 4) histogram calculation, 5) classification using svm, 6) region growing and 7) parameter extraction. a visualization of the dataflow is shown in figure  <dig>  steps  <dig> to  <dig> have been outlined before and were described in the subsection above, therefore we focus on the last two steps to detect the different regions of the labeled point cloud. it was assumed that regions of interest have a significantly bigger size than mislabeled regions. thus, smaller regions are mislabeled and can be connected to bigger regions next to them. this was done using a region growing algorithm. the results can be seen in figure  <dig>  the left side shows a characteristic histogram for wheat ears  and wheat stems  that were calculated out of the training data and used for subsequent svm classification. figure  <dig>  shows the results of the classification process of one plant after the region growing step. separated by colors, the regions are visible. originally the classification resulted in  <dig> regions. these were reduced to  <dig> regions by region growing, clearly dividing  <dig> ear and  <dig> stem regions. overall we reached a mean classification accuracy of  <dig> % at a calculation time of  <dig>  minutes and  <dig> thousand points to classify eleven of twelve wheat ears using a leave-one-out cross-classification method. a clear separation of a wheat laserscan was shown using surface feature histograms. the points were allocated to the classes ear and stem and aggregated to a relevant region size. this was done fully automated and enabled the application of a volume estimation algorithms.

after the classification of different plant organs quantitative plant parameters were deduced from 3d laserscans. an alpha shape volume estimation was applied to the organ regions. this method enabled an easy and fast way for volume estimation and an accurate description of the concave wheat ears. these parameters were related to manually assessed yield parameters. significant correlations were found between the measured ear volume and de facto yield parameters. the parameters total ear weight, total kernel weight and number of kernels showed high correlations of r2 =  <dig> , r2 =  <dig> , and r2= <dig> , respectively .

discussion
the main goal of the current research was to find a fast and accurate technique for the classification of different plant organs out of laserscanned plant point clouds. a method from robotics  <cit>  was modified and extended to the demands of plant organ classification from high precision laserscans for plant phenotyping. it was applied to the classification of grapevine point clouds to determine leaf and stem points,and to separate wheat point clouds into stem and ear points. both point cloud classification problems were solved with a high accuracy of more than 96% within a relatively short calculation time of a few minutes.

separation of plant organs was reached by a new surface description method. our method trains the local geometry of the organs and can e.g. be used for classification of various plants by using only one single manually labeled plant. previous research used a pre-calculated mesh  <cit>  with special surface assumptions like smoothness constraints or approximation by primitives to separate single plant organs. we were able to reduce the amount of external knowledge required for classification and to avoid mesh calculation by adapting a method based on the points itself. however, difficulties arise when the transition is not clearly defined between different plant organs. this is the case between a leaf and a stem or for plain stem regions which are similar to a plain leaf surface. here the results are small regions with a wrong label. to overcome this effect, we implemented a region growing algorithm following the assumption that smaller regions received an incorrect classification label. this was successfully implemented for the classification of large connected regions as shown for wheat ears and grapevine leaves, but fails for the classification of smaller regions like e.g. leaf veins. the classification workflow results in regions describing the single plant organs that can be used for a direct parameter extraction, such as e.g. ear volume. an accurate and early estimation of grain yield is desirable for plant breeding or agrobusiness. in plant breeding, genotypes with high potential yield have to be selected in high throughput. yield estimation in the field is required e.g. for planning harvest and storing requirements, for cash flow budgeting or for crop insurance purposes. until now extensive personal experience is essential for visually estimating yield of cereal crops, alternately destructive assessment is the method of choice  <cit> . our laserscanning approach can substitute traditional yield estimation techniques. principal benefits are the objectiveness, the high accuracy and reproducibility. separation of single organs is the key to enable plant parameterization on the organ level.

the proposed method can be applied to different plant types and different organ geometries. previous research with stereo camera systems  <cit>  or time of flight cameras  <cit>  is supported as well as laserscanning devices with various point resolutions  <cit> . this has been proven by the reduction of the point cloud resolution, still resulting in satisfying results . seitz s,  <dig>  <cit>  showed that algorithms for multi-view stereo reconstruction improve rapidly and provide a point accuracy that is only slightly lower than the accuracy provided by the laserscanning. furthermore  <cit>  had shown its applicability for the use of noisy point clouds with a very low accuracy. hence, the method is independent of the used 3d imaging sensor.

aiming at an integration in existing high throughput phenotyping environments a deeper look into the calculation time is necessary. the computational effort is closely linked to the number of points  and the number of points in the neighborhood . the bigger the used histogram radius and the higher the point cloud resolution, the more points influence the histogram calculation. this leads to a computational complexity of o as it was shown by  <cit> . we can confirm this assumption by our results. e.g. reducing the resolution from  <dig>  mm to  <dig>  mm results in 25% of the original number  of points and calculate histograms with the same radius of e.g.  <dig>  mm, the calculation time is reduced to about 10% compared to 25% of the original time. this can be explained by a decrease in the number of points that have to be considered in every calculation step . the calculation time for the histogram based approach is comparable to the processing time and thus it is well suited for online processing. compared to  <cit>  who used 2-d images to assess the leaf area of different arabidopsis genotypes, our approach enables an automated labeling of wheat and grapevine plants in less than two minutes for a resolution of  <dig> mm in 3d.

with respect to a fast and optimized calculation time - which can still be improved by e.g. faster implementation using the computers graphical unit - the method is well suited for the demands of automated high throughput phenotyping. these platforms collect an increasing amount of data, temporarily and spatially highly resolved  <cit> . an automated data processing method for high resolution point clouds is needed for classifying and characterizing various plant organs. beyond this scope our method can be seen as a generalized approach for high throughput plant parameterization. current methods  <cit>  can be improved by adding surface properties to the organ separation step without calculating a triangle mesh or special requirements regarding e.g. smoothness.

our method enables an automated classification of plant organs for plant parameterization. this can be implemented as an autonomous work package in a phenotyping process. based on the presented approach, a database with class-specific training data can be introduced, where expressive histograms are used for the classification of unknown point clouds. this will improve the modeling of plants  <cit>  which in turn can be used to improve the classification due to knowledge of the structure rules of a plant and its organs. the proposed method provides outstanding potential to be implemented in a sensor fusion approach for plant phenotyping or screening processes with optical devices  <cit> . future research will concentrate on linking 3d-laserscans with imaging sensor data such as hyperspectral imaging or thermography to improve the accuracy in observing the impact of abiotic or biotic factors on plant physiology and on the plant phenotype.

CONCLUSIONS
automated organ parameterization is of high importance for plant phenotyping. we demonstrated that this can be realized using 3d point clouds without applying any mesh processing algorithm. only little apriori knowledge of the plant organ surface is required, which can be trained independent of the data. we obtained highly accurate results for organ classification of a grapevine plant by using surface feature histograms. furthermore, our approach was applied to wheat ear parameterization, which was compared to manually measured yield parameters.

the strength of our approach is the flexibility for an application to various 3d measuring devices and it can be generalized for the classification of different plants and plant organs. automated and reproducible characterization of various plant 3d point clouds with high accuracy and its integration in high throughput phenotyping procedures was realized. future research will concentrate on enhancing the geometrical sensitivity. furthermore we will improve the direct parameterization of various organs like stem, ears and leaves at the same time and in one processing step by using multi-class classification.

