BACKGROUND
simultaneous measurement of gene expression on a genomic scale can be accomplished using microarray technology or by sequencing based methods  <cit> . many high-throughput mrna expression experiments produce data that can be of value to other researchers when analyzed in new contexts or in combination with data from other experiments. in particular, the statistical power and reproducibility of gene expression studies can be increased by combining data across multiple studies  <cit> . while next generation sequencing seems likely to replace microarrays for expression analysis in the near future, the large amount of microarray data already in existence could continue to be useful to researchers for many years to come.

modern microarrays are commercially produced, and one-color hybridization schemes are often employed. several companies have emerged as leading manufacturers, each using different manufacturing techniques, labeling methods, hybridization protocols, probe lengths, and probe sequences. table  <dig> lists some important characteristics of the microarray platforms analyzed in this work. these characteristics can affect microarray performance  <cit> . the length of probes represents a tradeoff between sensitivity and specificity, with longer probes being generally more sensitive and shorter being more specific. the use of linkers to reduce steric hindrance, as employed by the applied biosystems and illumina platforms in table  <dig> is one method for increasing the sensitivity of short probes. the method by which probes are constructed and attached, and the overall construction of the array, can affect probe uniformity and intra-platform reproducibility. labeling and detection chemistry affect the dynamic range of detection.

characteristics of microarray platforms analyzed in this work. see references  <cit>  for information sources.

chemiluminescence provides greater sensitivity for low levels of expression compared to fluorescence, but at the risk of saturation for highly expressed genes. the applied biosystems scanning procedure attempts to mitigate scanner saturation by using both a short and a long exposure to extend the dynamic range of its expression measurements. probe sequences affect the binding constants between probes and target and non-target molecules, and therefore the sensitivity and specificity of each probe depends partially on its sequence. salinity and composition of the hybridization solution, temperature, and incubation time of hybridization may also affect sensitivity and specificity. data from two microarrays are directly comparable only if those microarrays are identical in all design parameters including probe sequences and have been subjected to similar hybridization conditions. because no two platforms share the same set of probe sequences, no two platforms produce data that are directly comparable, even if all other variables are the same. for experimenters this restriction is not major. they need only ensure that all experiments are conducted using the same array platform and protocol. however, platform effects pose a significant problem for the re-analysis of data from multiple microarray studies.

researchers who perform high throughput gene expression assays often deposit their data in public databases such as arrayexpress  <cit>  and gene expression omnibus   <cit> , the latter of which currently houses  <dig>   <dig> assays distributed among  <dig>   <dig> platforms. heterogeneity of measurement platforms leads to challenges for the re-use of these large data sets, creating limitations for researchers wishing to combine them. extensive effort has been directed toward assessing the reproducibility of differential expression measurements across different platforms. several studies have found good agreement among gene expression profiles produced by different platforms  <cit> , while other studies have had conflicting results  <cit> . technical issues pertaining to such evaluations include homogeneity of rna samples, consistency of experimental protocols, mapping of probes across platforms, and the statistical methods used to assess reproducibility . those studies in which good intra-platform reproducibility was achieved and log ratios were compared across platforms generally showed good inter-platform reproducibility for oligonucleotide-based arrays. one study focusing on probe mapping in particular found that reproducibility between affymetrix and cdna platforms could be substantially improved by sequence-based re-annotation  <cit> , and another found that reproducibility was further improved by mapping probe sequences at the exon level  <cit> . more recent studies generally show better cross-platform reproducibility than earlier ones  <cit> . it seems clear that, at least under ideal conditions, differential expression analysis gives consistent results across platforms. it is therefore worth asking how data from different platforms might be combined in an analysis. models and techniques exist for the meta-analysis of microarray data from multiple studies and platforms  <cit> , and these have been applied extensively to investigate questions of biological interest  <cit> .

cross-platform normalization differs from meta-analysis; the former involves direct comparison between expression measurements obtained from different platforms while the latter combines the results of intra-platform comparisons at a higher level. while meta-analysis techniques are extremely useful tools, they are limited to combining the results of studies that have tested the same hypothesis or compared the same treatments, and can not easily be applied to the investigation of new hypotheses from existing data.

cross-platform normalization methods have been developed for the combination of data sets collected using different microarray platforms. these methods are the cross-platform normalization  method of shabalin et al. <cit> , distance weighted discrimination   <cit> , an empirical bayes  method also known as combat  <cit> , median rank scores  <cit> , quantile discretization   <cit> , normalized discretization   <cit> , the distribution transformation   <cit> , and a method known as gene quantiles , which was developed as part of the webarraydb service  <cit> . in addition to these specialized methods, quantile normalization   <cit> , a method commonly employed for intra-platform normalization, has also been applied to cross-platform normalization  <cit> . many of the specialized methods include or are based closely on qn. online analysis services currently offering some of these methods include webarraydb  <cit> , arraymining  <cit> , and dsgeo  <cit> . in addition, qn is available as part of bioconductor  <cit> , and code for some methods can be obtained from their respective authors.

cross-platform normalization could be a valuable resource to researchers. while several studies have employed it for microarray analysis  <cit> , it has not achieved the popularity of meta-analysis methods for the integration of results across studies and platforms. the online services listed above have received a total of  <dig> citations as of this writing according google scholar. it is difficult to judge the number of relevant citations for many methods, as some have alternative uses to cross-platform normalization or are introduced in publications describing other techniques. the publication describing xpn does not introduce any other methods or experiments, nor does xpn have any obvious applications other than cross-platform normalization. that article has been cited  <dig> times since its publication in  <dig> according to google scholar, with only nine of those citing papers satisfying a full text search for the string "xpn." those wishing to perform cross-platform normalization face three major obstacles. firstly, a choice must be made about which method or methods to employ. while the authors of each method have demonstrated their methods on at least one example data set, to our knowledge no empirical comparison of cross-platform normalization methods similar to ours is available. in particular, no third party empirical comparison has been attempted. the authors of xpn do provide a comparison of their method against several others  <cit> , but their analysis was conducted on a more limited data set and does not make use of resampling or any other procedure to evaluate the robustness of their results. this is not necessarily a shortcoming of their paper, but merely the result of a difference in objectives. the authors presented a method, and it is left for others to provide an unbiased evaluation. secondly, software for the selected method must be obtained and incorporated into a data analysis work-flow. the disunity of interfaces and software packages for cross-platform normalization makes this task quite difficult for researchers lacking advanced computer skills, especially for methods that are only available as part of an online service. some methods also rely on proprietary software, which presents an additional obstacle to integration. thirdly, current cross-platform normalization techniques are only applicable to a limited subset of data sets. all the methods listed above require that every treatment group or sample type be represented on each platform. if this restriction is violated then it becomes impossible to distinguish platform effects from treatment effects of interest, and the latter may end up being removed by normalization.

in this paper we provide a comparison of available methods based on the microarray quality control  project  <cit>  data set and a human sperm data set  <cit>  containing data from multiple platforms . envisioning potential applications to large scale databases or classification problems, we restrict our attention to cross-platform normalization performed without knowledge of treatment groups, and we examine the consequences of differently sized and missing treatment groups for the most successful methods. we also investigate the consistency of platform effects across different experiments. we have assembled an r  <cit>  package capable of performing all of the methods investigated with a unified interface and reasonable defaults for user selectable parameters. our package makes it possible for researchers to easily incorporate cross-platform normalization into existing work-flows, especially work-flows based on r or bioconductor, and to experiment with multiple techniques without significant extra effort. our package is available from the comprehensive r archive network . we explore a possible solution to the third difficulty above and show that it is insufficient in some cases.

RESULTS
initial evaluation
as an initial evaluation of the nine cross-platform normalization techniques, we applied each to a subset of the maqc data set. seven assays were selected at random from each of the four treatment groups, a, b, c, and d, included in the maqc experiment from the illumina  and affymetrix  platform groups. the resulting reduced data set was then subjected to cross-platform normalization. to visually assess the effectiveness of each normalization technique, mean-mean expression scatter plots  were produced for each treatment group and each normalization method. figure  <dig> shows mean-mean plots for treatment group a. plots for treatment groups b, c, and d are included as additional files  <dig>   <dig>   <dig>  because each treatment group consists of technical replicates, all points on a mean-mean scatter plot should coincide with the line y = x under ideal circumstances. the closeness of the points to that line provides a measurement of inter-platform concordance. throughout this work, we have used the squared pearson correlation between the x and y values of these plots, denoted r <dig>  as a statistical measure of inter-platform concordance.

based on figure  <dig>  the cross-platform normalization methods are ranked by r <dig> value as follows: xpn, eb, dwd, gq, qn, mrs, distran, qd, and nordi. there is a substantial gap between the fourth and fifth methods in the ranking, and another between the eighth and ninth. to better interpret these plots it is necessary to know the concordance that can be expected for technical replicates  within a single platform and for technical replicates between two platforms. ideally, the best cross-platform normalization methods will result in concordance levels similar to those obtained by technical replicates within a single platform. figure  <dig> shows mean-mean plots for non-overlapping sets of assays selected from the data set for each platform, and a mean-mean plot for data from the two platforms without cross-platform normalization, for each of the four maqc treatment groups. intra-platform concordance is greater than . <dig> for all treatment groups and platforms, while inter-platform concordance is around  <dig>  for all treatment groups. figures  <dig> and  <dig> demonstrate that xpn, eb, dwd, and gq substantially improve cross-platform concordance, while qn, mrs, distran, and nordi provide little improvement and in some cases reduce concordance. the similar shapes displayed by the cross-platform scatter plots in figure  <dig> suggest a consistency in platform effects among the four treatment groups. such platform consistency is explored later on in this work.

a trivial transformation could be devised to produce perfect concordance between platforms by the removal of all platform and treatment effects. however, such a transformation would be undesirable for cross-platform analysis because of the loss of treatment effects. to assess the degree to which treatment effects were retained during cross-platform normalization, we plotted receiver operating characteristic -like curves for seven of nine methods for treatment groups a and b from the reduced maqc data set . nordi and qd were excluded from further analysis because of their unsatisfactory scatter plots and the additional difficulty associated with discrete output. a true roc curve plots true positives against false positives for a classifier  <cit> . the roc-like curves used here show the proportion of genes classified as differentially expressed as a function of the estimated false discovery rate . to provide a basis for comparison, we performed differential expression analysis using each platform separately to obtain a native differential expression set for each platform. an roc-like curve was obtained from cross-platform data normalized by each method , along with four additional curves for comparison. two curves represent differentially expressed genes detected by either afx or ilm  and differentially expressed genes detected by both afx and ilm , and two more represent the intersections of genes detected by the cross-platform data set with the union  or intersection  of native differential expression sets from the individual platforms.

by comparing these curves we obtain statistics for over and under-detection of differentially expressed genes after cross-platform normalization as follows. over-detection can be assessed by observing the difference between the roc-like curve for genes detected with the cross-platform data set  and the curve for the intersection of the cross-platform genes and the union of the single platform genes , which gives the genes detected using the cross-platform data set but not using either single platform data set. under-detection can be assessed by observing the difference between the curve for the intersection of the two single platform gene sets  and the curve for the intersection of all three gene sets , which gives the proportion of genes detected by both platforms individually but not by the cross-platform data set. in our further analyses, the areas between these two pairs of curves are used as statistics to measure over and under-detection, denoted o and u, respectively, of differentially expressed genes. these area statistics have the advantage of not depending on any arbitrary fdr cut-off, and to our knowledge have not been used previously.

it is not possible to rank cross-platform normalization methods by either one of the statistics o or u described above. for example, a method may bring o to nearly zero by removing all treatment effects. such a method would not be desirable, and would result in a large u. each of the statistics o and u guards against unrestricted optimization of the other. the o and u statistics are related to false positive and false negative rates, respectively, and in practice a good cross-platform normalization should strike a balance between the two.

sorted from least to greatest under-detection, the methods are ordered: dwd, eb, gq, xpn, mrs, qn, distran. again, there is a major jump between the fourth and fifth ranked methods. when sorted instead by over-detection, the order is: mrs, qn, distran, xpn, dwd, gq, eb, with a major discrepancy between the third and fourth ranked methods. inspection of the roc-like curves shows that the lower levels of over-detection among mrs, distran, and qn can be understood in terms of lower total detection of differentially expressed genes. by all three measurements, the seven methods cluster into two groups. the first group, made up of dwd, eb, gq, and xpn, is characterized by higher concordance and over-detection and lower under-detection, while the second group, consisting of distran, mrs, and qn, is characterized by lower concordance and over-detection and higher under-detection. the roc-like plots for the two groups are qualitatively different . in the first group, the curve for the cross-platform normalized data lies between the intersection and union curves for the native differential expression sets. in the second group, the curve for the normalized data always lies below the native intersection curve.

bootstrapping
equally sized treatment groups
figures  <dig> and  <dig> provide a qualitative impression of the effectiveness of each method on the maqc data set. for a quantitative assessment, we used the bootstrap to obtain distributions for the statistics o, u, and r <dig>  defined above, for cross-platform normalization between the afx and ilm maqc data. additionally, we included maqc data from the applied biosystems  and agilent one color  platforms, obtaining bootstrap distributions for all three statistics and all six combinations of the four platforms. for all bootstraps, a sample size of  <dig> assays was fixed for each treatment group for a total of  <dig> assays per bootstrap per platform. figures  <dig>   <dig>  and  <dig> show the distributions of r <dig>  o, and u, for the seven non-discrete normalization methods. the xpn method includes a clustering step, and normalizations were performed with different clustering options. for comparison, distributions are also shown for data that have not been normalized  and for resampled data from each individual platform . the resampling trials simulate the result of performing an identical experiment again using each each platform separately. the resampled and non-normalized distributions serve as positive and negative controls, respectively, for successful cross-platform normalization.

in terms of concordance , results largely agree with our initial evaluation. methods can be divided into the same two groups. the rankings of dwd, eb, gq, and xpn fluctuate depending on the platforms, with one of the xpn methods always showing the highest ranking. xpn, dwd, eb, and gq all perform near the level of the resampling controls, while mrs, qn, and distran perform near the level of the non-normalized cross-platform control. over detection  showed the same pattern as in our initial comparison. we had stated that the reduced over-detection of mrs, qn, and distran may be due entirely to the reduced level of total detection for those methods. here we show that the increased over-detection of xpn, dwd, eb, and gq is still below the level of the resampling controls regardless of platform. under-detection  was near but somewhat above the resampling controls for xpn, dwd, eb, and gq for all platform combinations. mrs, qn, and distran fluctuated together depending on platform, always with a higher level than the other methods, and sometimes near the level of the negative control. dwd always showed the lowest level of under-detection, while an xpn variant was always the highest out of xpn, dwd, eb, and gq. variance of under-detection for the xpn methods appears markedly higher than for dwd, eb, and gq. a brown-forsythe levene-type test based on the absolute deviations from the median  <cit>  showed the pooled variance of the xpn methods differed from that of dwd, eb, and gq at a significance level of less than 1e -  <dig> 

the maqc data set is unusual in that it contains a large number of technical replicates. the human sperm data set contains more biological than technical replicates and is more representative of data sets encountered in biological research. we performed the same bootstrapping analysis on the afx and ilm human sperm data . again, treatment group sizes were held fixed at  <dig> for both platforms for data obtained from both normal  and teratozoospermic  individuals. results for concordance were similar to the maqc data set, except that xpn outperformed the resample controls. all methods again showed over-detection levels below those of the resampling controls. dwd again showed the lowest level of under-detection, followed by gq and eb. previous trials of xpn showed levels similar to those of mrs, qn, and distran when more than  <dig> gene clusters were used . xpn distributions for under-detection again showed higher variance than for dwd, eb, and gq, and the difference was significant at the 1e -  <dig> level.

over all, some results were consistent for all data sets tested. dwd, eb, gq, and xpn outperform mrs, qn, and distran in both concordance and under-detection, with dwd showing the lowest over-detection and xpn the highest concordance in all cases. over detection never exceeded levels observed in resampling controls, even for the non-normalized control, which in fact showed no over-detection. because all treatment groups were the same size for both platforms, platform effects would be expected to cancel out when comparing treatment groups. high variance within each treatment group due to platform effects explains the under-detection seen in the negative control. the performance of mrs, qn, and distran varied with the data sets tested. mrs, qn, and distran generally performed poorly. however, they still outperformed the negative control in the sperm data set, which is consistent with past successful applications of those methods.

unequally sized treatment groups
four cross-platform normalization methods, dwd, eb, gq, and xpn, showed satisfactory performance when evaluated using data sets with balanced treatment group sizes. applications in which treatment group sizes are not consistent across platforms can easily be envisioned. we evaluated the four successful cross-platform normalization methods again using the maqc data set with the same bootstrapping procedure. this time only data from treatment groups a and b were included, and the number of a and b samples was not necessarily equal between the two platforms. five trials were performed for each method using different combinations of sample sizes:  <dig> a,  <dig> b for afx and  <dig> a,  <dig> b for ilm;  <dig> a,  <dig> b for afx and  <dig> a,  <dig> b for ilm;  <dig> a,  <dig> b for afx and  <dig> a,  <dig> b for ilm;  <dig> a,  <dig> b for afx and  <dig> a,  <dig> b for ilm; and  <dig> a,  <dig> b for afx and  <dig> a,  <dig> b for ilm. results indicate that dwd is the most robust to sample size differences, but that such differences have some effect on all methods . the under and over-detection statistics for xpn responded differently than for the other methods. under-detection decreased for xpn as treatment group size disparity increased, and over-detection increased. for all other methods, the opposite was observed. all methods but dwd showed substantially decreased concordance with increasing treatment group size disparity. our modified clustering procedure reduced this effect in xpn to some extent.

missing treatment groups
all cross-platform normalization methods studied share a common strategy. first, a set of parameters is determined from the data. those parameters are then used to transform the data to remove platform effects. the parameters fitted from the data provide an estimate, in one form or another, of the platform effects present in the data set. cross-platform normalization is only possible when all treatment groups are represented on both platforms. otherwise, it becomes impossible to distinguish platform effects from treatment effects. relaxation of this restriction would improve the usefulness of cross-platform normalization to researchers wishing to apply it. it may be possible to overcome this limitation by determining platform effects ahead of time using a separate data set, and then applying those parameters to the data set one wishes to transform. this possibility depends on the consistency of platform effects across different studies and treatment groups. to evaluate whether such consistency exists, we attempted to use parameters derived from the maqc data set to perform dwd on the human sperm data set, first removing all n assays from the afx data and all t assays from the ilm data, and then the reverse. dwd was selected for this experiment because of its success in previous trials and because of the simplicity of its model while concordance statistics could not be produced for this data set because data from each treatment group were represented on only one platform, we were able to evaluate both over-detection and under-detection using the same bootstrapping procedure as before . sample sizes were again fixed at  <dig> for both platforms and treatment groups. "self.transfer" indicates that the human sperm data set, rather than the maqc, was used as a training set, which resulted in successful cross-platform normalization. "no.transfer" indicates that the missing treatments data set was used alone with no additional training data, which resulted in the removal of all treatment effects. the "transfer" data set, for which the maqc data set was used as a training set, showed over-detection near the level of non-normalized data, indicating that the maqc platform effects, as estimated by dwd, differ substantially from those of the human sperm data set. the difference here does not imply that there is no consistency in the properties of different platforms, but merely that if such consistency exists then dwd is not sufficient to take advantage of it.

exploring platform effects
the inconsistency between platform effects in the maqc and human sperm data sets may be due to differences in data processing or experimental protocols. because of the age of the human sperm data set, its authors were unable to give any details regarding their exact procedures. to further explore the consistency of platform effects for different treatments, we tried using the maqc a data to transform the maqc b data and using the human sperm n data to transform the t data. again we used the same bootstrapping procedure with  <dig> assays in each treatment group. results  show reduced but high concordance compared to non-normalized data and to "scrambled" normalization, in which the location parameters used by dwd were randomly re-ordered after being estimated from the training set. because the data being transformed contained only one treatment group, over and under-detection could not be assessed.

figures  <dig> and  <dig> indicate that there is some consistency in platform effects between treatment groups within the same study, but possibly less between the maqc and human sperm studies. we directly assessed the correlation between platform effects for different treatments, studies, and platforms again using dwd. figure  <dig> shows correlations obtained between dwd parameters for  <dig> pairs of data sets. each set shows the highest correlation with resampled data for the same treatment, study, and platform pair if present, the next greatest with data from a different treatment and the same study and platform pair, the next greatest with data from the same platform pair but different treatment and study, and the least with data from another platform pair regardless of treatment and study.

theoretical perspective
the four best performing methods, dwd, eb, gq, and xpn, model platform effects using location parameters, while the other five methods do not include location shifts. the representation of platform effect as a location parameter is somewhat consistent with a physical interpretation of the microarray hybridization process. the hybridization process can be coarsely described by the chemical equation

  p+gk+⇌k-h, 

where p, g, and h are the probe, the gene or transcript target, and the hybridized transcript, respectively, and k+ and k- are rate constants. for relatively large target concentrations, the signal for a hybridized probe at equilibrium is

  s=ig0p0k+k-1+k+k-g <dig>  

where s = ih is measured signal, g <dig> is the initial concentration of target rna or dna, p <dig> is related to the initial number of available probe sites, and i is related to the intensity of the marking mechanism associated with each target dna or rna molecule. the parameter i should be thought of as the intensity of the label on each target molecule. the number of target molecules present at the probe site multiplied by the intensity of each gives the total intensity at that site. model  has previously been applied to affymetrix genechip© data  <cit> . under this model, the log of the measured signal is given by

  log=log+logip0k+k--log1+g0k+k-. 

the parameters k+, k-, i, and p <dig> are determined by the microarray platform and experimental conditions such as hybridization temperature. only g <dig> is related to gene expression. assuming experimental conditions are about the same for all users of a given platform, a statistical model of log signal intensity for a particular probe might be

  yijk=ti+pj+cij+εijk, 

where yijk is the log signal value for gene i, treatment j, and repetition k; ti, pj, and cij are treatment, platform, and treatment-platform interaction effects, respectively; and εijk is a random variable associated with repetition. equation  is more general than, but fully consistent with, equation . the presence of a treatment-platform interaction term can be tested by analysis of variance . we performed anova using model  for each gene separately on abi, afx, ag <dig>  and ilm data with treatment groups a, b, c, and d from the maqc data set, using the lm function of the r stats package  <cit> . figure 12shows the distribution of p-values for the null hypothesis  that cij = c for all treatments and platforms. using the qvalue package  <cit> , we were able to estimate the proportion of genes, π <dig>  for which h <dig> is true, and subsequently the proportion of genes, π <dig>  for which h <dig> is false from the distribution of p-values using the method of story and tibshirani  <cit> . results indicate that treatment-platform interaction effects exist for  <dig> % of genes, or about  <dig>   <dig> genes out of  <dig>   <dig> total. because not all genes are differentially expressed, it is to be expected that some genes show no interaction effect. if there is only one treatment group, platform and interaction effects don't need to be distinguished. both p and c terms can be removed by a single location shift. for larger numbers of samples, the interaction term cannot be fully removed by a single location shift. an optimal location shift, in the least squares sense, for the m treatment case is

  yijk*=yijk-ηj 

  ηj=pj+∑i=1mnijcij∑i=1mnij 

where yijk* is the corrected value and ηj is the location shift used to correct for platform effects. the values nij are the number of repetitions for treatment i and platform j, and m is the total number of different treatment groups. it is assumed that the true values of the effects are known. in practice, ηj will be an estimate based on the data.

none of the methods studied here make explicit use of a least squares optimal location shift to remove platform effects. rather, this optimal location shift is used to illustrate the limitations of modeling platform effects as location parameters under model . the prospect of determining a location shift for a particular pair of platforms using one data set and applying that shift to another data set is complicated by the presence of interaction effects in equation . by equations  and , the difference between two treatment group averages in a two platform data set after the application of a location shift derived from another two-platform data set, assuming equally sized treatment groups, is

  ȳ1⋅⋅*-ȳ2⋅⋅*=t1-t2+12∑i=12∑j=12j- <dig> 

where cij♢ are the interaction terms from the training data set. depending on the values of cij and cij♢, transference of parameters could result in the increased over-detection seen in our missing treatment group experiment. other causes are also possible, including differences in scanners or image processing procedures.

uniformity of platform effects across different experiments is consistent with the model . additivity is not, although empirically it appears to be a useful approximation, as indicated by the relative success of the location based methods. the accuracy of that approximation may be reduced, however, when employing a separate training set to estimate platform effects. this reduction was observed in our analyses, in particular in figures  <dig> and  <dig>  model  is a sufficient explanation for all of our observations, which suggests it or the more general equation  may provide a good basis for an improved cross-platform normalization method that addresses the issue of non-identical treatment groups across platforms. however, fitting such a model would require a data set containing multiple matched treatment groups for any pair of platforms on which it could be used.

software
to facilitate the application of cross-platform normalization by other researchers, we packaged all the implementations used in this work, including those obtained from other authors, using the r package mechanism. our package, conor, includes documentation and provides a common interface for all methods, along with reasonable defaults for user-selectable parameters. the package can be downloaded at http://alborz.sdsu.edu/conor and is available from cran.

CONCLUSIONS
of the four methods capable of successful cross-platform normalization, dwd showed the least loss of treatment information and xpn showed the greatest inter-platform concordance, although the latter was sometimes in excess of resample controls and might be interpreted as a slight over-correction. dwd was the most robust to variations in treatment group sizes between the two platforms. this result is somewhat surprising because xpn incorporates an assay clustering step designed to correct for such variations  <cit> . our clustering variant showed reduced sensitivity to treatment size disparity, and it is possible that further improvement to the clustering step of the xpn algorithm could result in improved robustness. it is no surprise that gq and eb, which do not account for treatment group disparities, suffered reduced performance under such conditions. in general, those methods that employ location shifts  outperformed those that do not, and the performance of the methods that do not include such shifts was quite unsatisfactory. many of those methods were not originally designed for cross-platform normalization, and their failure to accomplish such normalization does not imply that they are insufficient to their other uses. the eb and xpn methods make use of distributional assumptions about the data. xpn uses a normally distributed residual for maximum likelihood estimation, while eb employs a complicated model including parametric prior distributions. for the log-transformed microarray data used in this study, these methods performed well. however, the distributional assumptions of these methods must be valid for their performance to be assured. when performed on non-log transformed data, for example, these methods fail to produce good results. in cases in which normality is in doubt, appropriate transformations  should be employed. our analyses considered cross-platform normalization in the absence of treatment group information. it is possible that superior methods to those investigated could be devised that make use of treatment information. the eb method is already able to accommodate treatment group membership information if it is available.

our experiment in normalizing the human sperm data set using parameters derived from the maqc data set shows that there may be some consistency in platform effects across different treatments. larger differences between platform effects in the maqc and human sperm studies may have resulted from differences in protocols between the two studies. however, they may also have resulted from larger disparity between gene expression patterns in sperm and those of other human tissues, in which case a more complicated model of platform effects might resolve the difference. ideally, data sets like the maqc project's could be used as "rosetta stones" for gene expression platforms, allowing data collected on one platform to be translated to be comparable with data from another platform regardless of treatment group disparities. this work has shown that a model including treatment-platform interaction terms will be required for such a system to be effective, and further investigation is required before such a system can be realized.

next generation sequencing technology is replacing microarrays for the measurement of gene expression. the types of platform effects present in microarray data are probably not relevant for sequencing-based expression data. nevertheless, existing databases, as well as microarray experiments that may be performed in the near future, represent a substantial resource. cross-platform normalization has the potential to become a valuable tool for gene expression research by allowing researchers to combine and analyze existing data together with new data or in new contexts. while at least nine methods are currently available, we've shown that only four of those methods provide reasonable results on the maqc and human sperm data sets. although researchers are encouraged to draw their own conclusions based on their particular needs, two methods emerged as most effective. in cases in which false positives are to be preferred over false negatives, or in which treatment group sizes are not equal for the various single platform data sets, dwd is the recommended cross-platform normalization method because of its lower under-detection and improved robustness. in cases in which false negatives are to be preferred to false positives, and for use with classifiers, xpn is recommended because of its superior cross-platform concordance. if there is doubt as to which situation applies, dwd is recommended, but there is no reason that multiple techniques could not be employed and the results compared. the existence of the conor package will make the latter option particularly painless. in cases in which treatment groups are missing from one platform or another, the dwd-based procedure described here is the only currently available method, but care must be taken to ensure that training data have sufficiently similar transcription profiles to the data being transformed.

cross-platform normalization of large or complex datasets in which treatment groups are missing will require improved models of treatment-platform interaction effects. future work should include the modification of xpn to improve robustness and allow for the use of a separate training set, as well as the investigation of other models of platform effects. this study has not examined every platform available. in particular, no cdna arrays were included, and the effectiveness of cross-platform normalization with such arrays should be investigated before those methods are applied. while the types of platform biases present in microarrays are not relevant to sequencing based assays, it is worth investigating the effects that different extraction, amplification, and sequencing methodologies have of such measurements, as well as how data from sequencing-based assays might be combined with microarray data. while the availability of an r package does much to make these methods accessible, there are some researchers who are not comfortable with the r command-style interface. for those researchers, a gui application or web interface integrating all of those methods may be beneficial, although web interfaces are already available for some methods. if the transfer of platform parameters between data sets is improved, a web-based database of such platform parameters that could be integrated into cross-platform analyses would be extremely useful.

