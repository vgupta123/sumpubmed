BACKGROUND
the term nanopublication refers to a citable unit of published knowledge that refers to a scientific assertion with accompanying provenance metadata that permits a reader to understand where the assertion was made   <cit> . an example of such an assertion 'hippocampo-hypothalamic connections: origin in subicular cortex, not ammon's horn' was unusually made in a paper's title in  <cit> , describing the localized origin of neuroanatomical projections from the hippocampal formation to the hypothalamus. if all scientific claims could be made as succinct, citable, computable elements , then the thread of a scientific argument could be made by linking these claims rather than citing documents that act as their containers. this model is the goal of researchers developing representations of scientific discourse  <cit>  and we present here a formulation for scientific reasoning based on experimental data within such a framework. as a central part of our formalism, we distinguish between observational assertions  and interpretational assertions . this is illustrated in figure  <dig> as a depiction of the reasoning process that underlies scientific research involving a direct interplay between data  and theory . we postulate knowledge constructs for each type of assertion: the 'experimental design model'  and the 'domain-specific reasoning model' . this 'cycle of scientific investigation'  itself has several stages.  a scientist uses their knowledge within a specific domain to generate a testable hypothesis.  the scientist must formulate an experimental design that tests this hypothesis.  having performed the experiment, the scientist may then construct observational assertions based on experimental data.  having then interpreted  observations from multiple experiments, the scientist would then generate interpretive assertions that contextualize the data into the broader context of an underlying factual statement or claim.  finally, these new revised or reaffirmed assertions may then be incorporated into the body of knowledge pertaining to the domain and may then contribute to subsequent hypotheses, etc. see figure  <dig> from  <cit>  for another depiction of scientific investigation as a cyclic process. within this paper, we describe a formulation called 'knowledge-engineering from experimental design'  and then demonstrate the ability to generate and reason over interpretive assertions within a well-defined scientific domain. neural connectivity  has been popular within the field of neuroinformatics for roughly two decades. see  <cit>  for an seminal paper deriving a hierarchical processing scheme for cortical areas in the macaque based on the laminar patterns of origin and termination of cortico-cortical connections. work has involved the development of connectivity repositories  <cit> , mathematical analyses  <cit>  and high-level theories of brain organization  <cit>  based mostly based on neuroanatomical tract-tracing studies in animal subjects. these studies involve injecting a minute quantity of tracer chemical into a structure in the brain. this tracer is taken up by neurons that impinge upon the injection site and then transported along the neurons' axonal fibers . by processing and examining the tissue histologically, it is then possible to infer the existence of neural projections between the location of the injection site and the location of transported label  <cit> .

this relatively simple experimental design provides a concise demonstration of the cosi model. tract-tracing experiments simply consist of a surgical injection of a chemical to a targeted location in the brain, followed by histological processing and neuroanatomical analysis. for this information to become a description of neural projections between brain structures, knowledge of the uptake and transport properties of the tracer chemicals must be invoked . thus, observational assertions should be formulated without background knowledge  and interpretational assertions invoke background knowledge to generate a knowledge base. it is important to note, that if the background knowledge changes then so too do the interpretations.

the formulation of the kefed model for tract-tracing experiments focuses on measurements of the ordinal labeling density  although in some rare cases, retrograde studies may be quantified through the use of careful cell counts, this is rarely reported. we only use ordinal scales in order to maintain a tractable, uniform approach. and labeling type  of the transported tracer indexed by parameters pertaining to  the location of the injection site defined by reference to a well-defined neuroanatomical nomenclature,  the tracer chemical used,  the locations surveyed for transported label . these five quantities are sufficient to generate an interpretation asserting that there exist neurons in a region of origin that project to a region of termination with a specified connection strength   <cit> .

at a high level, we capture the primary experimental observations of these experiments as parameters, constants and measurements . the interpretations that contribute to a model for reasoning about neural connectivity would be simply the locations of both a given projection's origin and termination and perhaps its strength .

this is the coarsest possible reasoning model of neural connectivity  and it is a prominent goal of the community to develop finer-grained representations   <cit> . other new methods of data acquisition are responsible for generating a great deal of new interest in studying 'connectomics'  <cit> . these methods include functional magnetic resonance imaging and diffusion weighted imaging for gathering neural connectivity data in humans  <cit> . there are also data-intensive methods to examine all synaptic connections between a small number of neurons within a very small volume of neural tissue through serial reconstruction of electron micrographs  <cit> .

despite these methodological developments in the field, our focus in this paper is concerned with using an example data set that demonstrates the interplay between a specific experimental design model and its derived interpretation. we assert that tract-tracing experiments provide the best-quality data for neural connectivity in non-human species and so are the best candidates for developing this model. as a software-based study, we present a working implementation of this software, instantiated as a read-only demonstration for neural connectivity  and as a fully-functional editable system, open for use in other domains .

implementation
bioscholar has both a general, domain-independent component and a customized domain-specific reasoning component. the kefed editor with its associated experimental designs do not depend on a particular scientific domain. they can be used to represent and store scientific experiments in any domain, and are not limited to tract-tracing or neurobiology. kefed models and the data from associated experiments can be stored and manipulated using the bioscholar program without any customization. reasoning models and queries for interpreting the data from an experiment are domain-dependent, almost by definition. as a case study, we present tract-tracing experiments and the derivation of a matrix showing brain region connections. the computation of the connection matrix, along with the geometric reasoning that form the neuroanatomical parts of bioscholar use additional resources such as brain atlases and background knowledge about the tract-tracing methodology. these domain-specific reasoning models are specifically designed to use data from a specific experimental model. such reasoning models operate on the measurement variable values and their associated context to generate suggestions of evidence and tentative conclusions based on the underlying scientific theories that inform the creator of the interpretation. this part of the bioscholar is, therefore highly customized for a particular application.

the downloadable software includes the generic bioscholar application and a specific neural connectivity demonstration. the generic bioscholar application can be applied to any domain and provides a graphical editor for experimental designs and a storage system for experimental data. the neural connectivity demo adds a domain-specific panel to the bioscholar application that displays the connetion matrix for the hippocampal region of the brain and can show the underlying studies for each matrix entry.

kefed models of tract-tracing experiments
kefed models are composed of experimental variables: either parameters or constants that are predefined as part of the experimental design ; or measurements that form the primary data from the experiment. our central premise is that observational assertions are typically based on the statistics of the measurements made within an experiment. each measurement has a context provided by the set of parameters that describe the conditions under which the measurement was made.

the indexing mechanism used to generate the context that links parameters to measurements is based on a workflow representation of the experimental protocol. we construct a graph representation of experimental objects, activities , branches and forks , parameters, constants and measurements. this overall methodology is illustrated in figure  <dig>  the indexing of a measurement is based on a path through the workflow back to the starting point of the protocol's workflow so that any parameter or constant falling on this path is used as an index . this intuitive methodology provides a powerful basis for practical knowledge engineering technology.

we have constructed a kefed model for tract-tracing experiments  which forms the basis of our demonstration application. we offer preliminary definitions for both the variables and other elements of the model . the kefed editor can currently annotate model elements  with terms from external ontologies. we invoke an intermediate-level representation of the experimental protocol where each step of the process is represented coarsely. for example, the procedure of performing a precise stereotactic microinjection of tract-tracer chemical is represented with a single model element  with two attached parameters .

definitions for the variables used in the tract-tracing study. the kefed system allows for complex multi-attribute variables .

kefed model elements for the processes and entities in the tract-tracing experiment, showing the closely matched terms from community-driven ontologies. those terms were added to the kefed model elements using the editor's ontology search interface. sources of the terms are the ontology of biomedical investigation , the foundational model of anatomy , the neuroscience information framework . the matched term is intended to be as close a semantic match as possible. if a specialized term is not available, a more general encompassing term is used.

kefed and geometric reasoning
we perform our reasoning using the powerloom® first-order logic knowledge representation and reasoning system  <cit> . powerloom provides us with a deductive reasoning engine that supports numerical calculations, n-ary relations and closed-world reasoning. powerloom has been developed over the course of ten years and applied in numerous domains including hybrid reasoning systems  <cit> , natural language understanding  <cit> , metadata search  <cit>  and interest matching  <cit> . it has a query language that allows us to access the information from our encoding of the experimental structures. we use the java implementation of powerloom, which also has support for a web services interface that we use to integrate our kefed reasoning system. we use queries and inference rules to construct interpretable statements concerning the existence and strength of connections between brain structures based on kefed-based assertions. not all of the additional expressive power of powerloom is used in the neural connectivity example. however, we do take advantage of the ability to create defined properties and define n-ary properties that can be used in constructing complex queries over the data. so that, for example, if we wanted to understand projections from the postsubiculum  to the retrosplenial  area, the system would construct queries for experiments where injections of anterograde tracer were made into post and terminal labeling was found in rsp or injections of retrograde tracer were made into rsp and cellular labeling was found in post .

this reasoning system also provides support for reasoning about geometric relationships between different brain regions. in tract-tracing experiments, tracer injection sites may be reported to be within particular regions, their subregions or to overlap two or more named structures. differences in nomenclatures across studies also may cause variation in the degree of detail use to describe which brain regions are implicated in a given experiment. our reasoning system must therefore be able to understand the geometric relationships of these regions.

the primary relationship of interest is regional containment, i.e., how regions are enclosed by each other. this also allows us to aggregate information from studies that studied different subregions. we support the reasoning over a containment hierarchy through the definition of a transitive containment relationship 'proper-part-of' for denoting a spatial region which is a proper part of another region. we also use an 'overlaps' relation to describe a region that covers a part of one region along with at least a part of another disjoint region. since injected tract-tracing can often spread to adjacent brain regions, this is necessary for a proper description of the actual experimental results. when looking for injections of interest, we want to find injections into subregions of our region of interest. this is computed using 'proper-part-of' and its transitive closure. but in addition we are also interested in finding injections that overlap a subregion of our region of interest. we make use of powerloom's ability to define relations to craft a specialized relation that represents regions that are part of the region of interest or that overlap a region that is part of a region of interest. by creating this named relation, we are able to build a series of other relations that describe the results of anterograde and retrograde experiments in a modular manner. we have tools that import the basic geometric relationships from the brain atlases. we translate the neuroanatomical ontology for the rat provided by provided by bams  <cit>  into powerloom where we use a transitive containment relationship to provide a hierarchy of brain regions. details of this mapping are described in additional files linked at the end of this article, including  a description of the process used to import brain region containment data ,  a copy of the containment data obtained from the bams database ;  a set of three powerloom files that describe qualitative geometric relations, their use within an atlas and an instantiation of these relations for a specific neuroanatomical atlas   <cit> . this allows us to use the reasoning system to manage the containment hierarchy and perform simple inferences on demand, in response to system queries. for our example above, we would also need to be able to retrieve kefed assertions that involve subregions of post or rsp. rsp contains dorsal  and ventral  subregions, the latter of which has additional subdivisions rspv-a, rspv-b/c in the bams neuroanatomical nomenclature  <cit> .

a web-based kefed curation system
we have built a prototype user interface for editing kefed models as a flex-based rich internet application. we used kap-lab's freeware  diagrammer program as the basis for this tool  <cit> . this is a flex component that permits users to construct graphs from elements that defined as svg-based primitives . it links these graphical elements to underlying actionscript classes defined by external developers. as the basis for these internal data-structures, we adopted the graph-based representations from the flare prefuse actionscript library, in order to use their graph-traversal and shortest-path algorithms  <cit> . this permitted us to implement the kefed model entirely within the flex interface as a web-application within an environment supplied by the tomcat web server. we used the persevere json-based web-accessible database to provide a generic, flexible storage for the kefed models generated within our application  <cit> . since persevere's http-based services for editing and deleting models required the use of put and delete http calls, we deployed the kefed editor web application with a proxy server based on the adobe blazeds messaging library. using this application, an experimental protocol can be built up .

the kefed editor uses the experimental protocol to trace data dependencies and automatically generate data input forms following the process in figure  <dig>  from the tract-tracing model  we generate an input form for recording the necessary data . the columns are derived by tracing the data dependencies for the measured values  along the protocol to the parameters for the experiment . tracing along the dependency links assures us that the relevant context for proper interpretation of the data is preserved. some of the parameter values are may be considered constant, either across all instances of the class of experiments  or sometimes for a particular experiment .

the spreadsheet interface uses information from the experimental design to present an appropriate interface to support data entry. any variables with a fixed set of values result in a pop-up menu of choices for the input. anatomical regions have a special widget that allows us to capture not only the region, but also the relationships between an arbitrarily-defined region of an injection-site or labeling-location and the named structures in the brain atlas.

system architecture
a component diagram illustrates the overall system architecture with our current implementation of the kefed editor system . the central hub of the system is a web-application running on an apache tomcat web-server. the client application is a flex  <dig>  application running through a blazeds remoting/messaging service on the server. this permits the client to communicate via http, soap and rest services with external resources . we uses two server-side persevere repositories  and a powerloom knowledge base.

within the 'experiment design' tab, the user is presented with a list of kefed models. at this point they may add a new blank model, copy or delete an existing model or edit one of the models in the list. if the user chooses to edit a model, they are taken to the main kefed model editor panel, where they may draw a model on a graphical palette. selecting each element in the diagram, changes the available controls to edit the semantic details of that element . at the global level, the user may then save or cancel their edits to taking them back to the list of all available models in the system. the 'observations' tab allows the users to add data to a kefed model corresponding to the execution of an individual experiment. as is the case with our representation of tract-tracing experiments, one kefed model can provide a template description for many experiments. this component shows a zoomable navigator control that that allows to the user may use to select variables within the experimental design and edit data their data values. this allows a scientist enter both the values of measurements and their parameter-based context .

the 'interpretations' tab will only ever be present when the system has been tailored for a specific reasoning model . in this case, the component contains a 'connection matrix' that tabulates hard-coded macroconnections that are reported in the knowledge base . this matrix should be considered a rudimentary reasoning model for neural connectivity. by double-clicking on a cell in the matrix, the system will issue a query to the powerloom knowledge base and retrieve all known observations that are relevant to the interpretation of interest. in this way, the system may directly link observational and interpretational assertions as shown in figure  <dig>  these observations are further linked to the underlying literature. those that are indexed by pubmed can also have their pubmed page displayed in a separate browser window.

RESULTS
as the main demonstration of the feasibility of this approach, we populated the knowledge base with connectivity information from  <cit> . this study describes a detailed analysis of the connectional topology of neural systems associated with spatial navigation in the rat  based on manually-curated connectivity data from the primary neuroanatomical research literature as part of  <cit> . this information was contributed to the bams repository and subsequently augmented with a small number of subsequently published studies. the focus of this paper is not concerned directly with making this particular knowledge base complete or up-to-date , but we use it as a well-defined starting point for this current implementation. the neural connectivity results from the tract-tracing experiments includes data from  <dig> publications. manual curation  <cit>  divided the information into  <dig> experiments comprising  <dig>  data points. each data point corresponds to a relation linking an injection report to a single labeling report. an experiment corresponds to multiple data points relating to a single injection. the connection matrix is a  <dig> by  <dig> matrix of brain regions in the hippocampus. querying for the data elements supporting an individual connection  generally executes within  <dig> seconds . generating the entire connection matrix takes roughly  <dig> minutes, and is performed off-line so that the results may be cached for display in the program. the retrieval of supporting items is performed as a live powerloom query using a web-service interface. of the  <dig>  data points,  <dig>  reported on connections with both endpoints in the hippocampus.

timing results are based on a macintosh powerbook with a dual core  <dig> ghz intel core2duo processor with 4gib ram, mac os ×  <dig> . <dig> using the java version of powerloom  <dig> . <dig> and 64-bit java  <dig> .0_ <dig> running with 1gib of heap space allocated. query results use software timing, which is reported in the interface for individual connection queries. the web browser and servers were running on the same host, which minimizes network delays.

the connection matrix is an interpretation and summarization of the underlying experimental results. the experiments report the transport of marker chemicals and dyes between brain regions. the interpretation of that transport is the fairly simple inference that the marker transport indicates a connection between neurons in the source and destination brain regions. this is made only slightly more complicated by the need to differentiate between anterograde and retrograde transport. the interpretation is computed by examining the data as represented by the model parameters and measurements. this structure is derived from the kefed model design and insures that the appropriate context is available for interpreting the data.

in addition to making this inference, the connection matrix also provides a summary by defining the structures that frame the results. some geometric reasoning may be needed to map from the histological observations to the connection reports. in addition, there is also the need to account for injections that spread and cover multiple brain regions, since such data provides weaker evidence for a connection because the marker chemical could have come from one of the other portions of the overlap. these elements should be included, so that an analyst can factor that into the considerations when reviewing the evidence for a particular connection.

the use of geometric reasoning is a significant contributor to the generation of the connection matrix. out of the  <dig>  individual connection reports,  <dig> involved the use of part-of reasoning and  <dig> used overlap relations.  <dig> our of  <dig> connections did not have any direct evidence and could be found only by considering the effects of geometric containment or overlap. an example of this is the connection between field 'ca1' and the entorhinal  areas of the hypothalamus. we curated five papers reporting connections between those regions. beckstead's paper  <cit>  reported a reterograde study with three separate injections, one generally in ent and the other two in specific sub regions . all three showed tracer in ca <dig>  deacon  <cit>  reported a retrograde study with separate injections into three regions, each of which overlapped ent but also included other areas, with labeling in ca <dig>  swanson  <cit>  published the results of two experiments with retrograde tracer injected into ent and found in ca <dig>  finally, van groen  <cit>  reported an anterograde experiment with two injections into ca <dig> and labeling found in ent. the geometric reasoning as well as consideration of the direction of marker transport had to be combined in order to assemble the full set of evidence for a connection between these regions.

the inferential reasoning makes use of powerloom's ability to define n-ary relations and provide rules for determining the values.  these relations are then used to build up the queries. in effect, they can act like pre-defined queries which allow sharing of the inferences and simplify the engineering of the domain model and the resulting creation of queries. an example we use to illustrate this mechanism  is based on a relation for computing the admissible geometric relationship between injection sites and the regions of interest in the connection matrix. this involves a combination of reasoning about part-whole relationships as well as extending that reasoning to include the effects of overlapping regions. this relationship is defined in powerloom by



   :documentation "checks whether ?sub is contained in super, or whether ?sub overlaps

         with ?super, including overlapping a part of ?super"

   :<= 

      

      

      

            ))))

this definition states that the relation 'part-of-or-overlaps' is satisfied if

 <dig>  the two regions are the same or

 <dig>  the sub-region is part of the super region or

 <dig>  the sub-region overlaps the super region or

 <dig>  there is some other region that is part of the super region and the sub-region overlaps that other region.

this illustrates the expressive power of the powerloom language. by defining this relationship once, it can be easily re-used in various queries. other relations are also defined with more complicated structure that are used to extract the data and properly interpret the direction of connection depending on whether an anterograde or retrograde experiment is being considered.

discussion
the task of curating data from literature resources is a serious challenge for developers of bioinformatics resources and, although the community lacks globally-applicable, production-level, open-source tools, there is a continuing effort to generate ontological standards, practical conventions and software to provide support. several other efforts utilize similar constructs to kefed in their efforts. obi's protocol-based view of experimental design as a general ontology capturing experimental methods  <cit>  motivates the development of several notable systems. the violin project is a web-based vaccine database and analysis system that both provides a repository for vaccine-based information and a suite of bioinformatics tools for literature mining and even the prediction of potential vaccine targets  <cit> . the adam system uses an ontological representation within a detailed conceptual model that effectively cycles through the cycle shown in figure  <dig> for a well-defined domain-specific model pertaining to yeast molecular biology  <cit> . the 'isa' family of tools  <cit> , derived from the phrase: 'investigation, study, assay', are based on a spreadsheet model that is similar to the kefed representation of data.

computational systems of scientific discourse such as swan  and the development of the concept of nanopublications are particularly relevant to this effort  <cit> . as a formalism for scientific knowledge engineering, our kefed-based toolset is significant for four reasons:  it is conceptually simple;  it is generally applicable;  it is comprehensible to biologists and  it supports a model of scientific inference. by developing a concrete implementation for this formalism, we not only hope to make it more accessible to end users, but strengthen our ability to study and improve the approach in collaboration with our colleagues cited above. although we have focused primarily on the use of this methodology for literature-based curation, it may also be used to curate primary data  <cit> .

in addition to data-driven tool development, we are also engaged in developing machine-reading tools that specifically target the definition of variables and their values to be extracted from natural language text in the published literature. the utopia documents system uses published pdf files as a live interface over underlying semantics that could be defined in a variety of frameworks such as kefed  <cit> . the goal of developing these new approaches and tools is to re-engineer the process of scientific publication, communication and discovery to leverage computable models directly into the process so that it becomes automatable and therefore scalable.

other work on scientific workflows  <cit>  uses a very similar formulation for scientific protocols. the taverna  <cit>  and myexperiment  <cit>  systems, in particular, have been used to create and share executable workflows for biomedical applications. development work in this field has concentrated on describing machine-executable workflows for data analysis. the emphasis in kefed is on a different and more general part of the process. kefed activities are more general in the sense that they do not require an executable computational step to be associated with them. in a typical kefed model , we do not expect to execute the protocol as data processing . it is, however, an interesting future design goal to link our kefed-based representation of the pre-computational part of a scientific workflow to executable tools that may process the data represented in the kefed format. kefed models could be extended to include taverna modules as elements. and kefed-enabled webservices could be made available as components to be used in taverna workflows.

part of the value of the kefed approach is it's intuitive appeal and simplicity for biomedical experts . kefed models are currently composed of a relatively small number of semantic elements:  entities and  processes involved in the experimental protocol,  experimental variables that contribute to the interpretation of observations and  the values of those variables. the bioscholar system currently allows entities, processes and variables to be annotated with ontology terminology via a lookup tool that uses the bioportal web-service from the national center for biomedical ontology. we provide a very small vocabulary of terms for our neural connectivity use-case in table  <dig>  the ontology for biomedical investigation  is a community-driven effort to construct a well-defined formal ontology for 'the description of biological and clinical investigations'  <cit>  based on a top level formulation provided by the 'basic formal ontology'   <cit> . future work is planned to exploit the correspondence between kefed elements and high-level classes within obi and even to use the kefed editor tool as a possible curation interface for ontology development within the obi community.

some of the reasoning processes used in the neural connectivity example could have been described using the owl  <dig>  <cit>  web ontology language, since it provides the ability to define and reason with transitive relations. however, we found the ability to define n-ary relations and rules for inferring the values of such relations provides a software engineering advantage. we may define complicated relationships and use them as named queries to facilitate the construction of evidence for neural connectivity. we also found the existence of a built-in query language to be convienient for development. in the future, moreover, we expect to make more use of the greater expressive power of a first order language and also to make use of powerloom's ability to perform arithmetic computations and support extensions for the addition of statistical reasoning.

in principle, however, one could apply a number of different reasoning systems that work over data curated with the domain independent part of bioscholar. all that would be needed would be the development of appropriate export functions for saving the kefed-curated data in an appropriate format for the reasoning engine. we plan to make export of the data in an owl compatible format part of a future version of bioscholar.

future directions
the system as it appears here is a prototype built with some non-standard elements  that will be modified going forward. we anticipate developing the kefed methodology to be maximally compatible within the field of 'semantic-web' approaches to biomedical informatics, by expressing kefed models in owl/rdf and by improving ontology harmonization with the obi project. in particular we will extend the ability to annotate particular variable values with ontology terms and eventually also use ontologies as the sources of variable values.

we expect to develop kefed-driven nanopublications in the near term. we anticipate developing kefed-based technology relatively small plugin components for other sites and systems. given also that the main source of information currently for our work derives from the scientific literature, we are actively developing text mining tools to assist with the curation of data into kefed models themselves  <cit> . as an exercise in knowledge modeling, the formulation of an individual kefed model may be expected to evolve  and thus, additional functionality built into the modeling software could promote and support this through a versioning function. finally, we intend to evaluate the system from the point of view of its performance for well-defined knowledge management tasks   <cit> .

future work for the kefed formulation itself will be to  represent relations of statistical significance between measurements with a parameter-based measurement context and to  represent correlations between variables. the way that we construct the measurement context becomes more complex than our current formulation can accommodate when data are processed in a such a way as to combine or distort the role of individual parameters. for example, a parameter we might track in an experiment is the identifier of a particular experimental subject. if we calculate the statistical mean value if a measurement, then the calculation involves aggregating measurement values across all experimental subjects, thus removing the id values of each individual subject from the mean value's measurement context. in order to expand and generalize our approach, we need to capture explicitly this mechanism into the underlying design of the kefed formalism. other, more complex elements to be modeled and included are 'loops' within the experimental design .

CONCLUSIONS
we here present the kefed formalism as a model for reasoning over scientific observations that support a given interpretation. we have instantiated this formalism within a general-purpose, open-source, fully-functional web-application that may be freely downloaded and used. we have provided a worked example from the domain of studying rat brain neural connectivity. the system is an early prototype but is designed to provide basic functionality to end-users and to provide a framework for future development within the field of biomedical knowledge engineering.

the functionality of the kefed editor provides benefits at three levels of the curation process.

 <dig>  provides a means to specify an experimental design that is intuitive for biologists to use. this design is then use to create data capture forms that record the context of experimental measurements.

 <dig>  provides a mechanism for associating elements of the experimental design with standard ontology terms. this annotation will promote interoperability and make the task of meta-analysis of experiments easier.

 <dig>  provides the infrastructure for building interpretive assertions within reasoning models that can trace their conclusions to the underlying data. the data can come directly from experiments or indirectly through the curation of published experimental reports. this can form the basis of a type of nanopublication that can trace its content to an underlying body of experimental data.

competing interests
the authors declare that they have no competing interests.

availability and requirements
software for the bioscholar project is described on the project home page at http://www.bioscholar.org/. the source code and applications are hosted at our google code project webpage http://code.google.com/p/bioscholar. this includes a non-editable implementation of the neural connectivity knowledge base  as well as a functional version of the general bioscholar system. this software is distributed under the mit open source license. running the self-contained server code requires java  <dig>  or higher and a computer with 1gb ram or more. the code is platform independent.

running the web-based client requires a web browser with the adobe® flash® plugin, version  <dig> or higher.

authors' contributions
gapcb formulated the basic idea behind the kefed approach and coordinated the project. tar and gapcb developed the bioscholar web application and wrote the paper. cr and eh both contributed to the development of the 'cycle of scientific investigation' as the large-scale formulation into which kefed modeling would apply. mb provided access to neural connectivity data and neuroanatomical ontologies from within the brain architecture management system .

supplementary material
additional file 1
description of the process of importing brain region containment data from the bams xml file for the swanson  <dig> atlas into powerloom.

click here for file

 additional file 2
brain region information from the swanson  <dig> atlas as downloaded from the bams web site.

click here for file

 additional file 3
powerloom file defining the qualitative geometric relations between regions including proper-part-of and overlaps. this provides the basic vocabulary for describing the relation between atlas regions.

click here for file

 additional file 4
powerloom file defining basic terms for representing an anatomical brain atlas. includes the brainregion concept and relations relating brain regions to their names and abbreviations.

click here for file

 additional file 5
powerloom file containing the names and containment relationships between brain regions as defined in the swanson  <dig> brain atlas. this is the file that contains the containment and name information from the bams xml file in powerloom format.

click here for file

 acknowledgements
this research is funded by the u.s. national institutes of health under grant r01-gm <dig> for the 'bioscholar' project http://bmkeg.isi.edu/ with some additional contributions from nih grant  and from the non-specific funding program from the michael j fox foundation . this work was also supported in part by the nih through the following ncrr grant: the biomedical informatics research network . we wish to acknowledge the programming contributions of marcelo tallis to the bioscholar project. in particular, thanks alan watts for the discussions that gave rise to the kefed model. thanks also to arshad khan, larry swanson, yolanda gil, jerry hobbs and hans chalupsky. especial thanks also to alan ruttenberg for discussions about the relationship between kefed and existing ontological approaches such as obi.
