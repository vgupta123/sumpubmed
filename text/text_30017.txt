BACKGROUND
in the early 1990s, the advent of high-throughput screening  and combinational chemistry methodologies was widely seen as having great potential to revolutionize modern drug discovery. however, the quality of the output from these technologies was limited than expected. despite advances in technology and understanding of biological systems, drug discovery is still a "lengthy, expensive, difficult, and inefficient process" with low rate of new therapeutic discovery  <cit> . drugs as well as drug-like compounds are distributed extremely meagerly through chemical space, which is estimated to contain ~ <dig> to ~ <dig> molecules. among the whole chemical space, the majority is nondrug molecules, the minority is druglike molecules. to assess whether a compound is druglike or not as early as possible in drug discovery process will be extremely meritorious. druglike compounds generally indicates molecules that contain functional groups and/or have physical properties consistent with the majority of known drugs, and hence can be inferred as compounds which might be biologically active or show therapeutic potential  <cit> . for a drug, properties like synthetic ease, stability, oral availability, good pharmacokinetic properties, lack of toxicity and minimum addictive potential are of utmost importance  <cit> . many of these properties depend on the inherent biological and physicochemical parameters of the molecule; whereas the complex structure of the whole drug molecule makes correlating attempts difficult to screen in such a large chemical space. meanwhile, about more than 80% of all failures of commercial drugs can be attributed to inappropriate absorption, distribution, metabolism, elimination, and toxicity  properties despite in vitro and in vivo testing  <cit> . only a small portion of druglike molecules would survive the rigorous evaluation process and be approved finally, which could be defined as approved drugs. the other compounds are regarded as experimental drugs, which are still in the clinical process or have not been approved for safety and effectiveness yet.

there have been many efforts made to create sets of 'rules' or 'filters' which, it is hoped, will help chemists to identify 'drug-like' molecules from 'non-drug' molecules. the best-known method of drug likeness prediction is the "rule of 5" developed by lipinski and co-workers  <cit>  by analyzing  <dig> available drugs from the world drug index . ajay et al.  <cit> , sadowski et al.  <cit> , and frimurer et al  <cit>  have constructed models to classify druglike and nondruglike molecules, one-dimensional parameters, including molecular weight, isis keys   <cit> , two-dimensional parameters, e.g. functional groups, ghose and crippen atom types  <cit> , were used as descriptors. a genetic algorithm-based approach developed by gillet et al.  <cit> , decision trees used by wagener et al.  <cit>  have been to distinguish druglike between non-drug compounds. these researches may distinguish compounds that are druglike and nondruglike with good accuracy . the most commonly used dataset are listed in table  <dig>  of which acd is used as the dataset of non-drugs, and wdi, mddr, or cmc is used as the dataset for drugs .

these above researches have focused on the classification of druglike and nondrug molecules. there are only a little druglike molecules would survive the clinical trials. discriminating the druglike compound from non-drug molecules is just the first step in long march. among the chemical space of the druglike molecules, the minority will be approved drugs. classifying approved drugs from experimental drugs may be more helpful to obtain future approved drugs. however, discriminations of approved drugs from other molecules have not been reported yet. can approved drugs be differentiated from experimental drugs? do the existing 'rules', features and modeling methods still work in the discrimination of approved drugs? in this paper, a further work has been done to assess the molecules which could be marketed drugs rather than experimental drugs. common used descriptors and classification methods have been utilized to discriminate approved drugs from experimental drugs. in order to evaluate the classification models, the models are applied to a highly possible drug-like database tcm-id   <cit> .

methods
dataset
our dataset were downloaded from drugbank <cit>  version  <dig> . as drugbank is a resource that combines detailed drug and target information, it contains approved drug and experimental drug. from the original dataset  <dig> molecules were processed. the final working set contained  <dig> approved drugs and  <dig> experimental drugs. the number of compounds per dataset in this study is shown in table  <dig> 

chemical descriptors
currently various sets of molecular descriptors are available  <cit> . in order to make approved/experimental classification of compounds, the molecules are typically represented by n-dimensional vectors. as the pro-processing, hydrogen was added. the charges and energy optimization of compounds were calculated by force field, mmff94x. the descriptors are calculated by the moe software . four sets of descriptors were calculated:  <dig> druglike index  <cit>  ;  <dig> widely applicable descriptors  <cit>  ;  <dig> standard moe descriptors ;  <dig> surface area, volume and shape descriptors . wd descriptors are based upon atomic contributions to van der waals surface area, log p , molar refractivity and partial charge. the surf descriptors depend on the structure connectivity and conformation; have been shown to be useful in pharmacokinetic property prediction. all descriptor columns were individually normalized to have a mean of zero and unit variance prior to generation of classification models.

classifications methods
the reported algorithms can be formulated in terms of machine learning methods. the standard scenario for classifier development consists of two stages: training and testing. during the first stage the learning machine is presented with labeled samples, which are basically n-dimensional vectors with a class membership label attached. the learning machine generates a classifier for prediction of the class label of the input coordinates. during the second stage, the generalization ability of the model is tested. here, four different methods are applied.

plsda
partial least squares  is a technique that generalizes and combines features from principal component analysis and multiple regression. its goal is to predict or analyze a set of dependent variables from a set of independent variables or predictors <cit> . this prediction is achieved by extracting from the predictors a set of orthogonal factors called latent variables which have the best predictive power. pls regression is one of the most powerful data mining tools for large data sets with many variables with high collinearity.

kpls
kpls was first described by s. wold  <cit>  and applied to spectral analysis in the late nineties. rosipal <cit>  introduced kpls in  <dig> as a nonlinear extension to the linear pls method. this nonlinear extension of pls makes kpls a powerful machine learning tool for classification as well as regression. kpls can also be formulated as a paradigm closely related   <cit>  to support vector machines .

ann
an artificial neural network , often called as "neural network" , is a mathematical model or computational model based on biological neural networks. it consists of an interconnected group of artificial neurons and processes information using a connectionist approach to computation  <cit> . in most cases an ann is an adaptive system that changes its structure based on external or internal information that flows through the network during the learning phase.

svm
support vector machines work by mapping the training data into a feature space by the aid of a so-called kernel function and then separating the data using a large margin hyperplane. intuitively, the kernel computes a similarity between two given examples. most commonly used kernel functions are rbf kernels. more details on svms have been provided in the literature numerous times  <cit> .

model evaluation and validation
to assess the ability of these four classification methods to predict new chemicals, five-fold cross-validation was used. 20% of chemicals were randomly chosen as the test set; the remaining 80% were used to generate the models. the test set was not used in any way to influence the training and selection of the models. for each five-fold validation, the random experiment was repeated  <dig> times independently. accuracy , sensitivity , specificity  and coefficient correlation  are often used to evaluate prediction systems. sn, sp and ac are expressed in terms of true positive , false negative , true negative , false positive  rates:        

results and discussions
classification 
RESULTS
in order to compare the classification ability of the four classifiers, the results of different descriptors on different models have been scanned. the results distribution of the four classification methods were displayed graphically in figure  <dig>  the median accuracy were  <dig> %,  <dig> %,  <dig> %, and  <dig> % by ann, svm, kpls and pls respectively. from figure  <dig>  it can be seen that the results of ann and svm were better than those of the kpls and plsda. svm gives stable performance; the next robust one is ann. the accuracy distributions of kpls and plsda are sparser and the results are not as robust as ann and svm. the classification performance of svm was slightly better than ann, significantly outperformed kpls  and pls . svm has also been compared to ann and linear discrimination analysis for drug and non-drug datasets previously  <cit> . results presented here are generally in agreement with these previous observations.

due to robust convergence behavior svm seems to be well-suited for solving binary classification problems especially with large variables. in previous studies, svm performed better than ann when large numbers of features or descriptors are used  <cit> . but it is not observed in this paper.

since the wd and surf descriptors are subsets of the standard moe descriptors, seven sets of descriptor combinations are used for classification. the classification results of four methods and seven sets of descriptors are shown in figure  <dig>  as reported before  <cit> ,  <dig> % and  <dig> % correction rates were obtained by ann and svm respectively in classifying drugs and nondrugs using the standard moe descriptors. in this paper, using moe descriptors with ann and svm classifiers gave classification rates of  <dig> % and  <dig> % in discrimination of approved and experimental drugs. the rank order of descriptor sets with regard to the overall classification accuracy yielded was as follows: moe+dli, moe, wd+dli, dli, wd, surf+dli, surf.

moe descriptors contained 2d and 3d descriptors. 2d molecular descriptors are defined to be numerical properties that can be calculated from the connection table representation of a molecule . there are two types of 3d molecular descriptors: those that depend on internal coordinates only and those that depend on absolute orientation. the descriptor number of moe is far more than that of other methods. from the result of our study, the more comprehensive the descriptors is, the better results are obtained. while the descriptors were chosen on the basis of simplicity, ease of calculation, and diverse representation of chemical properties, simple descriptors are popular in research. among these descriptors used in this study, the dli maybe made fairly important contribution that additional descriptors were unlikely to significantly improve prediction accuracy. considering the complexity of hundreds of thousands of descriptors, such generic and simple chemical properties are so predictive. these simple descriptors have been shown previously to encode and have been used successfully in the past to predict diverse datasets  <cit> . wd descriptors are applicable descriptors and the results of it are in the median of the best and worst. the surf descriptors led to approximately 10% lower accuracy than the best one. the surf descriptors have been shown to be useful in pharmacokinetic property prediction but not take effect in this case.

the fundamental problem of the method is how to characterize samples with precise and informative features. from the above results, moe descriptors conformed well in approved and experimental drugs classification. the dli descriptors, which made fairly important contribution, were employed to characterize molecules due to its calculation based upon the knowledge derived from known drugs.

consensus modeling
in this study, it is noticed that the classified results of different descriptors on different models various largely. for example, the number of approved drugs and experimental drugs which were correctly classified by over 60% methods was  <dig> %,  <dig> % on average respectively. the molecules are correctly classified in some models while misclassified in others, which indicates their complementary to each other.

thus we proposed jointly applications of all predictive systems. one possibility to combine several estimators is to employ a voting, e.g. calculating an ensemble average. the other is to construct a consensus model. the central idea of the consensus model is to use the results of multiple, heterogeneous classifiers with variables which may maximum the diversity of the classifiers as the input variables in a new layer classification.

each classification method has its own strengths and weakness; the ensemble of similar classifiers would inherit such benefits and drawbacks. the four classification methods used in this paper have different advantages, it is useful to construct a consensus model by summarizing different pattern  <cit> . here, the obtained classifiers' results in above section are fed into the second layer svm to get the final result. the results are listed in table  <dig> 

from the results in table  <dig>  the consensus model gained widely improvement and outperformed the other methods, such as the best svm and the voting model. the order of accuracy yielded was as follows: consensus model, best svm, voting model. compared to the results of best svm, the sensitivity of consensus model increased 13%, the specificity increased 6% and the accuracy increased 6%. compared to the results of voting model, the sensitivity of consensus model increased 17% and the accuracy increased 4%. the sensitivity means true positive, that is to say, correctly classified approved drugs. for example, an approved drug--sulfinpyrazone is misclassified by best svm and voting model as experimental drugs, while it is discriminated correctly using consensus model. the specificity means true negative. here it means classifying the experimental drugs correctly. an experimental drug--adenosine-5-diphosphoribose, which is misclassified as approved drugs by svm and voting model, is correctly classified by consensus model. the vote scheme is usually tend to accept the prediction with more voting supports, which may ignore the special samples. this limits the prediction accuracy. while in the consensus model, the results of first level classifiers are used as the input of the second layer svm, which will avoid unnecessary voting and can combine the results of different methods. the consensus model would further improve the prediction accuracy and robustness of a predictor.

application to herbal ingredients
herbal ingredients have been expected as a potential druglike database. the utility of natural products as sources of novel structures is still alive and well. in the area of cancer, over the time frame from around the 1940s to date, of the  <dig> small molecules, with 47% actually being either natural products or directly derived therefrom <cit> . a comparison by feher and schmidt  <cit>  showed that, overall, natural products are more similar to drugs than compounds obtained from combinatorial synthesis. a large proportion of natural products is biologically active and has favorable adme/t properties .

since the major properties were similar, we used the model constructed by approved drugs and experimental drugs to test herbal ingredients. the final model was applied to tcm-id. the results showed that  <dig> compounds were classified as potential drugs from  <dig> molecules. while about 58% and 73% ingredients passed lipinski  <dig> rules filter and oprea filter respectively.

in order to verify the discrimination results, there are three kinds of compounds listed in table  <dig>  type i is the intersection of herbal ingredients and approved drugs, type ii is the intersection of herbal ingredients and experimental drugs and type iii is unknown compounds. 76% compounds in typei all passed the filter by our model, while 80% passed lipinski  <dig> rules and 66% compounds passed the oprea  <dig> rules. about 22% compounds in typeii were misclassified as drugs by our model while 79% compounds were misclassified by lipinski  <dig> rules and 66% were misclassified by filter of the oprea  <dig> rules. from the above results, our model is comparable to lipinski  <dig> rules and oprea  <dig> rules when they are use to predict a compound as a candidate drug. our model is better than the others when they are used to justify a compound as nondrug. the model would be useful to narrow down the space of drug prediction and screening.

compounds in typeiii are unknown to us for whether they would be a candidate drug. the passed compounds by different filter rules are different. for example, aristolochic acid has been proved being carcinogenicity and high nephrotoxic and may be a causative agent in balkan nephropathy. it passed the filter of lipinski  <dig> rules and oprea  <dig> rules while it was taken as an experimental drug in our model. astragaloside iv, which is a main ingredient in many chinese patent medicines, is predicted as a candidate drug in our model while not pass the filter of lipinski  <dig> rules and oprea  <dig> rules. whether it is a potential drug or not will be tested by further experiments.

CONCLUSIONS
from the work, discrimination of approved drugs and experimental drugs is practicable. a comparison of four widely used classification methods has shown that, on average, the svm is able to generate the most predictive models to discriminate approved and experimental drugs, followed by ann, kpls and then plsda. seven sets of molecular descriptors were applied to the discrimination of approved drugs and experimental drugs. notably, these descriptors have comprehensible definitions and physicochemical meanings for drug properties. the classifiers have been complement to each other. the correct classification rate is up to  <dig> % by using the consensus model. the herbal ingredients dataset was tested, indicating that this database is a good source for drug discovery. furthermore, it will not only narrow down the space of drug prediction and screening but also facilitate drug discovery, which the approved drugs and experimental drugs' discrimination has been implemented into the early stage of drug discovery by discarding compounds that are likely to fail further down the baseline.

authors' contributions
kltang performed the classification, prediction and wrote the manuscript, rxzhu performed the molecules pre-processing and calculated the descriptors by moe. yxli participated in the study design. zwcao supervised the study. all authors read and approved the final manuscript.

