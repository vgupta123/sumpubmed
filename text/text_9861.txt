BACKGROUND
gene expression time course experiments have been used to investigate fundamental biological processes which are often dynamic in nature. for example, the cell cycle  <cit> , cell signalling  <cit> , circadian rhythms  <cit>  and developmental processes  <cit>  have been studied extensively using gene expression time-series data.

many computational approaches to time-series analysis are not always well suited to gene expression data, where missing measurements are common and time points may not be spaced regularly. in many conventional time-series models such as state-space models  <cit>  there is no straightforward manner to deal with missing data, and time points must occur at regular intervals. whilst gene expression experiments can be sampled regularly, such designs may not be optimal from a statistical or cost perspective. a method for modelling arbitrarily sampled time points may elicit more information from fewer samples, where time points are selected to capture pertinent temporal features.

furthermore, existing time-series models do not necessarily capture the structure of gene expression data. many gene expression time-series are performed with multiple biological replicates: the crude method of simply averaging the replicates may be discarding interesting information. it is also unclear what to do when the replicates are not sampled at the same times. there is a need for a temporal model which deals with the replicate structure.

our proposed model is based upon two important ideas: gaussian process  regression allows for parsimonious temporal inference, whilst a hierarchical structure accounts for  covariance between biological replicates. additional layers can be added to the hierarchy to model more structure in the data. for example, in a data fusion application, a layer of hierarchy can be used to account for differences between gene expression measurement platforms; or in a clustering application, a hierarchical layer can be added to account for temporal covariance of genes within a cluster.

gps have been successfully applied to the analysis of gene expression time series by several authors  <cit> . there is little doubt that they provide a coherent and principled framework for regression: for an introduction see  <cit> . our contribution is to propose hierarchical gaussian processes to deal with structure in the data. we provide an introduction to the idea, deriving a novel covariance function which accounts for structure. the idea is simple to implement yet highly effective as we demonstrate on several problems. a hierarchical gp model could easily be integrated with existing gp-based applications, allowing them to properly account for replicate structure.

in a further contribution, we manipulate the marginal likelihood expression for the hierarchical gp model for the case where each part of the structure is sampled at the same time, leading to an expression with reduced computational complexity. this situation is most likely to occur during clustering of genes, which must all be measured simultaneously using high throughput methods.

short time series are prevalent in gene-expression data sets  <cit> . our gp-based model is well suited to short time-series, and the behaviour of gps can be set to mimic that of other temporal models  through the covariance function  <cit> , though in this work we use a simple form for the covariance which assures smoothness of the underlying dynamics.

unlike other time-series based approaches, gps are not restricted to data which has been sampled at evenly spaced time points. the model therefore removes any restriction on temporal sampling — it can be totally irregular and differ between replicates. this also allows our method to deal with both randomly and systematically missing data. we show how the model can be used for data fusion where the temporal sampling differs between experiments.

related work
hierarchical models are an important idea in bayesian statistics  <cit> , allowing information to be exchanged between related groups of data. the idea is that by performing inference on the structure as a whole, rather than on each part of the structure independently, inference is improved. gps have been successfully used in models of gene expression time-series before; for example for inferring transcriptional regulation  <cit> , and to identify differential expression in time-series  <cit> . a key contribution of this work is to combine hierarchical structures with gps to provide a parsimonious and elegant method for dealing with replicated gene expression time-series.

an alternative to our method was proposed by  <cit> . in this model, uncertainty is assumed in the time of data collection, and the time-shift in each replicate is estimated. in our model, the times are assumed correct whilst the shift is assumed to occur in the expression. our model has significant computational advantages, since we can marginalise the shifts in expression analytically under the gp framework, whilst the method proposed in  <cit>  required optimisation of a large number of variables . further, our model is easily included in more complex gp-based models, such as the clustering application which we shall demonstrate. the estimation of time-shifts would be difficult to incorporate into a clustering method, especially considering the very large numbers of parameters which require optimising.

clustering expression data while modelling within-cluster variance is one of the primary applications of our model. previously,  <cit>  proposed a random effects model to account for variance between observations of genes and also within clusters of genes. further,  <cit>  and  <cit>  explored clustering methods with hierarchical structures to model replicate variance. in these models, replicate variance was modelled as multivariate gaussian around some gene-specific mean, and the gene’s expression was considered multivariate gaussian around a cluster-specific mean. this paper presents a similar but more powerful idea: we use a hierarchy of gps to model gene-specific and replicate-specific temporal covariance. we demonstrate that the introduction of a gp prior makes inference of clusters more viable by reducing the number of parameters required to model the data within a cluster, and we also provide a method for dramatically reducing the computational cost of evaluating clusters under our model. previous methods for clustering temporal data  have not used the replicate structure in the model.

methods
background: gaussian processes
gaussian processes  have been used extensively in a variety of regression problems, and have been applied to gene expression time-series by several authors  <cit> . we briefly introduce gp regression and introduce some notation: for an in-depth introduction one may consult  <cit> .

to perform regression using gps, we adopt a bayesian approach. starting with a prior directly over functions, we update the distribution in light of observed data, moving to a posterior distribution. using standard results for gaussian distributions, regression involves only some simple linear algebra. the gp prior is fully specified by two functions, a mean function m and a covariance function k, and is denoted 

  f∼gpm,k. 

for practicality, a zero-mean function is often assumed; throughout this work, the squared-exponential covariance function will be used: k=α exp{−γ2}.

our choice of covariance functions represents a prior belief that the underlying functions are smooth. other covariance functions could be selected using a model-selection procedure  <cit> . the parameters of the covariance function  control the amplitude  and relative length-scale  of the functions . the form of the covariance function captures a very simple assumption about the function: that function points which are close to each other  are highly correlated, whilst points which are distant are less correlated.

regression can be performed by using the marginal and conditional properties of multivariate gaussian distributions. supposing we have observations f of a function at times t, and wish to predict the values of that function at times t⋆, which we denote f⋆: the joint probability of f and f⋆ is given by 

  pff⋆=nff⋆ <dig> kt,tkt,t⋆kt⋆,tkt⋆,t⋆, 

where the covariance matrix kt,t has elements derived from the covariance function k, such that the th element of kt,t is given by k. consistency of the gp means that it is not necessary to consider the values of the function where we do not have data: these values are trivially marginalised. to perform regression, the conditional property of the multivariate gaussian gives: 

  p=nf⋆|kt⋆,tkt,t−1f,kt⋆,t⋆−kt⋆,tkt,t−1kt,t⋆. 

in practice, we are presented with a measurement vector y which is a noise corrupted version of f. assuming gaussian noisea it is possible to write p=n, where β is the variance of the noise and i the appropriately sized identity matrix, and then marginalise the variable f. equivalently, one can consider y to be observations of the gaussian process y, whose mean function is the gaussian process f, and covariance function is βδt,t′. this hierarchical structure is used later in this publication to build gp priors over replicates and clusters. either interpretation gives a joint density: 

  pyf⋆=nyf⋆ <dig> kt,t+βikt,t⋆kt⋆,tkt⋆,t⋆ 

and regression follows from the conditional property similarly to .

gaussian process regression is a bayesian method. we move from a prior over functions to a posterior, and a significant attraction of the method is that this occurs in closed form as . however we must still deal with hyper-parameters of the covariance function. here, we make use of the usual technique which is to optimise the hyper-parameters using type-ii maximum likelihood. that is, collecting the hyper-parameters α,β and γ in to a vector θ, we use gradient methods to optimise p with respect to θ. this is given by 

  logp=−d2log2π−12×log|kt,t+βi|−12y⊤−1y, 

which depends on θ through the covariance matrix kt,t.

a hierarchy across replicates
gene expression time-series may be collected in multiple replicates, to account for biological variation. the idea is that there exists some common trend, present in all replicates, which we wish to identify, and the measurements made of each replicate vary due to biological differences as well as technical noise.

we shall use the notation ynr to denote the vector of measurements of gene expression of the nth gene, in the rth biological replicate; these measurements were made at times which we collect into a vector tnr. the data for the nth gene is denoted yn={ynr}r=1nn, tn={tnr}r=1nn.

our proposed methodology mimics the structure of the data, directly modelling underlying time-series as well as the biological variation, and accounting for  measurement noise. first consider a time-series model of a single gene. to combine replicates of a particular gene’s time-series, we use a bayesian hierarchical approach: the underlying expression profile of the nth gene gn is presumed to be drawn from a zero-mean gp with covariance kg, whilst the expression profile of a particular replicate fnr is drawn from a gp whose mean is gn. thus 

  gn∼gp <dig> kg,fnr∼gpgn,kf. 

note that the two covariance functions kg and kf may in general be different: we have used the squared exponential function for both, with independent parameters. this simple model is illustrated in figure  <dig>  where the dependent nature of the functions is illustrated, as well as the effects of the hyper-parameters.

the elegance of the hierarchical approach lies in its linearity: it is simple to show that two points on the function fnr are jointly gaussian distributed with zero mean and covariance kg+kf. furthermore, two points in separate replicates are jointly distributed with covariance kg. thus, given a set of nn replicates of gene expression time-series for a particular gene, yn={ynr}r=1nn, taken at different time points tn={tnr}r=1nn it is possible to write the likelihood: 

  p=ny^n| <dig> Σn, 

where y^n has been used to denote the concatenation of yn, y^n=⊤, θ represents the parameters of the covariance functions kg and kf, and the block of Σn corresponding to ynr,ynr′ is given by 

  Σn=kg+kf+βiifr=r′kgotherwise. 

in order to make inferences about the functions gn and fnr, the covariances between the data y and the functions are required. using the superscripted ynr to denote the element of ynr observed at time t: 

  covynr,gn=kg, 

  covynr,fnr′=kg+kfifr=r′kgotherwise. 

inferences about functions can then be made using the standard methods described above, and hyper-parameters of the covariance functions can be optimised.

fitting a hierarchical model to a set of replicates can be used as a diagnostic tool. in particular, by examining the maximum-likelihood values of the covariance function parameters, we can assess how noisy the experiment is, and how similar the replicates are. figure  <dig> shows three examples of hierarchical regression of the time course data described the results section, for three genes , with each gene shown in one row in the figure. the leftmost panes in the figure show the inferred function for the gene, gn, and subsequent panes show the inferred functions for each replicate, fnr.

these examples demonstrate different behaviours of the time-series which are captured by the model. for the first gene, cg <dig>  the replicates are quite similar, and most deviation of the data from gn is attributed to noise. the model attributes 87% of the data’s variation to the underlying function gn, and only 6% each to replicate variance and noise, i.e. the model ‘recognised’ the similarity of the replicates.

the gene represented by the middle row is ap- <dig>  and it can be seen that there is considerable replicate variance: although each replicate follows a similar pattern, the pattern is ‘amplified’ differently in the replicates. here, the model attributes 60% of the data’s variance to the function gn and 34% to fnr, with 6% to noise.

the gene represented by the bottom row of figure  <dig> is oststt <dig>  here, the variances of gn, fnr and noise are 55%, 36% and 8% respectively. the model recognises the differences in the replicates, but uses a long length scale for fnr. in this gene, the detailed pattern of the time-series is captured entirely by gn, and fnr is used to account for amplitude shifts between replicates. note that these cannot be simply ‘normalised out’ because not all replicates cover the same temporal region. these genes were selected using a simple filtering procedure. the model was fitted independently to each gene on a microarray, and the genes were ranked according to the ratio of signal variance  and replicate-plus-noise variance .

deeper hierarchies
in many cases, gene expression time-series may have more structure than simply biological replicates. for example, we could incorporate previous studies in a hierarchical fashion. in general, suppose that there is some underlying function gn which models the general gene expression activity for the nth gene. subsequently, we define the functions eni for each experiment which we want to model, and finally fnir for the r th replicate in the i th experiment. 

  gn∼gp <dig> kg,eni∼gpgn,ke,fnir∼gpeni,kf. 

with every layer of the hierarchy, we have introduced new parameters corresponding to the covariance function for that layer. note that the hierarchy can be extended arbitrarily to represent the structure of the data. for example, we might want to model biological variation where the lineage is known, or to model inter-species variation, or to build a hierarchy which reflects the phylogenetic relationship between species.

an efficient model of clusters
clustering of gene expression time-series is often performed with a view to finding groups of co-regulated or associated genes. the central assumption is that genes which are involved in the same biological processes will be expressed together: they share an underlying time-series.

in order to model a group of genes as defined by a cluster, the hierarchical model is extended to a three-layer hierarchy across the cluster, individual genes and replicates.

all genes in the ith cluster are presumed to share an underlying profile hi, and subsequently each gene follows a profile gn and each replicate of that gene follows a profile fnr. the mean of each level in the hierarchy is given by the level above, so the data yi in cluster i is modelled by: 

  hi∼gp <dig> kh,gn∼gphi,kg,fnr∼gpgn,kf. 

if y^i is the concatenation of all of the y^n representing genes in the ith cluster, noting that each y^n is itself a concatenation of the biological replicates, then the marginal likelihood of the expression data in the ith cluster, yi is given by 

  p=ny^i| <dig> Σi 

where the covariance matrix Σi is structured such that the block corresponding to the two genes n and n′ is given by 

  Σi=Σn+khifn=n′khotherwise. 

note that the diagonal blocks of Σi are themselves block-structured, reflecting the double hierarchy in the model.

the computational complexity of this model grows cubically as the size of the cluster increases, which is an undesirable property. to reduce the computational load, it is possible to exploit a known property of the data. in each array all genes are simultaneously measured, although we allow different times for each replicate. denote t^ the concatenation of the times in all replicates, define kh as the covariance matrix formed by evaluating kh on the grid of t^, and Σn a covariance matrix structured as , modeling the variance of a single gene. the marginal likelihood can then be written 

  p=2π−nid2|kh|12|Σn|ni2|kh−1+niΣn|12exp{−12{∑n=1niyn⊤Σn−1yn−ni2y¯i⊤Σn−1−1Σn−1y¯i}}, 

where y¯i is the mean of the y^n in the cluster, d is the length of t^, and ni is the number of genes in the cluster . this expression has reduced the computational complexity of the model from o to o.

an example of this model is shown in figure  <dig>  the inferred function h, shown in the bottom-left pane has a single wide peak at around  <dig> hours; all of the functions gn  show a similar pattern, though the functions are each ‘distorted’ a little, with the width of the peak varying from gene to gene. similarly, each replicate shows a similar pattern to the mean function for the corresponding gene, with smaller variations. the bottom row shows the predictive density for a new gene within the cluster.

clustering
to use our model for clustering, the partitioning of genes into clusters needs to be inferred. dunson  <cit>  proposed a clustering scheme where a gp is used to model the function within a cluster, and a dirichlet process prior is placed on the partitioning. this leads to a gibbs sampling scheme where each gibbs step involves removing a gene from the clustering and then stochastically re-allocating it. our model potentially improves on dunson’s formulation since we consider a structured covariance across the genes and replicates , though it would be possible to use the same gibbs sampling scheme to infer the cluster partitions.

heller and ghahramani  <cit>  showed that inference in a dp can be effectively approximated using an agglomerative clustering scheme dubbed bayesian hierarchical clustering b. cooke et al.  <cit>  applied this hierarchical clustering scheme to gene expression time-series with a gp prior, and we extend their work using a hierarchically structured gp to model the clusters, as well as the efficient computation of the marginal likelihood as per equation .

the algorithm is depicted in algorithm  <dig>  and works in a ‘bottom-up’ fashion. starting with each gene in an individual cluster, the clusters are merged by greedily selecting the merge which maximises the log marginal likelihood of the data . once no more merges are available to improve the overall marginal likelihood, the hyper-parameters are optimised, and the procedure is repeated with the new covariance function in an em fashion.

RESULTS
in a recent study of drosophila development  <cit> , gene expression was measured in eight replicates measured across six species at differing time-points.  <dig> genes  were investigated using agilent microarrays. here we focus on melanogaster development: time courses for typical genes are shown in figure  <dig> and  <dig>  with eight replicates at up to thirteen time-points. note in particular that no replicate contains all the time-points: some replicates cover only the last few points, whilst some have broader coverage.

for all the missing data experiments, the covariance function hyper-parameters were set to the maximum likelihood value using gradient based-numerical optimisation. whilst we show that the hierarchical gp has better performance than the gp in all cases, it does not require any extra computation. all experiments took only a few minutes on a desktop pc.

missing data imputation
the imputation of missing data is a straightforward method for validation of our model. in this section, we remove data systematically, effectively removing entire microarrays from the experiment and predicting what was on them. most missing data imputation methods cannot handle this type of missing data, highlighting an advantage of our method. this experiment also validates our assertion that it is important to include the replicate structure in modelling microarray time-series, and that simply averaging the data on a time-point basis is not satisfactory.

algorithm  <dig> cluster replicated gene expression time-series   

whilst systematically missing data are not common in the laboratory, this test does examine the performance of our model in some potentially interesting applications. for example, we may wish to predict the future gene expression levels of a patient given the time series observed in other patients.

the results of imputing missing data are compared with the simple but oft-used technique of averaging the replicates, using both the mean and median of the non-missing replicates. the method is also compared with a simple gp model which does not account for replicate structure. we investigated the effectiveness of our algorithm using varying amounts of missing data, removing  <dig>   <dig>   <dig> and then  <dig> of the  <dig> microarrays at random. each experiment was repeated  <dig> times with different randomisations; for each we computed the rmse  averaged over all missing arrays and over all genes. the mean rmse and two standard deviations as measured over the randomisations are shown in table  <dig> 

the rows correspond to hierarchical gps , non-hierarchical gps , and imputation using the mean and median of available replicates. columns represent increasing amounts of missing data.

we note from table  <dig> that our contribution of adding replicate structure to the gp methodology makes a significant difference to the results, since the standard gp offers only modest improvement over the simple averaging methods. we also note that the averaging methods are only possible where time-points are duplicated between replicates, a restriction which the gp methodology removes.

randomly missing data imputation
our proposed model is novel in the sense that it can impute entire missing arrays, as above. most missing data algorithms assume randomly missing data and use correlation between genes for imputation. to compare our algorithm with those from the literature, we randomly removed  <dig> values from the melanogaster dataset, and measured the error on imputation. for comparison, we also used two popular methods, k-nearest-neighbour   <cit>  and bayesian principal component analysis   <cit> .

gene expression experiments usually contain many types of effect aside from the one under study. in this case, the data includes cross-sectional effects which arise from array-specific and sample-specific causes, and are not due to the underlying time-series. these are treated as noise by our model, whereas pca and knn make no distinction between longitudinal and cross-sectional variance and will freely impute these effects. this is illustrated in figure  <dig>  where cross-sectional effects mean that the missing datum’s true value lies below that seen by averaging the replicates, or imputed by hgp. the hgp and knn methods, being sensitive to these effects impute the true value well, despite it being inconsistent across replicates.

to test the methods’ abilities to impute the replicable part of the signal, we tested the imputed values of the three methods against the median value for the missing time-point, averaged across replicates. we measured the rmse over the  <dig> imputations, and repeated the experiment  <dig> times with different randomisations. the mean rmse  and two standard deviations are shown in the first column of table  <dig> 

the first column shows the rmse measured against the replicate-median, and the second column shows the rmse against the model with no missing data.

another way to investigate the ability of the model to deal with missing data is to examine the difference between the model as inferred with some missing points to that inferred with all the data: the results of doing so are shown in the second column of table  <dig>  whilst this method may not give a completely fair reflection of the performance of the pca and knn methods, the small size of the errors on imputation imply that our model is relatively insensitive to missing data: because the model can borrow statistical strength from other replicates, small amounts of data missing at random make little difference to the model.

data fusion
the data under investigation are sampled at two-hour intervals. to improve our knowledge of the system, it is possible to perform data fusion with existing data sets. we demonstrate this with two previous studies:  <cit> , which offer more tightly temporally-spaced data, but with fewer replications .

we constructed a hierarchical model across the three experiments, and across replicates within the experiments. the data were considered on a gene-by-gene basis, and the model was optimised for each gene. an example gene  is shown in figure  <dig>  the figure shows the inferred function for each replicate in each experiment, as well as the inferred mean function for each experiment  and the inferred ‘top-level’ function  which underlies all the experiments.

clustering
in order to investigate the usefulness of our model in a clustering task, we first selected  <dig> dynamically differentially expressed genes using a method similar to  <cit> .

we computed the marginal likelihood using our hierarchical model and a simpler gp model without replicate-specific or gene-specific variance. this model, simply fitting a gp to the lumped data is similar to the method proposed in  <cit> , which represents the current state-of-the-art. cooke et al <cit>  compared their method to several other algorithms and concluded that the gp method allowed for the discovery of clusters in a more effective manner than non-temporal models. here we show that this method can be improved further by considering the gene-wise and replicate-wise intra-cluster structure of the data’s variance. for both models, we applied the em algorithm with several restarts , selecting the solution with the highest log-likelihood. we used our own implementation for cooke et al.’s method to ensure that results were comparable: i.e. that improvements in the method were due to the hgp structure, rather than specifics of the implementation. we are primarily concerned with the improvements that the hgp model can offer in explaining cluster variance, and this allows for a direct comparison.

for further comparison, we used the r package mclust  <cit> . mclust fits a range of gaussian models of increasing complexity; in the first instance, we simply concatenated the replicates and mclust struggled to fit some models in the  <dig> dimensional space. subsequently, we provided mclust with shorter vectors formed by averaging the replicates at each time point, which gave similar results. we include the validation for both methods. in both cases, we used all available covariance structures for mclust, and let the package pick the best using its bic  approach.

in order to validate the different clusterings, we use the biological homogeneity index   <cit> , which assesses the number of genes with common function within each cluster, assigning the entire clustering a score from  <dig> to  <dig> with larger values corresponding to more biologically homogeneous clusters. for biological annotation, we used the three gene ontology  categories , which correspond to molecular function , biological process  and cellular component . computation of the bhi is then straightforward: it is the proportion of within-cluster pairs that share at least one biological annotation. the bhis and log-likelihoods for all the experiments are shown in table  <dig>  we note that other comparisons between the clusters and the gene ontology may be possible, for example the go term overlap score  <cit> , but we use the bhi here for ease of interpretability.

the first three columns report the biological homogeneity index  for the gene ontology categories of molecular function , biological process  and cellular component . the two last columns report the log-likelihood ℒ of the models and the number of recovered clusters.

from the table, it can be seen that hgp method improves the biological homogeneity for all three go categories. by directly comparing with the standard gp method, we have demonstrated that the improvement in clustering performance is not due simply to the clustering methodology or the gp correlations which give the gp method a small improvement over mclust, but the hierarchical structure of intra-cluster variance which allows genes and replicates to differ in a temporally-correlated fashion.

CONCLUSIONS
we have presented a method based on hierarchically structured gps, which are a practical and flexible framework for modelling replicated time-series. the framework has a wide range of applications, and can be extended for various data structures besides biological replications.

the method performed well in several tasks, including missing data imputation and clustering. we have shown that the method performs particularly well in missing data imputation, and that small amounts of missing randomly data have only a minor effect of the model. biological validation through the bhi confirms the importance of modelling intra-cluster variance in a hierarchical fashion.

above we showed how fitting the simplest of our proposed models can lead to a quantitative assessment of how biological replications are behaving, as well as illustrating how our method deals with different types of replicate variation. of course, if the replicate variance is truly independent – e.g. if only technical variation is present – then we recover standard gp regression. in this case the hierarchical approach requires the inclusion of an extra parameter, but we find that the additional computational complexity is negligible.

a problem with standard gp regression is that the computational complexity grows cubically with the number of data. we have presented a method which exploits the necessary condition that all genes in a cluster are measured on the same time-points in order to significantly reduce the computational complexity and make our clustering algorithm applicable to large data sets. we note that the complexity of the clustering algorithm scales poorly with the number of genes: the initial step of the algorithm must compare the likelihood of merging of each pair. to address this, randomised versions of the same algorithm can be adopted  <cit> , and our hierarchical model and its efficient computation as  could be used with no modification.

whilst we have demonstrated that our model is useful in several applications, we envisage a number of extensions. for example, our model could be used for data fusion of microarray data with high-throughput sequencing data. or, the hierarchical structure could be used in models of pathway activity  <cit> , which may include prior information about gene groupings from gene ontology.

although we have only used simple gp models within our hierarchical structure, the idea can be applied to more complex gp models, such as those proposed to model gene interactions  <cit> .

endnotes
a other noise distributions are possible, but break the conjugacy of the model and thus complicate inference, see  <cit> .

b note that hierarchical in this sense means a hierarchical partitioning of the genes, distinct from our bayesian hierarchical model applied within the cluster.

appendix
efficient computation of a cluster likelihood
the expression for the marginal likelihood of a cluster of genes as given in equation  can be derived by considering the values of the underlying function h at the time points t, which we denote h. the model  can be written: 

  p=∫p∏k∈cipdh. 

this consists of a prior for the latent variable h and a likelihood for the data associated with each gene in the cluster, conditioned on the latent variable. the objective here is to marginalise  the latent variable to achieve a tractable expression. expanding equation , 

  p=∫−d/2|Σn|−n/2|kh|−1/2exp−12h⊤kh−1h−12∑k∈ci⊤Σn−1dh. 

some re-arrangement and completing the square inside the exponent leads to 

  p=∫−d/2|Σn|−n/2|kh|−1/2exp−12⊤Λ−12h^⊤Λh^−12∑k∈ciy^k⊤Σn−1y^kdh. 

where we have defined for brevity Λ=kh−1+ngΣn− <dig> and h^=Λ−1Σ−1ngy¯i. the first and third lines of this expression can be moved outside the integral, and we recognise the gaussian nature of ∫exp−12⊤Λdh=d/2|Λ|1/ <dig>  substituting this and the expressions for h^ and Λ back into  leads to the expression given in .

competing interests
the authors declare that they have no competing interests.

authors’ contributions
jh designed the studies, implemented the algorithms in python and drafted the manuscript. mr and ndl assisted in design and analysis of the experiments. all authors read and approved the final manuscript.

