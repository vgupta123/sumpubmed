BACKGROUND
one of the most challenging tasks of systems biology is to reconstruct structures and mechanisms of interaction between components of cellular systems from available experimental data. in view of recent technological developments for large-scale measurements of dna expression levels, this problem can often be formulated more specifically as a problem of gene network inference from microarray gene expression data. in particular, microarray time-series represent an important source of information about cellular dynamics. various approaches have been proposed to reconstruct network structures from microarray time series. these approaches include additive regulation models  <cit> , dynamic bayesian networks   <cit> , s-system models  <cit>  and boolean networks  <cit> . each of these concepts allows for several modifications, which multiplies the number of possible models for data analysis. the problem is not trivial as little is known about molecular interactions in experimentally observed systems. the mismatch between the real mechanisms used for data generation and the models used for network inference may lead to arbitrary network structures. therefore it is difficult to expect that any one of the proposed formalizations can ensure acceptable performance for any biological system. nevertheless further attempts to develop models that provide greater accuracy and flexibility with respect to the system under investigation would be appreciated.

the additive regulation model is a widely used approach for network inference from time series data  <cit> . it is represented by a set of ordinary differential equations:

 dyidt=∑j=1nwijyj+bi 

where yi is the intensity level of node i at time t; n is the number of measured nodes; bi is the constant output observed in the absence of regularity inputs and wij is the coefficient representing the influence of node j on the regulation of node i. as experimentally obtained time series are available in a finite number of discrete time points n, the continuous differential representation  should be converted into the discrete-time form:

 yi=yi+∑j=1j≠knwijyjΔtk+biΔtk 

where k =  <dig>  ...,n- <dig> and Δtk is the time interval between the measurements at times tk and tk+ <dig> 

network inference fits developed models to experimental data. fitting adjusts the unknown model parameters so that an optimal value for a fitness criterion is ensured. for the inference model, this criterion can be defined as

 χ2=1nn−p∑i=1n∑k=1n1ψik <dig> 

where y^i are the measured time series, ψ ik are the statistical weights and p is the number of estimated parameters. with the proper weights ψ ik, a χ <dig> criterion value close to  <dig> indicates an acceptable fit. the estimated parameters encode information about the structure of the network.

in this paper we generalize the additive regulation model by converting differential equations into integral equations with adjustable kernel functions. these kernel functions can be selected based on prior knowledge or defined through iterative improvement in data analysis. this makes the integral model very flexible and thus capable of covering a broad range of biological systems more adequately and specifically than previous models. as the number of the unknown parameters for even medium-sized networks may exceed the number of experimentally measured points, fitting algorithms for underdetermined problems have to be applied. among different fitting strategies  <cit>  the forward selection fitting algorithm has shown reasonable performance, in particular for sparse networks, and, therefore, it has been adopted in this paper.

we tested the proposed generalization for the additive regulation model with simulated and experimental data. mathematical models have been developed for real biological systems including the glycolysis pathway in yeast  <cit>  and the mitogen-activated protein kinase  cascade  <cit> . these models are available as sbml modules  <cit>  that can be imported in jdesigner  <cit>  to simulate time series. these time series are then sampled at random time intervals and statistical noise is added to mimic experimentally observed distortions. we also used the public yeast cell cycle microarray time series datasets measured by spellman et al.  <cit>  to demonstrate practical applicability of the developed approach.

RESULTS
mathematical framework
the additive regulation model  can be easily used to derive first approximations for network structures. however, if the first-order ordinary differential equations  are not appropriate for a particular system or experimental dataset, the inference approach based on eq.  provides little possibility for easy adjustments. therefore we are looking for generalizations of the basic additive regulation model  that would allow us to systematically approximate broader range of dynamic behaviors. with this aim we integrate the ordinary differential equation  yielding:

 yi−yi=∑j=1nwij∫t0tyjdt+bi 

where t <dig> is the initial time point. the coefficient wij can be moved under the integral and converted into the function wij:

 yi=∑j=1n∫t0twijyjdx+bi 

where bi is a function generalizing the second term in the right-hand part of eq. . the fitness criterion for the integral model can be defined similar to eq.:

 χ2=1nn−p∑i=1n∑k=1n1ψik <dig> 

now the inference model is completely defined by the kernel functions wij and by the background functions bi. this model, besides higher flexibility, allows for a straightforward interpretation in terms of control theory  <cit> . the integral equation  can be considered as the reaction of a system  on the n external inputs, represented by yi, with wij being system impulse response functions.

we propose the integral model  as a generic environment for devising more specific models. instead of changing the form of the differential equation , the integral model  allows for continuous change of the various parameters of the kernel or background functions. the parameters that are known from prior knowledge can be fixed in analysis, whereas the others can be made free and estimated from experimental data. certain parameters can also be used to identify the shape of the kernel or background functions. some examples of the generic representations for the kernel functions are given in the methods section.

higher model flexibility is accompanied by larger uncertainty about the derived structures, as different models or sets of model parameters can be in accordance with experimental data. typical solutions for underdetermined problems are to collect more experimental data or to use more prior knowledge from the other sources of information. the advantage of the integral inference model is that  once we have more experimental data, we can leave more parameters free in fitting, and  once we have more prior knowledge, we can smoothly integrate it in the inference model. in contrast, the differential model  needs to be redefined and reprogrammed in both cases.

the kernel or background functions can be rather complex for adequate description of the molecular/genetic interactions. as little has been formalized in this field so far, we have to use approximations. we are looking for such representations for wij and bi that result in the inference models linear with respect to the unknown parameters. these models can be represented as linear regression models allowing us to directly compute the best-fit parameters from the data. it is also straightforward to apply non-linear models, but these models lead to non-linear regression, requiring computationally intensive, iterative approaches. therefore we generally prefer to use linear models unless we have strong evidence or prior knowledge that a model should be non-linear. three linear models – polynomial, exponential and delta-function – for wij and bi are presented in the methods section.

fitting algorithm
the network reconstruction using the differential additive model  has been described in the background section. the same approach can be applied for the developed integral model : this model is fit to experimental data and the unknown parameters are estimated by minimizing the χ <dig> fitness criterion . links created from the estimated parameters, if the corresponding parameters are significantly different from zero, form the network structure. in  <cit> , different strategies to search for optimal network structures have been reviewed and compared. the searching strategies are model independent and therefore can be applied to both models,  and , without modification. here we apply the forward selection algorithm  <cit>  as a good compromise between prediction accuracy and speed of processing. the algorithm we use is essentially equivalent to the "forw-reest-k" algorithm from  <cit> ; we have just diversified a set of stopping criteria. the implemented algorithm is outlined as follows:

 <dig>  we begin without links for the network. a default model defined by eq.  with all wij =  <dig> or by eq.  with all wij ≡  <dig> is assigned to each non-interacting node.

 <dig>  the default model is fit to the data and the χ <dig> fitness criterion is calculated for each node.

 <dig>  the node showing the largest χ <dig> value is probably regulated by one of the other nodes. a link between the node of interest and each of the other nodes that are not yet identified as regulators for the node of interest is created.

 <dig>  the resulting sub-network is fit to the experimental data. the link that ensures the best quality of fit is conserved in the system.

 <dig>  the procedure generates links until the stopping criterion is fulfilled. we have implemented the following stop-criteria:

• we stop the procedure if the node with the lowest quality of fit is already linked to all the other nodes of the network. thus, there are no more free nodes that can improve the fit for the node of interest . this indicates that either the algorithm has achieved the local minimum or the inference model is not correct. in any case we still can continue to increase the overall quality of fit by more precise fitting for some of the other nodes. however, this may lead to over-fitting for these nodes and therefore is undesirable.

• the procedure can be stopped if the overall χ <dig> quality criterion has reached a certain limit, or when the overall number of links  surpasses a user-defined value.

• finally, the user can decide when to stop iterations based on visual inspection of the residuals – the differences between the experimental and the reconstructed time series. however, this may be problematic for large networks.

we use the χ <dig> criterion as an indicator of correspondence between the inference model and experimental data because the inference model is expected to reproduce experimental data. however, if the statistical weights ψ ik in eqs.  and  are not correct, the absolute value of the χ <dig> criterion is meaningless. using the experimental errors as ψ ik can lead to overestimation of χ <dig>  because experimental data are presented in both the left- and the right-hand parts of the fitting models  or. integration averages experimental errors in the right-hand part of eq.. thus, its contribution can be ignored in the overall statistical error, and ψ ik is equal to the experimental error. the sum in the right-hand part of eq.  can also be considered as a smoothing operation. however, the error from the experimental point yi in the first term of the right-hand part of eq.  is comparable to yi in the left-hand part of eq.  and must be taken into account. in this case we define ψ ik as a product of experimental error and √ <dig>  then values for χ <dig> close to  <dig> indicate appropriate fit for both models.

if we assume that any link between any pair of nodes is possible, then the number of the unknown parameters can exceed the size of experimental datasets that are typically available. this leads to underdetermined systems and requires additional conditions to regularize the solution. in this respect the forward selection proceeds in a "natural", although not optimal, way: a new link is added only when it is necessary to increase the quality of fit.

the main problem of the algorithm is that it can easily be trapped in the local minima. if a wrong node is selected at an early iteration because it gives the best quality of fit for the selected node, the decision cannot be reconsidered at later iterations taking into account additional links created after that wrong decision. nevertheless, we found that this algorithm performs reasonably well in many cases, particularly for relatively sparse networks.

testing
we compared performances of the differential and integral inference models using various artificial systems producing simulated data and three experimental datasets from  <cit> .

as available experimental datasets are typically limited in size, we explored models where the number of free  parameters was small. thus we tested two kernels for the integral model: the zero-degree polynomial  and lb =  <dig> in eq.) and the single exponential  and lb =  <dig> in eq.). in each case we had one free parameter per link. this also equalizes the degrees of freedom in the compared differential and integral inference models. the delta-function model described in the methods section was not applied because all tested systems demonstrate behavior continuous in time.

to appreciate how our predictions are far from random, we also applied the integral model with the zero-degree polynomial kernel to infer network structures from the permuted data, i.e. when node labels are randomly assigned to generated time series.

arbitrary networks
in the first set of experiments the model used for network inference was that used for data generation.

simulation
artificial regulatory networks were generated with random and scale-free topologies. for random topology, any two nodes are connected with the probability p independent from the other connections. for scale-free topology  <cit> , the number of links at each node is approximated by a power-law distribution p ~ kγ . we used the growing network with redirection algorithm  <cit>  to generate networks with scale-free topology. the number of nodes in the generated networks was 20; the probability p for the random networks was equal to  <dig> ; and the parameter γ for the scale-free networks was set to  <dig>  for all cases. we demonstrate examples of networks undergoing random topology  and scale-free topology . a set of first-order ordinary differential equations  was used to simulate time series. the parameters wij were randomly generated from the uniform distribution in the interval . the background levels bi were set to zero and the initial states yi were set to  <dig> for all nodes.

we used the fourth-order runge-kutta formula  <cit>  to numerically solve differential equations. the solution was built on  <dig> time points uniformly spaced over the interval . the resulting time series were sampled to produce  <dig> time points to approach the quality of experimental data. we split the original 1000-point time series into  <dig> intervals of  <dig> points. at each interval the output time point was randomly selected. this led to a time series with non-homogeneous  time intervals between subsequent measurements. each of  <dig> intensity values was statistically distorted. the distorted value was generated as a gaussian random variable with the mean equal to the true value and standard deviation proportional to the true value. the coefficient of proportionality – noise-to-signal level – was set to  <dig> .

inference
as time series were simulated using a set of first-order ordinary differential equations, the corresponding inference model is either the differential model ) or the integral model ) with the zero-degree polynomial kernel  and lb =  <dig> in eq.). although the single exponential kernel may also be used in this case, it is clearly non-adequate and therefore it was not tested.

we reconstructed the networks from the generated time series using the forward selection procedure. each time the fitting procedure added a new link, we updated the number of links for true positives , false positives  and false negatives . then tp, fp and fn values were combined to estimate positive predictive value  and sensitivity value  defined as in  <cit> :

 ppv=tptp+fp;se=tptp+fn 

other possible performance measures, such as negative predictive value or specificity, are not relevant for sparse networks when the forward selection procedure is used for reconstruction. during first iterations of the fitting procedure the number of tn largely exceeds the number of tp leveling the difference between reconstruction models.

we stopped the forward selection procedure if the χ <dig> fitting criterion became smaller than  <dig>  or if a particular node became saturated. adequate fit should give χ <dig> values close to  <dig>  as experimental errors – and thus statistical weights ψ ik – in the χ <dig> criteria for eqs.  or  are directly accessible in simulations. limiting the value of the χ <dig> criterion to  <dig>  leads to substantial over-fitting. however, as we recorded the history of generated links , this allowed us to explore a broader range of model fitness values.

we averaged the dependence of ppv and se on the total number of links over  <dig> runs of the simulation procedure. a different network structure, different link parameters, different time sampling and different noise realizations were generated at each run.

artificial biological systems
we used two mathematical models for real biological systems  to test the performance of the developed inference models for more realistic systems. these models can be imported in jdesigner  <cit>  as sbml modules  <cit>  and used to simulate time series. the network structures and sbml files used for simulations are also available from our web page  <cit> . we stress that we used these modules as they were originally developed, i.e. without any modifications in the structure or in the kinetic parameters of the models. mathematical representations and kinetic parameters of the models can be viewed in jdesigner. we used jdesigner to integrate the models on  <dig> time points spaced uniformly over the interval  for yeast glycolysis and  for the mapk cascade.

two data distorting steps were performed as before: we left  <dig> time points at random time intervals, and added gaussian noise with noise-to-signal level equal to  <dig> . examples of time series used for the inference are available on our web page  <cit> .

besides comparing the differential and integral inference models, we also tested here two kernels for the integral model: the zero-degree polynomial  and lb =  <dig> in eq.) and single exponential  and lb =  <dig> in eq.).

the forward selection fitting procedure generated the dependence of the ppv, se ) and χ <dig> criteria  and) on the total number of generated links. the resulting curves were averaged over  <dig> runs of the simulation procedure. the simulation procedure generated different time sampling and different realizations of noise at each run, whereas the network structure, kinetic laws and kinetic parameters remained the same.

real data
to demonstrate applicability of the developed approach to real experimental data, we used the yeast  cell cycle microarray time series dataset  <cit> . this dataset consists of three sub-sets measured using different cells synchronization methods  <cit> : α factor-based , size-based  and cdc15-based .

as others did  <cit> , we selected a part of the yeast cell cycle pathway available from kegg  <cit>  . assuming that this pathway reflects biological reality, we can count the number of tp, fp and fn and calculate ppv and se as it is done for artificial systems.

as experimental errors and therefore the statistical weights ψ ik in eqs.  or  were not available, the absolute value of the χ <dig> fitting criterion could not be used as a stopping condition for the forward selection procedure. however, as it will be shown for artificial systems , numerous fp links are required to yield the χ <dig> criterion close to  <dig>  taking into account that fitting models are very approximate, it may not be always reasonable to require perfect fitting quality. therefore we investigated the performance  of the inference models as a function of the number of generated links.

as for the artificial systems, we compared here performances of the differential and integral inference models. in the integral model we used the same two kernels: the zero-degree polynomial  and lb =  <dig> in eq.) and single exponential  and lb =  <dig> in eq.).

we also applied dbn approach to infer network structures from the experimental datasets. we used the banjo software  <cit>  to perform bayesian inference. for analysis, we selected the alpha and elu datasets as only these two datasets were measured at equidistant time points. the latter is prerequisite for banjo. to run banjo we used the same input settings as given in  <cit> . we calculated ppv and se for the inferred networks that had the highest score in the banjo output.

independent artificial data
finally, we performed an additional comparison of the differential and integral inference models based on an independent set of artificial data described in  <cit> . briefly,  <dig> random 10-gene networks with an average in-degree per gene of  <dig> were generated. for each network, time-series data  were simulated using linear ordinary differential equations. each data point was statistically distorted with noise-to-signal ratio equal to  <dig> . in our analysis we first sampled the 1000-point time series to produce 20-point time series, which were then used for network reconstruction. as the network structures are known, we built the dependencies of ppv and se on the number of generated links for each network. the obtained dependencies were further averaged over  <dig> networks.

software
the developed algorithms for the network inference were implemented in the software package neti, freely available from our web page  <cit> .

discussion
arbitrary networks
we present the resulting ppv and se curves for random topologies  and scale-free topologies . we also show the dependence of the averaged overall fitness  on the number of links. the χ <dig> criteria were calculated from eq.  for the differential inference model and from eq.  for the integral inference model. we found that the integral model was superior to the differential model for both scale-free and random topologies, demonstrating higher predictive power and sensitivity. the networks with scale-free topology were reconstructed with greater accuracy  than those with random topology. moreover, adequate fit  corresponded to the best reconstruction  only for the scale-free networks. for random topology the best reconstruction was achieved at a χ <dig> value somewhat greater than  <dig>  in this case, the inference procedure needed more links to reproduce the simulated time series. many of those links were false positives, decreasing the ppv values. the better performance for the scale-free networks can be due to the fact that they had fewer nodes that simultaneously regulated another node. therefore, the fitting procedure has fewer chances to incorrectly select a node as a regulator. despite the correspondence between data producing models and network inference models, reconstruction was not perfect. there are various reasons for that.

although the underlying mathematical models were equivalent, the numerical implementations were different. we used an algorithm based on the fourth-order runge-kutta formula for data generation. this was more accurate than the algorithms that we used for reconstruction: simple euler formula  <cit>  in the differential model or trapezoidal rule  or) in the integral approach. as the euler formula is less numerically accurate than the trapezoidal rule, the differential model may generate more false positives.

randomized time sampling and statistical distortions further reduced the accuracy of reconstruction. however, we expect that the integral model should be more resistant to noise, as each data point is approximated by an integral ), smoothing noise contribution from all previous data points. in the differential model, the only one, previous, time point is used to fit the current one, and therefore the recovered values are subject to higher variation.

model identifiability is another problem: even if we could collect an infinite amount of experimental data and implement an "ideal" fitting procedure  <cit> , the model might not be identifiable for certain network configurations. a model might become non-identifiable if, for example, two nodes demonstrate  similar behavior, and are indistinguishable under realistic noise-to-signal levels and/or with numerical errors.

finally, we note that non-perfect performance of the fitting procedure can lead to local minima solutions.

artificial biological systems
our results demonstrate the advantage of the integral inference model for both artificial biological systems: the yeast glycolysis pathway  and the mapk cascade . however, this approach did not perform as well as in the case when a set of linear differential equations was used to generate data. this is due to inadequacy of the model used for the network inference to that used for data generation. this model inadequacy is also the reason why the inference model needs so many links to reproduce the simulated time series reasonably well . good approximation corresponds to very modest ppv, whereas the highest ppv was achieved at a much larger χ <dig> value with fewer links. our findings indicate that the links generated during early stages of network reconstruction are more accurate than those generated later. links generated later may be needed only to improve approximation.

comparing the zero-degree polynomial and single exponential kernels, neither showed clear advantage. moreover, their performance differed depending on the number of generated links. for the region with the highest ppv , the polynomial kernel seemed to be more powerful for the mapk cascade , whereas the exponential kernel gave better results for the yeast glycolysis pathway . this poses an important problem of adequate selection of the kernel function. different ways, ranging from formalizing prior knowledge to more elaborated algorithms of model fitting, can be envisaged. this, however, remains a subject of future work.

real data
from the resulting ppv and se curves presented in fig.  <dig> we conclude that the integral model with either polynomial or exponential kernels outperforms the differential model for all three experimental sub-sets. the reconstruction models showed similar performance for the alpha and elu experimental datasets, whereas for the cdc <dig> set, ppv and se values were somewhat lower. this suggests that a different, more adequate, model should be found in that case.

as for the artificial systems, there was no systematic advantage of one integral kernel versus another one. the polynomial kernel generally produced higher ppv and se values for the alpha and elu experimental datasets , and the exponential kernel was more performing for the cdc <dig> . these observations confirm a conclusion that adequate kernel selection may lead to substantial improvements in the reconstruction.

in the banjo output, the highest score networks had  <dig> links for the alpha dataset and  <dig> links for the elu dataset. we compared the dbn performance with performances shown by the differential and integral  additive models. as the forward selection algorithm built dependencies of ppv and se on the number of generated links, we selected ppv and se at the same number of links as generated by banjo . the results are collected in table  <dig>  we can conclude that the dbn performance is comparable to the performance of the differential inference model and both are outperformed by the integral inference model with either polynomial or exponential kernels. polynomial kernel is the most powerful for the alpha dataset at the given number of links. these results should be considered with caution as applying inference models is conditioned on the algorithm of reconstruction: simulated annealing in banjo and forward selection for the integral additive model. as a subject for further research, it may be promising to implement the integral additive model in the dbn framework.

*) reconstruction from  <dig> random permutations.

independent artificial data
the average dependencies of ppv and se on the number of generated links are presented in fig.  <dig>  as for our own artificial data , the integral inference model demonstrated clear advantage for the independent dataset too. we note three differences as compared to fig. 3:  the number of generated links in fig  <dig> is smaller because the networks are smaller in the independent dataset ,  the confidence intervals in fig.  <dig> are wider because the number of available networks is smaller in the independent dataset , and  as in  <cit> , we did not include self-feedback loops when computing ppv and se, although those are presented in the network structure . the latter might lead to decreased predictive power as the both, differential and integral, inference models can account for self-regulation.

to summarize the obtained results, we note that although the performance of the integral inference model differed depending on the system, it was always superior to the differential inference model. in the integral model, we used the zero-degree polynomial kernel and the single-exponential kernel with the fixed decay time. the decay time  was selected such that the kernel function decreased slowly within the measurement time range. the zero-degree polynomial kernel can also be considered as a particular case of the exponential kernel with the decay time approaching infinity or, in practical applications, just somewhat bigger than t. therefore the variation between two kernels was not expected to largely influence the performance. however, the observed difference in the inference results was sometimes significant . this indicates that refined selection of the kernel function can be an important perspective for network inference improvements.

CONCLUSIONS
in this paper we propose a generalization of the additive regulation model represented by a set of differential equations. differential equations are one of the well-advanced formalizations in biochemical systems modeling. although the model defined by eq.  is a rough approximation, it can be progressively modified to cover more realistic models that adequately account for interaction mechanisms and kinetic rates.

one way to increase flexibility of this model is to convert it into a set of integral equations with adjustable kernel functions. then, instead of changing the form of the differential equation, changing the kernel function or the various parameters of the kernel function allows the model to cover a broad range of systems. properly identifying the kernel function can make the inference model more specific for the system under investigation and ensure improved accuracy of network reconstruction. thus, our proposed approach is a generalization in a sense that it provides an easy and broadly applicable way to create specific models for particular datasets. the model can be adjusted by parametric fitting, using complimentary experimental data and by formalizing knowledge from the literature and biological databases.

the basic model that we consider in this paper is additive, i.e. the cooperative regulatory contribution of different nodes is a sum of the contributions from each node. integral representation can also cover more complicated schemes including an s-system model  <cit> , defined as a set of zero-degree ordinary differential equations with higher-order kinetic rate laws.

the integral inference model  can be incorporated into the dbn framework in the same way as it was suggested for the differential model   <cit> . in this case such equations as  or  can be used to specify conditional links between the nodes and the corresponding conditional probability distributions.

in this paper, the kernel functions  were characterized by a single unknown parameter per link. consequently the compared integral and differential inference models had the same overall number of degrees of freedom. thus, just by reshaping the inference model, while preserving the total number of free parameters, we were able to improve network reconstruction. however, the problem of network inference may often be underdetermined even for such simplified models: the number of the unknown parameters may exceed the number of experimentally measured points. although the forward selection fitting algorithm offers an effective solution to the problem, it is not the only possible approach. for example, interpolation techniques  <cit>  can be used to artificially increase the amount of experimental data, or dimensional reduction methods  <cit>  can be used to decrease the number of free parameters. as more complicated inference models, characterized by larger number of parameters, can be envisaged, the choice of the most appropriate approach for solving underdetermined problems deserves special attention in the future.

the forward selection fitting algorithm can be improved as well. for example, as considered in  <cit> , we can explore regulatory nodes by pairs, triples, etc. rather than one by one. this might avoid the local minima problem, but would definitely increase the time of processing. though adding nodes one by one is not a perfect solution, it creates the dependence of the model performance  on the number of generated links. the importance and trustworthiness of the generated links are functions of iteration of the forward selection procedure that generated these links. the links generated during early stages of reconstruction should gain more attention in the follow up analysis. this approach releases importance of the stopping criteria; which, for real experimental data, are often difficult to formulate.

networks derived from limited data should only be considered as rough approximations for real network structures. experiments should be designed to yield datasets to improve the reconstruction. therefore, reverse engineering of the regulatory networks should be defined as an iterative process where the steps of network inference and experimental design are performed in turn. thus, the initially derived network can be used to optimally design experiments. this would allow improved identification of the network structure with less experimental effort and expense. proper formalization of such iterative algorithm is a subject of further research.

