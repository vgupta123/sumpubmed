BACKGROUND
with the emergence of the first experimentally determined protein structures, the investigation of the conformations of their amino acid side chains began. it quickly became apparent that the χ  dihedral angles - the main degrees of freedom in side chains - are not distributed freely, but tend to cluster around certain positions  <cit> . this behavior was already well known for dihedral bond angles in small organic molecules  <cit> . as more protein structures were solved to a high resolution, an increasingly accurate analysis of the adopted conformations became possible.

today, the most common way to describe the conformational space of side chains is through so-called rotamer libraries: collections of representative side chain conformations, called rotamers  <cit> . these libraries are usually compiled from experimentally determined, high resolution protein structures by clustering the side chain conformations. clusters of side chain angles thus obtained can then for example be represented by gaussian distributions  <cit> . traditionally, a rotamer in a library corresponds to the mean conformation of such a cluster and may be interpreted as a local energy minimum  <cit> . in recent studies, rotamer libraries with many thousands of rotamers were used  <cit> . such libraries are built to cover the conformational space with high resolution.

the accurate description of side chain conformational space is an important ingredient of the solution to many biomolecular problems, such as protein design, docking and high resolution protein structure prediction. over the past decades rotamer libraries have been successfully applied in all of these contexts. arguably, the most well studied field is the prediction of side chain conformations for a fixed protein backbone; there is a manifold of programs in the public domain devoted to this problem  <cit> .

rotamer libraries are usually applied as discrete collections of side chain conformations. discretizing conformational space is a popular approximation to solve problems that are computationally expensive otherwise. for example, when assigning side chains in the densely packed protein core, discretizing the search space leads to exhaustive yet fast search strategies  which can quickly find a global minimum solution  <cit> . however, in recent studies it was shown that a markov chain monte carlo  sampling scheme combined with a detailed rotamer library yields equally good or better results, which suggests that the combinatorial problem often poses no significant obstacle to finding a global minimum solution  <cit> .

the discretization in rotamer libraries inherently leads to edge effects  <cit> . in docking problems for example, small differences in the side chain conformation may result in large differences in energy. rotamers are often used as stiff building blocks; not considering the conformations in between rotamers may skip energetically favorable configurations  <cit> . there are three common heuristic strategies to tackle these issues. the first, which is most commonly used, is tweaking the energy functions; for example, by reducing the influence of mild steric clashes  <cit> . the second is to increase the number of rotamers in the library in order to improve its resolution  <cit> . finally, one can combine rotamer based sampling with some form of continuous optimization  <cit> . another problem associated with rotamer libraries is the occurrence of so-called non-rotameric states: side chain conformations that cannot be assigned to any of the standard gauche+, gauche- or trans states  <cit> . such conformations are typically missing in rotamer libraries and difficult to fill in correctly  <cit> .

here we present basilisk, a dynamic bayesian network  <cit>  that formulates a probabilistic model of the conformational space of amino acid side chains. the model is generative: it allows sampling of plausible side chain conformations. basilisk loosely stands for bayesian network model of side chain conformations estimated by maximum likelihood. basilisk represents all relevant variables in continuous space and thus avoids the problems that are due to the discretization used in rotamer libraries. furthermore, basilisk incorporates the ø  and ψ  angles. this makes it possible to condition the sampling upon the residue's backbone conformation, which is known to exert a strong influence on the side chain's conformation  <cit> . basilisk represents all amino acids in a single probabilistic model, which is an entirely novel way of attacking this problem. such an approach corresponds to a powerful machine learning technique called multitask or transfer learning, which often leads to better models with fewer parameters  <cit> .

we first describe the basilisk model, then proceed to evaluate its performance, and conclude with illustrating some potential applications.

RESULTS
parameterization
for our purposes, bond angles and bond lengths in amino acid side chains can be considered as fixed to their ideal values, as they show only very small variations  <cit> . this leaves the rotations around the bonds - the χ dihedral angles - as the main degrees of freedom. accordingly, the sequence of χ angles is a good parameterization of the conformation of a given side chain. the same parameterization of the conformational space is also used in most popular rotamer libraries  <cit> . the number of angles necessary to describe a side chain conformation varies between zero and four for the  <dig> different standard amino acid types. figure  <dig> illustrates the dihedral angles for glutamate.

in previous studies, it has been shown that the side chain conformation correlates highly with the conformation of the backbone  <cit> . for the backbone, the two main degrees of freedom are the ϕ and ψ dihedral angles, which when plotted against each other result in the celebrated ramachandran plot  <cit> . we incorporate ϕ and ψ angles in basilisk to be able to condition the sampling on the backbone conformation.

basilisk: a generative model of side chain conformations
bayesian networks are graphical models that determine the possible factorizations of the joint probability distribution of a set of random variables  <cit> . a bayesian network is a graph in which the nodes represent the random variables, and the edges encode their conditional independencies. the graph is directed and acyclic, and is often chosen based on prior, expert knowledge. if sequences of variables are modeled, the models are called dynamic bayesian networks   <cit> . here, dynamic originally referred to time sequences, such as speech signals, but arbitrary sequences can be modeled. each position in the sequence is called a slice. the sequences represented by a dbn are allowed to have different lengths; a property which we use to our advantage, as explained below.

basilisk was implemented as a dbn, and its parameters were estimated by a maximum likelihood method using a data set derived from more than  <dig> crystal structures . the model is shown in figure  <dig> 

we briefly describe the most important features of the model. for each slice, an input node  indicates which angle and amino acid type are modeled. for example,  <dig> indicates the χ <dig> angle of aspartate,  <dig> indicates the χ <dig> angle of aspartate, and so forth. we recently used a similar approach to formulate a probabilistic model of rna structure  <cit> .

the natural manifold of all the dihedral angles combined is the hypertorus: a torus with dimension three or higher. basilisk constructs a probability distribution on this manifold in the following way: the model has a single output node per slice, in the form of a von mises distribution  <cit> , which can be considered the circular equivalent of a gaussian distribution. the von mises distribution takes the circular nature of the data into account: a dihedral angle in [- π, π[ is naturally represented as a point on the circle. the von mises distribution belongs to the realm of directional statistics  <cit> : the statistics of angles, directions and orientations. we previously developed probabilistic models of rna and protein structure based on the combination of dbns and directional statistics  <cit> . the von mises distribution was also used previously in a seminal study on probabilistic models of the protein backbone in terms of the ϕ and ψ angles  <cit> , and in a preliminary study on clustering of side chainrotamers  <cit> .

the problem of representing amino acid types that differ in the number of χ angles within one model is elegantly solved by using a dbn with a variable number of slices. there are two slices for the ϕ and ψ angles, followed by a sequence of slices that represent the χ angles. for example, to model glutamine, which has three χ angles in its side chain, one slice is added to the dbn that is shown in figure  <dig> 

the dependencies between the input nodes  and the output nodes  are mediated by a sequence of interconnected, discrete hidden nodes. the values of these nodes are never observed: their technical purpose is to model the dependencies between the amino acid type and the χ angles on the one hand, and the sequential dependencies between the χ angles on the other hand. the hidden nodes are so-called nuisance variables, that are integrated away in parameter estimation, sampling and inference. it should be noted that the hidden nodes thus introduce dependencies between all angles, and not just between two consecutive angles - a common misconception.

our aim was to describe all side chain and backbone angles for all different amino acid types in a single probabilistic model. this approach is known as multitask or transfer learning in the field of machine learning  <cit>  and has several advantages. as the same set of distributions is used to model all amino acids , it leads to a lower amount of free parameters. moreover, it makes "knowledge transfer" possible between amino acids with similar conformational properties during training  <cit> . finally, for rotamer libraries, one needs to determine the optimal number of rotamers for each amino acid type separately, while in our approach, only the size of the hidden node needs to be determined. this can be done using an established statistical procedure for model selection .

several other network architectures were discarded during model selection as they could not adequately capture the joint distributions, which illustrates the importance of the network's architecture. neither regular hidden markov models, nor various mixture models produced satisfying results . a similar observation was made for the probabilistic model of rna structure mentioned previously  <cit> .

it is important to note that the model as depicted in figure  <dig> represents a single amino acid. when assigning side chains to an entire protein backbone, the model is simply applied to each position in the chain. sampling conformations from basilisk is fast: generating  <dig>  arginine side chain conformations takes about two seconds on an average desktop computer .

probability distributions
the joint probability distribution encoded by the bayesian network is  

where  is the sequence of χ angles,  is the angle index information which includes the amino acid type, ϕ and ψ are the backbone angles, and  is the sequence of hidden node values.

for most purposes, the conditional and marginal distributions are of interest. basilisk allows backbone dependent sampling of the χ angles by conditioning on the ϕ and ψ angles. the conditional probability distribution for this case is given by:  

where the sums run over all possible hidden node sequences .

the marginal, conditional probability distribution for the backbone independent case is given by:  

where the sum again runs over all possible hidden node sequences . the backbone angles are thus simply disregarded in this calculation.

the marginal, conditional probabilities p for a single angle are represented by von mises distributions . the parameters of the von mises distribution are specified by the value of the hidden node, h.

as basilisk is a simple extension of a hidden markov model, all relevant joint and marginal probabilities can be calculated in a straightforward manner using the forward algorithm  <cit> .

initial analysis
for generative probabilistic models, an obvious first quality check is visual inspection. accordingly, we start by investigating whether basilisk captures the angular preferences found in the training data, before performing a more rigorous and in-depth analysis.

for these first tests, we generated over  <dig>  samples with the same amino acid composition as the training set. figure  <dig> compares the marginal angular distributions of the training set with those of the basilisk samples for arginine and lysine. we show plots for arginine and lysine because they are the only amino acids with four χ angles; they were most difficult to capture accurately with alternative models . a comparison of all remaining relevant amino acids is available as additional material .

as a second test, we inspected pairwise histograms of the χ <dig> and χ <dig> angles for all relevant amino acids. these plots provide an indication of whether the model captures the correlation between two angles correctly. again we compare samples from basilisk model with the training data.

the results of the visual inspections provide a strong indication that the model behaves as desired. we now move on to a more qualitative, in-depth analysis.

basilisk concurs with a standard rotamer library
in the following tests, we compare basilisk to several rotamer libraries, as these are the method of choice to explore the conformational space of amino acid side chains for many purposes.

we use the dunbrack backbone independent library  <cit>   as a representative rotamer library, as it is widely used and based on rigorous statistical analysis of high quality protein structures. in the construction of the dunbrack library, it was assumed that the distribution of each angle in a rotamer follows a gaussian distribution. accordingly, rotamers in this library are reported as a sequence of gaussian distributions - one for each χ angle. this allows us to evaluate the probability density value for any given side chain conformation according to the dunbrack library.

for all calculations we used the basilisk model with the backbone angles marked as unobserved - which results in a backbone independent likelihood - for fair comparison with the backbone independent dunbrack rotamer library.

as a first test, we determine whether the dunbrack rotamer library and basilisk report similar probabilities for the same conformations. we calculated the log-likelihood of the side chain conformations according to the dunbrack backbone independent rotamer library and according to basilisk for all side chains in the test set . the results show that the two methods indeed correlate very well . figure  <dig> shows a scatter-plot of the log-likelihood values for all rotamer conformations in the dunbrack library according to the library itself, and according to basilisk. again we find a very good correlation . outliers, especially in the low probability region, are limited to very rare rotamer conformations with little to no observations according to the dunbrack library.

in the following paragraphs we take a more detailed look at the probability distributions encoded in the basilisk model, and compare with several standard rotamer libraries. for this analysis we again use the dunbrack library, but also include two additional backbone independent libraries  <cit> .

the kullback-leibler  divergence is a standard measure of the similarity between two probability distributions  <cit> . here, the kl divergence is used to compare the quality of the rotamer libraries versus basilisk. we compare basilisk and the rotamer libraries with the experimental data in the test, which is here used as a reference or truth model. we then calculate the relative kl divergence between basilisk and each library . table  <dig> shows the results for each amino acid. positive numbers indicate that basilisk models the conformations in the test set more accurately than the method compared to, while negative numbers indicate that basilisk is less accurate.

columns 2-4: the differences in the kl divergences between basilisk without backbone information and a set of standard rotamer libraries. last column: the differences in the kl divergences between backbone independent basilisk and basilisk including backbone information. in both cases, positive numbers indicate that backbone independent basilisk captures the observed preferences in the test set more accurately.

overall, basilisk captures the conformational preferences of amino acid side chains more accurately than any of the rotamer libraries, with few exceptions. for example, the dunbrack library performs better for tryptophan. we speculate this is due to the relatively low abundance of tryptophan in the training data , and the fact that we are training an all amino acid model. an amino acid with few observed data points will have a smaller impact on the estimated parameters than an amino acid that was presented more often during training. the relatively low performance of the lovell library can be explained by the small number of rotamers in the library. especially for long side chains such as glutamine, lysine or arginine, too many rotamers appear to be missing.

note that only libraries reporting both mean and variance for each χ angle are suitable for this analysis. many rotamer libraries are mere discrete sets of possible conformations  <cit> : they cannot be evaluated in the same, rigorous way.

basilisk captures the backbone's influence
it is well known that there is a strong correlation between backbone and side chain conformations  <cit> . this backbone dependency is captured by the basilisk model by incorporating the backbone's two main degrees of freedom: the ϕ and ψ dihedral angles.

to the best of our knowledge, basilisk is the first model that captures this correlation in continuous space; that is, without resorting to the usual discretizations of the conformational space. comparison with other models is therefore difficult. notably, a comparison with backbone dependent rotamer libraries based on the kl divergence is not possible due to their lack of an expression for the joint probability of the backbone and the side chain angles. however, we do present two decisive tests. first, we resort to visual inspection, followed by a quantitative evaluation based on the kl-divergence between backbone dependent and independent basilisk. in the next section, we evaluate the influence of the backbone information on side chain sampling for a fixed backbone.

for a quantitative evaluation, we turn again to the kl-divergence; this time, to compare basilisk with and without backbone dependency. as in the previous test, where basilisk was compared to different rotamer libraries, this test determines which model is closer to the theoretical truth model as embodied by the test set . table  <dig>  shows the differences between the kl divergences for all relevant amino acids. the negative numbers indicate that the backbone dependent model resembles the experimental data most. this indicates that basilisk indeed captures the influence of the backbone, and that incorporating backbone information improves the accuracy for all amino acids. this conclusion is also supported by the results described in the next section.

application: side chain sampling for a fixed backbone
in the previous sections, we evaluated the probability distributions encoded in basilisk. we now proceed to evaluate the applicability of the model. as a proof of concept we implemented a side chain prediction algorithm that assigns side chains to a fixed protein backbone. xiang and honig  <cit>  showed that given a large rotamer library, an mcmc approach leads to good accuracy in predicting buried side chain conformations. following their study, we combine side chain sampling from basilisk with an mcmc method and an unmodified lennard-jones potential  <cit> . the main purpose of the potential is to avoid steric clashes between the side chains. the parameters for the potential were derived from the opls force field as implemented in tinker  <cit> .

for the evaluation, we considered a χ angle within ± 20° of its value in the crystal structure as correct  <cit> . we only included buried side chains in the protein core in the evaluation, because exposed side chains often have few steric restraints and we did not use any energy term that accounts for the solvent interaction. however, all side chains were included in the mcmc procedure and none were fixed, in order not to bias the simulation towards the native state. the test set contained  <dig> single chain crystal structures that were used to evaluate side chain prediction algorithms in other studies  <cit> .

to avoid getting trapped in local minima, we resampled three random residues at a time  <cit> . this effectively enables side chains to swap their positions. after a fixed set of mcmc steps, the lowest energy structure was selected as the final prediction. for details on the energies and the sampling see sampling strategy and energies.

basilisk is a true probabilistic model: it can be used as a proposal distribution to implement mcmc methods that respect detailed balance, since its exact contribution can be taken into account. the first test uses a lennard-jones potential as the only energy component, and brings in basilisk solely as a proposal function. we use the basilisk model to propose new side chain conformations, which are subsequently accepted or rejected based on their energy . table 2b shows that already with this very simple approach, we reach a quite reasonable performance: more than 87% of the χ <dig> angles were correctly predicted .

the table shows the percentage of correctly predicted χ angles for the different mcmc experiments. a number of residues , number of buried residues , b using the lennard-jones energy and basilisk as a proposal distribution, c using basilisk without backbone information, d using basilisk with backbone information , e using irecs or scwrl with default parameters, f percentage of correctly predicted χ <dig> angles given a correctly predicted χ <dig> angle.

in a second test, we use the basilisk likelihood as a pseudo-energy component  <cit> , combined with the lennard-jones potential. table 2c shows that the prediction quality increases . incorporating backbone information in basilisk  increases the performance compared to the backbone independent  and the lennard-jones only case . it should be noted that none of these tests include energies that evaluate key features such as hydrogen bonds, salt-bridges or electrostatic interactions.

for comparison, table 2e also reports the prediction accuracy of irecs  <cit>  and scwrl  <dig>  <cit> , which are two leading programs in the field. in both cases, the results are on a par with basilisk. scwrl  <dig> and irecs are specialized programs optimized for both prediction accuracy and speed: they use fine tuned and optimized force fields combined with backbone dependent rotamer libraries. the comparison serves to illustrate the quality of basilisk as a probabilistic model; with respect to computational performance, scwrl  <dig> and irecs  are clearly superior to the unoptimized application of basilisk .

CONCLUSIONS
in this paper, we introduce a generative, probabilistic model of the conformational space of side chains that allows sampling of realistic, native-like side chain angles in continuous space. basilisk incorporates a continuous backbone dependency, which to the best of our knowledge is entirely novel. another unique feature is that basilisk represents all relevant natural amino acids within one model. this powerful approach is known as multitask or transfer learning in the field of machine learning, and comes with several advantages.

in the first tests we showed that basilisk is able to accurately capture the angular preferences found in proteins. using the kl divergence, we confirmed that the model compares favorably with several standard rotamer libraries.

basilisk also captures the effect of the backbone conformation on the side chain, and samples realistic angular distributions for various areas of the ramachandran plot. again using the kl divergence, we confirmed that including backbone information leads to more accurate results.

as a proof of concept, we implemented a simple side chain prediction method that assigns side chains to a fixed protein backbone, using an mcmc sampling scheme and an unmodified lennard-jones potential as energy function. the results show the applicability of combining a continuous description of conformational space with a detailed energy function. adding basilisk as an explicit pseudo-energy term improves the prediction results. best results are obtained when the backbone conformation is taken into account.

specialized side chain prediction programs combine highly tuned energy functions with an efficient exploitation of the discrete nature of rotamers. this makes them very fast, yet accurate. basilisk as such does not compete with those programs, but provides a solution where a detailed, continuous description of conformational space is required. the possibility to combine an unmodified, standard force field with basilisk opens great possibilities for applications such as docking, structure prediction or protein design. for example, the calculation of side chain entropies is important for tasks such as protein quality assessment or protein design  <cit> . basilisk can facilitate these calculations - which are now often performed with discrete rotamer libraries - in continuous space.

basilisk, when combined with our previously described probabilistic model of the protein backbone , can be used to sample protein structures in continuous space and in full atomic detail. an obvious potential application is to sample protein conformations by combining torusdbn and basilisk with a physical force field, with applications in protein structure prediction, simulation and design.

basilisk illustrates the enormous potential and increasing importance of probabilistic models and probabilistic machine learning methods in structural bioinformatics  <cit> . we believe that basilisk is an excellent solution for problems that require going beyond discrete representations of amino acid side chains in protein structure simulation, prediction and design.

