BACKGROUND
generally, protein structure prediction consists of a conformational sampling step followed by a scoring step in which the best model is selected from the ensemble. the relative importance of the two steps depends on the modelling difficulty and the details of the specific method. in the conformational sampling step of ab initio structure prediction methods it is common practice to generate a vast number of models and to subsequently select the best candidates based on an energy function  <cit> . until several years ago, in comparative modelling usually only a few, if any, alternative models have been generated and the quality of the prediction was rarely better than the best template. however, in recent years there has been a clear trend in the field to generate a variety of models based on different template structures  and/or alternative alignments and to select the best candidate based on the estimated quality of the resulting models  <cit> . in order to cope with the uncertainties in modelling, early decision making, such as choosing the best template or alignment, can be postponed and performed at a later stage in the modelling pipeline based on the quality of the resulting structural model. for this last step, scoring functions for selecting the highest quality model among alternatives are of crucial importance.

these scoring functions fall into one of two categories, namely consensus or clustering methods which rely on the analysis of the structural density in the ensemble of models and approaches being able to estimate the quality of a single model without relying on consensus information. the basic idea of consensus-based methods is that conformations predicted more frequently are more likely to be correct than structural patterns occurring in only a few models  <cit> . the second category includes methods taking into account evolutionary information  <cit> , stereochemical plausibility of the models  <cit>  and the environment compatibility of their residues  <cit>  as well as energy-based methods which include physics-based energy functions  <cit>  and knowledge-based statistical potentials  <cit> . composite scoring functions analysing multiple structural features have been introduced and shown to perform better than any single term  <cit> .

quality estimation can be performed on different dimensions: relative vs. absolute and global vs. local. the estimation of the relative quality of a model compared to a set of alternatives is, as mentioned above, a fundamental step in protein structure prediction and also in optimisation techniques . on the other hand, the estimation of the absolute quality of a model is of tremendous importance for the biological community since it is the quality of the model which dictates its biological applicability   <cit> . traditionally, scoring functions have been assessed with regard to their ability to rank models by quality, while the estimation of absolute values of model quality has been only marginally addressed in the literature. besides the global quality, local error estimation on a per residue basis has become an active field of research  <cit> . although the accuracy of local predictions is limited, these methods may be very valuable for biologists by helping them to discriminate between reliable and unreliable regions in the model.

model quality assessment programs have been evaluated for the first time in a community-wide experiment in  <dig> as part of critical assessment of fully automated structure prediction   <cit>  and most recently at casp <dig>  <cit> . the assessment of the predictions submitted to the quality assessment category of casp <dig> clearly indicates that consensus based methods such as pcons  <cit>  outperform current scoring functions operating on single models. on the other hand, methods relying solely on structural density information have inherent limitations: first, they are not able to provide an estimate of the absolute quality of a single model or to rank just a small set of models. second, these methods tend to fail when the highest quality candidates are far away from the dominant structural cluster of the ensemble. outstanding predictions which are far removed from the bulk of the remaining models are hardly recognised  <cit> , and, in the case of hard free modelling targets, the ensemble does often not contain any meaningful density information at all. the approach pursued by lee and co-workers  <cit>  for the quality assessment category of casp <dig> was also quite successful. this group produced quite accurate models for the template-based modelling category  <cit>  and defined the quality of all other models as relative distance to their own models.

based on these findings, we present in this paper a new approach to model quality estimation which combines different aspects of the approaches described above while simultaneously minimising their weaknesses. we use an optimised version of our recently published composite scoring function qmean  <cit>  in order to define an ensemble of reference models which is used to calculate the structural consensus score. this method, called qmeanclust, combines a scoring function able to assess single models and perform an initial ranking with the strengths of using structural density information. due to the pre-selection step, qmeanclust represents a compromise between the rigorous clustering strategy of pcons  and the strategy to define quality by comparison to a "best reference model". based on the model ranking of qmeanclust, it is investigated whether using the ensemble of models for a given target sequence to retrieve target-specific statistical potentials  <cit>  can lead to a further performance improvement .

the paper is structured as follows: first we describe the optimised qmean scoring function. we demonstrate that the inclusion of an all-atom interaction term in addition to the residue-level term improves the performance both with respect to correlation between predicted model score and degree of nativeness and in the task of selecting the best model. then we compare different strategies to combine qmean with structural density information resulting in two versions of qmeanclust as well as in the selfqmean scoring function. we show that qmeanclust is indeed able to counteract the inherent limitations of purely consensus-based methods. all three scoring functions are compared to state-of-the-art methods on the basis of two comprehensive test sets. finally, local versions of the three scoring functions for the per-residues error estimation are presented and the performance is compared to a recently published method.

RESULTS
qmean: composite scoring functions for the evaluation of single models
we recently described the qmean composite scoring function consisting of a linear combination of five terms including  <dig> statistical potentials  <cit> . the combination of broadly orthogonal information has been shown to improve model selection. the qmean composite scoring function includes a torsion angle potential over three consecutive amino acids for the analysis of the local geometry of a model, a solvation potential describing the burial status of the residues and a distance-dependent interaction potentials based on cβ atoms for the assessment long-range interactions. two terms describing the agreement of predicted and calculated secondary structure and solvent accessibility are also included. in this work, the qmean composite scoring function has been extended by an all-atom distance-dependent interaction potential term in order to capture more structural detail. a short description of all qmean versions and the terms used in their calculation can be found in table  <dig> 

the first section of table  <dig> shows the target-averaged performance of different qmean versions on the casp <dig> dataset consisting of all server models submitted for  <dig> targets. the other sections show the performance of various qmeanclust and selfqmean implementations which, in contrast to qmean, take into account consensus information. the weighting factors for the different composite scoring functions are optimised on the casp <dig> training set.

average correlation coefficient and total maximum gdt_ts score of the selected models of different qmean versions obtained on the test set containing all casp <dig> server models. a description of all qmean versions is given in table  <dig>  for the qmeanclust consensus score, a multitude of strategies for pre-selecting reference models based on qmean score is investigated. the models of the reference set are defined based on a certain z-score cut-off, by using only a percentage of top scoring models or by including only models being close to the highest scoring model. the different cut-offs used for template-based modelling targets  of free modelling targets  are indicated. underlined values are used in table  <dig> for comparison to other methods. the selfqmean scoring function is based on ensemble-specific statistical potentials.

for each qmean version, the performance of an alternative implementation which penalises incomplete models by multiplying the score by the fraction of modelled residues is given as well. taking into account the coverage of the models with respect to the target sequence considerably improves the correlation to the gdt_ts score  <cit>  by penalising incomplete models with otherwise good stereochemistry. this performance increase in estimating the relative model quality can be attributed to the fact that the gdt_ts score, traditionally used in the assessment of casp, is by definition dependent on model completeness. table  <dig> underlines that a large increase in performance can be obtained by including predicted secondary structure and solvent accessibility agreement terms as shown previously . the integration of an all-atom term  further improves the correlation between predicted quality of the model and its similarity to the native structure. more importantly, the all-atom term increases the ability of the scoring function to select good models. this is reflected by the significantly higher  total gdt_ts score of the best models selected by qmean <dig> of  <dig>  compared to  <dig>  for qmean <dig> 

for comparison, the performance of the top methods of the quality assessment category of casp <dig> are shown in table  <dig> together with the maximum gdt_ts of the top performing server, i.e. a scoring function that always selects the models of the zhang server  <cit> . for a description of the other methods visit the casp <dig> website . the gdt_ts values as well as the data of the other methods are based on the quality assessment data of casp <dig> and the data of tasser-qa have been kindly provided by the authors  <cit> .

average correlation coefficient and total maximum gdt_ts score of the optimised qmean, qmeanclust and selfqmean versions and the top performing methods of casp <dig>  only scoring functions with predictions for all  <dig> targets are shown.

a statistical analysis of the above results is given in figure  <dig>  from the scoring functions being able to return a score for a single model, qmean <dig> shows the best correlation coefficient  over all methods participating in casp <dig> . the difference is statistically significant at the 95% confidence level based on a paired t-test. qmean also shows the best performance in selection of good models for each target as reflected by the highest total gdt_ts values followed by abipro and circle-qa, but in this case the difference is statistically not significant. scoring functions which take into account structural density information such as selfqmean and qmeanclust produce considerable higher correlation coefficients and total gdt_ts scores .

a further improvement may be achieved by using more specialised qmean versions for different modelling situations, such as qmean with all-atom term for template based targets and without for free modelling targets. first results suggest that the overall effect is only marginal and that the qmean version including the all-atom term leads to a better performance over the whole difficulty range. using one scoring function for all modelling situations is not ideal as highlighted recently by kihara co-workers  <cit> . they showed that for a threading scoring function consisting of two terms, different weighting factor combinations are optimal for different protein families. therefore, training weighting factors specifically for proteins of similar size and amino acid or secondary structure composition may improve the performance, especially in the prediction of absolute values of model quality  <cit> . optimising weighting factors in composite scoring functions based on a linear combination of terms is complicated by the fact that the different terms are dependent on the protein size which influences to ability of the combined scoring function to predict the absolute quality.

qmeanclust: including structural density of the model ensemble
in this section we describe a new method, termed qmeanclust, which combines the qmean scoring function with structural density information derived from the ensemble of models. in the straightforward implementation of methods based on structural density information, the score for a given model is calculated as its average  distance to all other models in the ensemble. different similarity measures are used for building the distance matrix: e.g. maxsub  <cit>  in 3djury  <cit> , lgscore  <cit>  in pcons  <cit>  and tmscore  <cit>  in the consensus method described in modfold  <cit> . in this work, the gdt_ts score  <cit> , a well established similarity measure in the casp assessment, is used. in all the above mentioned implementations, the single models are equally weighted in the calculation of the final score, no matter how good or bad a model is. in 3djury only model pairs above a certain distance cut-off are considered in the calculation.

clustering methods tend to fail when the top models are far away from the most prominent structural cluster or when there is no structural redundancy present in the ensemble that can be captured. especially for difficult, template-free modelling targets the best models are usually not the most frequent conformations in the ensemble . in order to cope with the limitations of current clustering approaches, we investigated two strategies for the combination of the qmean composite scoring function and structural density information from the ensemble. in the first approach, qmean is used to select a subset of higher quality models against which the subsequent distance calculations are performed. the final score for a given model is defined as the median distance of this model to all models in the subset . an implementation based on the mean instead of the median gdt_ts is also investigated. in the second approach, the models are weighted according to their qmean score ; for deriving the distance matrix, the distance of a given model to more reliable models  is weighted stronger, which in turn reduced the influence of random models on the calculation.

different strategies and cut-offs for model selection have been investigated. a benchmark of several alternative implementations on the casp <dig> test set can be found in table  <dig>  in comparison to the performance of qmean, considerably higher correlation coefficients are obtained for all qmeanclust versions .

if the whole ensemble of models is used in the derivation of the distance matrix , the weighted mean performs comparable or better than taking the mean or median both in terms of correlation between predicted and observed model quality and the ability to identify good models. if only a subset of high-quality models is used in the calculation of the distance matrix, a score based on the distance median produced the best results and is used in the final version. three different approaches have been investigated in order to select a subset of models based on qmean:  selection based on the z-scores which are calculated by subtracting from each model the mean qmean score of the ensemble and dividing it by its standard deviation,  selection of a certain percentage of top ranking models as well as  a strategy in which only models with a similar qmean score as the top ranked model are used in order to cope with qualitatively outstanding predictions.

a combination of both pre-selection of models based on qmean and weighting the distances according to qmean in the subsequent clustering calculations is not useful as shown for the selection based on z-scores. z-scores have been calculated based on the model qmean score and only models above a given z-score threshold are used for the clustering process. table  <dig> shows that, with increasing z-score threshold , the ability of the weighted mean strategy to select good models gradually decreases, whereas the performance of the median strategy increases . using the median rather than the mean reduces the influence of outliers in smaller data sets. for the other two selection strategies, only median is shown, i.e. the final qmeanclust score of a model is the median distance of this model to all other models in the subset selected by the given strategy.

model selection based on z-scores has several disadvantages: the number of models selected using a given z-score cut-off is highly dependent on the modelling difficulty. for an easy template based modelling target, the models in the ensemble tend to be very similar and there are no models with high z-scores . on the other hand, for free modelling targets there are sometimes outstanding predictions compared to the bulk of more or less random models. capturing these predictions in the selection step is the only way to circumvent the inherent limitations of consensus based methods. furthermore, different selection cut-offs may be needed for template based modelling targets  and free modelling targets  since the former contain much more structural redundancy which can be captured by clustering methods and more targets can potentially be used in the calculation of the distance matrix.

in the fourth section of table  <dig>  the results of a selection strategy based on a fixed percentage of top scoring models are shown. a total gdt_ts of  <dig>  is achieved by using the top 20% models for tbm targets and top 10% for fm targets. discrimination between tbm and fm targets is done based on mean qmean score by assigning targets with a model averaged qmean score above  <dig>  to the template-based modelling category. this cut-off has been derived empirically by comparing the score distributions of fm and tbm targets . the better performance of the approach, which uses a more tolerant model selection for tbm targets, may be attributed to the fact that the model ensemble of tbm targets contains more useful consensus information. in the case of fm targets, qmean is often able to identify some of the better models which are subsequently used in the consensus calculation.

alternatively, a simple selection strategy aiming at capturing outstanding predictions has been investigated . only models with a similar qmean score compared to the highest scoring model are considered for the distance calculation. a selection of models within  <dig>  qmean units from the maximum for tbm targets and  <dig>  units for fm targets results in a total gdt_ts of  <dig> . since the tbm models are structurally more homogenous, more models are selected in tbm targets than fm targets using these thresholds. for the subsequent comparison to other methods, the best versions of qmean, qmeanclust and selfqmean  are used. the corresponding values are underlined in table  <dig> 

at casp <dig>  none of the quality assessment programs  was able to select better models out of the ensemble of server models than the zhang server  <cit>  submitted for each target  <cit> . the best qmeanclust implementation shows a better model selection performance than tasser-qa  <cit>  and a naive scoring function that simply takes the zhang server models . the difference is statistically significant at the 95% confidence level based on a paired t-test. figure  <dig> underlines that qmeanclust and the single model scoring function qmean show a statistically better  selection performance than pcons, the best performing clustering based method at casp <dig>  in terms of correlation between predicted model quality and degree of nativeness, qmeanclust has significantly higher pearson's  and spearman's  correlation coefficients than tasser-qa and any other tested scoring function.

although the ability of qmeanclust to pick the best model is better than a naive predictor that simply picks zhang models, it can still potentially be improved. the weighting factors for the qmean scoring function used for model prioritisation has been optimised for regression and not for selecting the best model. qui et al.  <cit>  recently described an approach in which a composite scoring function has been optimised for model selection using support vector machines. most current scoring functions ignore a trivial parameter for the estimation of model quality: the presence and closeness of a structural template which can be used to build the model  <cit> . zhou and skolnick  <cit>  recently described a scoring function in which the extent a model is covered by fragments of templates identified by threading is used as quality measure. qmean could benefit of such a term representing orthogonal information to the present implementation.

selfqmean: use of statistical potential terms derived from model ensemble
the idea of using the ensemble of models for a given target as basis to derive target-specific statistical potential terms has previously been investigated  <cit> . in their work, wang et al. generated a decoy-dependent implementation of the rapdf interaction potential  <cit>  by deriving the distance frequencies from the models in the decoy set and weighting each count according to the rapdf score of the model. this decoy-dependent statistical potential performed better that the original rapdf scoring function but not as good as a simple density score based on the average rmsd of a model to all others. here we followed a similar strategy with the difference that a combined scoring function using multiple statistical potentials is used and that an improved density scoring function  is used for weighting the models contributing to the selfqmean score . as can be seen from table  <dig>  while selfqmean generates considerably higher correlation coefficients than qmean, the ability to select good models does not improve. the decoy-dependent scoring function does not perform better than qmeanclust, which is based on structural density information alone. building a composite scoring function based on target-specific potentials is problematic since the weighting factors are highly dependent on the modelling difficulty: ensembles containing lots of very similar models, e.g. in high accuracy template based models, result in much lower absolute energies in the statistical potential terms than sets of diverse models. we tried to circumvent the problem by just adding the energy z-scores of each term. these results suggest that the level of detail captured by target-specific scoring functions decreases compared to the direct derivation of structural differences based on consensus methods. the structural density information seems to be captured more precisely when directly derived from the distance matrices without doing the detour using model ensemble specific statistical potentials. these methods are also not able to overcome the limitations of purely consensus based methods being determined by the most dominated structural cluster.

comparison of qmeanclust with 3djury-like consensus method
in this section we address the question whether qmeanclust and its strategy of selecting a subset of high quality models for the calculation of the structural density is really superior to pure consensus methods and whether the new method is able to identify good models even if they are far away from the most dominant structural cluster. for the comparison we use a 3d-jury like  <cit>  implementation based on gdt_ts . as can be seen from table  <dig>  this approach achieves a total gdt_ts of  <dig>  compared to  <dig>  of qmeanclust. a closer inspection of the performance differences on the  <dig> casp <dig> targets reveals that qmeanclust in many cases is able to circumvent the inherent limitations of 3d-jury. the table on the left-hand side of figure  <dig> lists all targets where the model selection based on qmeanclust is at least  <dig>  gdt_ts units better  or worse  than the one based on 3d-jury. the results of three targets are shown in more detail in figure  <dig>  two examples are shown  in which the pre-selection of models based on qmean  resulted in better model selection by qmeanclust compared to 3d-jury. the results are especially pronounced in the case of target t <dig>  the models of this target seem to be based on two categories of templates and the majority of groups seem to have used the less appropriate one. the dashed area containing all models within a qmean score of  <dig>  units from the best ranked model captures vast majority of the models of the highest quality cluster and only a fraction of the dominant structural cluster. the pre-selection step results in a qmeanclust ranking which is not dominated by the models of the second cluster as opposed to the 3d-jury ranking. the correlation coefficients are  <dig>  for qmean,  <dig>  for the 3d-jury like approach and  <dig>  for qmeanclust.

targets t <dig> represents an example in which qmeanclust failed to improve over a purely clustering based approach. this can be attributed to the inconsistencies in the qmean ranking in which a set of similar but very poor models have been ranked too high. for this target the best model selection would have been actually obtained by qmean .

moulder test set: performance in a realistic modelling situation
as the qmean scoring function has been optimised on casp <dig> models and tested on casp <dig> models, one might raise the argument that it tends to be over-trained for this special situation and also to the gdt_ts score used there. therefore we analysed the performance of qmean on the moulder test set which represents a more realistic modelling situation. the moulder test set consists of  <dig> different targets, each with  <dig> alternative models generated by modeller  <cit> .

the table shows the rmsd difference  between the selected model by the scoring function and best model in the ensemble, averaged over the  <dig> protein targets of the moulder test set. in order to increase the robustness of the statistics, each calculation is repeated  <dig> times on random subsets of 25% of the model ensemble. for comparison, the mean Δrmsd and standard deviations for qmeanclust  are  <dig>  and  <dig>  Å respectively. for a detailed comparison of qmean and qmeanclust see table  <dig> 

the performance of qmeanclust on the moulder test set is highly dependent on the composition and quality of the decoy set as is apparent from data in table  <dig>  the data are sorted by increasing median rmsd of the  <dig> decoy sets and no re-sampling has been applied such that the entire set of  <dig> models is used per target. the performance of qmeanclust decreases with increasing diversity of the decoy set which is also reflected by number of near-native models in the set. qmeanclust shows a considerably worse model selection performance compared to qmean on the decoy sets in the lower part of the table. on the  <dig> decoy sets with less then  <dig> near-native models , the difference is statistically significant in a paired t-test . these model ensembles do not seem to contain useful structural density information which could be captured since only few models have a rmsd below  <dig> Å. on the entire moulder test set the qmean scoring function achieves an average Δrmsd of  <dig>  Å compared to  <dig>  Å of qmeanclust. overall, the single model scoring function qmean selects for  <dig> targets the best available model in the ensemble and for  <dig> targets a model deviating less than  <dig> Å. on the other hand, qmeanclust performs equally well on decoy sets populated with a high fraction of near-native models. the average Δrmsd over the  <dig> targets containing at least  <dig> near-native models of qmean is  <dig>  Å compared to  <dig>  Å for the consensus method qmeanclust. the performance difference is statistically not significant . although the results have been obtained on a small test set of only  <dig> targets, they underline the fact that the performance of consensus scoring functions is highly dependent on the composition of the model ensemble to be analysed.

the first two data columns contain the median rmsd of the models in the decoy set and the number of models with rmsd <  <dig> Å . for all  <dig> target proteins, the rmsd difference  is given between the selected model and best model in the ensemble.

qmeanlocal: local quality estimation
structural density information can not only be used globally by comparing entire models but also on the residue level by analysing the local structural diversity among the models  <cit> . a region modelled entirely different in one model compared to the majority of the others is very unlikely to be correct. table  <dig> shows a comparison of clustering and non-clustering approaches concerning local quality estimation on the casp <dig> test set.

r = average pearson's correlation coefficient; tau = kendalls's tau on a per model basis; roc = area under roc curve averaged over all  <dig> targets  or using all residues pooled together ; low/top10% = average cα distance of the 10% lowest/highest scoring residues per target.

the per-residue predictions based on qmean, qmeanclust and selfqmean are compared to the recently published proqres scoring function . in proqres a neural network is used to combine several local descriptors  <cit> . recently, fasnacht et al.  <cit>  published a local composite scoring function based on different terms combined by support vector machines resulting in a slightly better performance. the svm approach, as well as proqres, have been shown to outperform classical scoring functions such as verify3d  <cit>  and prosaii  <cit> . a direct comparison to these methods is therefore not necessary and a rigorous benchmark against other local quality estimation methods is beyond the scope of this work. rather, the general performance differences of non-clustering, clustering and "self-clustering" methods should be highlighted and discussed here.

the qmeanlocal composite scoring function described here consists of a linear combination of  <dig> structural descriptors. the local scores are calculated over a sliding window of  <dig> residues which resulted in the best performance compared to alternative window sizes . in analogy to the global qmean version,  <dig> statistical potential terms are combined with  <dig> terms describing the local agreement between predicted and measured secondary structure and solvent accessibility. additionally, two trivial descriptors are used: the average solvent accessibility and the fraction of residues in the segment with no defined secondary structure. the weighting factors have been optimised on the models submitted to casp <dig> with the cα distance as target function .

qmeanlocal estimates the local quality using only the model, whereas the following two approaches consider the ensemble of models. we investigated two different approaches for local quality estimation relying on the structural density information contained in the ensemble of models .

in the local consensus approach the cα deviations among the equivalent positions in the models after a sequence-dependent superposition with the program tmscore  <cit>  are analysed in order to derive a quality score. in analogy to the global qmeanclust score, either a subset of all models is used in the distance calculation and the median distance is retrieved, or a weighted mean distance according to the global model quality score is calculated. in this way, segments of more reliable models have a stronger influence on the predicted local score. the model ranking based on qmeanclust is used for model selection and weighting. a weighting according to qmean has been also investigated but resulted in a worse performance . the statistical potential terms in selfqmeanlocal are trained on the best ranking models of the ensemble. the remaining terms are identical to those in qmeanlocal and the weighting factors are derived using the casp <dig> data set.

the last two columns in table  <dig> show an analysis of the lowest and highest scoring 10% residues per target according to the corresponding quality score. qmeanlocal shows the best performance in recognising reliable regions as reflected by the best average cα distance of the lowest scoring 10% residues. as is the case with possibly any other scoring function analysing single models , qmeanlocal is not able to distinguish regions with high and very high deviation from native. if the model ensemble contains structural redundancy which can be captured by consensus based methods, the local version of qmeanclust is very effective in identifying regions in models which deviate from the structural consensus and regions which are potentially correct. for template-based modelling, correlation coefficients between predicted and calculated local deviation from native were observed as high as  <dig>  over the residues of the model ensemble of some casp <dig> targets. for the analysis of single models or in the case when the ensemble does not contain useful density information, composite scoring functions such as qmeanlocal may be used. depending on the modelling situation either one or the other approach may be used to identify incorrect regions in the model which can be subjected to local conformational resampling in a model refinement protocol.

the quality measures described so far all rely on the entire set of residues of all models per target  and describe the general agreement of predicted and measured local model quality. they do not explicitly analyse whether a method is able to estimate the reliability of different regions within a model. therefore we also analysed for each model the degree of correspondence between predicted and observed local deviation using kendall's tau rank correlation coefficient. table  <dig> reports kendall's tau averaged over all models per target. the performance of selfqmeanlocal lies between non-clustering and clustering methods.

a roc curve analysis of the terms contributing to qmeanlocal suggests that the performance is strongly carried by trivial arguments such as solvent accessibility and secondary structure composition . two analogous terms are used both in proqres and in the svm approach of fasnacht et al. the performance differences can therefore be partly explained by improved statistical potential terms. the qmeanlocal version presented in this work is only a starting point and a more elaborated approach is needed for combination the terms e.g. svms or neural networks. nevertheless, the linear combination of terms used in qmeanlocal performs considerable better than the neural network based proqres.

CONCLUSIONS
the qmeanclust scoring function described in this work combines the qmean composite scoring function which operates on single models with structural density information contained in a model ensemble. we showed that this approach is able to circumvent to some extent the inherent limitations of consensus methods which tend to fail if the best models are not part of the most prominent structural cluster. a statistically significant improvement over other methods relying on structural density information alone is obtained by selecting a subset of models based on the qmean score and calculating structural density only with respect to this subset.

the qmean scoring function outperforms all non-consensus methods participating at casp <dig>  both in terms of correlation to gdt_ts and in the task of selecting the best model. the results on the moulder test set show that qmean has not been specifically optimised for the context of casp but represents a valuable tool for model selection on more realistic data sets. compared to the original qmean version  <cit> , an all-atom term has been added to the composite scoring function increasing its ability to select good models especially in the template based modelling category. combining the terms with a more advanced machine learning algorithm may further its performance as model selector for qmeanclust.

at casp <dig>  consensus based methods have been shown to be superior to methods acting on single models. nevertheless, none of the participating scoring functions was able at that time to select better models than the best server from zhang has submitted. the qmeanclust scoring function presented in this work performs significantly better than a naive scoring function always picking zhang models. the high correlation coefficients obtained for the global and local versions make qmeanclust a good candidate for a refinement protocol. it may be used to enrich the ensemble with good models and to reliably identify deviating regions which then can be subjected to local conformational re-sampling and refinement in a similar way as recently described by the baker group  <cit> .

the outstanding performance of consensus methods over scoring functions operating on single models at casp is not observed on the moulder test set. the performance of qmeanclust on the more realistic modelling test set highly depends on the composition of the ensemble of models to be analysed. for decoy sets containing many near-native conformations, the performance of the two scoring functions is similar. however, consensus methods will fail on decoy set which include only few near-native protein conformations and do not contain useful consensus information. performance estimates of consensus methods based on large meta-datasets  might overrate their applicability in more realistic modelling situations, and further research is required to investigate the influence of the ensemble composition and the methods used to generate these models.

the two scoring functions qmean and qmeanclust are publicly available as part of the qmean server  <cit>  under the following address: .

