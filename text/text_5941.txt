BACKGROUND
a key step in preparing raw high-throughput  data into analyzable data suitable for answering medical and biological questions is labeling the measured features with the identities of the molecular species purportedly assayed: “molecular identification” . there are many ways to get these mis, thanks to a proliferation of annotation databases and algorithms. mi may come from  an online annotation resource ,  an annotation data object in a bioinformatics-capable software environment , or  an algorithm . if the mi process is done well, then the analysis of ht biological data has the best chance of yielding meaningful results.

incorrect mis appear to be frequent  <cit> . it is common for two well-respected mi methods or resources to diverge substantially  <cit> . thus many mis are likely to be incorrect. if so, then any analysis which depends on biological interpretation risks missing or mischaracterizing an important discovery , because biological interpretation depends on correctly identifying the assessed molecular species.

in choosing mi methods, ht data analysts have limited guidance. which techniques they use for filtering and mapping are typically based on convenience, habit, and heuristics. further, research articles seldom report which techniques they chose. when their choices are data-driven, the same data set under scientific study is also used to assess the choices, leading to potential biases.

to improve mi, we need to measure its quality. the approach promoted here provides a “measuring instrument” for the quality of an mi method, an instrument to be used for comparing mi methods and for tracking changes in mi quality over time.

one kind of mi is identifier filtering : deciding which features in a data set to include and which to exclude based on some believability criterion, whether computed or curated. each ht platform produces a large set of features; each feature is labeled by an identifier . prior filtering of features is especially important in light of the multiple testing quandary, which is aggravated when many incorrect features compete with the genuine features for the attention of a statistical testing procedure. there are numerous criteria for filtering out less believable features, but the practical question is which single idf criterion is best, or how to construct a combination better than any single one.

another kind of mi is mapping between the identifiers from two platforms: id mapping . more than ever, bioinformatics analysis involves integrating data from multiple platforms. data integration across platforms is needed for a sufficiently full picture of biological systems. but the term “data integration” has multiple meanings. integrating ht data from multiple platforms on the same samples can occur at three levels.

a) separate analyses
many studies report combined analyses across assay platforms, but the data integration consists of reporting independent separate analyses of each platform, culminating in combining the results of each in simple ways, for example, a comparison of biomarker candidate lists  <cit>  or interpretations of modulated features  <cit> . this kind of study does not require merging the data by sample. good mi is nevertheless important in these studies, because good identifier filtering  will remove misidentified features from the data, decreasing false discoveries and increasing detection of true discoveries.

b) merged by sample
one can also merge data by sample to create a combined collection of measured molecular features. sample-wise merging enlarges the feature set by obtaining features from both platforms. some studies develop predictive or prognostic models utilizing these enlarged sets  <cit> . no idm is required. again, good idf is important.

c) merged by sample and semantics
to generate deeper understanding and fulfill the promise of systems biology, the data need to be merged not just by sample, but by biological meaning as well: semantic merging. this requires identifier mapping, idm, to connect the mis annotating measurements on two different platforms.

the resources that do algorithm-based and annotation-based idm are numerous . but they disagree with each other. they may even disagree with themselves, comparing results based on web service queries to results based on file downloads, or comparing one year to another  <cit> . when undertaking a sophisticated systems analysis performed on a multiple-platform data set, incorrect mis will at best complicate analysis, and at worst obscure the truth and sabotage the chance to build meaningful systems biology models.

the paradigm we present here give us a way to interrogate the quality of the idm and idf methods in the context of biological material. this approach uniquely fills a major gap in the effort to improve bioinformatics analysis. after presenting examples, its potential range of application is discussed.

methods
we present a general strategy to compare quality of data preparation strategies. the essential ingredients are:

• a substantial number of biological samples .

• two bioinformatic ht datasets measuring related classes of molecules, such as mrnas and proteins, or micrornas and mrnas, or gene copy number and mrnas, on the same set of samples.

• a set of candidate methods for ways to accomplish idm or idf. the result of each candidate m is a set s of id pairs accepted by m. candidates can be composites of other candidates: for example strategies combining one idm and one idf strategy, or boolean combinations of multiple idms or idfs.

• an idm method to create the full pool of id pairs. when the candidate methods themselves are idm methods, the full pool is just the union of the sets of pairs from the candidate idm methods.

• a simple target model, relating the measurements, to be applied separately for each id pair  of features in the full id pair set. this will typically be a regression model, where the primary feature is to be predicted by the secondary features. the predictor feature list may be augmented by auxiliary features, such as sample categories. in the examples, the simple model is that, for each pairing of transcript and putative protein product, protein abundance is proportional to  transcript abundance when mi and idm are correct, but unrelated when it is not.

• a model quality score, notated as mq, for each id pair p. in the applications described below, mq is the correlation of the two features.

in the case of mapping mrna expression and protein expression, we expect a correctly mapped and biologically coupled feature pair to manifest in a strong positive correlation. in other cases, a correctly mapped pair might manifest as a strong negative correlation, for example when the pair consists of a microrna species and a transcript that it putatively downregulates.

we form the collection of all scores mq for the union of id pairs from all the candidate methods m: ∪m{mq : p ∈ s}. this list of mq scores can be analyzed immediately via regression modeling, visualization, and two-sample tests, to see which of the methods m are most competent at mi.

the mixture model for evaluation of resources
however, the enterprise is more effective if we first convert the mq scores into posterior probabilities. figure  <dig> illustrates the key argument. the central concept is that pairs of ostensibly related features from two different platforms should fall into three categories:

“+”: both features are correctly identified and mapped between platforms, and truly biologically coupled  as expected,

“0”: both features are correctly identified and mapped, but biologically decoupled in the sample group under study, due to causes unaccounted-for up to now, so that the correlation, regression coefficient, or other measure of association is near zero. this decoupling is sometimes called discordance.

“x”: one or both features are incorrectly identified, or incorrectly mapped to each other.

comparing two methods a and b for idf or idm, the best of the two should be relatively enriched for the “+” and “0” categories of feature pairs. with enough samples and enough feature pairs, the identity of the best method should become clear.

the “0” group deserves further discussion. these pairs have correct mi, but additional biological factors decouple the two identified molecules. these extra factors may be as simple as unaccounted-for sources of variation in the target feature, lowering the signal to noise ratio. for example, in relating transcript to protein, true biological decoupling could occur, because of variation in rates of protein degradation, post-translational modification, and other factors affecting protein abundance as detected by mass spectrometry. decoupling can stem from more exotic causes. variation in microrna might interfere with translation in a way that does not manifest itself in the raw abundance of the transcript. feedback loops may buffer or magnify variation in transcript. there could be variation in transcript splicing, or in the time delay between transcription and translation. in measuring transcript expression cross-hybridization of other transcripts with the probesets targeting the genuine transcript could vary across subjects. further discussion of decoupling and its causes is in day  <dig>  <cit> .

on the level of individual targets, a single dataset cannot directly distinguish true decoupling, “0”, from incorrect mi, “x”. however, by aggregating tens of thousands of targets, typical for the ht platforms being merged, the ensemble of models and scores will overcome the signal-to-noise problem by volume of the number of identifier pairs, and help us find the mi performance differences we seek.

the following simple argument motivates the claim that the observed proportions of strong correlations reflect the relative quality of a and b. our notation for the counts in the three groups is: are coupled and correctly mapped by a, are correctly mapped by a but not coupled, and are incorrectly mapped. if the true proportion in the “+” group is greater for a than b, then

  na+na++na0+xa>nb+nb++nb0+xb. 

as the number of samples increases, the measurement error in assessing whether a single pair is in the “+” group decreases. with sufficient numbers of id pairs, determining which proportion in  is larger becomes more accurate. suppose also that, given that a pair is correctly mapped, the coupling/decoupling status  is independent of the method, so that

  na+/na++na0=nb+/nb++nb <dig> 

is a constant δ+. then the proportion of correct mi is greater for method a:

  na++na0na++na0+xa>nb++nb0nb++nb0+xb. 

when  is true as well as , the ratios of the two sides are the same in . the same conclusion holds if, instead of ,

  na0/na0+xa=nb0/nb0+xb 

is a constant δ <dig>  so that the proportion of correct mappings among those either decoupled or incorrect is the same for a and b. note that conditions  and  are not equivalent. in summary, under mild assumptions, the resource with a larger observed proportion of good correlations is also the better mapping resource, and the ratio of the two sides in , which can be observed, is a consistent estimator for the ratio of the two sides of , the proportions of correct pairs.

mixture model for model quality score 
our next step is to make the argument more rigorous and subject to quantitative analysis. suppose that we have chosen an association measure mq, for use as a measure of the likely correctness of an id pair.  suppose the observed correlation for pair k depends on the correctness of the mapping as follows:

  mqp~nψgp,τgppwhereτgpp=σp2+vgp 

  prgp=g=πgforg∈"+","0","x" 

where g indicates the group for pair p as defined above. we assume that ; that is, unless the pair is correct and coupled , its mq has mean zero. the measurement error variances σp <dig> are presumed known or estimated by bootstrap. the group variances v+, v <dig>  vx are unknown. from the observational point of view, the “0” and “x” groups are indistinguishable, so define π−=π0+πx and v−=/π−. we can now estimate the unknowns ϕ= easily by an ecm algorithm  <cit>  , constraining ψ−=ψ0=ψx=  <dig>  to yield the maximum likelihood estimate ϕ^=ψ^+,π^+,v^−,v^+.

next, we can estimate the probability of each pair belonging to the “+” group, using the empirical bayes “plug-in” technique, which replaces the parameters by their em estimates. defining π+p*=prgp="+"|mqp,ϕ^ and π−p* =  <dig> − π+p*, the posterior odds are

  π+p*π−p*=prgp="+"|mqp,ψ^+,v^+,π^+prgp="−"|mqp,ψ^−,v^−,π^−=π^+π^−exp−mqp−ψ^+2/2v^++σp2/v^++σp2exp−mqp−ψ^−2/2v^−+σp2/v^−+σp <dig>  

in addition, we gain an estimate of the accuracy of this posterior probability, in the form of a posterior variance, approximated using the delta method to convert from the bootstrap estimate of the sampling variance of the correlation to an estimate of the variance of the posterior probability:

  v+p*=va^rπ+p≐σp2π+p*π−p*2mqp−ψ^−v^−+σp2−mqp−ψ^+v^++σp <dig>  

thus for each id pair p, the mixture model provides a data-determined estimate of the probability that it is a correct annotation, and a measure of uncertainty for that probability. these ingredients provide what we need to decide which of two methods for id mapping to use. .

we can contrast this use of mixture models to schaefer et al’s study  <cit>  using a mixture model to examine concordance of chip-chip and chip-seq data, using data from just two samples. aside from the difference in the number of samples studied, schaefer’s purpose also was different: to characterize the concordance and discordance of the platforms. this contrasts with the purpose of our paradigm, to evaluate id mapping and filtering methods.

expected utility to inform selection of best practices
in search of best practices, we want to choose between the id pairs provided by method m=a or method m=b. a simple estimate of the proportion p+m of correct id pairs is just the mean of the  over the id pairs from method m. an optimally weighted mean

  p^+m=Σp∈smπ+p*v+p*−1/Σp∈smv+p*− <dig> 

is a more accurate estimate; it takes into account the variation in standard errors. this is important, since some correlations are highly unstable, for example due to a low variance in either protein or transcript expression. these will manifest as having middle-range values for π+p*, far from  <dig> or  <dig>  now we choose a value for lfp=the loss associated with a “false positive”, and utp=the utility of including a “true positive”. with this estimate, one can choose whether to reject the entire subset of probesets produced by method m using a standard bayesian expected loss calculation:

  eu1=eutilityperpair|methodm=Σp∈smπ+p*utp−π−p*lfpv+p*−1/Σp∈smv+p*−1=utpp+m−lfpp−m 

  eutotal=totalexpectedutility|methodm=nmeum <dig> 

the break-even point is p+m=lfp/. we can choose method m=a or b based on which makes either the average or the total expected utility the largest, depending on the purpose. the posterior probabilities from  utilize as a prior the overall component probability as estimated by the generalized em algorithm; this can be modified to a true bayesian prior if desired. we also can take into account that some proportion of the correctly included or mapped pairs are in group “0”. one data set standing alone cannot distinguish “0” from “−”. however, if the analyst is willing to speculate on the ratio introduced in , then letting δ+=nm +/ we can modify  by adding an extra term accounting for the appearance of some correct pairs in the “−” group:

  eu1=utp+lfpp+m−lfp+p+m=p+mutpδ+−1+lfp2−δ+−1−lfp 

which is just an increasing linear function of p+m. if our criterion is eu total , a more stringent method may improve p+m but decrease the number of pairs returned, nm, enough to reverse the optimal choice. this gives the analyst a basis to choose a more generous method, if it benefits the analytical purpose.

RESULTS
we illustrate the paradigm with two distinct evaluations of mi  and one evaluation of threshold choice, all using the same pair of ht datasets for samples in an endometrial cancer setting. a full description of the data is published  <cit> . briefly, in a study of analyses of  <dig> endometrial cancer and  <dig> noncancer endometrial samples, liquid chromatography-tandem mass spectrometry generated  <dig>  distinct uniprot accessions, and the affymetrix u <dig> plus  <dig>  microarray provided expression data on the same samples. in a previous report, we utilized these data to compare the quality of three annotation resources, david  <cit> , envision  <cit> , and netaffx  <cit> , for mapping identifiers between affymetrix probeset ids and uniprot accession ids, selected by virtue of providing direct mappings of probesets.

the analysis begins by utilizing only the id maps retrieved from each resource. we comprehensively compared the retrieved sets of id maps. for example, less than half  of the uniprot protein accessions pulled identical lists from netaffx and envision. similar results were obtained comparing each of netaffx and envision with david.

for each idm pair , the data were merged by sample and the correlation between the two platforms computed. we proceeded under the presumption that better identifier matching should generate a higher rate of match pairs with strong correlations between the transcript signals and corresponding protein spectral counts. we decomposed the correlations, as described above, into a mixture with a zero-centered component and a positive component . the left-most component can be interpreted as our “–” group: a mixture of our “0” and “x” groups, which cannot be distinguished empirically at this point; the second as our “+” group. the mixture distribution model sheds light on the degree to which positive correlations exceed negative ones, allowing estimation of the distribution of correlations among correctly mapped protein-probeset pairs, without needing to know at this point which specific pairs are correctly mapped and which are not. it also provides a measure more useful than the correlation itself: the posterior probability of belonging to the right-hand mixture component. this component  corresponds to the “+” group: probeset-protein id pairs which are both correctly identified and mapped, and biologically correlated.

note that the empirical density smooth  is raw; it summarizes the observed correlation distribution. in contrast, the bimodal mixture fit  obtained from the em algorithm estimates the true underlying correlation distribution. it properly takes into account the measurement variances, estimated via individual bootstraps, to deconvolve  the observed distribution . it is not expected to approximate the density smooth unless the correlation measurement error is zero. utilizing the bootstrap for estimating the measurement error variances σp <dig> is important. in figure  <dig> we see the bootstrap estimates plotted against correlation. overall, the relationship echoes the normal-theory variance formula, but there is tremendous variability around that relationship, probably due to the nature of spectral count data. in figure  <dig>  we see the relationship between posterior probability and its posterior standard deviation. ordinarily one expects large measurement standard deviations  to associate with large posterior standard deviations. however, a large measurement standard deviation implies a paucity of information about the classification, a posterior probability far from zero or one, and an insensitivity of the posterior probability as the correlation value changes; this view of behavior with large σp <dig> is confirmed by inspection of equation  and figure  <dig> 

next we examine the mixture from the decision theory perspective, in order to illuminate selection of best practices. in table  <dig>  the consequences of choosing an id method are represented for a subset of id pairs corresponding to proteins with a minimum average spectral count across the samples. the values guiding the decision analysis, chosen for illustration, are:

• utp=2=utility of including into further analysis a “true” correctly mapped pair.

• lfp=1=the loss, or negative utility, of including an incorrectly mapped pair.

• δ+=1=proportion of correctly mapped pairs which are coupled.

use all=the union. columns: npairs=the number of uniprot-probeset pairs reported by the indicated service; utrue=the average utility from “+” and “0” pairs; lfalse=the average loss from “−” pairs; eu mean is the average net utility per pair; eu total=npairs?×?eu mean.

.

the all-or-none decision is appropriate when the purpose of the evaluation is to select a best practice for id mapping, to be applied when integrating other data sets with the same feature identifiers. since envision reports out fewer pairs, its relative standing declines if the criterion is the eu total instead of eu mean. utilizing weighting reflecting relative measurement precision has a notable effect. in this case, without weighting david slightly outperforms netaffx , but utilizing the weighting, as in table  <dig>  reverses the ranking, though the difference is still small. the subjective elements in the decision include: utp, lfp, δ+ and whether to rely on eu mean or eu total. the relative ranking of the choices is usually insensitive to these elements.

to examine all reasonable id mapping strategies, we need to include boolean combinations . utilizing “eu total” as the criterion, the optimal strategy across individual and boolean strategies is to keep id pairs that envision reports. using “eu mean” ), table  <dig> would favor intersecting envision and david pairs, but one must balance the improvement against the extra effort of retrieving an id map from a second data source. in the rest of the paper, where we turn the focus away from id mapping strategies, we take this conclusion into consideration, and utilize only the microarray/mass spectrometry id pairs that envision provides to integrate the data.

columns: as in previous table. rows: boolean combinations of netaffx-affirmed , envision-affirmed  and david-affirmed  id pairs.

assessing probeset filtering
another application of the paradigm uses the same integrated proteotranscriptomic data, restricted to the envision-selected pairing, to evaluate the performance of probeset filtering mechanisms.  “jetset”  <cit>  calculates the product of a specificity score, a coverage score, and a robustness score, and removes probesets for which a higher-scoring probeset for the same gene symbol exists. the probeset acceptance rates among the  <dig> probesets of the u133plus <dig>  array are seen in table 3:

1pairs initially filtered as described above.

2regression estimates are from a linear model predicting “+” group status with main effects only.

the most recent method, jetset, has odds ratios  in excess of  <dig>  with both masker  and pdba <dig> , but much less with affytag . masker is roughly independent of pdba <dig> and affytag . finally, pdba <dig> is inversely related to affytag . these results suggest that the filtering are not just repackaging the same insights, so strategies combining multiple methods deserve consideration.

next, we introduce the integrated data to evaluate the methods and their boolean combinations. note that jetset, plandbaffy, and other methods only use other bioinformatics resources to draw their recommendations. in contrast, our paradigm utilizes biological measurements on samples and requires the integration of biological data across platforms, in this case with a proteomic dataset. therefore, it provides an independent validation using biological material. for illustration, figure  <dig> shows scatterplots for spectral counts identified as annexin  <dig>  versus two probesets mapped to p <dig>  the leftmost shows a correlation of  <dig> , low enough to question the mapping, while the rightmost correlation is  <dig> , high enough to yield some confidence in the mapping, despite the fact that “affytag” id filtering would accept the left probeset and not the right. a single id pair proves nothing; the aggregate across many tags is needed to learn anything about the quality of an id filtering method.

before we consider the decision-theoretic aspect, a look at a linear regression model to predict posterior probability of the “+” correlation group is revealing . we assess the id mapping and id filtering choices together using the r function glm, with regression weights equaling the reciprocal of the variance estimates, 1/ v*+p, derived above via bootstrap and delta method. in this model, the terms for the netaffx and david id mapping retrieval were nonsignificant, as was the term for the affytag filtering method. the estimates were  <dig>  for envision_q ,  <dig>  for jetset ,  <dig>  for pdba <dig>  and  <dig>  for masker . this reinforces our decision to utilize the envision-mapped pairs only for evaluating filtering methods. setting aside affytag, then, we can look at second-order effects. among the id pairs approved by envision, the model was carried by the interaction term between pdba <dig> and jetset: estimate= <dig> , p?<? <dig> ) despite the large or noted above. even in the complementary dataset, containing only id pairs disapproved by envision, the estimates are very similar, including the interaction term .

this result reinforces the suggestion that the best practice is to utilize envision for id mapping, and for id filtering to utilize probesets which both jetset and pdba accept. it confirms the common view that the affy tag, which dates to the origin of the array and represents knowledge from that time, is of little use for this purpose. masker eliminates few probesets, but does provide significant extra value if jetset is not used .

turning to the decision paradigm, we use the same subjective parameters as before, and generate the results in table  <dig> 

these tables illustrate results with the same data and the same decision parameter settings as in the id mapping example above. the results strongly suggest that the best strategy is to apply the pdba filter alone if the criterion is eu total, but if the criterion is eu mean then by sacrificing quantity of pairs one can increase the average quality substantially by applying both the pdba and the jetset filters.

it is an important point that, while this conclusion depended on data integration, it is useful for any analyst dealing with data from the u133plus <dig>  microarray, regardless of whether data integration with a proteomic or other platform is contemplated.

assessing threshold selection
we demonstrate the use of our paradigm for selecting thresholds in the context of filtering individual spectral events in tandem mass spectrometry. the purpose of presenting a threshold-related example is to demonstrate handling of a complication not seen in our previous examples: as the threshold changes, the actual data change, therefore the correlations and the bootstrap estimates of variance need recalculation. a common quality measure for spectral events is the cross-correlation, xcorr; another is the relative improvement of the best identification over the second-best, deltacn. for both measures, larger values should generally correspond to events with more reliable protein identifications. a reasonable question is whether the initial thresholds were stringent enough, or alternatively permitted too many erroneously identified spectral events.

in this example, we chose eight proportions  to use as potential thresholds. for each proportion, we then calculated the quantiles for xcorr and deltacn, then kept only the spectral events where both values exceeded the corresponding quantile. next, we recalculated the correlations and variances, but kept the mixture model from the original data, using it to transform from correlation to posterior probabilityas we did in the previous examples.

figure  <dig> and table  <dig> show the results. as the threshold proportion changes, the thresholds for xcorr and deltacn change. removing the lowest-quality spectral events did not improve the mean expected utility.  from these results, we conclude that the original thresholds for xcorr and deltacn were sufficiently stringent.

discussion
in this article, our examples focus on studies of best practices that can be obtained from integrating proteomic and transcriptomic data. we have demonstrated assessing and comparing methods for choosing an identifier mapping database, choosing an identifier filtering method, and setting an identifier filtering threshold. note that, while our paradigm requires integrating data across platforms, identifier filtering applies to just one of the platforms, so the insights derived about identifier filtering methods can help even the data analyst working on that single platform. furthermore, since every id filtering evaluation depends on an id mapping, when a better id mapping method is found, it will lead to better id filtering comparisons.

in comparing id mapping methods, the methods do not need to be one-step mappings like the three we selected for the proteogenomic id mapping study. in fact, the set of id pairs do not need to consist of the same id types, as long as they map features from the same pair of platforms. for example, a promising alternative is absidconvert  <cit> , which converts between id domains by intermediate passage through mapping to a tree of genomic intervals, providing two-step indirect mappings and flexible, dynamic redefinition of probe-based features. the non-rigid mapping to genomic coordinates obviates many problems and potentiates some great applications. applying absidconvert to id mapping between platforms requires an extra step that is not uniquely defined. given mappings of two identifiers to genomic ranges, one must decide whether those ranges are “the same” for purposes of mapping between the the identifiers. different rules for this decision generate different id mapping methods, which are subject to our paradigm for comparative evaluation without special considerations.

with the decision framework, our evaluation paradigm can compare id mappings even when the pairs are totally distinct. for affymetrix arrays, many groups demonstrate methods to replace the probe sets by constructing new features, encoded in a chip definition file , with concomitant evidence of superiority  <cit> . in that case, each id pair will belong to only one resource or method. the evaluation paradigm proceeds without change, with the mixture model utilizing all pairs just as above. the only substantive impact is that in fitting linear models predicting the posterior probability, like the one above that demonstrated a positive interaction between pdba <dig> and jetset, one can no longer estimate and test interaction terms.

it remains to consider to what extent the +/0/x classification could reflect reality. an incorrect mapping is an incorrect mapping, so the identity of the “x” group of id pairs is conceptually clear-cut. however, the distinction between the coupled “+” and decoupled “0” groups can shift with context. first, an id pair that is uncoupled in one data set might be coupled in another, reflecting differences in the biology in the two settings. second, the dichotomous distinction is artificial. one might suppose instead that there is never total decoupling, just a variable amount of masking of the association, due to variation in the levels of known and unknown factors. however, the assumption in  seems plausible enough, since to our knowledge no mapping resources take into account results from data on sample.

the timing of mapping resource retrieval
the proteogenomic integration supporting the examples presented here are from identifier mapping retrievals in  <dig>  in practice, an analyst will expect more recent retrievals to have higher quality. subsequent releases of each resource do change; for example, from  <dig> to  <dig>  netaffx has changed the uniprot match list for over 10% of probe sets in the hu133plus <dig>  array. the staying power of best practices recommendations may exceed expectations; we have found no hint of a time trend in quality as measured by our correlation/posterior probability paradigm.

nevertheless, analysts requirea convenient way to update best practices evaluations, especially for the large segment without r expertise. our future plans call for a repository of integratable data set pairs from different platforms, and a web interface to make these method comparisons as easy and accessible and replicable as possible.

wider applications
as long as there is data from two or more platforms on many samples, the paradigm we present can be applied to compare competing methods for virtually any data preparation step for either platform, filtering being just one example. we could use the same integrated protein expression/gene expression experiment described above to compare spectrum-to-protein  <cit>  identification algorithms in “shotgun” mass spectrometry, and with nontraditional methods. for example, the proteogenomic mapping tool  <cit>  was proposed to improve genomic annotation, but can be repurposed to a new idm method that might prove superior to the combination of spectral protein identification algorithm and id mapping resource used in our examples here.

the paradigm also has a broad field of other applications, which belong to “id mapping and filtering” only in an exended sense. each of these presents special challenges, but no serious obstacles. one example arises in the setting of comparing segmentation algorithms for gene copy number data. another example is comparing gene expression measures from expression arrays and rna-seq, to clarify the strengths weaknesses and perhaps complementary nature  <cit>  of the data from each. among the many processing decisions in these studies, one is how to link the array probes or probe sets to genomic regions to which rna-seq reads are aligned. another application is comparing mrna target algorithms for microrna species, using correlation with expression. this can be considered a more complex form of id mapping. however, it is more challenging, since the art of modeling the relationship between the entire complement of microrna species and the expression of a target gene expression is in its infancy, and highly complex. due to the multiple targets of micrornas, a proposed microrna regulator could have indirect effects with positive or negative correlations to the putative target transcript. however, the prior argument goes through if indirect effects cause positive or negative correlations equally, or less stringently if any asymmetry in the correlations is independent of whether method a or b produces the pair.

bioconductor packages for evaluation of id mapping and filtering
the examples described here utilize the idmappinganalysis  <cit>  and idmappingretrieval  <cit>  packages. idmappinganalysis provides a set of functions to compare the performance of selected id mapping and filtering methods, using correlation across the samples between two measurements of features defined by the primary and secondary ids. the new functionality presented in this article is now incorporated into version  <dig> . <dig> of idmappinganalysis  <cit> , available through bioconductor  <dig>  development branch. these include the ecm algorithm used for mixture model fitting, the delta method for the variances of the posterior probabilities, and the calculation of the expected utilities.

CONCLUSIONS
the paradigm which we present here depends on integrating two data sets on the same samples, a set of samples large enough to estimate correlations accurately. it does not depend on any special nature of the data preparation steps being assessed, so its range is not limited to just id mapping and id filtering. it behooves one to repeat those assessments on other data set pairs, to study the generalizability of the conclusions. the cancer genome atlas   <cit>  is well-suited to advance both the need to check generalizability and the opportunity to optimize a variety of data preparation steps. tcga provides data on many thousands of human tumor samples and over a dozen bioinformatics ht platforms. therefore it provides a wealth of opportunity for developing a systematic catalog of such assessments of data preparation methods, and makes the assessments easily and routinely available to analysts. as one example, in tcga there are multiple pairs of rna-seq and expression microarray data sets. alignment algorithms provide a way to link these data sets for correlation analyses of the kind described here. as another example, tcga has reverse-phase proteomic experiments on  <dig> ovarian cancer samples with corresponding affymetrix array results. in a forthcoming report, we describe the use of these data in devising and validating best practices for array id filtering.

availability of supporting data
the gene expression data were obtained from affymetrix u <dig> plus  <dig>  microarrays. the raw data .cel and .chp files are available through geo in a miame compliant format  and were released december  <dig>   <dig>  the proteomic data were summed readings from two tandem mass spectrometers. details of the sample preparation, instrumentation, and spectral identifications are in maxwell et al.  <cit> . details of the identifier mapping resources utilized are in day et al.  <cit> .

abbreviations
mi: molecular identification; ht: high throughput; id: identifier; idf: identifier filtering; idm: identifier mapping.

competing interests
there are no competing interests to report.

authors’ contributions
rsd developed the methodology and software code. kkm developed the applications to id filtering. all authors read and approved the final manuscript.

supplementary material
additional file 1
ecm algorithm for two clusters with constraints.

click here for file

 acknowledgements
we gratefully acknowledge the support of nih grants r <dig> lm  <dig> and t <dig> lm  <dig>  and dod grants w81xwh-11-2- <dig> and w81xwh-05-2- <dig> 

colleagues who contributed to developing the microarray data include: jh risinger, u chandran, j allard, c miller, m sherman, c zahn, j oliver, s banerjee, t litzi, j carlson, j farley, s rose, a berchuck, e kohn, t conrads, r herberman, gl maxwell. colleagues who contributed to developing the microarray data include: gl maxwell, bl hood, u chandran, d kirchner, vs kolli, nw bateman, j allard, c miller, m sun, ms flint, c zahn, j oliver, s banerjee, t litzi, a parwani, g sandburg, s rose, mj becich, a berchuck, e kohn, ji risinger, tp conrads.
