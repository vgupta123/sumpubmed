BACKGROUND
a grn is a complex set of highly interconnected processes that govern the rate at which different genes in a cell are expressed in time, space, and amplitude. such a network is commonly represented by many pairs of proteins and genes, in which one protein/gene regulates the abundance and/or activity of another protein/gene  <cit> . grn’s can be modelled and simulated using various mathematical and computational approaches  <cit> . the modelling and simulation of grn’s is performed over the cdna microarray data. there are two types of dna microarray data: time series and time independent . the time series data are obtained by sampling temporally the measurement process, whereas time-independent data sets are obtained by recording the gene expressions from independent sources, for example, different individuals, tissues, and experiments  <cit> . as time series data would enable one to capture the time varying nature of a grn, it is the preferred form of data used in reverse engineering algorithms. moreover, time series data only gives the expression levels of genes without any knowledge of other cellular elements like protein/metabolite concentrations. in this paper a grn is represented as a graph which consists of a set of nodes that represent genes and a set of edges that represent the interactions between genes. thus the grn inference problem investigated in this paper refers to finding the regulatory relationship between the genes of an organism.

reverse engineering of gene regulatory networks remains a major issue and area of interest in the field of bioinformatics and systems biology. a survey paper  <cit>  discusses a number of models related to this area, viz. bayesian networks  <cit> , dynamic bayesian networks  <cit> , boolean networks  <cit> , probabilistic boolean networks  <cit> , differential equation models  <cit>  and information theory models  <cit> . there is no gold standard method to reverse engineer gene regulatory networks; each method has its own advantages and disadvantages. based on simulations of different models, it has been observed that differential equation models and dynamic bayesian networks provide higher accuracy, but they are computationally expensive and hence, are applicable for only a small data set. boolean networks can be used to study the coarse grained properties of genetic networks  <cit> . such binary representation of gene expression is clearly an approximation, as most biological phenomena manifest their properties in the continuous domain.  even though it is inherently deterministic, the boolean formalism has enjoyed success in predicting biological behaviour, such as the accurate qualitative distinction between known tumor sub-classes  <cit> .  this work suggests that meaningful biological information is not lost when measured, continuous-domain, gene expression data is made binary. information theoretic methods to reverse-engineer grns build on such boolean network models of gene expression and have gained popularity due to their simplicity and less computational cost  <cit> . each of the information theoretic schemes discussed in this paper as well as dbns however can be easily extended to handle multiple levels of quantization to achieve higher inference accuracy at the cost of computational overhead.

aracne  <cit>  and reveal  <cit>  are two popular information theoretic approaches towards grn inference. both of these methods establish relationships between genes based on the mi metric. zhao  <cit>  analyzed the limitations of mi and proposed the conditional mutual information  based approach to infer grns. one of the major disadvantages of information theoretic approaches is the selection of the mi and cmi thresholds, for which zhao  <cit>  proposed the minimum description length  principle and showed its effectiveness in selecting the best mi threshold. the mdl principle states that if multiple theories exist, the one with the minimum description length is the optimal. however the definition of description length varies for different models and applications. in their mdl implementation, zhao  <cit>  defined the description length as the sum of the model length  and data length . one limitation of the mdl principle was that the model length quantity in the description length expression could make the implementation arbitrary  <cit> . to circumvent this problem, we have earlier proposed the predictive minimum description length  principle approach  <cit>  wherein we showed that by removing the model length quantity from description length and using cmi a higher inference accuracy can be obtained. 

mi and cmi metrics are central in establishing the relationships between genes in information theory models. hence, in order to design a smart grn inference algorithm, it is important to study the behaviour of these mi and cmi metrics on microarray data of various sizes. the mdl implementation of zhao  <cit>  will henceforth be referred to as “network mdl” in the rest of the paper.

another major disadvantage in information theory based models is that mi and cmi do not give directions between relationships. a unit time delay was assumed in our earlier pmdl  <cit>  implementation. zou  <cit>  showed that the time lags in regulating one gene by another play an important role in inference accuracy as evident in their dynamic bayesian network based approach. to incorporate the effects of time-lags in information theoretic methods, we propose a new time lag computation method in this paper, which is used to modify the standard mi and cmi computations. based on our modified mi and cmi metrics, we next present novel time-lagged grn inference schemes that show promising results in terms of improving the inference accuracy.

our major contributions in this paper can be summarized as follows:

 <dig>  we show that the performance of the inference algorithms saturate beyond a certain data size due to  the saturation in the information theory metric mutual information. note that we have only varied the data size in our experiments to understand the effects of regulatory time-lags between genes on the algorithms. the overall performance of the algorithms would also be affected by other factors , which might lead to other novel innovations that need to be considered in designing reverse-engineering schemes. this is however outside the scope of this paper. 

 <dig>  a new way of computing time lags between any pair of genes is presented. our scheme makes sure that time lags cannot be negative and we argue that a more biologically pragmatic view is that a gene can affect another gene only when it is up-regulated. this assumption makes more sense in the boolean network formalism of grns where a gene can only be in two possible states: on  and off .

 <dig>  we introduce the time lagged mutual information  and time lagged conditional mutual information  quantities.

 <dig>  we present novel grn inference schemes based on tlmi, tlcmi, mdl and pmdl principles that provide higher accuracy over the existing information theoretic methods.

RESULTS
in this section, we first report the results of the existing inference schemes that were run on the time-series micro-array data of varying size and illustrate that the performance of the methods saturates beyond a certain number of time points. we also report how the pair-wise mi metric saturates beyond a certain data size. we then present our new time lag computation scheme and the modified version of the network mdl algorithm wherein, we replace the mi metric which considers unit time delay with the tlmi metric . we next present a modified version of the pmdl algorithm, by replacing the mi and cmi metrics with the tlmi and tlcmi metrics. finally the results from the network mdl, pmdl and modified network mdl and pmdl algorithms are compared.

parameters to evaluate inference accuracy
benchmark measures recall r and precision p are used to evaluate the performance of the algorithms. although different definitions for recall and precision exist in the literature  <cit> , in this paper, r is defined as ce/ and p is defined as ce/, where ce denotes the edges that exist in the true network and in the inferred network, me are the edges that exist in the true network but not in the inferred network, and fe  are edges that do not exist in the true network but do exist in the inferred network.

synthetic data generation methodology for the in silico experiments
the performance of information theory and dbn based algorithms over different data size was carried out over random synthetic networks which were generated by the genenetweaver tool  <cit> .

it was imperative for us to use synthetic data over time series micro-array experimental data in this phase due to the following reasons:

• very few experimental data sets have equal time intervals between experiments and also the data size is generally limited to around  <dig> time points. in our in silico runs, we wanted to keep equal time intervals between each time point data such that we can understand the true effects of regulatory time-lags between genes on the inference accuracy. it is generally not possible to assign a single time-lag value to a gene-pair if the expression readings for each time point were not evenly spaced as mentioned in zou  <cit> . 

• also, the saturation in inference accuracy generally requires a larger data size  and it would have been difficult to identify the role of mi in bringing about this theoretical limit on the accuracy of information theoretic schemes with a smaller biological data set .

• it should be noted that the genenetweaver software derives the in silico grns from the prior knowledge database of yeast  which contains  <dig> genes and  <dig> interactions. thus in order to create a sample grn with  <dig> nodes, genenetweaver clusters the yeast transcriptomic network into modules and chooses the module having number of genes closest to the given input  to create the in silico network. each such module maps to a particular biological function and this strategy essentially ensures that there is minimum cross-talk of these set of genes with the others in the yeast network resulting in a higher efficacy of the inference algorithms that use them.

biological network data generation methodology to evaluate performance of proposed algorithms
the time series dna microarray data from spellman et al  <cit>  was used to infer gene regulatory networks using the proposed algorithms. the spellman experiment was chosen because it provides a comprehensive series of gene expression datasets for the yeast cell cycle. four time series expression datasets were generated using four different cell synchronization methods: cdc <dig>  cdc <dig>  alpha-factor and elutriation with  <dig>   <dig>   <dig> and  <dig> time points respectively. the alpha-factor dataset contained more time points than cdc <dig> and elutriation datasets with fewer missing values than cdc <dig>  therefore, we chose to use time series expression data from the alpha-factor method to infer the gene regulatory networks.

we used the same preprocessing steps as in  <cit> . initially the data is quantized to  <dig> or  <dig>  in order to quantize the expression values of every gene, they are sorted in ascending order and the first and last values of the sorted list are discarded as outliers; then the upper 50% is converted to  <dig> and the lower 50% is converted to  <dig>  any missing time points are set to the mean of their respective neighbors. if the missing time point is the first or the last one, it is set to the nearest time point value.

four separate biological networks  used for comparison purposes were derived from the yeast cell cycle pathway  <cit> . the fine tuning parameter required by the network mdl based algorithms is set to  <dig>  to retain most of the connections .

effects of data size on grn inference
effects on information theory models
a network and data set with  <dig> time points was generated as in  <cit> . the resulting data set had expression levels quantized to two levels. each of the algorithms was run  <dig> times starting with the first  <dig> time points. increments of five time points were made for every subsequent run. and, for every run, the values of precision and recall were computed. in the network mdl algorithm, the free parameter was set to  <dig> , and in the pmdl algorithm, the conditional mutual information threshold was set to  <dig>  for best performance as reported in  <cit> . the plots for precision and recall are shown in figure  <dig> 

for the pmdl algorithm, it was observed that the precision increased until  <dig> time points, and, beyond that, the precision remains relatively stable for the two smaller tested networks . for the larger network , the precision increased until  <dig> time points before saturation. the recall for pmdl algorithm increased until  <dig> time points before saturation for each of the  <dig> tested networks. for the network mdl algorithm, it was observed that precision increased until  <dig> time points and fluctuated after that. the recall for the network mdl algorithm kept increasing for all the test cases with considerable fluctuations.

for further analysis we considered the recall/precision ratio as shown in figure  <dig>  as seen in figure  <dig>  the recall and precision for the two information theoretic algorithms achieved saturation with increase in the number of time points. to approximately identify the minimum number of time points required to achieve maximum inference accuracy, we have used the recall/precision ratio metric. hence, the number of time points where the inference accuracy achieves saturation will point to the approximate data size required to achieve best performance for each of these algorithms.

effects on dbn based scheme
to understand the performance implications of the more conventional dbn approach on the number of time points, we conducted similar experiments with the dbn scheme developed by zou  <cit> . as the time complexity of this dbn approach increased exponentially with the number of time points, we studied the effects on inference accuracy for a smaller dataset. we generated a  <dig> gene network with  <dig> time point’s data using the genenetweaver tool  <cit> .  since the algorithm required a minimum of  <dig> time points, we studied the effects from  <dig> time points to  <dig> time points with steps of two as illustrated in figure  <dig> 

from figure  <dig> it is seen that neither the precision nor recall parameters for the dbn approach saturate as the number of time points are increased. in fact, the best precision is achieved for data sizes of  <dig> and  <dig> time points , whereas, the best recall is achieved for data sizes of  <dig> and  <dig> time points . however, both precision and recall fluctuates appreciably with increase in the data size resulting in high fluctuations in the recall/precision ratio metric as well . these results somewhat non-intuitively suggest that the dbn approach achieves best performance for a lower data size  as the recall/precision ratio is the lowest for data sizes of 8- <dig> time points . thus the dbn approach does not necessarily achieve better performance as the data size is increased making it difficult for biologists to devise the right experiments. however, we need to conduct more comprehensive tests on the dbn approach  before we can make this conclusion although the high time complexity of this approach makes it increasingly difficult to run the test cases.

why do information theory based models saturate?
the performance saturation of the methods motivated us to study the behavior of the information theoretic quantities of entropy, conditional entropy and mutual information. for these set of experiments, biological synthetic data was created using the genenetweaver tool  <cit> . we built a five gene network and produced synthetic data based on  <dig> time points. the synthetic data was quantized to two levels and then the information theoretic quantities were calculated.  figure  <dig> shows the plots for entropy, conditional entropy and mutual information. we have computed the entropy of all the genes in the network across  <dig> time points while the conditional entropy and mi were computed for each pair of genes. we find that with more data  both the entropy and conditional entropies increase in the network  resulting in very low values for mi .

the plots conclude that the saturation in the methods was due to the saturation in the mutual information quantity which goes close to zero even though the entropy increases in the network. this would conceptually mean that there is room to improve on the inference accuracy , yet the mutual information metric will not be able to point us to the right direction. other information theoretic algorithms, like reveal  <cit>  use the ratio of mi and entropy to infer the network for this purpose which supposedly gives good performance. however, from the entropy and mutual information curves in figure  <dig>  we can see that the ratio of mutual information and entropy will also saturate, as the entropy increases in the network, and hence this ratio might also not be the right metric to achieve better accuracy by making use of more time point’s data. the recently proposed directed mutual information metric  <cit>  might be a better metric than the conventional mi based algorithms. we do plan to conduct similar studies on the performance of grn inference algorithms based on these different metrics as a function of the number of time points in the future. it is imperative to identify the right metric for the research community to decide which class of grn inference algorithms can work best with time-series data and also understand the ideal data size for them. 

the saturation in mi due to increasing number of time points would suggest that the mi should not be computed for the entire range of time points of micro-array data available from the experiments. grns are inherently time varying, and hence the pair-wise mi between any  <dig> genes needs to be computed over the time range where the first gene will have substantial regulatory effect on the other one. this can be best approximated by estimating the regulatory time-lags between each gene pair, and subsequently computing the mi between them for this particular time range. this concept was used to compute the time-lags between genes and the tlmi and tlcmi metrics as discussed in the methods section. note that, the time lag computation concept initially proposed in  <cit>  to implement time-lagged dbn needs to change to avoid the case of negative time-lags.

tlmi based network mdl implementation
a network with  <dig> genes was derived from the yeast cell cycle  <cit>  and spellman’s data  <cit>  was used for the gene expression values at different time-points. the tlmi implementation of the mdl algorithm inferred  <dig> edges of which three were correct where as mi implementation  <cit>  inferred seven edges of which one was correct. these initial results favor our approach. figure  <dig> shows the true network and networks inferred using tlmi based network mdl and network mdl algorithms.

we repeated the same process for two other biological networks with  <dig> and nine genes from the yeast cell cycle and spellman’s data  <cit> . the corresponding results are shown in figure  <dig> and figure  <dig> respectively. for the  <dig> gene network, mdl inferred a total of  <dig> edges of which seven were correct where as tlmi based network mdl approach inferred a total of  <dig> edges of which eight were correct, resulting in an improvement in both precision and recall. for the  <dig> gene network, the network mdl approach inferred a total of nine edges of which three were correct where as the proposed tlmi based mdl approach inferred a total of six edges of which three were correct. in this case, while recall for both methods is the same, the precision of the proposed approach is better.

tlmi and tlcmi based pmdl implementation
we also incorporated the proposed tlmi and tlcmi metrics in the pmdl based algorithm. a network with  <dig> genes was derived from the yeast cell cycle  <cit>  and spellman’s data  <cit>  was used again for performance evaluation. the new pmdl implementation inferred  <dig> edges of which five were correct while the earlier pmdl algorithm inferred  <dig> edges of which five were correct . while the numbers are close the correctly inferred edges were different. the comparable performance of the two pmdl implementations point to a need for further investigation on the time-lagged cmi metric. the precision and recall values for the algorithms are given in table  <dig> 

performance: time and space complexities of proposed algorithms
the performance of the pmdl algorithm depends on three factors: the number of genes, the number of time points and most importantly the number of parents inferred for each gene by the algorithm. to see what role these factors play we will look into the time and space complexities of the algorithm. a schematic for the pmdl algorithm is shown in figure  <dig> while that for the network mdl algorithm is shown in figure  <dig> 

step  <dig> of the pmdl algorithm iterates n <dig> times where n is number of genes, m is the number of time points, and τ is the time lag. from line  <dig> to line  <dig> the algorithm iterates n <dig> times, lines  <dig> and  <dig> of the algorithm iterates n <dig> times. finally from lines  <dig> to  <dig> the algorithm iterates n <dig> times. thus the time complexity of the over-all algorithm is Θ). 

from the time complexity it can be seen that if the number of genes is larger than the number of time points then the run time of pmdl algorithm depends on the number of genes. and if the number of time points is larger than the number of genes then the run time depends on the number of time points. in the worst case  is zero for all genes and the algorithm runs in Θ time.

when it comes to space complexity, the conditional probability tables play a major role. if a gene has n parents then the conditional probability tables take 2n units of space. thus, the amount of memory needed by the algorithm depends on the number of parents inferred by the network. as the space complexity grows exponentially based on the number of parents it is possible that the algorithm may run out of memory for a data set with as few as  <dig> genes whereas it may run for as little as  <dig> minutes for a data set with several hundred genes. there are  <dig> ways to overcome this limitation: 

 <dig>  restrict the number of parents.

 <dig>  take the next smallest description length, instead of using the smallest one.

the first approach will guarantee results when the number of parents is restricted to a small value but this may lower the accuracy of the result. the second approach may take more time to run but as we are not restricting the number of parents the accuracy of the algorithm is not affected. some bench marking studies are required on the above two approaches to see which one works best.

in the mdl based implementation we discard the lines  <dig> to  <dig> from the pmdl based implementation. the worst case time complexity is again Θ.

CONCLUSIONS
in this paper, we have studied the effects of cdna microarray data size on three algorithms: pmdl, network mdl, and a dbn based approach. the study shows that the data size plays an important role in the inference accuracy of each of these algorithms. the experiments were carried out on synthetically generated time-series data and the performance saturation points were listed for these algorithms. the immediate benefit of this work lies in helping biologists to devise cdna microarray experiments intelligently depending on the class of grn inference algorithms they are likely to use to achieve maximum accuracy. in a bid to understand the performance saturation of the information theoretic approaches, we also found out that mutual information saturates and effectively tends to zero as the entropy in the network increases with increase in the data size. these observations lead us to believe that mi by itself might not be the best metric in devising information theoretic approaches for grn inference. the dbn approach however showed good performance only for a smaller data size which is non-intuitive and requires further analysis for validation. based on these findings, we introduced two new information theory metrics viz. tlmi and tlcmi and used them in the network mdl and pmdl based algorithms to develop two novel grn inference algorithms. the results indicate that transcriptional time lags play an important role in gene regulatory network inference methods as evidenced by the higher accuracy provided by our algorithm.

