BACKGROUND
the comparative toxicogenomics database 
the etiology of many chronic diseases involves interactions between environmental factors and genes and proteins that modulate important physiological processes. unfortunately, the mechanisms of actions of most chemicals and the etiologies of environmentally influenced diseases are not well understood  <cit> . we are developing ctd  to promote understanding about the effects of environmental chemicals on human health  <cit> . to achieve this goal, we integrate manually curated data with select public data sets to provide a centralized, freely available resource for exploring cross-species chemical-gene and protein interactions and chemical- and gene-disease relationships.

ctd biocurators manually curate three types of data relationships from the peer-reviewed scientific literature: a) chemical-gene/protein interactions, b) chemical-disease relationships, and c) gene/protein-disease relationships . currently, ctd provides over  <dig>  interactions between  <dig>  chemicals and  <dig>  genes and proteins in  <dig> species as well as more than  <dig>  chemical-disease and  <dig>  gene/protein-disease relationships. by integrating curated data among chemicals, genes and diseases, novel transitive relationships can be inferred. ctd provides over  <dig>  inferred gene-disease relationships and  <dig>  inferred chemical-disease relationships that may be used to develop novel hypotheses about chemical-gene-disease networks. additional molecular network and functional genomics insights can be determined through the integration of data sets from resources like the gene ontology   <cit>  and kyoto encyclopedia of genes and genomes   <cit> .

ctd is unique among other publicly available chemical, gene or disease databases, because: a) it focuses on environmental chemicals, b) it integrates manually curated and external data sets to specifically support understanding about the complex connections between chemicals, genes/proteins and diseases and c) it serves as more than just a data repository by supporting the generation of novel hypotheses about the environmental etiologies of human diseases through novel data integration and analysis tools  <cit> . the batch query tool allows users to retrieve associated data sets  for a list of chemicals, genes or diseases of interest. the vennviewer tool generates venn diagrams for associated data sets for up to three chemicals, genes or diseases of interest . additional tools in the pipeline will further enhance the capability of analyzing user-defined data sets in conjunction with ctd data sets.

ctd curation
the ctd manual curation process is well defined and has been described previously in detail  <cit> . here we provide a brief summary of the process. journal articles are prioritized for curation by chemicals of interest. they are identified by querying titles and abstracts from medline using pubmed  <cit>  and controlled chemical terms and synonyms from the national library of medicine's medical subject headings   <cit> . documents are ranked in date order . biocurators read abstracts and full-text articles from which they capture chemical-gene/protein interactions and disease relationships.

all curated interactions and relationships are captured using controlled vocabularies and ontologies to maximize consistency among biocurators, ensure reproducible data retrieval by users, and enable integration of ctd data with other databases. the ctd chemical vocabulary derives from a modified subset of the chemicals and supplementary concepts in the "drugs and chemicals" category of mesh. for genes and proteins, ctd uses official gene symbols and names from the national center for biotechnology information's  entrez-gene database  <cit> . where possible entrez gene entries representing orthologs are merged into a single, cross-species gene entity in ctd . curators use these cross-species genes in ctd to capture chemical interactions and disease relationships. the ctd disease vocabulary uses terms from mesh and omim  <cit> . ctd interaction types are described using terms from a hierarchical vocabulary of  <dig> diverse relational terms  developed by ctd curators. organisms in which chemical-gene interactions are curated are specified using terms from the eumetazoa portion  of the ncbi taxonomy database  <cit> .

curators are trained by a lead curator, using a manual that provides detailed instructions for identifying and capturing chemical-gene interactions and disease relationships. currently data are captured in excel spreadsheets that include the following data: curator id, date of curation, pubmed identification number, interaction, species in which the interaction was observed, interacting chemical, interacting gene/protein, associated diseases and author contact information for follow-up purposes . curated data are then loaded into a database for quality control review prior to public release. interactions are captured in the spreadsheets using a ctd-defined shorthand or code that is translated into full sentences in the public web application .

curation challenges
high quality manual curation of the scientific literature is a common bottleneck to populating biological databases. it is challenging to keep pace with the increasing volume and scope of published biological data, although ctd curation efforts have become increasingly efficient. to further enhance the efficiency of curation and evaluate our coverage of the published literature for priority research areas we embarked on the project described here. the goals of this project are to: a) generate a baseline analysis of ctd manual curation; b) develop a prototype text-mining application that would address ctd curation needs by identifying chemical, gene/protein, and disease terms in journal articles to rank them effectively for manual curation, and to provide interactive tools for extraction of chemical-gene-disease interactions; and c) assess the future impact of this workflow on curation and data coverage in ctd. ctd staff developed prototype applications for the document-ranking task in collaboration with members of the information technology center of the mitre corporation and the university of colorado school of medicine's center for computational pharmacology. based on results presented in this report, future studies will focus on implementing our text-mining pipeline into the ctd manual curation workflow.

RESULTS
to assess the extent to which text mining could improve the coverage and efficiency of curation, we performed a baseline study of the current manual curation workflow. this assessment allowed us to identify where in the workflow the prototype could be applied. two prototypes were developed and evaluated using a gold standard of manually curated interactions and relationships from ctd.

baseline analysis of ctd manual curation
to determine areas of the ctd curation process that could benefit from text mining, we established baselines for curation rates and consistency. three ctd biocurators were given an identical set of  <dig> journal articles identified using pubmed along with terms for three different chemicals. biocurators were instructed to curate and record the time they spent on each article. results are reported in table  <dig> 

aall times and rates were recorded or calculated in minutes

bcuration rate = time spent per curated article. sd = standard deviation.

crejection rate = time spent per rejected article.

total data extracted = total number of chemical-gene, chemical-disease, and gene-disease interactions.

ddata extraction rate = macro-average of individual rates of the number of interactions for each curatable article.

on average, biocurators rejected 40% of the  <dig> journal articles as not having curatable data. although the rejected articles contained both chemical and gene terms, they were typically rejected because they did not describe an actual chemical-gene interaction. rejected articles were easily identified and on average, biocurators only invested 7% of their time on them . biocurators averaged  <dig> minutes per curatable journal article, including those for which the full text was consulted. as indicated by the differences in the average time spent per curatable article, curation rates varied by individual biocurator. the large standard deviations were due to the fact that some journal articles had only a few interactions and took only a few minutes to curate, while others had many interactions and took much longer; four articles in this set had between  <dig> and  <dig>  curated interactions. the longest average time spent on an individual article from this set was  <dig> minutes, but the time investment resulted in curation of a substantial amount of data. an average of  <dig> interactions were extracted from each curated article, at an average rate of  <dig>  interactions per minute. these data establish a critical baseline for future studies in which the impact of integrating text-mining tools on the ctd manual curation process will be measured.

inter-biocurator agreement
to determine whether text mining could enhance precision and recall of data curation, we measured a baseline for inter-biocurator consistency by calculating how often biocurators captured the same chemical-gene interactions from the same journal article using the set of  <dig> articles described above.

we performed the analysis in two steps. in step  <dig>  we assessed curator consistency about whether or not to curate a particular article. table  <dig> demonstrates that the curators agreed on the disposition of 86/ <dig> articles  and had an average pair-wise agreement of 85%. in step  <dig>  we compared agreement between each curator and a "gold standard" set of interactions, averaged over all the documents curated by that curator. to prepare the "gold standard," the lead biocurator validated any interaction where curators disagreed, labeling each interaction as correct or incorrect for each curated paper. this set of correctly labeled interactions enabled us to compare each curator's results to the gold standard and to calculate precision and recall on a per-document basis; precision and recall were calculated only for those documents curated by that curator. the results  showed that 91% of the interactions extracted by ctd biocurators were judged by the lead curator to be correct . average recall was  <dig> .

anumbers represent each of the three ctd biocurators.

aonly curated chemical-gene interactions were analyzed ; consequently, these numbers differ slightly from those reported in table  <dig> 

bprecision = correct interactions for individual biocurator/total interactions for individual biocurator.

crecall = correct interactions for individual biocurator/total correct interactions from all biocurators.

df1-measure is the harmonic mean of precision and recall = /. precision, recall, and f1-measure were macro-averaged over the set of articles curated by that curator.

ecalculated using data from three biocurators.

assessing performance of prototype text-mining applications
assessment of the potential value of our prototype text-mining tools focused on: a) effectiveness of identification of "actors" in abstracts of biomedical journal articles where an actor was defined as a chemical, gene/protein or disease of relevance to the ctd project; and b) effectiveness of document ranking to help prioritize journal articles for manual curation.

actor identification
tools for identifying chemical , gene/protein  and disease  terms were identified and integrated into a prototype workflow. experiments described here were compared against a set of manually curated data from  <dig>  journal articles in ctd for  <dig> chemicals. the effectiveness of the text-mining tools was evaluated to determine the proportion of manually curated actors that were successfully identified . overall the tools identified 80% of curated actors  from the  <dig> manually curated set of articles . because the text-mining tools were limited to searching only the titles and abstracts of journal articles, whereas much of the manually curated data derived from the full text, this calculation understated the effectiveness of the tools. consequently, a second ratio, the adjusted actor identification ratio, was developed to account for this added complexity. using the adjusted ratio 92% of the actors that were manually curated from the titles and abstracts of journal articles were identified by the text-mining tools . the average response times of the abner and oscar <dig> text-mining tools were each approximately one second per abstract; the metamap tool was  <dig> minute,  <dig> seconds.

document ranking
a goal of a text-mining tool for ctd was to identify relevant journal articles and prioritize them for manual curation. there were two important factors for gauging the effectiveness of ranking journal articles: a) the extent to which the system identified and ranks relevant documents , more highly than non-relevant documents; and b) the extent to which the system ranked documents that were information-rich more highly than those that were not . these two issues are critical because many times there are more documents available for a given area of interest than can be realistically manually curated. currently, we impose cut-off criteria available through the pubmed query interface . instead we would like to use a more informed ranking method to ensure that we are achieving more complete coverage of curated data in ctd while also optimizing biocurator productivity. mean average precision  was used to quantify the ability of a ranking system to rank relevant documents more highly than non-relevant documents and a correlation coefficient  was used to correlate the ranking of articles with data richness. the text-mining study found that the map was 63% for the baseline case ; this rate is actually quite high and reflects the skill of the ctd biocurators in effectively employing the pubmed search capabilities. nonetheless, the text-mining tools improved significantly upon the default ordering: map increased to 72% for the lucene-based application, and 73% for the rule-based application - an improvement of almost 16% over the baseline case. the correlation between pubmed ordering of documents and the richness of curated interactions was  <dig> . correlations more than doubled with the text-mining tools:  <dig>  for the lucene ranking method and  <dig>  for the rule-based ranking method. figure  <dig> illustrates the important implications of improved ranking on the resulting curated data. when ranked using the rules-based application vs. pubmed ordering , curation of the top 10% of the  <dig>  articles would result in  <dig> more chemical-gene interactions, including  <dig> additional genes,  <dig> additional chemicals and  <dig> more diseases.

the caveat to these results is the tools "overtagged" the articles: only 36% of the tagged actors participated in curated interactions ; altogether, 64% of the tagged terms had no curatable interactions associated with them; we describe these as 'false positive actor mentions'. there are a number of reasons for these false positives, including legitimate mentions of genes/disease/chemicals that are not involved in a curatable interaction in the paper; gene names that are synonyms of chemicals ; and many short names or symbols  that are synonyms of genes  and chemicals tellurate) and are confusable with commonly used adverbs, prepositions or conjunctions in english. in order to create a tool that curators can productively use to extract interactions from articles, it will be important to reduce these false positive actor mentions.

indomethacin case study
based on the promising results for actor identification and document ranking described above, we evaluated the potential for our rule-based text-mining tool to identify and rank a another test set of articles for curation. to do this, we retrieved data from medline for indomethacin, a chemical for which we had previously curated  <dig> journal articles. this time we used a broader pubmed query to evaluate the performance of our text mining tools in comparison with our existing curated data for this chemical. we identified  <dig>  journal articles of which our  <dig> curated articles were a subset. based on identification of actors by our text-mining actor recognition tools, we filtered the  <dig>  results to a set of  <dig> journal articles that contained gene/protein actors not currently associated with indomethacin in ctd. these  <dig> journal articles were then ranked and reviewed by our lead biocurator who determined that  <dig>  articles contained curatable data for indomethacin. notably, there was a strong correlation between the ranking of these articles by the text-mining tools and whether the articles contained curatable data . this correlation was not seen with our previous method for ordering articles for curation, namely the descending order of pubmed identifiers, which typically reflect publication date. overall, map improved from 54% under the baseline case to 68% under the rule-based case. subsequent curation of these  <dig> articles indicated that text mining effectively identified articles with novel data for indomethacin including  <dig> genes,  <dig> chemical-gene interactions, and  <dig> diseases. these results have important implications for future implementation in our curation process regarding the potential of text mining to help assess the existing scope of curated data in ctd, identify novel data for curation and inclusion in ctd, and effectively prioritize documents for curation.

discussion and 
CONCLUSIONS
a major goal of ctd is supporting development of novel hypotheses about the complex relationships between chemicals, genes/proteins and diseases. in most cases, such complex relationships have not yet been elucidated. to support hypothesis development we have taken a reductionist approach by curating individual relationships and integrating them in ways that have the potential to reveal previously unidentified, complex connections. as with other manually curated resources, these efforts are challenged by the increasing scope and volume of data being published. in this study we explored whether we could find a solution that would merge manual curation, which is highly accurate but time consuming, with text mining, which is scalable but error-prone  <cit> .

there are still relatively few examples of working tools inserted into a biocuration pipeline, despite a number of assessments of text mining applied to biomedical curation  <cit> . the textpresso software  <cit>  has been applied successfully to a number of model organism databases, as well as to other kinds of curated databases. textpresso uses multiple ontologies to create lists of terms that can be identified in running text. users can construct their own search using these ontologies. other tools in active use are prominer  <cit>  and rlims-p  <cit> , which extract from articles gene/protein terms and phosphorylation events, respectively. the european bioinformatics institute's whatizit software  <cit>  provides, among other things, a retrieval/search engine for pubmed abstracts, identifying molecular biology terms in a number of categories and linking them to publicly available databases. there are other similar special purpose search tools, such as ihop  <cit>  or chilibot  <cit>  that focus on identifying specific types of biological entities  and their relations. however, none of these solutions addressed the specific needs of the ctd curation workflow.

we report here a novel approach to building a text-mining solution for our publicly available database that began with establishing baseline metrics for our current curation process. from the results of this analysis we identified areas in which text mining could add value to the ctd data curation workflow. we determined that identification of journal articles from medline for potential curation yields a large percentage  of articles that are not curatable, but that rejection of these journal articles consumed a relatively small percentage of biocurator time . these results suggest that biocurator identification of relevant journal articles is efficient; however, more effective identification and ranking of relevant journal articles by a text-mining application would further maximize productivity and increase the quantity of data curated in ctd. we performed inter-biocurator agreement studies to determine how well biocurators agreed when curating an article, to provide an upper bound for performance of text mining. we calculated that precision for curated actors was high  and recall was lower . this is consistent with results reported by camon et al.  <cit> , where an inter-curator agreement study for go annotation of proteins showed high precision , but variation in the depth or exhaustiveness of curation, leading to missing annotations and lower recall .

based on our curation needs assessment, we developed two prototype text-mining applications. one application was built using the lucene search engine api  <cit>  whereas the other was rule-based. both applications integrated a set of publicly available actor identification tools for chemicals, genes/proteins and diseases. we leveraged the large corpus of curated data from ctd to construct a gold standard data set that included over  <dig>  curated actors from  <dig>  journal articles describing  <dig> different chemicals. this gold standard data set was used to examine the potential value of these text-mining applications to enhance ctd curation.

the two performance areas of particular interest to us were: a) how effectively the actor recognition tools identified terms of interest  in journal articles; and b) how reliably the applications could rank documents such that ranking could assist with prioritizing articles for manual curation. actor identification was very effective , particularly when adjusted for actors that seemed to be found only in the abstracts of journal articles from our control data set . interestingly, text mining and manual curation share many of the same challenges, not the least of which is gene name identification and inconsistency in nomenclature use  <cit> . given these challenges, our actor identification results were particularly gratifying.

the new document ranking strategies showed great promise for effectively identifying information rich, relevant journal articles. based on ctd curation experience, we identified a range of criteria against which to rank documents. both ranking strategies effectively improved the ranking over the baseline case, although our rule-based application slightly outperformed lucene in every metric. in addition, the rule-based application enabled us to exercise greater control over document scoring and ranking because it was entirely customized for ctd curation unlike lucene, which is customizable to an extent, but was designed to be general-purpose. similar results were found in a new test case for indomethacin journal articles, where we demonstrated that the text-mining applications ranked articles with curatable data more highly that those without curatable data. this correlation is a significant finding because it shows that these tools will allow us to cast a wider net when identifying potential journal articles for curation because we will be able to prioritize articles for curation more knowledgeably and maximize the productivity of biocurators by presenting them with a subset of information-rich journal articles that are more likely to contain curatable data . specifically, our rules-based application will enable us to more effectively identify information-rich articles and thereby capture more data from an equivalent number of articles. effective actor identification will also enable better assessment of our data coverage for particular chemicals, genes, or diseases and consequently identify data that may be missing or in need of updating in ctd using an approach similar to our indomethacin study. finally, although we might maximize information retrieval by mining the full text of journal articles rather than just abstracts, our indomethacin results corroborate a recent report indicating that reviewing abstracts as an indexing unit may be comparable to reviewing the full text of articles  <cit> . therefore, at least for ranking, attempting to overcome the many additional challenges associated with mining full-text articles may not yield substantially better results than mining abstracts.

we are greatly encouraged by the results of our prototype text-mining applications. our results demonstrate that it is possible to integrate "off-the-shelf" tools to provide significant value to a biocuration workflow. we applied a method based on inter-biocurator agreement of manual annotation to identify where to insert text-mining tools into the curation workflow to maximize pay-off. we were able to assemble quite rapidly a text-mining pipeline by using freely available entity recognition software; we developed two ranking strategies and evaluated their performance. we estimate that the actual tool acquisition and integration took only a few staff weeks; the bulk of the time on the project was spent in creation of a baseline for comparison, and in evaluation of the performance of the two ranking approaches . while we chose entity recognition systems based on the specific ctd application, we believe that this approach can be extended both to handle other parts of the ctd curation pipeline, and to other curation applications. to further improve our results, we will evaluate the impact of optimizing weighting criteria using multivariate analysis; modifying requirements for retrieving actor terms ; and using additional criteria including inclusion of ctd action terms in the search for actors, and extending analysis to the full text of journal articles. we will also look carefully at certain aspects of the ebi's whatizit software. although whatizit employs all of the major recognition tools that we selected for integration into our prototypes, we will specifically evaluate their disease tools in an attempt to mitigate the extended response times we experienced during metamap processing.

based on our results we are planning modifications to our existing manual curation process that are illustrated in figure  <dig>  medline will continue to be searched using pubmed for priority chemical terms and their synonyms. resulting journal articles will be text-mined using actor identifiers for chemicals, genes and diseases, as well as action terms. these actors will be cross-referenced with corresponding vocabularies in ctd. corroborated actors will be highlighted, and journal articles will be ranked and loaded into the curation database. biocurators will review and curate highlighted journal articles using an online curation application with real-time quality control measures. curated data will be loaded into our production database on a real-time basis, and made available to the public monthly. new baseline assessments will be made to accurately determine the impact of incorporating text mining with the ctd curation process.

this report provides a compelling demonstration that text mining for the biological literature has matured to the point where it is feasible and cost-effective to insert text-mining tools into the curation pipeline to improve both curation throughput and quality. our approach, consisting of baseline creation, tool integration and evaluation can be readily generalized to other applications both within ctd and for other curated databases.

