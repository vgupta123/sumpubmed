BACKGROUND
conceptual analysis is the process of mapping from natural language texts to a formal representation of the objects and predicates  meant by the text. the history of attempts to build programs to do conceptual analysis dates back to at least  <dig>  <cit> . recent advances in the availability of high quality ontologies, in the ability to accurately recognize named entities in texts, and in language processing methods generally have made possible a significant advance in concept analysis, arguably the most difficult and general natural language processing task. here we report on the design, implementation and several evaluations of opendmap, an ontology-driven, integrated concept analysis system that significantly advances the state of the art. we also discuss its application to three important information extraction tasks in molecular biology.

information extraction  efforts are widely acknowledged to be important in harnessing the rapid advance of biomedical knowledge, particularly in areas where important factual information is published in a diverse literature. in a recent plos biology essay rebholz-schuhmann  <cit>  argued, "it is only a matter of time and effort before we are able to extract facts  automatically. the consequences are likely to be profound." existing examples include extraction of information about gene-gene interactions  <cit> , alternative splicing  <cit> , functional analysis of mutations  <cit> , phosphorylation sites  <cit> , and regulatory sites  <cit> . the primary significance of opendmap to these efforts is that it leverages the large-scale efforts being made in biomedical ontology development, such as the open biomedical ontologies foundry   <cit> .

logical representations of reality, such as those built on the obo foundry, use a set of predicates that formally describe properties of, or relationships among, objects. predicates are defined with a specific number and type of admissible arguments. for example, the predicate expresses might be specified to take two arguments, a gene and a cell type, meaning that the specified gene is expressed in all normal cells of the specified type. such predicates can also be related to each other through abstraction  and packaging  hierarchies, as done in the obo foundry. the semantics defined by the predicates and hierarchies in such ontologies provide a powerful tool for natural language processing.

independently constructed ontologies have played at best a modest role in prior natural language processing systems. guarino  <cit>  characterizes various uses of ontologies in information systems: only systems that use an ontology at run time  to explicitly represent the domain knowledge exploited by the system qualified for what guarino called an "ontology-driven information system proper." to our knowledge, opendmap is the first system developed to exploit a community consensus ontology as the central organizing principle of an information extraction system; for example, none of the systems that participated in the  <dig> trec genomics evaluation for recognizing instances of gene ontology terms in text  <cit>  meet the guarino definition. other language processing systems have used either small, ad hoc conceptual representations developed specifically for the application, or structured linguistic resources, such as wordnet  <cit> , which do not meet the logical requirements for an ontology. while the implementation reported below exploits only a small portion of the obo foundry, and the crucial relationship ontology component of the foundry is still in an early stage of development, the organizing principles of opendmap generalize straightforwardly.

the metamap system  <cit>  identifies biomedical concepts from free-form textual inputs and maps them to entries in the unified medical language system  metathesaurus; semrep  <cit>  is a related system that maps to predications drawn from the umls semantic network, and semgen  <cit>  is another related system that is focused on mapping to umls terms relevant to the etiology of genetic disease. these systems and their extensions have been used to extract semantic relationships relevant to pharmacogenomics  <cit>  and to compare alternative sources of information  <cit> , among other applications. opendmap is like metamap and its descendents in that it can only produce output drawn from a predefined semantic representation. the main difference is that metamap, semrep and semgen are structured as traditional nlp systems, with a lexicon that enumerates possible concepts that might be associated with a word or phrase. multiple possible mappings are returned, with rankings. opendmap provides an alternative method of organizing knowledge about language, so that each concept has associated with it a set of patterns that describe how that concept can be realized in language; there is no explicit lexicon.

to appreciate the differences between opendmap and previous work in biomedical text mining, it is also useful to contrast its handling of syntactic structure and of semantic content with other systems. at one end of the spectrum are systems that employ essentially asyntactic representations. early in the modern period of genomic natural language processing, some such systems were able to achieve significant  results using techniques based on text literals only. these include  <cit> . one line of subsequent work has attempted to increase the coverage of these early systems, which utilized manually-built patterns, by automatically acquiring considerably larger sets of patterns – see, for example, huang et al.  <dig>  <cit> . another line of subsequent work has focused on adding a modest, but still useful, level of linguistic abstraction by explicitly including either lexical categories , word stems, or both  <cit> . these systems were essentially agrammatical; in contrast, opendmap utilizes a classic form of "semantic grammar," freely mixing text literals, semantically typed basal syntactic constituents, and semantically defined classes of entities.

although opendmap is capable of utilizing full syntactic parses, the patterns for the three separate tasks discussed in this paper utilize primarily shallow syntactic parses . it remains to be seen what depth of syntactic parsing is useful in biomedical text mining. some early systems explored full parsing  <cit> , but they were not generally fruitful, and typical systems have employed at most shallow parsing  <cit> ; only recently has productive attention returned to syntactically ambitious approaches to biomedical text  <cit> , much of it taking a dependency-based, rather than a constituent-based, approach.

all of the systems discussed thus far have in common the fact that they employ some notion of explicit patterns, be they agrammatical, syntactic, or semantic. in a separate line of work, patterns are entirely implicit – that is, they exist only to the extent that they are captured by orthogonal features. this work approaches relation extraction as a classification problem; a classic example is the work of craven and kumlein  <dig>  <cit> . bunescu et al.  <dig>  <cit>  presents a detailed analysis of a number of classification-based approaches; the state of the art is characterized by the participants in the recent biocreative protein-protein interaction shared task  <cit> .

opendmap has been applied in three domains: protein transport, protein-protein interaction and the expression of a gene in a particular cell type. the three application domains are independently significant. protein transport, the directed movement of proteins from one cellular compartment to another, is a broadly important biological phenomenon. although protein subcellular localization information is centralized , information about transport is not. protein transport information is published throughout the scientific literature, but no previous method was able to capture it systematically. protein-protein interaction extraction has been the subject of dozens of systems . widely used web resources such as ihop  <cit>  and chilibot  <cit>  are based entirely on automated extraction of protein-protein interactions from text. this task was used in the biocreative community evaluation, described below. the third application area, extraction of assertions that a particular gene is expressed in a particular cell type, is of significance since it appears to be the predicate found most frequently in the biomedical literature; a form of the verb "express," usually its nominalization "expression," appears in nearly 20% of ncbi's generifs  <cit> .

the protein transport task is illustrative of another distinguishing aspect of the opendmap approach: it provides mechanisms for handling relationships involving more than two entities. note that the protein transport predicate has at least three arguments: what protein is transported, from where, and to where . although some linguistic expressions of the concept may elide an argument, the predicate itself inherently describes a greater than binary relationship. wattarujeekrit et al.  <cit>  and cohen and hunter  <cit>  present evidence that many important predicates in biomedicine require more than two arguments. however, most previous efforts at extracting relationships from biomedical text have addressed exclusively binary relationships. geneways  <cit>  and rlmps-p  <cit>  are the only other biomedical ie systems of which we are aware that extracted greater than binary relationships, and neither is ontology-driven.

assessing the accuracy of an information extraction system is a very labor-intensive activity. in order to identify information that could have been extracted, but was not , a person must go through a large volume of text to determine all of the relevant assertions. to estimate the reliability of these manually derived assertions, at least two people must complete that task to assess inter-rater reliability. once such data is used for one evaluation and system developers have seen it, further use of the data will generate upwardly biased accuracy estimates as system developers fit their systems to it. for these reasons, large-scale community evaluations of information extraction systems are particularly important. the second critical assessment of information extraction in biology,   <cit> , community evaluation included a test of systems designed to extract human protein-protein interaction information from the full texts of hundreds of journal articles, called the ips task. human curators from the intact database  <cit>  manually extracted interaction assertions from these articles using the same curatorial standards as for the database. the results produced by human experts were compared to the results submitted from  <dig> systems developed by laboratories around the world, providing the best current assessment of the accuracy of protein interaction information extraction systems. the performance of opendmap on the protein interaction task was evaluated as part of this shared task. more limited evaluations of the accuracy in the other applications are also reported in the results section.

the accuracy of an information extraction system depends on the genre of texts on which it operates  <cit> . this report demonstrates the application of opendmap to full texts of scientific journal articles, to medline abstracts, and to generifs . generifs are particularly attractive targets for information extraction, due to their roughly sentential length , breadth of coverage, manual preselection for relevance, and association with at least one normalized gene reference. despite these attractive features, this is the first report of an information extraction system targeting them.

RESULTS
opendmap information extraction systems were produced for extracting protein transport assertions , protein-protein interaction assertions  and assertions that a gene is expressed in a cell type . each of these systems was run over all abstracts in medline as of june  <dig>   <dig>  producing a total of  <dig>  transport instances,  <dig>  interaction instances and  <dig>  expression instances. these results are provided in rdf format in the additional files  <dig>   <dig>   <dig>   <dig> 

one particularly striking result is the diversity of journals from which these assertions were mined. the transport relationships were extracted from  <dig>  different journals; the interaction relationships from  <dig>  different journals; and the expression relationships from  <dig>  different journals. a total of  <dig>  unique journals contributed to these results, nearly 40% of the journals indexed in medline each year .

for the biocreative evaluation, the interaction system was run on the full texts of all of the  <dig> articles in the test set, producing  <dig> interaction assertions. performance was averaged per article, since a few articles had a very large number of interactions and would have dominated a per assertion calculation. opendmap's average f-measure of  <dig>  was 10% higher than the next best scoring system, and more than three standard deviations above the mean performance. opendmap's recall was similar to the other high scoring systems; its advantage arose from being substantially more precise , achieving an average precision of  <dig> , more than 20% better than the next best system. due to intact's curation criteria, which require clear experimental evidence for an interaction in the text, these results are quite conservative. many "false positives" were in fact assertions of interactions, but fell short of the evidential requirements for intact curation.

a manual evaluation of the performance of the protein transport recognition system was based on all  <dig> generifs containing a form of the word "translocate" . since transport is a greater than binary relationship, the extraction was only counted as correct if all of the components extracted matched the human annotation. for that strict criterion, opendmap achieved precision of  <dig>  and a recall of  <dig>  . if incomplete extractions are counted as correct, precision is unchanged at  <dig>  and recall rises to  <dig>  . a substantial proportion of the errors were due to imperfect recognition of proteins; if opendmap is given correct protein identifications as inputs, precision is  <dig> , strict recall is  <dig>   and incomplete recall is  <dig>  .

a manual evaluation of the performance of the expression recognition system was based on  <dig> generifs containing a form of the word "express," . open dmap had a precision of  <dig> , but missed many statements that annotators identified as expression assertions, achieving a recall of only  <dig>  . a substantial portion of these errors were due to imperfect recognition of gene names; if opendmap is given correct gene identifications as input, precision is  <dig>  and recall is  <dig>  . many other failures to identify expression assertions were related to coordination; the test set had an average of more than two expression assertions per sentence, but the ie system extracted only about  <dig>  assertions per sentence.

discussion
as demonstrated by its performance in the community evaluation, opendmap advances the state of the art for extracting protein-protein interaction predications from the full texts of biomedical research articles. furthermore, this level of performance appears to generalize to other information extraction tasks, including extracting information about predicates of more than two arguments.

there are several reasons why opendmap exhibits better performance than any other biomedical information extraction system to date. opendmap is an extension of the direct memory access parsing  paradigm described in  <cit>  and  <cit> . three innovations distinguish the present work from those prior efforts. first, the ontology component of opendmap is independent of the rest of the system. the knowledge representation component is the well-established, open source protégé ontology development system  <cit> , and opendmap concept analyzers can be associated with any ontology compatible with protégé, for example, the obo foundry. second, opendmap is fully integrated with the open source unstructured information management architecture,   <cit> , which allows the results of any text processing application interfaced to uima to be exploited by the opendmap system. as demonstrated below, this mechanism facilitates the use of many external language processing systems, including tokenizers, sentence boundary detectors, entity recognition systems, and syntactic parsers. since the inputs and outputs of each system are mapped by uima to a common annotation structure accessed by opendmap, the use, comparison and combination of various approaches to language processing can all be fully integrated into opendmap patterns. the third innovation in the opendmap system is an expanded pattern language for specifying how concepts can be expressed in text. the pattern language not only allows specifications of mixtures of any concepts available from either the ontology  or the results of uima text processing , but it also has new features that allow more flexible concept ordering than previous dmap analyzers .

the intimate connection between the ontology and the natural language processing system provides two significant advantages over prior information extraction systems generally. first, the output of the information extraction system is always constructed from elements of the ontology, ensuring that the knowledge representation is grounded with respect to a carefully constructed model of reality. in contrast, the outputs of most natural language processing systems are grounded only in substrings of text, not normalized to any model at all. progress in normalizing biological entities recognized in text to specific database identifiers  <cit>  has made the output of text processing systems much more valuable. mapping the properties and relationships extracted to a community ontology similarly provides a significant increment in the value of the output from text processing systems.

the second advantage of the opendmap approach is that all of the knowledge used by the system to recognize concepts is structured by the ontology. in contrast, the nearly universal alternative approach is to embody knowledge of language into a lexicon, which associates individual lexical items with their possible semantic interpretations. in the opendmap approach, information about which concepts are potentially relevant to the analysis of a particular text passage straightforwardly places limits on the linguistic knowledge relevant to analyzing that passage. this approach finesses many difficult ambiguity resolution problems faced by lexicon-driven systems, since these limits on the knowledge applied to conceptual analysis prevent many multiple interpretation problems from arising at all. for example, the string "hunk" refers to a cell type , a gene , and the general english word meaning a large piece of something without definite shape. a traditional, lexicon-driven system would have an explicit method for assigning the correct word sense to any occurrence of the string "hunk." however, opendmap patterns specify expectations of semantic classes ; if it is possible to construe a string as an instance of an expected class, the pattern matches. the fact that there might be possible alternative interpretations of the matching string has no consequence, and no explicit ambiguity resolution step is necessary. ambiguity is a leading cause of errors in text processing systems, and this approach is one of the contributing factors to opendmap's superior performance. our top-down approach to restricting possible interpretations does not address all problems due to ambiguity in language; for example, errors in preprocessing systems  are not effected.

the use of uima greatly facilitates the incorporation of various applications as input to opendmap. the outputs of nlp tools integrated into the system are described by the extensible uima type system. in the case that a new type of information is produced by a preprocessor, opendmap patterns would have to be modified to take advantage of the new type of information available. for example, the first time an external cell type tagging system is added, the uima type of the result of that processor must be linked to a cell-type concept in an opendmap ontology in order for it to be used in patterns. however, if a new nlp tool produces a uima output type that has been used by opendmap previously, then no changes in the ontology or patterns are needed.

we believe that the outputs of information extraction systems are not likely to useful until the f-score  is greater than about  <dig>   <cit> , so the various sources of error in these systems must be addressed. a significant cause of errors in the opendmap system as evaluated is incorrect identification of gene and protein names. the uima architecture makes it trivial to adopt and exploit better gene/protein recognition systems as they are developed. the best gene name identification and normalization systems from the biocreative assessment achieved f-scores greater than  <dig> , significantly above the ~ <dig>  f-score of the abner system  <cit>  used by opendmap to achieve the reported performance. use of such a system should improve the performance of opendmap.

error analysis of the false positives in the transport data set indicates that more than 80% are due to errors in the syntactic analysis. for example, in the sentence "rho protein regulates the tyrosine phosphorylation of fak through translocation from the nucleus to the membrane," the subject of the translocation was incorrectly identified as fak  by the stanford parser. that parser was developed for general english rather than biomedical text, so using specialized syntactic analysis systems may improve the precision of opendmap. remaining problems in false positives are due to problematic tokenization, failures to properly resolve anaphoric reference, and, rarely, negation. false negatives are due to gaps in concept recognition patterns, more than half of which arise from a failure to properly handle coordinated clauses and conjunctions. addressing these issues remains an open area of research.

another issue was that the stanford parser was too slow to use in the application of the transport system to all of medline, so it wasn't run. opendmap ignores aspects of patterns that require inputs that aren't present, so the patterns that contained syntactic dependencies did not have to be altered. these syntactic constraints are important for accuracy, however. tested on the gold standard set for the system without the parser precision drops to  <dig> , while strict recall remains largely unchanged, rising to  <dig> .

CONCLUSIONS
despite opendmap elevating the state of the art for biomedical information extraction significantly beyond previous levels, error rates remain high. in the most challenging biocreative task, finding curatable assertions in full text documents, only about 29% of the relevant assertions were found, and only about 39% of the extracted assertions were completely correct. such error rates mean that automatically generated databases cannot replace manual curation efforts. however, the evidence is quite clear that manual curation cannot keep up with the rate of data generation  <cit> . the surprisingly large number of journals that contained information relevant to these three ie tasks suggests that the temporal approach taken in  <cit>  may actually underestimate the severity of the problem.

although the outputs produced by large-scale ie systems are not yet suitable for producing factual databases for direct use by biomedical researchers, the current level of performance provides two important facilities to the research community. first, the results of these efforts can be used to significantly increase the efficiency of manual curation efforts. each extracted assertion is tied to a specific text, which can be used to direct the attention of manual curators both to relevant documents and to specific relevant passages within a document. effective integration of ie results into curatorial workflows will require the development of new tools. opendmap developers are working with curators at intact to address these issues. the open source availability of opendmap will facilitate the work of others addressing this issue as well. the second important use of the sorts of results that ie systems are currently able to generate is in statistical integration with multiple sources of noisy data, such as those described in  <cit>  and  <cit> . as demonstrated in the latter, the proper addition of even noisy data from the literature substantially improves the quality and coverage of protein-protein interaction networks for several species.

