BACKGROUND
a large number of methods for low-level analysis of microarray data have been developed, but the relative merits of these methods are generally not easy to assess  <cit> . analytical methods are commonly motivated by theoretical properties or how well they perform on simulated microarray data  <cit> . neither approach is fully satisfactory, since they rely on model assumptions that are not necessarily supported by empirical studies. for real data, the true values are not known and therefore cannot be characterized and used for evaluation. data from spike-in experiments, where the mrna-ratios of a set of artificial clones are known, can be used to determine the relative merits of a set of analysis methods  <cit> . the design of a spike-in experiment needs to be based on assumptions of how real microarray data behave. however, these assumptions are generally less restrictive than the ones needed for simulating microarray data. the presented evaluation study used eight in-house produced spike-in microarrays  with approximately  <dig>  spots,  <dig>  of which were spiked at different concentrations, i.e., differentially expressed  genes. in comparison with the spike-in study performed by qin et al.  <cit> , our spike-in array encompasses more de-genes, allowing us to obtain reliable estimates of the methods' abilities to detect de-genes .

microarray studies are often used to screen for de-genes. in this case, the sensitivity and specificity of the study are of interest. the receiver operating characteristic curve  shows the relationship between sensitivity and specificity and can be used to characterize the classification properties of a study  <cit> . alternatively, pre-processed microarray data are sometimes used in so-called high-level analyses . in this case, the sensitivity and specificity of detection is no longer the most appropriate framework for evaluation. rather, the properties of the normalized log-ratios need to be understood.

in this article,  <dig> normalization procedures were evaluated. we simultaneously evaluated three filtration methods, two techniques for background adjustment, seven scanning procedures, two ways of dealing with negative intensities, and four censoring approaches. the majority of these methods are well established, but we also introduced some novel ones: partial filtration handles data from spots not properly identified by the image analysis software, c-spot inclusion handles negative background adjusted intensities, and censoring moderate extreme ratios caused by weakly expressed genes.

RESULTS
the general model
we consider a two-channel cdna-microarray experiment with a reference and treated channel. let μ denote the true gene expression level of a gene. the raw intensities cannot be directly used to identify de-genes, since they are influenced by systematic variation. normalization aims to remove systematic variation and create normalized log-ratios that are used to calculate test-statistics that rank the genes according to how likely they are to be de. genes with test-statistics above a user defined cut-off value are classified as de. for each gene and array the normalized log-ratio should be an observation of the true log-ratio of interest, i.e. log <dig> . the methods used for transforming raw data to normalized log-ratios constitute a normalization procedure. we consider raw data generated from arrays that have been scanned at four laser settings, where the normalization procedures involve filtration, background adjustment, merging data from different scans, channel normalization, and censoring .

design of spike-in microarray arrays
in a spike-in experiment, control clones  are printed on an array. we will refer to control clones as genes even though they do not correspond to actual genes. prior to labeling, the biological samples are spiked with control genes of known concentration. all other experimental steps are identical to a standard two-channel microarray experiment. the evaluation study presented in this paper used an in-house produced cdna-array , consisting of  <dig> non-differentially expressed  genes and  <dig> de-genes from the lucidea universal scorecard , where each gene was spotted  <dig> times. the nde-genes were spiked with different rna-concentrations ranging from zero to very high concentrations. the de-genes were either three-fold or ten-fold up- or down-regulated, and were spiked with low or high rna-concentrations; see figure  <dig>  technical details about array production and experimental protocols are described in the methods section.

methods and tools for evaluation of spike-in microarray data
an analysis involving image analysis, normalization, and a test generates normalized log-ratios and test-statistics . a gene is classified as de if its test-statistic is above a user determined cut-off value c. the experiment's sensitivity is the proportion of de-genes that are correctly classified. the false positive rate  is the proportion of nde-genes that are falsely classified, while the false discovery rate  is the proportion of nde-genes among the genes classified as de.

the analyzed microarray data are characterized by the properties of the normalized log-ratios and their classification properties . the former is characterized by the roc-curve, describing the relationship between the sensitivity and the fpr. if the purpose is to screen for de-genes it is sufficient to consider the classification properties. however, unbiased estimates of the normalized log-ratios are important in order to understand the biology and are desirable when combining results from different techniques . furthermore, if the bias depends on the genes' mrna-concentrations , then results from high-level analyses such as clustering or classification can be misleading. we propose that the following properties should be considered when evaluating analysis methods:

i. high sensitivity at the user acceptable fdr.

ii. the expected values of the average normalized log-ratios of de-genes should be close to the true log-ratios, and the bias should not depend on the genes' mrna- concentrations.

the relative importance of these properties depends on the purpose of the experiment.

the properties of the normalized log-ratios can be summarized with estimates of the overall bias and standard deviation. consider an experiment with r de-genes, where the kth gene is replicated nk times and has the true log-ratio. the reflected bias and the selected bias are measures of property ii. the reflected bias is estimated by

b^de=∑k=1r∑i=1nksignnde,
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacuwgibgygaqcamaabaaaleaacqwgebarcqwgfbqraeqaaogaeyypa0zaasaaaeaadaaewbqaamaaqahabagaem4camnaemyaakmaem4zacmaemoba42aaewaaeaacqqhpowvdawgaawcbagaem4aasgabeaaaogaayjkaiaawmcaaawcbagaemyaakmaeyypa0jaegymaedabagaemoba42aasbaawqaaiabdugarbqabaaaniabgghildgcdaqadaqaaiqbd2eanzaarawaasbaasqaaiabdugarjabdmgapbqabagccqghsislcqqhpowvdawgaawcbagaem4aasgabeaaaogaayjkaiaawmcaaawcbagaem4aasmaeyypa0jaegymaedabagaemocaihaniabgghildaakeaacqwgubgbdawgaawcbagaemiraqkaemyraueabeaaaagccqggsaalaaa@59aa@

where m¯ki
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacuwgnbqtgaqeamaabaaaleaacqwgrbwacqwgpbqaaeqaaaaa@30cd@ are the average normalized log-ratios taken over all arrays, and where nde is the total number of de-spots on the array. the selected bias is similarly estimated as the reflected bias albeit only genes classified as de are used to estimate the bias. for some problems, the selected bias may be a more relevant measure than the reflected bias. in order to determine if the average normalized log-ratios have a strong linear relationship to the true log-ratios, it is necessary to study the bias of the de-genes individually. the overall standard deviation of the de-genes can be estimated by

s^de=∑k=1r∑i=1nk2nde−r,
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacuwgzbwcgaqcamaabaaaleaacqwgebarcqwgfbqraeqaaogaeyypa0zaaoaaaeaadawcaaqaamaaqahabawaaabcaeaadaqadaqaaiqbd2eanzaarawaasbaasqaaiabdugarjabdmgapbqabagccqghsislcuwgnbqtgaqegaqeamaabaaaleaacqwgrbwaaeqaaagccagloagaayzkaawaawbaasqabeaacqaiyagmaaaabagaemyaakmaeyypa0jaegymaedabagaemoba42aasbaawqaaiabdugarbqabaaaniabgghildaaleaacqwgrbwacqgh9aqpcqaixaqmaeaacqwgybgca0gaeyyeiuoaaoqaaiabd6gaunaabaaaleaacqwgebarcqwgfbqraeqaaogaeyoei0iaemocaihaaawcbeaakiabcycasaaa@52e7@

where m¯¯k
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacuwgnbqtgaqegaqeamaabaaaleaacqwgrbwaaeqaaaaa@2f89@ is the average taken over all arrays and replicates.

description of the data analyses used in the evaluation study
eight hybridized spike-in lucidea arrays were scanned at four settings : 70/ <dig>  80/ <dig>  90/ <dig>  and 100/ <dig> , where the numbers were percentages of maximum values. these scans are referred to as the  <dig>   <dig>   <dig>  and  <dig> scans. the pre-processing procedures considered in this work involved seven consecutive steps: image analysis, filtration, background adjustment, merging data from several scans, channel adjustment, censoring, and calculations of test-statistics . the analyses were carried out using scanarrayexpress  <dig>  , bioconductor  <cit> , the aroma package  <cit> , and the in-house s-plus library umeasamed. the evaluations were carried out using the in-house s-plus library edma  <cit> .

image analysis
the standard way to conduct image analysis is to analyze the two images obtained from one scan together, so that the spots are equally defined for both channels. we propose an alternative method, the combined image analysis where the scan's images are analyzed with images from a second scan , so that the spots are equally defined for all four images. this approach is possible since scanarray express allows four images to be analyzed simultaneously. all the  <dig> evaluated analyses used combined image analysis. the median of the spots' pixel values was used to calculate the intensities. for one array, additional image analyses were done in the standard way using both scanarrayexpress  <dig>  and genepix  <dig>  ; the software generate "flags" indicating whether the spots are properly identified  <cit> . the percentage of so-called not-found spots was used to characterize the different image analyses . combined image analysis using additional images from a higher scan will improve spot finding and thereby improve the quality of the data.

filtration
intensities from not-found spots  were treated in three different ways:

i. complete filtration: the intensities were treated as missing values.

ii. partial filtration: the intensities were treated as missing values during normalization, but prior to calculating test-statistics the spot's log-ratios were set to zero. in the special case when all arrays generated not-found spots, the gene was removed from the experiment.

iii. no filtration: the intensities were treated as intensities of found spot.

complete filtration is commonly used while partial filtration is a novel method. the idea behind partial filtration is that spots called "not found" commonly arise from genes that are not expressed in either channel, and therefore can be regarded as nde-genes.

background adjustment
the analyses either did not apply any background adjustment, or applied the standard background adjustment removing the local background intensities from the observed intensities. background adjustment divided the spots into three groups: a-spots, where both the reference and the treated background adjusted intensities  were positive, b-spots where either the reference or the treated ba-intensity was negative, and c-spots where both the ba-intensities were negative.

merging data from several scans
scans generated 16-bit images and, since the median was used to calculate the spot intensities, all intensities were integers between  <dig> and  <dig> - <dig>  henceforth, intensities equal to the maximum value will be called saturated. one common approach to deal with saturation is to adjust the scanner settings such that only a small fraction of the intensities will be saturated. two alternative approaches, restricted linear scaling  and the constrained model   <cit> , combine intensities from two or more scans in order to expand the linear range of the experiment. rls is a slight modification of the algorithm suggested by dudley etal.  <cit> . seven scanning procedures were considered:

i. using data from the  <dig> scan.

ii. using data from the  <dig> scan.

iii. using data from the  <dig> scan.

iv. using data from the  <dig> scan.

v. rls using combined data from the  <dig>   <dig>  and  <dig> scans .

vi. rls using combined data from the  <dig>   <dig>  and  <dig> scans .

vii. cm using data from all four scans with the  <dig> data as baseline.

the  <dig> scan can be thought of as a standard scan since it was the highest scan where only a small fraction  of the intensities were saturated. from a practical point of view, the cm and rls procedures demand more scanning and image analyses. in addition, databases created for microarray data storage do not commonly support data from several scans, e.g., base  <cit> . the storage problem can usually be solved by creating additional software  <cit> .

channel adjustment
the print-tip lowess normalization  <cit>  was used to remove the systematic differences between channels. for the lucidea experiment, only data from nde-genes were used to fit the lowess curves. however, data from all a-spots were adjusted. clearly, this approach is an idealization, since the de-genes in a real experiment affect the estimated curves. however, if the proportion of de-genes is small, and if the true log-ratios are symmetrically distributed around zero, then this effect is small. for two analyses different proportions of de-genes were used to fit the lowess curves. for these analyses, inclusion of a small number of de-genes had marginal effect on the analyses' sensitivities and biases . intensities from b-spots were treated as missing values, while intensities from c-spots were treated in two different ways:

i. removed: the c-spots' intensities were treated as missing values.

ii. included: the c-spots' log-ratios were set to zero prior to calculating the test-statistics.

the rationale for including c-spots is again that these spots commonly arise from genes that are not expressed in either channel and therefore have mrna log-ratios equal to zero.

censoring of low intensities
a-spot intensities were censored such that all intensities below a user-defined censoring value λ were increased to this value. in this work the censoring values  <dig>   <dig>   <dig>  and  <dig> were used. in practice, using minimal censoring  is equivalent to applying no censoring at all. the idea behind censoring is to moderate the variance of the weakly expressed genes. it still remains to determine how to select an optimal censoring value. in this paper, background adjustment is a spot level procedure whereas censoring is an adjustment applied globally to an array.

test-statistics
the statistics generated by the b-test were used as test-statistics.

empirical results of the evaluation study
the data generated by the eight hybridized lucidea arrays were normalized in  <dig> ways as described in table  <dig>  the notation s.p.λ refers to a normalization that used scanning procedure s and procedure p  with censoring value λ. the censoring value  generating the highest sensitivity for a group of analyses using scanning approach s and procedure p, will be referred to as the groups optimal censoring value.

for all normalizations the properties of the analyzed data were summarized by observing the sensitivity at the  <dig> %,  <dig> %, and  <dig> % fprs , the overall reflected bias , and the overall standard deviation . figure  <dig> shows the bias and sensitivity for an interesting subclass of analyses. six normalizations were selected as particularly interesting and were investigated in some detail .

normalizations without background adjustment did not benefit from censoring, therefore only results observed at the minimal censoring are presented in this paper. the number of c-spots was low when either partial or complete filtration was used , and consequently including c-spots  gave similar results to excluding c-spots , so only results from the later analyses are presented in this paper. the partial filtration with background adjustment  performed considerable better  than the partial filtration without background adjustment  . normalizations without filtration  and minimal censoring had very low sensitivities. in this case, optimal censoring gave considerable higher sensitivities, but these were still lower than the sensitivities obtained when procedure v was used .

henceforth, we concentrate on what are arguably the four most interesting procedures: complete filtration without background adjustment , complete filtration with background adjustment and minimal censoring , complete filtration with background adjustment and optimal censoring , and partial filtration with background adjustment . these procedures were combined with the seven scanning procedures to give a subclass of  <dig> normalizations. the properties of these normalizations are discussed below.

overall bias and standard deviation
for all except one of the analyses , the reflected bias was negative and the magnitude of the regulation was underestimated . background adjustment had a positive effect on the bias, while censoring and the use of partial filtration resulted in high bias . the use of the  <dig> and 80-scan procedures resulted in relatively small bias, while the cm-procedure gave high bias . the standard deviation was generally high among normalizations using partial filtration, and low among methods using complete filtration without background adjustment or the cm-procedure .

sensitivity at the  <dig> % false positive rate
normalizations that used complete filtration and minimal censoring  had generally low sensitivities  , while analyses that used partial filtration had relatively high sensitivities  . normalizations that used the cm-procedure or the 80-scan procedure  had high sensitivities  .

sensitivity at the  <dig>  and  <dig> % false positive rates
the results at the  <dig> % fpr were similar to those obtained at the  <dig> % fpr, although the variability between the analyses was smaller . the variability at the  <dig> % fpr was even smaller, and the analyses' sensitivities varied between  <dig> and 88% . normalizations that used the  <dig> or 100-scan procedure had with one exception  the smallest sensitivities, while analyses that used the cm-procedure had among the highest sensitivities .

a detailed comparison between six selected normalizations
four of the best performing normalizations,  <dig> ii. <dig>   <dig> v.i, cm.i.l, and cm.ii.l, together with  <dig> i. <dig> and  <dig> ii. <dig> , were selected for further comparison. the ma-plots  for the six analyses are shown in figure  <dig>  note the characteristic rocket shape formed by the nde-intensities for the analysis  <dig> ii.1; this analysis had low bias and low sensitivity . the other analyses avoided the typical rocket shape and thereby achieved higher sensitivity but also higher bias . the trade-off between an analysis' ability to identify de-genes and its ability to obtain low bias has previously been discussed, e.g.  <cit> .

a large proportion of the genes expressed at very low concentrations were removed prior to the test, independent of which normalization was used . for analysis  <dig> ii. <dig>  the standard deviation of the nde-genes decreased with the mrna-concentration, indicating that the majority of the extreme nde-log-ratios were caused by genes expressed at low concentrations .

for analysis  <dig> v. <dig> the selected bias  was considerable lower than the reflected bias . it follows that analysis  <dig> v.  <dig> divides the de-genes into two categories; the correctly classified genes with relatively low bias and the falsely classified genes with high bias. genes with several so-called not found spots are likely to fall in the second category. spot finding was positively correlated with the mrna-concentration , and de-genes with low mrna-concentrations had higher bias, higher standard deviation, and lower sensitivity than genes with high mrna-concentrations .

for most of the other normalizations, de-genes expressed at low concentrations had considerable higher bias and lower sensitivity than genes expressed at high concentrations . highly-regulated genes  expressed at low concentrations  had the highest bias . these genes were expressed at lower concentrations than any of the other de-genes. interestingly, the highly up-regulated genes  <dig> and  <dig> had equal or higher bias than the moderately-regulated genes  <dig> and  <dig> even though they were expressed at higher concentrations. this suggests that the magnitude of the regulation affects the bias so that highly-regulated genes generally have higher bias than moderately-regulated genes.

discussion
in some important aspects our experiment differs from an ordinary microarray experiment. most importantly, the lucidea data were not influenced by any biological variation. it is unclear how adding biological variation influences the relative ranking of the evaluated analyses. furthermore, the evaluation is based on eight arrays. it is possible that the number of arrays in an experiment affects the relative ranking of the analyses. non-expressed genes that are switched on and expressed genes that are switched off can be very interesting. genes of this type are not present on the lucidea array. from an experimental point of view we have the complication that each array was scanned at four settings : 70/ <dig>  80/ <dig>  90/ <dig>  and 100/ <dig> , and it is possible that data from the higher settings lost some information due to photobleaching. the sensitivities, biases, and standard deviations presented in this paper are all point estimators, the uncertainties of these estimates are not considered in this paper. despite these limitations, the lucidea experiment gives valuable information about the relatively performances of the evaluated analysis methods.

in microarray analyses, one of the most important and difficult problems is to select a cut-off value in order to control the false discovery rate. this problem is not considered in this paper.

the  <dig> evaluated analyses represent only a small fraction of all available pre-processing procedures. the background adjustment, the print-tip lowess normalization, and the b-test used in the evaluation are all widely used methods, but not necessarily the best methods available. for example, it is possible that better results can be obtained using more advanced background adjustment procedures  <cit> . furthermore, the inclusion of c-spots, partial filtration, and censoring generate log-ratios that are affected by censored intensities. although the b-test is a robust test  <cit> , it was not designed to handle censored observations. all analyses used the same type of image analysis. it is possible that there exist image analysis methods with significantly better spot finding properties than scanarrayexpress and that the use of such methods could change the relative ranking of the evaluated normalization procedures.

both partial filtration and the inclusion of c-spots are built on the idea that not-found spots and c-spots are most likely observations from non-expressed genes. however, occasionally these spots arise due to experimental failures. the probability that not-found spots and c-spots arise from non-expressed genes might be determined by considering observations from all arrays simultaneously. analyses using this information are likely to perform better than the methods suggested in this paper.

considerable space was devoted to censoring. even though there is no method for determining the optimal censoring values. however, censoring increased the sensitivities of most analyses using background adjustment, sometimes dramatically. we find these results promising and think that they can serve as an inspiration for further research.

CONCLUSIONS
the use of spike-in experiments is a powerful approach for evaluating microarray preprocessing procedures. the sensitivities at low false positive rates and the reflected bias are useful measures for characterizing analyzed microarray data.

in general, there was a trade-off between the ability of the analyses to identify de-genes and their ability to provide unbiased estimators of the desired ratios. no single analysis achieved both low bias and high sensitivity. the magnitude of the regulation of the de-genes was underestimated by almost all analyses, often less than 50%  of the true regulation were observed. moreover, the bias depended on the underlying mrna-concentrations; de-genes with low concentration generally had higher bias than genes expressed at high concentration.

when very low false positive rates were considered ; many of the analyses had relatively low sensitivities. however, analyses that used either the cm-procedure or partial filtration had with few exceptions high or very high sensitivities. if bias is not a major problem; we strongly recommend the use of either the cm-procedure or partial filtration, which gives considerable higher sensitivities than some commonly used analysis methods.

