BACKGROUND
microarray technology has been widely used to identify differential expressed  genes in biomedical research in the past decade. many transcriptomic microarray studies have been generated and made available in public domains such as the gene expression omnibus  from ncbi  and arrayexpress from ebi . from the databases, one can easily obtain multiple studies of a relevant biological or disease hypothesis. since a single study often has small sample size and limited statistical power, combining information across multiple studies is an intuitive way to increase sensitivity. ramasamy, et al. proposed a seven-step practical guidelines for conducting microarray meta-analysis
 <cit> : " identify suitable microarray studies;  extract the data from studies;  prepare the individual datasets;  annotate the individual datasets;  resolve the many-to-many relationship between probes and genes;  combine the study-specific estimates;  analyze, present, and interpret results". in the first step although theoretically meta-analysis increases the statistical power to detect de genes, the performance can be deteriorated if problematic or heterogeneous studies are combined. in many applications, the data inclusion/exclusion criteria are based on ad-hoc expert opinions, a naïve sample size threshold or selection of platforms without an objective quality control procedure. kang et al. proposed six quantitative quality control measures  for decision of study inclusion
 <cit> . step - are related to data preprocessing. finally, step  and  involve the selection of meta-analysis method and interpretation of the result and are the foci of this paper.

many microarray meta-analysis methods have been developed and applied in the literature. according to a recent review paper by tseng et al.
 <cit> , popular methods mainly combine three different types of statistics: combine p-values, combine effect sizes and combine ranks. in this paper, we include  <dig> popular as well as state-of-the-art methods in the evaluation and comparison. six methods  belonged to the p-value combination category, two methods  belonged to the effect size combination category and four methods  belonged to the rank combination category. details of these methods and citations will be provided in the method section. despite the availability of many methods, pros and cons of these methods and a comprehensive evaluation remain largely missing in the literature. to our knowledge, hong and breitling
 <cit> , campain and yang
 <cit>  are the only two comparative studies that have systematically compared multiple meta-analysis methods. the number of methods compared  and the number of real examples examined  were, however, limited. the conclusions of the two papers were suggestive with limited insights to guide practitioners. in addition, as we will discuss in the method section, different meta-analysis methods have different underlying hypothesis setting targets. as a result, the selection of an adequate  meta-analysis method depends heavily on the data structure and the hypothesis setting to achieve the underlying biological goal.

in this paper, we compare  <dig> popular microarray meta-analysis methods using simulation and six real applications to benchmark their performance by four statistical criteria . using simulation, we will characterize the strength of each method under three different hypothesis settings . we will compare the similarity and grouping of the meta-analysis methods based on their de gene detection results  and use an entropy measure to characterize the data structure to determine which hypothesis setting may be more adequate in a given application. finally, we give a guideline to help practitioners select the best meta-analysis method under the choice of hypothesis setting in their applications.

methods
real data sets
six example data sets for microarray meta-analysis were collected for evaluations in this paper. each example contained 4– <dig> microarray studies. five of the six examples were of the commonly seen two-group comparison and the last breast cancer example contained relapse-free survival outcome. we applied the metaqc package
 <cit>  to assess quality of the studies for meta-analysis and determined the final inclusion/exclusion criteria. the principal component analysis  bi-plots and the six qc measures are summarized in additional file
1: figure s <dig>  tables s <dig> and s <dig>  details of the data sets are available in additional file
1: table s <dig> 

underlying hypothesis settings
following the classical convention of brinbaum
 <cit>  and li and tseng
 <cit>  , meta-analysis methods can be classified into two complementary hypothesis settings. in the first hypothesis setting , the goal is to detect de genes that have non-zero effect sizes in all studies:

 h0:∩k=1kθk=0versusha:∩k=1kθk≠0hsa 

where θ
k
 is the effect size of study k. the second hypothesis setting , however, aims to detect a de gene if it has non-zero effect size in "one or more" studies:

 h0:∩k=1kθk=0versusha:∩k=1kθk≠0hsb 

in most applications, hs
a
 is more appropriate to detect conserved and consistent candidate markers across all studies. however, different degrees of heterogeneity can exist in the studies and hs
b
 can be useful to detect study-specific markers . since hs
a
 is often too conservative when many studies are combined, song and tseng  proposed a more practical and robust hypothesis setting  that targets on de genes with non-zero effect sizes in "majority" of studies, where majority of studies is defined as, for example, more than 50% of combined studies . the robust hypothesis setting considered was:

 h0:∩k=1kθk=0versusha:∑k=1kiθk≠0≥rhsr 

a major contribution of this paper is to characterize meta-analysis methods suitable for different hypothesis settings  using simulation and real applications and to compare their performance with four benchmarks to provide a practical guideline.

microarray meta-analysis data pre-processing
assume that we have k microarray studies to combine. for study k , denote by x
gsk
 the gene expression intensity of gene g  and sample s , and y
sk
 the disease/outcome variable of sample s. the disease/outcome variable can be of binary, multi-class, continuous or censored data, representing the disease state, severity or prognosis outcome . the goal of microarray meta-analysis is to combine information of k studies to detect differentially expressed  genes associated with the disease/outcome variable. such de genes serve as candidate markers for disease classification, diagnosis or prognosis prediction and help understand the genetic mechanisms underlying a disease. in this paper, before meta-analysis we first applied penalized t-statistic to each individual study to generate p-values or de ranks
 <cit>  for a binary outcome. in contrast to traditional t-statistic, penalized t-statistic adds a fudge parameter s <dig> to stabilize the denominator
t=x¯-y¯/ and to avoid a large t-statistic due to small estimated variance
s^. the p-values were calculated using the null distributions derived from conventional non-parametric permutation analysis by randomly permuting the case and control labels for  <dig>  times
 <cit> . for censored outcome variables, cox proportion hazard model and log-rank test were used
 <cit> . meta-analysis methods  were then used to combine information across studies and generate meta-analyzed p-values. to account for multiple comparison, benjamini and hochberg procedure was used to control false discovery rate 
 <cit> . all methods were implemented using the "metade" package in r
 <cit> . data sets and all programming codes are available at
http://www.biostat.pitt.edu/bioinfo/publication.htm.

microarray meta-analysis methods
according to a recent review paper
 <cit> , microarray meta-analysis methods can be categorized into three types: combine p-values, combine effect sizes and combine ranks. below, we briefly describe  <dig> methods that were selected for comparison.

combine p-values

fisher the fisher’s method
 <cit>  sums up the log-transformed p-values obtained from individual studies. the combined fisher’s statistic
χfisher2=-2∑i=1klogpi follows a χ <dig> distribution with 2 k degrees of freedom under the null hypothesis . note that we perform permutation analysis instead of such parametric evaluation for fisher and other methods in this paper. smaller p-values contribute larger scores to the fisher’s statistic.


stouffer stouffer’s method
 <cit>  sums the inverse normal transformed p-values. stouffer’s statistics
tstouffer=∑i=1kzi/k follows a standard normal distribution under the null hypothesis. similar to fisher’s method, smaller p-values contribute more to the stouffer’s score, but in a smaller magnitude.


adaptively weighted  fisher the aw fisher’s method
 <cit>  assigns different weights to each individual study
taw=-∑k=1kwk⋅logpi,wk=0or <dig> and it searches through all possible weights to find the best adaptive weight with the smallest derived p-value. one significant advantage of this method is its ability to indicate which studies contribute to the evidence aggregation and elucidates heterogeneity in the meta-analysis. details can be referred to the additional file
 <dig> 


minimum
p
-value  the minp method takes the minimum p-value among the k studies as the test statistic
 <cit> . it follows a beta distribution with degrees of freedom α =  <dig> and β = k under the null hypothesis. this method detects a de gene whenever a small p-value exists in any one of the k studies.


maximum
p
-value  the maxp method takes maximum p-value as the test statistic
 <cit> . it follows a beta distribution with degrees of freedom α = k and β =  <dig> under the null hypothesis. this method targets on de genes that have small p-values in "all" studies.


r-th ordered
p
-value  the rop method takes the r-th order statistic among sorted p-values of k combined studies. under the null hypothesis, the statistic follows a beta distribution with degrees of freedom α = r and β = k – r +  <dig>  the minp and maxp methods are special cases of rop. in song and tseng
 <cit> , rop is considered a robust form of maxp  to identify candidate markers differentially expressed in "majority" of studies.

combine effect size

fixed effects model  fem combines the effect size across k studies by assuming a simple linear model with an underlying true effect size plus a random error in each study.


random effects model  rem
 <cit>  extends fem by allowing random effects for the inter-study heterogeneity in the model. detailed formulation and inference of fem and rem are available in the additional file
 <dig> 

combine rank statistics

rankprod  and ranksum  rankprod and ranksum are based on the common biological belief that if a gene is repeatedly at the top of the lists ordered by up- or down-regulation fold change in replicate experiments, the gene is more likely a de gene
 <cit> . detailed formulation and algorithms are available in the additional file
 <dig> 


product of ranks  and sum of ranks  these two methods apply a naïve product or sum of the de evidence ranks across studies
 <cit> . suppose r
gk
 represents the rank of p-value of gene g among all genes in study k. the test statistics of pr and sr methods are calculated as
prg=∏k=1krgk and
srg=∑k=1krgk, respectively. p-values of the test statistics can be calculated analytically or obtained from a permutation analysis. note that the ranks taken from the smallest to largest  are more sensitive than ranking from largest to smallest in the pr method, while it makes no difference to sr.

characterization of meta-analysis methods
mds plots to characterize the methods
the multi-dimensional scaling  plot is a useful visualization tool for exploring high-dimensional data in a low-dimensional space
 <cit> . in the evaluation of  <dig> meta-analysis methods, we calculated the adjusted de similarity measure for every pair of methods to quantify the similarity of their de analysis results in a given example. a dissimilarity measure is then defined as one minus the adjusted de similarity measure and the dissimilarity measure is used to generate an mds plot of the  <dig> methods. in the mds plot, methods that are clustered in a neighborhood indicate that they produce similar de analysis results.

entropy measure to characterize data sets
as indicated in the section of "underlying hypothesis settings", selection of the most suitable meta-analysis method largely depends on their underlying hypothesis setting . the selection of a hypothesis setting for a given application should be based on the experimental design, biological knowledge and the associated analytical objectives. there are, however, occasions that little prior knowledge or preference is available and an objective characterization of the data structure is desired in a given application. for this purpose, we developed a data-driven entropy measure to characterize whether a given meta-analysis data set contains more hs
a
-type markers or hs
b
-type markers
 <cit> . the algorithm is described below:

 <dig>  apply fisher’s meta-analysis method to combine p-values across studies to identify the top h candidate markers. here we used h =  <dig> , h represents the rough number of de genes  that are contained in the data.

 <dig>  for each selected marker, the standardized minus p-value score for gene g in the k-th study is defined as
lgk=-logpgk/-∑k=1klogpgk. note that 0 ≤ l
gk
 ≤  <dig>  large l
gk
 corresponds to more significant p-value p
gk
, and
∑k=1klgk= <dig> 

 <dig>  the entropy of gene g is defined as
eg=-∑k=1klgkloglgk. box-plots of entropies of the top h genes are generated for each meta-analysis application ).

intuitively, a high entropy value indicates that the gene has small p-values in all or most studies and is of hs
a
 or hs
r
-type. conversely, genes with small entropy have small p-values in one or only few studies where hs
b
-type methods are more adequate. when calculating l
gk
 in step  <dig>  we capped –log at  <dig> to avoid contributions of close-to-zero p-values that can generate near-infinite scores. the entropy box-plot helps determine an appropriate meta-analysis hypothesis setting if no pre-set biological objective exists.

evaluation criteria
for objective quantitative evaluation, we developed the following four statistical criteria to benchmark performance of the methods.

detection capability
the first criterion considers the number of de genes detected by each meta-analysis method under the same pre-set fdr threshold . although detecting more de genes does not guarantee better "statistical power", this criterion has served as a surrogate of statistical power in previous comparative studies
 <cit> . since we do not know the underlying true de genes, we refer to this evaluation as "detection capability" in this paper. an implicit assumption underlying this criterion is that the statistical procedure to detect de genes in each study and the fdr control in the meta-analysis are accurate . to account for data variability in the evaluation, we bootstrapped  the samples in each study for b =  <dig> times and show the plots of ean with standard error bars. in the bootstrapping, the entire sample is either selected or not so the gene dependence structure is maintained. denote by r
meb
 the rank of detection capability performance  of method m  in example e  and in the bth  bootstrap simulation. the mean standardized rank  for method m and example e is calculated as
msrme=∑b=1brmeb/#ofmethodscompared/b and the aggregated standardized rank  is calculated as
asrm=∑e=16msrme/ <dig>  representing the overall performance of method m across all six examples. additional file
1: table s <dig> shows the msr and asr of all  <dig> methods and figure 
 <dig>  shows plot of mean with standard error bars for each method ordered by asr. we note that msr and asr are both standardized between  <dig> and  <dig>  the standardization in msr is necessary because in the breast cancer survival example we cannot apply fem, rem, ranksum and rankprod as they are developed only for a two group comparison.

biological association
the second criterion requires that a good meta-analysis method should detect a de gene list that has better association with pre-defined "gold standard" pathways related to the targeted disease. such a "gold standard" pathway set should be obtained from biological knowledge for a given disease or biological mechanism under investigation. however, since most disease or biological mechanisms are not well-studied, obtaining such "gold standard" pathways is either difficult or questionable. to facilitate this evaluation without bias, we develop a computational and data-driven approach to determine a set of surrogate disease-related pathways out of a large collection of pathways by combining pathway enrichment analysis results from each single study. specifically, we first collected  <dig>  pathways  from msigdb :  <dig>  pathways from "go",  <dig> pathways from "kegg",  <dig> pathways from "biocarta" and  <dig> pathways from "reactome", respectively. we filtered out pathways with less than  <dig> genes or more than  <dig> genes and  <dig>  pathways were left for the analysis. de analysis was performed in each single study separately and pathway enrichment analysis was performed for all the  <dig>  pathways by the kolmogorov-smirnov  association test. denote by p
uk
 the resulting pathway enrichment p-value from ks test for pathway u  and study k . for a given study k, enrichment ranks over pathways were calculated as r
uk
 = rank
u
. a rank-sum score for a given pathway u was then derived as
su=∑k=1kruk. intuitively, pathways with small rank-sum scores indicate that they are likely associated with the disease outcome by aggregated evidence of the k individual study analyses. we choose the top |d| pathways that had the smallest rank-sum scores as the surrogate disease-related pathways and used these to proceed with the biological association evaluation of meta-analysis methods in the following.

given the selected surrogate pathways d, the following procedure was used to evaluate performance of the  <dig> meta-analysis methods for a given example e . for each meta-analysis method m , the de analysis result was associated with pathway u and the resulting enrichment p-value by ks-test was denoted by
p˜med1≤d≤|d|. the rank of
p˜med for method m among  <dig> methods was denoted by
vmed=rankmp˜med. similar to the detection capability evaluation, we calculated the mean standardized rank  for method m and example e as
msrme=∑d=1dvmed/#of the methods compared/d and the aggregated standardized rank  as
asrm=∑e=16msrme/ <dig>  representing the overall performance of method m. to select the parameter |d| for surrogate disease-related pathways, additional file
1: figure s <dig> shows the trend of msr
me
  versus |d|  as |d| increases. the result indicated that the performance evaluation using different d only minimally impacted the conclusion when d >  <dig>  we choose d =  <dig> throughout this paper.

note that we used ks test, instead of the popular fisher’s exact test because each single study detected variable number of de genes under a given fdr cutoff and the fisher’s exact test is usually not powerful unless a few hundred de genes are detected. on the other hand, the ks test does not require an arbitrary p-value cutoff to determine the de gene list for enrichment analysis.

stability
the third criterion examines whether a meta-analysis method generates stable de analysis result. to achieve this goal, we randomly split samples into half in each study . the first half of each study was taken to perform the first meta-analysis and generate a de analysis result. similarly, the second half of each study was taken to perform a second meta-analysis. the generated de analysis results from two separate meta-analyses were compared by the adjusted de similarity measure . the procedure is repeated for b =  <dig> times. denote by s
meb
 the adjusted de similarity measure of method m of the bth simulation in example e. similar to the first two criteria, msr and asr were calculated based on s
meb
 to evaluate the methods.

robustness
the final criterion investigates the robustness of a meta-analysis method when an outlying irrelevant study is mistakenly added to the meta-analysis. for each of the six real examples, we randomly picked one irrelevant study from the other five examples, added it to the specific example for meta-analysis and evaluated the change from the original meta-analysis. the adjusted de similarity measure was calculated between the original meta-analysis and the new meta-analysis with an added outlier. a high adjusted de similarity measure shows better robustness against inclusion of the outlying study. this procedure was repeated until all irrelevant studies were used. the msr and asr are then calculated based on the adjusted de similarity measures to evaluate the methods.

similarity measure between two ordered de gene lists
to compare results of two de detection methods , a commonly used method in the literature is to take the de genes under certain p-value or fdr threshold, plot the venn diagram and compute the ratio of overlap. this method, however, greatly depends on the selection of fdr threshold and is unstable. another approach is to take the generated de ordered gene lists from two methods and compute the non-parametric spearman rank correlation
 <cit> . this method avoids the arbitrary fdr cutoff but gives, say, the top  <dig> important de genes and the bottom  <dig> non-de genes equal contribution. to circumvent this pitfall, li et al. proposed a parametric reproducibility measure for chip-seq data in the encode project
 <cit> . yang et al. introduced an orderedlist measure to quantify similarity of two ordered de gene lists
 <cit> . for simplicity, we extended the orderedlist measure into a standardized similarity score for the evaluation purpose in this paper. specifically, suppose g
1
 and g
2
 are two ordered de gene lists  and small ranks represent more significant de genes. we denote by o
n
 the number of overlapped genes in the top n genes of g
1
 and g
2
. as a result, 0 ≤ o
n
 ≤ n and a large o
n
 value indicates high similarity of the two ordered lists in the top n genes. a weighted average similarity score is calculated as
sg <dig> g2=∑n=1ge-an·ong <dig> g <dig>  where g is the total number of matched genes and the power α controls the magnitude of weights emphasized on the top ranked genes. when α is large, top ranked genes are weighted higher in the similarity measure. the expected value  and maximum value of s can be easily calculated:
enullsg <dig> g2=∑n=1ge-αn·n2/g and
maxsg <dig> g2=∑n=1ge-an·n. we apply an idea similar to adjusted rand index
 <cit>  used to measure similarity of two clustering results and define the adjusted de similarity measure as

 s*g <dig> g2=sg <dig> g2-enullsg <dig> g2maxsg <dig> g2-enullsg <dig> g <dig> 

this measure ranges between - <dig> to  <dig> and gives an expected value of  <dig> if two ordered gene lists are obtained by random chance. yang et al. proposed a resampling-based and roc methods to estimate the best selection of α. since the number of de genes in our examples are generally high, we choose a relatively small α =  <dig>  throughout this paper. we have tested different α and found that the results were similar .

RESULTS
simulation setting
we conducted simulation studies to evaluate and characterize the  <dig> meta-analysis methods for detecting biomarkers in the underlying hypothesis settings of hs
a
, hs
b
 or hs
r
. the simulation algorithm is described below:

 <dig>  we simulated  <dig> genes with  <dig> gene clusters  and other  <dig>  genes do not belong to any cluster. the cluster indexes c
g
 for gene g  were randomly sampled, such that ∑ i{c
g
 = 0} =  <dig>   <dig> and ∑ i{c
g
 = c} =  <dig>  1 ≤ c ≤  <dig> 

 <dig>  for genes in cluster c  and in study k , we sampled
∑ck'~w-1Ψ, <dig>  where Ψ =  <dig> i20 × 20 +  <dig> j20 ×  <dig>  w-  <dig> denotes the inverse wishart distribution, i is the identity matrix and j is the matrix with all elements equal  <dig>  we then standardized
Σck' into Σ
ck
 where the diagonal elements are all 1’s.

 <dig>   <dig> genes in cluster c was denoted by the index of g
c <dig>  …, g
c <dig>  i.e.
cgcj=c,where1≤c≤40and1≤j≤ <dig>  we sampled gene expression levels of genes in cluster c for sample n as
xgc1nk',…,xgc20nk't~mvn <dig> ∑ck where 1 ≤ n ≤  <dig> and 1 ≤ k ≤  <dig>  and sample expression level for the gene
g~n <dig> σk <dig> which is not in any cluster for sample n, where 1 ≤ n ≤  <dig>  1 ≤ k ≤  <dig> and
σk <dig> was uniformly distributed from , which indicates different variance for study k.

 <dig>  for the first  <dig>  genes , k
g
  was generated by sampling k
g
 =  <dig>   <dig>   <dig>   <dig> and  <dig>  respectively. for the next  <dig>  genes , k
g
 =  <dig> represents non-de genes in all five studies.

 <dig>  to simulate expression intensities for cases, we randomly sampled δ
gk
 ∈ { <dig>  1}, such that ∑ 
k
δ
gk
 = k
g
. if δ
gk
 =  <dig>  gene g in study k was a de gene, otherwise it was a non-de gene. when δ
gk
 =  <dig>  we sampled expression intensities μ
gk
 from a uniform distribution in the range of , which means we considered the concordance effect  among all simulated studies. hence, the expression for control samples are
xgnk=xgnk', and case samples are
ygnk=xgn+50k'+μgk·δgk, for 1 ≤ g ≤  <dig>   <dig>  1 ≤ n ≤ 50 and 1 ≤ k ≤  <dig> 

in the simulation study, we had  <dig>  non-de genes in all five studies , and  <dig>  genes were differentially expressed in 1 ~  <dig> studies . on average, we had roughly the same number  of genes in each group of k
g
 =  <dig>   <dig>   <dig>   <dig>   <dig>  see additional file
1: figure s <dig> for the heatmap of a simulated example . we applied the  <dig> meta-analysis method under fdr control at 5%. with the knowledge of true k
g
, we were able to derive the sensitivity and specificity for hs
a
 and hs
b
, respectively. in hs
a
, genes with k
g
 =  <dig> were the underlying true positives and genes with k
g
 = 0 ~  <dig> were the underlying true negatives; in hs
b
, gene with k
g
 = 1 ~  <dig> were the underlying true positives and genes with k
g
 =  <dig> were the true negatives. by adjusting the decision cut-off, the receiver operating characteristic  curves and the resulting area under the curve  were used to evaluate the performance. we simulated  <dig> data sets and reported the means and standard errors of the auc values. auc values range between  <dig> and  <dig>  auc = 50% represents a random guess and auc =  <dig> reaches the perfect prediction. the above simulation scheme only considered the concordance effect sizes  among five simulated studies. in many applications, some genes may have p-value statistical significance in the meta-analysis but the effect sizes are discordant . to investigate that effect, we performed a second simulation that considers random discordant cases. in step  <dig>  the μ
gk
 became a mixture of two uniform distributions: π
gk
 unif ⋅+ ⋅ unif, where π
gk
 is the probability of gene g  in study k to have a discordant effect size . we set π
gk
 =  <dig>  for the discordant simulation setting.

simulation results to characterize the methods
the simulation study provided the underlying truth to characterize the meta-analysis methods according to their strengths and weaknesses for detecting de genes of different hypothesis settings. the performances of  <dig> methods were evaluated by receiver operating characteristic  curves, which is a visualization tool that illustrates the sensitivity and specificity trade-off, and the resulting area under the roc curve  under two different hypothesis settings of hs
a
 and hs
b
. table 
 <dig> shows the detected number of de genes under nominal fdr at 5%, the true fdr and auc values under hs
a
 and hs
b
 for all  <dig> methods. the values were averaged over  <dig> simulations and the standard errors are shown in the parentheses.
hs


a 

and 
hs


b 

and the concluding characterization of targeted hypothesis setting of each method

a
r
b
b
b
b
a
a
b
r
b
b
figure 
 <dig> shows the histogram of the true number of de studies  among the detected de genes under fdr = 5% for each method. it is clearly seen that minp, fisher, aw, stouffer and fem detected hs
b
-type de genes and had high auc values under hs
b
 criterion , compared to lower auc values under hs
a
 criterion . for these methods, the true fdr for hs
a
 generally lost control . on the other hand, maxp, rop and rem had high auc under hs
a
 criterion   compared to hs
b
 . maxp detected mostly hs
a
-type of markers and rop and rem detected mostly hs
r
-type de genes. pr and sr detected mostly hs
a
-type de genes but they surprisingly had very high auc under both hs
a
 and hs
b
 criteria. the rankprod method detected de genes between hs
r
 and hs
b
 types and had a good auc value under hs
b
. the ranksum detected hs
b
-type de genes but had poor auc values  for both hs
a
 and hs
b
. table 
 <dig> includes our concluding characterization of the targeted hypothesis settings for each meta-analysis method . additional file
1: figure s <dig> shows the result for the second discordant simulation setting. the numbers of studies with opposite effect size are represented by different colours in histogram plot . in summary, almost all meta-analysis methods could not avoid inclusion of genes with opposite effect sizes. particularly, methods utilizing p-values from two-sided tests  could not distinguish direction of effect sizes. stouffer was the only method that accommodated the effect size direction in its z-transformation formulation but its ability to avoid de genes with discordant effect sizes seemed still limited. owen  proposed a one-sided correction procedure for fisher’s method to avoid detection of discordant effect sizes in meta-analysis
 <cit> . the null distribution of the new statistic, however, became difficult to derive. the approach can potentially be extended to other methods and more future research will be needed for this issue.

results of the four evaluation criteria
detection capability
figure 
 <dig> shows the number of de genes identified by each of the  <dig> meta-analysis methods . each plot shows mean with standard error bars for  <dig> bootstrapped data sets. additional file
1: table s <dig> shows the msr and asr for each method in the six examples. the methods in figure 
 <dig> are ordered according to their asr values. the top six methods with the strongest detection capability were those that detected hs
b
-type de genes from the conclusion of table 
1: fisher, aw, stouffer, minp, fem and ranksum. the order of performance of these six methods was pretty consistent across all six examples. the next four methods were rop, rankprod, maxp and rem and they targeted on either hs
r
 or hs
a
. pr and sr had the weakest detection capability, which was consistent with the simulation result in table 
 <dig> 

biological association
figure 
 <dig> shows plots of mean with standard error bars from the pathway association p-values  of the top  <dig> surrogate disease-related pathways for the  <dig> methods. additional file
1: table s <dig> shows the corresponding msr and asr. we found that stouffer, fisher and aw had the best performance among the  <dig> methods. surprisingly we found that although pr and sr had low detection capability in simulation and real data, they consistently had relatively high biological association results. this may be due to the better de gene ordering results these two methods provide, as was also shown by the high auc values under both hypothesis settings in the simulation.

stability
figure 
 <dig> shows the plots of mean with standard error bars of stability calculated by adjusted de similarity measure. additional file
1: table s <dig> contains the corresponding msr and asr. in summary, rankprod and ranksum methods were the most stable meta-analysis methods probably because these two nonparametric approaches take into account all possible fold change calculations between cases and controls. they do not need any distributional assumptions, which provided stability even when sample sizes were small
 <cit> . the maximum p-value method consistently had the lowest stability in all data sets, which is somewhat expected. for a given candidate marker with a small maximum p-value, the chance that at least one study has significantly inflated p-values is high when sample size is reduced by half. the stability measures in the breast cancer example were generally lower than other examples. this is mainly due to the weak signals for survival outcome association, which might be improved if larger sample size is available.

robustness
figure 
 <dig> shows the plots of mean with standard error bars of robustness calculated by adjusted de similarity measure between the original meta-analysis and the new meta-analysis with an added outlier. additional file
1: table s <dig> shows the corresponding msr and asr values. in general, methods suitable for hs
b
  have better robustness than methods for hs
a
 or hs
r
 . the trend is consistent in the prostate cancer, brain cancer and ipf examples but is more variable in the weak-signal mdd and breast cancer examples. ranksum was surprisingly the most sensitive method to outliers, while rankprod performs not bad.

characterization of methods by mds plots
we applied the adjusted de similarity measure to quantify the similarity of the de gene orders from any two meta-analysis methods. the resulting dissimilarity measure  was used to construct the multidimensional scaling  plot, showing the similarity/dissimilarity structure between the  <dig> methods in a two-dimensional space. when two methods were close to each other, they generated similar de gene ordering. the patterns of mds plots from six examples generated quite consistent results . figure 
 <dig> shows an aggregated mds plot where the input dissimilarity matrix is averaged from the six examples. we clearly observed that fisher, aw, stouffer, minp, pr and sr were consistently clustered together in all six individual and the aggregated mds plot . this is not surprising given that these methods all sum transformed p-value evidence across studies . two methods to combine effect sizes and two methods to combine ranks  are consistently clustered together. finally, the maxp and rop methods seem to form a third loose cluster .

characterization of data sets by entropy measure
from the simulation study, selection of a most suitable meta-analysis method depends on the hypothesis setting behind the methods. the choice of a hypothesis setting mostly depends on the biological purpose of the analysis; that is, whether one aims to detect candidate markers differentially expressed in "all" , "most"  or "one or more"  studies. however, when no biological prior information or preference exists, the entropy measure can be objectively used to determine the choice of hypothesis setting. the analysis identifies the top  <dig>  genes from fisher’s meta-analysis method and the gene-specific entropy of each gene is calculated. when the entropy is small, the p-values are small in only one or very few studies. conversely, when the entropy is large, most or all of the studies have small p-values. figure 
 <dig> shows the box-plots of entropy of the top  <dig>  candidate genes identified by fisher’s method in the six data sets. the result shows that prostate cancer comparing primary and metastatic tumor samples had the smallest entropy values, which indicated high heterogeneity across the three studies and that hs
b
 should be considered in the meta-analysis. on the other hand, mdd had the highest entropy values. although the signals of each mdd study were very weak, they were rather consistent across studies and application of hs
a
 or hs
r
 was adequate. for the other examples, we suggest using the robust hs
r
 unless other prior biological purpose is indicated.

conclusions and discussions
an application guideline for practitioners
from the simulation study, the  <dig> meta-analysis methods were categorized into three hypothesis settings , showing their strengths for detecting different types of de genes in the meta-analysis . for example, maxp is categorized to hs
a
 since it tends to detect only genes that are differentially expressed in all studies. from the results using four evaluation criteria, we summarized the rank of asr values  and calculated the rank sum of each method in table 
 <dig>  the methods were then sorted first by the hypothesis setting categories and then by the rank sum. the clusters of methods from the mds plot were also displayed. for methods in the hs
a
 category, we surprisingly see that the maxp method performed among the worst in all four evaluation criteria and should be avoided. pr was a better choice in this hypothesis setting although it provides a rather weak detection capability. for hs
b
, fisher, aw and stouffer performed very well in general. among these three methods, we note that aw has an additional advantage to provide an adaptive weight index that indicates the subset of studies contributing to the meta-analysis and characterizes the heterogeneity  indicates that the marker is de in study  <dig> but not in study  <dig>  etc.). as a result, we recommend aw over fisher and stouffer in the hs
b
 category. for hs
r
, the result was less conclusive. rem provided better stability and robustness but sacrificed detection capability and biological association. on the other hand, rop obtained better detection capability and biological association but was neither stable nor robust. in general, since detection capability and biological association are of more importance in the meta-analysis and rop has the advantage to link the choice of r in hs
r
 with the rop method , we recommend rop over rem.

*1
a
a
a
r
r
b
b
b
b
b
b
b
*1cluster number of methods in the mds plot ).

below, we provide a general guideline for a practitioner when applying microarray meta-analysis. data sets of a relevant biological or disease hypothesis are firstly identified, preprocessed and annotated according to step  -  in ramasamy et al. proper quality assessment should be performed to exclude studies with problematic quality . based on the experimental design and biological objectives of collected data, one should determine whether the meta-analysis aims to identify biomarkers differentially expressed in all studies , in one or more studies  or in majority of studies . in general, if higher heterogeneity is expected from, say, heterogeneous experimental protocol, cohort or tissues, hs
b
 should be considered. for example, if the combined studies come from different tissues , tissue-specific markers may be expected and hs
b
 should be applied. on the contrary, if the collected studies are relatively homogeneous , hs
r
 is generally recommended, as it provides robustness and detects consistent signals across the majority of studies. in the situation that no prior knowledge is available to choose a desired hypothesis setting or if the researcher is interested in a data-driven decision, the entropy measure in figure 
 <dig> can be applied and the resulting box-plot can be compared to the six examples in this paper to guide the decision. once the hypothesis setting is determined, the choice of a meta-analysis method can be selected from the discussion above and table 
 <dig> 

CONCLUSIONS
in this paper, we performed a comprehensive comparative study to evaluate  <dig> microarray meta-analysis methods using simulation and six real examples with four evaluation criteria. we clarified three hypothesis settings that were implicitly assumed behind the methods. the evaluation results produced a practical guideline to inform biologists the best choice of method in real applications.

with the reduced cost of high-throughput experiments, data from microarray, new sequencing techniques and mass spectrometry accumulate rapidly in the public domain. integration of multiple data sets has become a routine approach to increase statistical power, reduce false positives and provide more robust and validated conclusions. the evaluation in this paper focuses on microarray meta-analysis but the principles and messages apply to other types of genomic meta-analysis . when the next-generation sequencing technology becomes more affordable in the future, sequencing data will become more prevalent as well and similar meta-analysis techniques will apply. for these different types of genomic meta-analysis, similar comprehensive evaluation could be performed and application guidelines should be established as well.

competing interests
the authors declare that they have no competing interests.

authors’ contributions
gct supervised the whole project. lcc developed all statistical analysis and hml developed partial statistical analysis. gct and lcc drafted the manuscript. all authors read and approved the final manuscript.

supplementary material
additional file 1
supplementary methods of  adaptive weighted  fisher,  combined statistical estimates  methods of fem and rem,  combined rank statistics methods: rank product  and rank sum . figure s <dig>  metaqc. figure s <dig>  heatmap of simulated example . figure s <dig>  the histograms of the true number of de studies among detected de genes under fdr = 5% in each method for discordance case. figure s <dig>  cumulative moving average to determine d =  <dig>  figure s <dig>  the roc curves and auc for the hypothesis settings of hs
a
-type and  hs
b
-type  in each meta-analysis method. figure s <dig>  multidimensional scaling  plots of individual data sets. figure s <dig>  stability and robustness plot for α =  <dig> ,  <dig>  and  <dig> . table s <dig>  detailed data sets description. table s <dig>  metaqc results. table s <dig>  data sets and number of matched genes. table s <dig>  mean standardized rank  and aggregated standardized rank  for detection capability. table s <dig>  mean standardized rank  and aggregated standardized rank  for biological association. table s <dig>  mean standardized rank  and aggregated standardized rank  for stability. table s <dig>  mean standardized rank  and aggregated standardized rank  for robustness.

click here for file

 acknowledgements
this work was supported by the national institutes of health .
