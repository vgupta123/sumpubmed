BACKGROUND
the common decomposition method in the network analysis
transcriptional regulation is largely exerted through a set of regulatory proteins, called transcription factors . these tfs regulate transcriptional activity via directly or indirectly interacting with dna and their effect can be either positive or negative. an important feature of the tfs is that their activities are commonly  modulated at the post-transcriptional level, such as phosphorylation or ligand binding, thus the tf activity  does not necessarily correlate with tf mrna, or protein, levels. furthermore, the tf-gene interaction is condition-dependent  <cit> .

transcriptome profiles are often modeled in a log linear fashion  <cit> :

  e=ap+Γ 

where matrix e represents the log ratio of gene expression of n genes in m microarray data, matrix p describes the profiles of l hidden tfas, while matrix a defines the control strengths  of tf to genes, and finally Γ is the unavoidable measurement noise. matrix decomposition of the eq.  does not provide a unique solution for a and p even with the same residual Γ, unless it is properly constrained.

different methods have been developed to determine a and p uniquely under different assumptions. principal component analysis   <cit> , assumes that the rows in the p matrix are orthonormal, while independent component analysis   <cit>  requires that the expression modes are statistically independent and non-gaussian. although these methods are useful in reducing the dimensionality, they do not provide tfas because their assumptions do not reflect the underlying biological network. matrixreduce  <cit>  assumes that the control strength of the tf to its regulated gene is proportional to the number of occurrence of the tf motif in the promoter region of the gene, and the activities of the transcriptional regulators associated with each motif are determined by regression analysis. this above assumption needs to be refined, particularly when genes in the network are regulated by multiple tfs. moreover, the tf-gene interaction is condition-dependent  <cit> , which makes the problem even more challenging.

network component analysis
network component analysis   <cit>  is a method that also aims to solve both a and p in eq.  by incorporating tf-gene interaction information as constraints. differing from matrixreduce, nca quantitatively determines both activities of the transcriptional regulators and the control strengths  of tf-gene interactions. the network topology also needs to satisfy some criteria  <cit>  to guarantee uniqueness of solution for the matrix decomposition of eq. --networks that meet these three criteria are termed nca-compliant. the conditions necessary for nca-compliance are  <cit> :  a selected tf must regulate n - l+ <dig>  or less, genes, where n and l are the number of selected genes and tfs in the network, respectively;  the regulon of one tf cannot be a subset of another tf; and  the number of tfs regulating a gene must be less than or equal to the number of transcriptome measurements . in the event that these necessary conditions are not met, the regulatory network can be broken into smaller nca-compliant subnetworks for analysis. in higher eukaryotes, where a single gene can be regulated by a large number of tfs, criterion  may not be met. to facilitate the analysis of regulatory networks that violate criterion , we develop a data-augmentation algorithm below.

nca correctly identifies the tfa profiles, if tf-gene relationships are provided. however, it is virtually impossible to obtain condition-dependent tf-gene connectivity information at the genome level for every condition of interest. although there are extensive databases of regulatory interactions created from chip-chip studies  <cit> , dna adenine methyltransferase identification   <cit> , or manual- and computer-aided literature mining  <cit> , these databases may contain numerous false positives for a condition of interest. using connectivity input with false positives may lead to inaccurate estimations of the control strengths . and, in the case of a large percentage of false positive connections in a tf's regulon, the estimated tfa may be highly inaccurate. to remove the influence of false positive connectivity on data analysis, yu and li  <cit>  used two sets of tf-gene interactions: a set of low-confidence interactions and a subset of higher-confidence interactions derived from biomedical literature and chip data respectively. the algorithm started by using the higher-confidence interactions as the constraints for the decomposition, and then added a new tf-gene edge per iteration from the lower-confidence set until the residual satisfied a specified criterion. yu and li tested the approach with saccharomyces cerevisiae expression data measured under normal and stress conditions. unfortunately, in the case of mammals, the number of high confidence tf-gene interactions is, currently, limited thus only a few tfs may be analyzed by the method of yu and li. to build accurate models of regulation in mammals, it is essential to develop a strategy that incorporates as many available tfs as possible into the analyzed network, while screening out the false tf-gene interactions. in this study we develop an iterative algorithm to trim the tf-gene interaction network to suit the specific condition of interest. the method integrates nca with stepwise regression, which is a statistical method for model selection, so that the trimmed network will only contain relevant edges. we then apply a permutation test to identify key tfs and their target genes in the trimmed network. finally, we employ a statistical sampling method to generate additional data from the existing data; this additional data is used when the original data set fails to meet the third criterion for nca-compliance. the generation of additional data increases stability of nca for complex regulatory networks, but does not lead to overfitting because the stepwise regression component of our network trimming approach eliminates any redundancy.

RESULTS
the method developed here includes two stages :  trimming the network by an iterative algorithm that integrates nca with forward stepwise regression, and then  identifying the most important key tfs and target genes by permutation tests. to stabilize the nca algorithm when insufficient data are available, a statistical method is employed.

trimming the network by the iterative nca-stepwise regression algorithm
edge-trimming of the network is accomplished using the forward stepwise regression method . the expression of individual genes is modeled in eq.  as:

  ei=∑j∈ciaijpj+Γ 

where, ci is the set of tfs regulating gene i. only tfs with a non-zero connection to gene i are included in ci. here, we are interested in estimating aij for a given expression profile ei.

to estimate aij, forward stepwise regression requires the explanatory variables p's . the tfas are first estimated from nca using the full connectivity pattern za <dig>  which includes false positive connections. we have previously shown that most tfa profiles obtained by nca are very robust  <cit>  when the fraction of false positive edges in za was below a certain level  <cit> . by assuming that the false positive edges in the full connectivity pattern za <dig> exist at the moderate level which does not affect the tfas, the trimming algorithm  is summarized below:

i) calculate tfa based on the full set of za <dig> using nca.  the tfa for each tf is used as the explanatory variable in equation  <dig>  performing nca with the tikhonov regularization algorithm  <cit>  is recommended because of its stability to ill-conditioned matrices generated during the bi-linear optimization phase.

ii) initially, assume that only one tf regulates the gene, or k =  <dig>  and generate different models using all the tfs in ci <dig> which is the list of indices of non-zero elements defined by row i of za <dig>  the coefficient aij and residual sum of squares  of all the models are calculated by linear regression using the tfa determined from step .

iii) select the model having the smallest rss.

iv) calculate the modified akaike information criterion  <cit> , aicc:

  aicck=mlog2πσ^2+mm−k− <dig> 

where m is the number of columns in matrix e, and σ^2=rssm is the estimated variance of fitting errors computed from maximum likelihood. the aicck= <dig> is calculated by eq.  for the chosen model. we use the modified aicc instead of the f statistic because it includes a penalty term for small values of m to avoid overfitting. aicc also does not require a user-input threshold as used in the f test.

v) the procedure from  to  is repeated for k = k+ <dig> by incorporating an additional tf, from ci, to the best model identified in . the aicck is computed at the end of each iteration and compared with one in the previous iteration to decide if the new model better explains the ei than the model from the previous iteration. if aicck≥aicck− <dig>  the procedure is stopped, and only the k- <dig> tfs from the previous iteration are used to explain ei.

vi) steps  to  are executed for each gene. when finished, the method identifies from ci <dig> a subset of tfs, defined as citriml, to describe the expression data for gene i. in other words, only the strong interactions between gene i and the tfs in the final model are retained in the trimmed network. figure  <dig> illustrates in detail how the method is applied to a gene that is initially thought to be regulated by three tfs. after this step the original network structure za <dig> is modified to zatrim l= <dig> 

vii) compare updated zatrim l= <dig> with the previous one zatrim l- <dig>  if the number of retained edges is greater than 99%, or any practical value suitable to the specific application, then the iteration stops and the final connectivity is defined as zafinal. otherwise repeat step  to  to obtain new zatrim l+ <dig> 

the steps for trimming edges  to  ) are encoded by a matlab function in additional file  <dig> 

approach validation with synthetic data
to assess the performance of our algorithm we defined a synthetic regulatory network with "true" css and "true" tfas, and then explored the effect of noise, false connectivity, and the number of independent data sets on the cs and tfa estimates from our algorithm. the method used to generate the synthetic network is described in additional file  <dig>  in brief, we designed a synthetic network of  <dig> genes regulated by  <dig> tfs that mimics key characteristics of mammalian regulatory networks, such as the murine transcription network . a prominent feature of the complex mammalian regulatory networks is that genes are often regulated by multiple tfs. the complexity of a connectivity network is described by the distributions of the number of tfs regulating a gene; the distributions of both the synthetic  and the mouse network  follow a power law distribution.

we benchmarked our algorithm by comparing the deconvolution results to the true values as a function of a variety of key factors. we explored the robustness of our algorithm as a function of noise , independent data sets , and the false connection rate . the fcr is defined as the ratio of the false connected edges  over the number of true connected edges. we evaluated the algorithm at two different noise levels , four data set sizes, r =  <dig>   <dig>   <dig>   <dig> and  <dig>  and four fcrs . examining our algorithm as a function of r could guide in selecting an appropriate number of microarray experiments for a particular research problem. due to high costs and low sample sizes that are often associated with studies involving mammals, it is important to know the required sample size. note that in the r =  <dig> case, genes regulated by more than  <dig> tfs would violate nca criterion  and the regulatory networks for these genes would be underdetermined. although this problem is prevalent when analyzing mammalian transcriptome data, it may be overcome by generating additional data in silico .

we first assessed the performance of the iterative nca-stepwise regression algorithm for  the speed of convergence, and  the accuracy of reconstructed tfas and expression under various noise levels and numbers of independent data in a set at the fcr =  <dig> . the iterative algorithm converged at the second iteration, l =  <dig>  with less than 1% of the edges trimmed in the second generation. after the first iteration , the number of edges in the trimmed connectivity network decreased around 23% to 30% compared to the original network , but the relative fitting errors  between raw and reconstructed expressions  did not change much after the first iteration. this result implies that forward stepwise regression with modified aic robustly removed most of the irrelevant edges from the network structure in the first iteration. even though in some cases up to 30% of the edges were eliminated in the final networks, the final nca-derived tfas in all cases were nearly identical to the initial derived tfas and to the "true" signals. the signal-to-noise ratio  was used to measure how good the derived tfas were compared to the "true" values .

the main aim of the algorithm was to eliminate the false positive tf-gene interactions in the initial network. the false positive connections represent condition-specific interactions that are not relevant in the condition of interest as well as errors in the network. we evaluated the recovery of the edges at two levels: all and important tf-gene interactions. we focused on this qualitative aspect because a strong tf-gene interaction indicates that the gene's expression profile may serve as a biomarker for the activity of the respective tf in similar conditions. an important edge between a tf-gene pair will have a large |cs|, thus indicating that the gene's expression is highly sensitive to variations of the respective tfa. knowing which genes in a tf's regulon are receiving a relatively strong signal will guide interpretation of the effects of pleiotropic global regulators such as p <dig> that have a wide range of influence. in this analysis, we arbitrarily classify a tf-gene interaction as important if its |cs| is in the top 30% of its regulon.

to visualize the increased performance imparted by our network trimming algorithm, we've generated receiver operating characteristic  curves for the untrimmed and trimmed network as a function of noise . the roc curves  indicate that algorithm performance increases with the number of experiments, and performance is optimal when the number of the data points is high enough  to ensure the nca criterion  satisfied. not surprisingly, the performance was better at low noise level  at which roc curves of nca compliant networks were discrete from that of incompliant network. when assessing performance based on recovery of all the true-positive interactions in the network, there did not appear to be a substantial benefit conferred by network trimming. however, when we focus on the important interactions, the trimming algorithm increases overall performance, especially for low experiment numbers .

finally, we explored the robustness of the algorithm at different fcrs. we focused on the worst case scenario, low number of experiments and high noise, and three fcrs =  <dig> ,  <dig> , and  <dig> . the performance based on all edges was quite robust for fcr < =  <dig> , and with decayed performance evident at fcr =  <dig>  . a similar trend was also observed when exploring only important edges.

exploring biological data
we used gene expression data from wild type  mice  <cit>  to test the applicability of our method. gene expression was measured by affymetrix chips in four different setups:  <dig> and  <dig> hours after treating mice with either placebo or rad <dig> --a derivative of rapamycin. rad <dig> binds to the immunophilin fk binding protein- <dig>  to generate an immunosuppressive complex that binds to and inhibits the activation of the mammalian target of rapamycin , a key regulatory kinase. data were downloaded from ncbi's gene expression omnibus . three different configurations were employed to compare the effect of rad <dig> treatment vs. a placebo on gene expression at different time points  as well as between time points  after rad <dig> treatment. to explore the value of our data augmentation algorithm, the expression data were pre-processed in two different manners: with or without using our data augmentation algorithm . in brief, in the augmented expression data the three log ratios were generated based on averages of replicated samples and then augmented  <dig> times, while in the "raw" replicated expression data, the log ratios were established between rad <dig> replicates and averages of placebo replicates at the respective time points and between the averages of rad <dig> replicates at two time points to also obtain a total of  <dig> ratios for each gene.

the connectivity matrix za <dig> was constructed from the transcriptional regulatory element database tred  <cit>  of cold spring harbor laboratory. in this study a tf-gene interaction was assumed to exist if the information for binding quality in tred was defined as "known", "likely", or "maybe". the analyzed network contained  <dig> genes regulated by  <dig> tfs. the trimmed network structure and its regulatory signal were first derived by the iterative algorithm. the permutation approach described in methods  was then used to identify significantly perturbed tfs under rad <dig> treatment. in this analysis the tfa null distributions were built from n =  <dig> randomly scrambled data sets  using the trimmed connectivity matrix obtained in the iterative algorithm. the tfs were identified as being significantly perturbed if the p-values of a two-tailed z-test were less than  <dig>  based on the simulated data  in which a large percentage  of tfas were set to be perturbed. the roc curves  indicate the optimal cut off p-values for the trimmed and original networks around  <dig> - <dig> .

we first assessed the advantage of data augmentation by examining the relative fitting errors between the reconstructed and input expression data. although both augmented and raw replicated expression data were the same size and were analyzed by the same connectivity matrix, the relative fitting error when using the augmented data set was  <dig>  whereas the raw data had a relative fitting error of  <dig> . another potential disadvantage of using the raw data was that more edges were removed from the network during the trimming process . note, that in the simulation at the high noise level  the significant removal of edges would decrease the tpr. when the raw data were used expected interactions, such as hif1a-eno <dig>  were trimmed from the network. however, the removal of edges did not drastically affect the tfa profiles. the average of correlation coefficients for each tfa between the first and second iteration were  <dig>  and  <dig>  for the raw replicated and augmented data, and that of final tfas between two scenarios was  <dig> . in the following section, we focus on results obtained with the augmented expression data due to the higher tpr.

similar to the synthetic examples, trimming of the mouse network converged after two iterations with about 75% of the original edges retained. trimming the network allowed us to identify key interactions that were obscured when employing the untrimmed network. for example, when the data are analyzed using the trimmed network eno <dig> is predicted as an important target of hif1a with a |cs| =  <dig>  . eno <dig> is known to be regulated by hif1a  <cit> , and has been used as a reporter for hif1a activity  <cit> . however, when analysis of this network is performed without trimming, this interaction is obscured .

additionally, trimming the network allowed us to correctly infer the direction of regulation of tfs to genes. for example, expression of the multidrug resistance phosphoglycoprotein  is known to be activated by trp <dig>  <cit> . besides trp <dig>  several other tfs such as cebpb, hif1a, tcfap2a, and pgr are also indicted as abcb1b regulators by tred. without network trimming, the nca implied that abcb1b was repressed by trp <dig>  however, after the weak interactions between other tfs and abcb1b were removed, abcb1b's expression was correctly predicted to be activated by trp <dig> and repressed by tcfap2a . the incorrect prediction with the initial network was due to overfitting problems arising when many regulators are used to explain the variation of few data points.

in addition to identifying important tf-gene interactions in the rad <dig> response, we were interested in exploring how the network response is integrated; thus, we explored relationships between perturbed tfs. the tfas of  <dig> tfs  were significantly  perturbed in prostate tissue of wild type mice at  <dig> or  <dig> hours after treating mice with the mtor inhibitor rad <dig>  tfa profiles for the  <dig> tfs  with p-values <  <dig>  are shown in figure  <dig>  the p-values were then adjusted by the benjamini and hochberg method to account for multiple hypotheses testing. the tfas of eight tfs  were consistently identified as significantly  perturbed after  <dig> hours. among the  <dig> significantly perturbed tfs, atf <dig>  cebpb, and relb responded earlier at  <dig> hours after treatment, and were down-regulated further after  <dig> hours, while the remaining tfs were only significantly perturbed at  <dig> hours. rad <dig> treatment decreased all of the tfas except hoxa <dig>  hoxc <dig>  trp <dig>  and stat5b. the perturbation of hif1a was confirmed in the original paper  <cit> , while atf <dig>  <cit> , cebpb, and nfkb <dig>  <cit>  were identified as targets of rapamycin in different human cell lines. by mapping the perturbed tfs to kegg database, we found the set of perturbed tfs was enriched for three pathways: acute and chronic myeloid leukemia, and mapk signaling pathways with the p-values of fisher's exact test less than  <dig>  and fold enrichment being greater than  <dig>  recently it has been found that rad <dig> activates the mapk pathways through a pi3k-dependent feedback loop in human cancer  <cit> .

to identify relationships between the  <dig> significantly perturbed tfs we subjected them to a variety of informatics analyses. these tfs were first subjected to signaling pathway analysis to see if they shared any common upstream pathways. three signaling pathways commonly used by these tfs were identified with the functional annotation tool box from david  <cit> :  the jnk/p <dig> mapk signaling pathway, which involves trp <dig>  nfkb <dig>  and fos as its down-stream targets,  the acute and  chronic myeloid leukemia pathways which contain sfpi <dig>  stat5b and rara. to determine if any of the tfs interact each other, we used the string  <cit>  toolbox to identify gene/protein interactions . string identifies interactions based on evidence from experimental data, homology, text mining, etc. experimental data indicate that cebpb interacts with myb, sfpi <dig>  and atf <dig>  <cit> , that relb interacts with nfkb <dig>  <cit> , and trp <dig>  also associated with hif1a, atf <dig> and wt <dig>  <cit> . in brief, these key tfs are highly connected to each other by either sharing common signaling pathways or through protein-protein interactions.

discussion
although nca can deduce a tfa, it may not accurately estimate the strength of the tf-gene connectivity because the initial network connectivity map may contain a number of false positive tf-gene connections. these false positive connections, typically, arise from either a false prediction or a condition-dependent tf-gene interaction. the goal of network trimming is to identify the key tfs and their regulated genes from the initial network connectivity map containing a moderate level of false connections. our algorithm trims superfluous connections, so that the important connections will standout. removing connections that are not relevant to the condition of interest is of crucial importance when dealing with pleiotropic global regulators, such as p <dig> 

we, also, present a data augmentation algorithm that expands the applicability of nca to the study of mammalian transcription networks which frequently cannot be analyzed by nca due to a dearth of data. besides stabilizing the nca numerical decomposition, generating additional data in silico allows more genes to be analyzed thus reducing the possibility that important genes will not be analyzed. and, we show that our augmentation algorithm circumvents the problem of a high degree of biological noise in the real biological data, in which the estimated css become artificial products of fitting noise rather than reflecting the strength of association between tf-gene, and that noise leads to a lower tpr for important tf-gene interactions as was demonstrated with the synthetic and biological examples. one potential drawback of using our data augmentation algorithm is that some biological variation in tfas may be averaged out. to assess if any biological variation was averaged-away during data augmentation, it is possible to analyze the raw data with the trimmed network. our method rules out the influence of overfitting that can arise from data augmentation; the stepwise regression component of our network trimming approach eliminates redundancy such that the number of regulators regulating each individual gene in the final network is constrained by the number of available data points.

the performance of our approach does not depend on the size of the network, but rather features of the network structure such as: how many tfs regulate a gene, number of genes regulated by a tf , overlap between regulons, etc. because our goal is to extend nca to the analysis of complex mammalian networks, the simulated network structure was constructed similar to the murine network, and incorporated the aforementioned features at different levels. for example, the simulated network regulon size varies from  <dig> to more than  <dig> genes. various regulation patterns are also covered in this network:  some tfs mostly regulate their genes alone , while some tfs often strongly overlap with other tfs in regulating genes .

our analysis indicates that the algorithm is beneficial in the case that the number of experiments, r, is so small that prior incarnations of nca cannot be used. when few data sets are available at the time of analysis, our method can be used for screening the important tfs which will aid in the design of further experiments for studying their regulated genes. the transcriptome data from the new experiments can be added to the existing datasets for another round of analysis to improve the prediction further.

we employed our approach to analyze transcriptome data taken from wild type mice treated with rad <dig>  <cit>  . rad <dig> is an inhibitor of mtor, which is a serine/threonine protein kinase that regulates cell growth, proliferation, and motility through both transcriptional and translational regulation. among the  <dig> key tfs identified as targets of rapamycin by the method, hif1a, cebpb, nfkb <dig>  and atf <dig> are confirmed by literature as rapamycin-related tfs. foxo is a tf that has recently been reported  <cit>  to be involved in mtor signaling, but unfortunately it was not included in the analyzed network because it was not in the database from which the original connectivity matrix was derived. our algorithm is only able to identify target tfs from a given network, and it is beyond the scope of the approach for identifying tfs without information regarding their regulated genes.

since  <dig> out of  <dig> tfs have not been identified in the literature as being related to rad <dig>  we searched for potential links in known signaling pathways and reported, or predicted, protein interactions. if they are perturbed by rad <dig> treatment, it is plausible that they share common signaling pathways or interact with each other. pathway analysis and protein interaction analysis based on literature mining indicated the presence of evidence supporting interactions between a number of the tfs . taken together, the nca results and pathway/interaction analyses highlight additional components of the rad <dig> response that may be of interest when developing targeted therapeutics.

like the gibbs sampling method  <cit> , our method aims to identify the most reliable edges in the nca compliant network. however, the novelty of our strategy is that it trims the network so that we can analyze a network with more genes and less data points than the gibbs sampling method. thus, our method can start with a nca incompliant network whereas the gibbs sampling method requires the initial network as nca compliant, so the gibbs sampling method is not suitable for interpreting a large number of mammalian data sets. overall, we've provided an approach that facilitates the application of nca to complex mammalian networks with limited data.

CONCLUSIONS
the advantage of our new algorithm, relative to the original nca, is that our algorithm can identify the important tf-gene interactions. identifying the important tf-gene interactions is crucial for understanding the roles of pleiotropic global regulators, such as p <dig>  also, our algorithm has been developed to overcome nca's inability to analyze large networks where multiple tfs regulate a single gene. thus, our algorithm extends the applicability of nca to the realm of mammalian regulatory network analysis.

