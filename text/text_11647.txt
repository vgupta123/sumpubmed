BACKGROUND
despite current comprehensive efforts  <cit> , three-dimensional structure has been determined for only a fraction of sequence-based protein families  <cit> . thus there is a need for powerful methods of structure prediction from protein sequence. the most reliable and widely used approaches are based on the detection of statistically supported sequence similarity to proteins of known structure. for both effective development of better structure prediction methods based on sequence similarity, and comparative performance analysis of existing methods, it is crucial to have a good benchmark and a comprehensive methodology for accurate and sensitive evaluation.

the quality of a sequence comparison method can be judged by the quality of 1) similarity detection in a database of sequences or alignments, and 2) sequence alignment for a pair of structurally similar protein domains. these general criteria lead to a variety of possible settings for a method's evaluation. multiple surveys have been published that compare the performance of methods for remote homology detection and structure prediction . to assess the quality of similarity detection from sequence, workers generally use a set of protein domains from an established structure classification, such as scop  <cit>  or cath  <cit> , and compare similarity predictions to classification groupings at various hierarchical levels, e.g. family, superfamily, fold, etc. when used as benchmarks, these classifications, while being excellent sources of information, present multiple problems. first, although scop folds group proteins with general structural similarity and scop superfamilies correspond to evolutionary groups, the relationships between superfamilies within the same fold remain undefined: some superfamilies within a fold are very similar and can serve as good templates for each other, others are quite different, and fold similarity between them may not be useful for modeling. second, although many scop folds are structurally distinct, there are multiple examples of folds with pronounced structural similarity between them, such as rossmann-like doubly-wound sandwich folds of α/β scop class, immunoglobulin-like β-sandwiches, and β-propeller folds. third, existing manually curated classifications do not provide reference alignments for the evaluation of sequence-based alignment accuracy. in the published surveys, the accuracy of sequence alignments is usually assessed on a different protein set, by comparing sequence alignments with the 'gold standard' pairwise structure-based alignments produced by some software, for instance dali  <cit> .

in the bi-annual community-wide assessments of protein structure prediction, casp   <cit>  and cafasp   <cit> , the testing set is limited to a small number of newly solved protein structures   <cit> . however, along with being a strong catalyst in development of structure prediction methods, casp pioneered efforts in development of approaches to evaluation of models. among various parameters used by casp and related benchmarks, reference-independent global distance test score   <cit>  has proven to be one of the most informative and robust measures. this score assesses the quality of structure superposition. large-scale evaluation projects livebench  <cit>  and eva  <cit>  provide quite a few methods to score protein models. however, casp and livebench efforts are largely aimed at structure modeling techniques and thus compare model to structure. our goal is to validate sequence similarity and homology inference tools, and thus to compare a protein to its homolog or structural analog.

to our knowledge, in spite of the variety of existing evaluation protocols  <cit> , there is no satisfactory approach that  is based on a large and statistically unbiased set of proteins with clearly defined relationships; and  covers all performance aspects of sequence-based structure predictors, such as sensitivity and specificity, alignment accuracy and coverage, and structure template quality. with the aim of designing a comprehensive evaluation method, we  select a statistically balanced set of divergent protein domains from scop, and define similarity relationships for the majority of these domains with a rigorous algorithm that uses the best of information available in scop, while correcting inconsistencies and problems mentioned above; and  develop protocols for the assessment of similarity detection and alignment quality from several complementary perspectives .

our protocol is based on three principles. first, for a sequence similarity search method to be successful, it needs to  rank protein domains from a database in a meaningful way, so that high-scoring domains correspond to good 3d structure matches: i.e. true positives should score high,  align those true positives in a way consistent with 3d structure. we refer to  and  as 'similarity detection' and 'alignment quality' evaluation. second, traditional way of reference-dependent evaluation, in which a ranked hit list or evaluated alignment are compared to a 'gold standard' reference, e.g. to scop hierarchy or to dali alignment, should be complemented with reference-independent evaluation, in which structure comparison characteristics of sequence-based alignment are computed and analyzed. this casp-style reference-independent evaluation has been successfully applied by us to alignment programs  <cit>  and, while showing agreement with reference-dependent evaluation, does not need reference databases, bypassing additional source of problems with reference. third, while there is a need for methods to detect global, domain-level similarity, in particular for finding good templates for structure modeling and evolutionary links between domains, it is of an interest to find short, local fragments that are conformationally similar to fragments of the query domain. these fragments can be used by structure prediction methods to assemble models from. we evaluate both 'global' and 'local' properties of a search algorithm.

general workflow of the evaluation protocol that we have developed is shown on fig.  <dig>  first, we assess the quality of similarity detection, i.e. method's ability to discriminate between correct and incorrect similarity predictions by estimating their statistical significance. roc curves  <cit>  and sensitivity curves similar to roc curves are constructed, based on several criteria for a match to be true positive. reference-dependent evaluations use a 'gold-standard' set of pre-defined relationships between domain pairs and a set of structural alignments. the more traditional of these protocols regards as correct any prediction of similarity for domains that are known to be similar; the other, more stringent protocol additionally requires a certain degree of alignment accuracy . reference-independent evaluations are based on gdt_ts scores and thus inherently take into consideration the quality of predicted alignments. in these protocols, gdt_ts scores are adjusted for the global and local modes of evaluation . the global mode favors fold predictions for the whole query domain and tolerates potential inaccuracy of detail. the local mode rewards precision of the predicted alignment, however short the predicted fragment is, while correcting for higher probability of a good quality random match between shorter fragments. there might be a situation when the estimates of statistical significance produced by a method from a raw alignment score are biased by the query's length, amino acid composition, number of sequences in an alignment and other factors. this bias would deteriorate the performance on the set of all-to-all domain comparisons, in spite of a good ranking of hits by the raw score for each individual query. in order to control for such situation, each protocol includes both assessment of all-to-all comparisons combined within the dataset, and the evaluation of detection quality for individual query domains . second, we assess the produced alignments of true positives regardless of their assigned statistical significance. for pairs of similar domains binned by sequence identity, we calculate several reference-dependent and reference-independent measures of alignment quality .

we apply this evaluation pipeline to several well-known sequence and profile methods and show that different aspects of evaluation  reveal different properties in the evaluated methods, highlighting advantages and weaknesses of each method.

RESULTS
to assess a method for remote sequence similarity detection , we evaluate the method as 'a searcher'  and as 'an aligner' . first, we carefully select a dataset of  <dig> domain representatives from scop, and determine their similarity relations by combining the expert scop assignments of superfamilies with multiple automated methods for structure and sequence comparison. we are able to reduce the number of 'undefined' domain relationships to 10% of the whole set, and to re-define similarity relations between some of the scop folds. second, we use the pairs of similar domains as a benchmark for the assessment of alignment quality, from both global  and local  perspectives. third, we use all-to-all comparisons in the whole set of domains to assess the quality of similarity detection. we develop four protocols with different definitions of true and false positive predictions . as an illustration, we benchmark several profile-based methods for sequence comparison and compare their performance from several different standpoints.

benchmark dataset
our benchmark set of protein domains   comprises a large statistical sample;  provides unbiased representation of existing protein structures; and  contains a considerable portion of domains pairs whose similarity is challenging to detect. the dataset contains  <dig> scop domains from  <dig> superfamilies of seven classes. fig. 2a shows the distribution of domain lengths, between  <dig> and  <dig> residues with a median of  <dig> residues. fig. 2b shows the distribution of number of representatives per scop superfamily. representation of different scop classes in our dataset is similar to the astral scop <dig> set .

scop is a manually curated structure classification based on both structural and evolutionary considerations. well known for a high quality of domain delineation and diligent analysis of domain similarities, scop is often used as a 'gold standard' for homology detection and fold recognition  <cit> . however, there are at least two factors that limit the quality of this classification as a standard: a large 'gray area' of unknown relationships between different superfamilies of the same scop fold, and many examples of different folds that are structurally similar to the extent that one would serve as a good template for another. the simplest solution is to regard only well-established categories, considering domains from the same superfamily as similar, domains from different classes as dissimilar, and disregarding all intermediate cases  as 'unknowns'  <cit> . however, in a set of scop domain representatives, the 'unknown' category may include a considerable fraction of pairs. to reduce this category, soding  <cit>  applied maxsub score  <cit>  as an additional criterion of domain similarity.

our goal was to use the well-established  cases of similarity represented by scop superfamilies, on one hand, and the clear cases of dissimilarity represented by different scop classes, on the other hand, and to train svm on these cases. the resulting svm does not reproduce criteria of scop classification, but is directed only at the structural similarity between domains. as detailed below, application of this svm adds a significant number of structural similarities that are generally consistent with multiple observations of different research groups. similar svm-based approaches  have been successfully used by others .

in order to produce statistically sound benchmark dataset, we set the goal of reducing the fraction of 'unknown' relationships to as low as 10%. to achieve this goal, we use an svm-based consensus of a number of structure- and sequence-based methods, which allows us to classify the majority of 'unknown' scop category. out of total  <dig> , <dig> domain pairs, only  <dig>  share a scop fold, whereas  <dig>  are classified as similar by svm. svm more than triples the number of similar domains, adding  <dig>  similar pairs from different folds. about two thirds of these  have dali z-score >  <dig> ; the inclusion of the remaining pairs was guided by other svm features, mainly fast score, the second largest svm component. distribution of the added pairs among scop classes reflects the structural diversity within each class and their representation in the whole set. about a half  belongs to the large α/β class, which contains many homologous rossmann-type folds that are separated in scop by features other than overall structural similarity  <cit> . out of  <dig> structural folds in the α/β class of scop  <dig> , at least  <dig> folds are rossmann-type, with a structure pattern of the doubly-wound α/β sandwich. next large group  belongs to all-alpha class containing a number of structurally similar folds. many domains of all-beta class  belong to multiple immunoglobulin sandwich folds and beta-propeller folds. α + β class is the most diverse and accordingly the least represented of the major scop classes: it contributes  <dig>  or ~ 7% of all similar domain pairs added by svm. at the same time, only  <dig>  pairs that share a fold are not classified as similar by svm. on the scop superfamily level, only  <dig>  pairs should be classified as similar, almost  <dig> times fewer than classified by svm. out of total  <dig> , <dig> domain pairs, our method classifies  <dig>  pairs  as similar ,  <dig> , <dig> pairs  as dissimilar , and  <dig> , <dig> pairs  as 'unknown'.

creating a reliable benchmark set of pairwise similarities between domains is different from the task of domain classification. the problem of automated classification of scop domains has been addressed elsewhere . our goal was not to construct a new classification, but to assign more consistent similarity relationships to domain pairs for benchmarking purposes. classification would further require establishing transitive connections between domains and additional optimization of the methods for hierarchical grouping of domains, which is out of scope of this work.

reference-dependent evaluation of method's performance can be performed with two types of reference:  known relationships between domains of the testing set; and  known structure-based alignments of domain sequences. in fold recognition assessment, evaluation  has been traditionally performed using a large-scale structure classification , whereas evaluation  has been ignored. in other words, a true similarity prediction providing incorrect alignment has been treated the same as a prediction providing correct alignment. in our benchmark, this traditional approach  is complemented by the alignment-based approach, where the true predictions of domain similarity are additionally assessed by the criteria of alignment quality . there are two main motivations behind this approach. first, better alignment quality often results in better recognition of sequence similarity. for example, results of recent casps  show a need for such a combined evaluation of structure modeling methods. second, a better method may consist of two separate steps: initial detection of a similarity followed by the construction of a high-quality alignment for the detected pair. put in a pipeline, these steps may produce a better structural model. our evaluation criteria would cover this case as well.

both types of reference-dependent criteria would penalize short alignments that are structurally reasonable but differ from the 'gold standard', for example, alignments of similar structural fragments  therefore reference-dependent evaluation may be considered a global rather than local assessment of structure prediction.

in addition, we perform evaluations that do not require any prior knowledge about protein relationships or alignments. these evaluations are based on the quality of structure superposition suggested by a sequence alignment of interest, reflected in the gdt_ts score  <cit> . the global mode  rewards detecting good overall structural templates for the query, i.e. global fold recognition. the local mode  rewards finding local but precise alignments to segments of the query, i.e. fragment modeling. different sequence-based alignment methods may be optimal for different modes of structure prediction. thus using both modes is necessary for a balanced and informative evaluation.

evaluation examples
as an illustration, we use our benchmark to compare the performance of several methods for the detection of remote sequence similarities: psi-blast version  <dig> . <dig>  <cit> , methods for profile-profile comparison  information used), and for the comparison of profiles combined with predicted ss . these programs are used for all-against-all comparison of domains in the benchmark set. the resulting sequence alignments, with statistical significance assigned, are processed using the evaluation methods described above.

for the assessment of alignment quality, all pairs of domains defined as similar are used, and various parameters of the produced alignments are calculated for several ranges of sequence identity . for each parameter, the rankings of methods are consistent in all identity bins. despite similar alignment coverage , profile-profile methods in general achieve alignment accuracy higher than psi-blast, which involves profile-sequence comparison .

the results of reference-dependent assessment are shown in fig. 4a–d. hhsearch, a method utilizing ss predictions for the compared profiles  <cit> , produces the largest number of accurate residue matches reflected in qdeveloper , whereas compass and prof_ss provide a larger fraction of accurate matches within the produced alignment, as reflected in qmodeller . these differences seem to be caused mainly by the higher coverage achieved by longer hhsearch alignments . the local accuracy over the aligned structural regions is much more similar for all the methods , although qlocal is slightly higher for the methods that consider ss predictions, hhsearch and prof_ss.

the results of reference-independent assessment of alignment quality are shown in fig. 4e,f. the original gdt_ts scores are shown in fig. 4e. hhsearch performs best, followed by prof_ss and profile-profile methods with no ss considered. this result is similar to the global reference-dependent evaluation by qdeveloper . the ranking by local gdt_ts measure  is different from the global measure: prof_ss shows the best performance, closely followed by compass, in accord with the ranking by reference-dependent local measure qmodeller . notably, hhsearch version with ss considered produces lower local gdt_ts than the version without consideration of ss , presumably due to the inclusion of alignment regions with higher structural deviation between domains.

for the evaluation of sequence similarity detection, we use sensitivity curves similar to roc curve  <cit> , which are based on the list of predictions  produced by a method of interest and sorted by their statistical significance . we construct several sensitivity curves based on different approaches to the assessment of hits as true or false positives . in all evaluation settings, methods based on profile-profile comparison show better performance than psi-blast. hhsearch performs best in three of the four settings. profile-profile methods with no ss consideration are ranked next in most cases.

fig. 5a and 5b respectively show the results of reference-dependent evaluation with no requirement for alignment quality, and with a certain level of alignment accuracy required for a hit to be considered a true positive. notably, the two evaluations produce the same ranking of methods' performance. according to reference-dependent assessment, hhsearch provides the best similarity detection, followed by compass and the version of hhsearch with no ss considered, then prof_ss and psi-blast. thus additional analysis of accuracy of predicted alignments does not make significant changes in the ranking of evaluated methods. this result suggests that the quality of predicted alignment generally correlates with statistical significance of a hit, and that all methods produce similar fractions of the top true positive hits with accurate alignments.

fig. 5c and 5d show the results of reference-independent evaluation in local  and global  modes. interestingly, the ranks of methods in the global mode are similar to the reference-dependent setting, except for a clearly lower performance of compass compared to the hhsearch version with no ss considered. this difference may be attributed to the length of the alignments produced by the two methods. according to our observations, compass tends to construct shorter alignments including regions of highest similarity between two profiles, whereas hhsearch generates alignments covering longer segments of the query. despite the latter alignments may include regions of lower accuracy, they are more valuable for the prediction of whole domain structure and therefore favored by the global evaluation mode . the difference in the alignment coverage of the two methods may be due to the different methodological frameworks. compass employs the 'traditional' profile comparison and uses smith-waterman algorithm for the alignment construction with fixed gap penalties, whereas hhsearch is based on hhm-hhm comparison and features adjustable gap penalties, which might produce more extended alignments.

in the local mode of reference-independent evaluation , the methods are ranked differently: the performance of compass is the best, followed by the performance of hhsearch versions with and without consideration of ss. this ranking suggests that shorter alignments produced by compass have higher prediction accuracy 'per residue' and may provide a better detection of local structural similarities. comparison of fig. 5c and 5d illustrates a tradeoff between the quality of global and local predictions: more extended alignments tend to include a larger portion of less accurate regions but better predict overall structural fold, whereas shorter alignments limit the ability for global fold recognition but are better in precise modeling of structural fragments.

fig. 5e shows the sensitivity curves produced in the same setting as in fig. 5a–d, but with true and false positives determined by scop relations only . the relative difference between the two hhsearch versions is much less pronounced than on our benchmark, since the addition of secondary structure gains the main improvement in the area of extremely remote sequence similarity that corresponds to scop levels higher than superfamily .

the results of paired tests for detection quality on individual queries  are different from the results on all-to-all domain comparisons. for reference-dependent evaluation without consideration of alignment quality of the produced hits, the ranking of performance is hhsearch > hhsearch  > prof_ss > compass > psi-blast, where '>' sign denotes statistically significant difference . consideration of alignment quality results in the same ranking. the ranking produced by the global mode of reference-independent evaluation is hhsearch > compass > hhsearch  > prof_ss > psi-blast, whereas the ranking for the local mode is prof_ss > hhsearch > compass > hhsearch  > psi-blast .

methods are compared by sensitivity values at 50% selectivity, calculated separately for each query. for each pair of methods, p-values of paired wilcoxon rank test are shown for four types of criteria for true/false positive distinction : reference-dependent without alignment quality and with alignment quality, and reference-independent global and local. plus and minus signs by the p-values denote respectively positive and negative difference for the method indicated on the left vs the method indicated on the top. the left column includes mean values over all queries for each method.

the assessment of detection quality split into individual queries disregards the ability of a method to make the estimates of statistical significance that would be transferable between queries. in this assessment, only ranks of hits produced by individual query are considered. typically, for a given query the estimated statistical significance of a hit  monotonically depends on the 'raw' score of the produced alignment. therefore, for the hits produced by a single query the ranks of e-values are the same as the ranks of raw scores. thus splitting the assessment into individual queries in effect bypasses the procedure of estimating statistical significance altogether. comparing the results of this assessment  to the results for all queries combined  highlights the quality of the e-value estimation implemented by different methods. in particular, the evaluation on individual queries  shows higher performance for the methods using ss predictions , which suggests better ranking by the raw alignment scores when a single query is considered. in contrast, the performance of prof_ss is lower according to 'all-to-all' evaluations . these results suggest that prof_ss is more applicable to the search for locally similar structural fragments, and that this method may have a potential to improve the estimates of statistical significance, so that these estimates are more compatible for different queries, regardless of query's length, residue composition, and other properties.

the results produced by the presented benchmark are in general accord with previously reported evaluations  <cit>  in the parts where similar approaches are used. our results confirm the superiority of profile-profile comparison over profile-sequence comparison. in addition, both our reference-dependent evaluation  and reference-independent evaluation  support the conclusion  <cit>  that the use of predicted secondary structure in the comparison of msas can improve the quality of similarity detection. in particular, hhsearch version that uses secondary structure performs better than hhsearch without the use of secondary structure . compared with benchmarks that are based entirely on scop , our testing set provides much higher sensitivity in the distinction between different methods, mainly due to a careful selection of divergent domains and a small fraction of 'unknown' relationships.

we also introduce evaluation approaches that have not been used in similar systems before. in some cases, the results produced by these approaches differ from the results of more traditional evaluations. first, we provide gdt_ts-based reference-independent assessments of similarity detection . the two modes of this evaluation, global and local, provide additional information about the quality of the searches for the overall structure similarity between domains and for similar structural fragments, respectively. as in the case of compass  <dig>  , the same method can perform quite differently according to these two types of detection quality. such evaluations allow the user to determine which methods are more appropriate for a particular task. second, in addition to the evaluations of similarity detection on the whole set of all-to-all domain comparisons, we implement the separate evaluation for different queries. a similar approach was proposed by soding  <cit>  who constructed the distributions of maxsub scores of the top hit for each query. we use a more direct approach that is based on individual sensitivity/selectivity curves and provides a single number  characterizing the comparison between two detection methods. such evaluation should be especially valuable for developers of new methods, allowing them to evaluate other parts of the methods separately from the tedious and often problematic procedure of e-value estimation. as an example, this evaluation  shows a potential for further development of prof_ss and pinpoints the procedural part that may cause a lower performance of this method in the all-to-all setting .

CONCLUSIONS
we have developed a comprehensive benchmark system that serves as a tool for a statistically unbiased assessment of methods for remote sequence similarity detection, from various complementary perspectives. this tool should be useful both for users choosing the best method for a given purpose, and for developers designing new, more powerful methods. the benchmark set, reference alignments, and evaluation codes are available to download from  <cit> .

