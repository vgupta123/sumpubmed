BACKGROUND
since the introduction of dna microarrays  <cit> , the technology is now well established for the investigation of diverse problems in biology and medicine  <cit> . historically pcr products were often used as microarray probes. oligonucleotide microarrays have now become more popular, especially since the number of fully sequenced genomes is increasing fast . synthetic oligonucleotide probes allow the manufacture of probe sets with consistent validated quality. in addition, the increased experimental control available with oligonucleotide probes allows the construction of highly uniform arrays  <cit> . with careful probe design, both sensitivity and specificity in target detection can be greatly improved  <cit> .

it should, however, be emphasized that it is always the combination of careful probe design together with well-matched experimental conditions that determines the performance of an array  <cit> . although this has been recognized, the issues of experimentally validating a newly designed array and the determination of well-matched conditions that optimize sensitivity and specificity of the probe set have in general received considerably less attention than probe design itself. while microarray probes are designed for minimal cross-hybridization at certain idealized reaction conditions, calculations are based on corresponding model parameters. surface interactions, however, moderate effective local concentrations, and buffer additives determine the effective hybridization temperature. these complex effects are only partly understood and the correct parameters can hence not be calculated in advance. the effective hybridization temperature in probe design computations thus differs from the optimized physical temperature that should be used for hybridizations.

for each probe, hybridization below its optimal hybridization temperature results in increased cross-hybridization giving reduced signal specificity. hybridization above that temperature, however, is less sensitive, yielding reduced signal intensities and thus a degraded signal-to-noise ratio. an essential property of a well designed probe set is its ability to discriminate as many gene transcripts as possible. strong sequence similarities between related transcripts often restrict the choice of specific probes to just a few suitable oligonucleotides, which can have very different thermodynamic properties. consequently, even for well designed probe sets, the hybridization temperature that optimizes the performance of individual probes can vary considerably. for maximizing overall array performance, the challenge hence is to find, by calibration, the optimal experimental conditions that form the best compromise for the entire probe set.

although several aspects of array performance and calibration have been studied  <cit> , finding an optimal trade-off between probe sensitivity and specificity, poses a particular challenge. maximizing the contrast between two differentially expressed samples may be a promising way of determining optimal conditions empirically. while one can easily construct a variety of quality measures based on differential expression, quality measures need to be chosen with care, and intuition can be misleading. cross-hybridization of differentially expressed targets, in particular, can create spurious signals. these confound quantitative analysis and can invalidate quality measures based on differential signal strength alone. it can consequently be shown that neither visualizations like scatter plots nor simple summary statistics of differential expression provide robust performance indicators.

this manuscript demonstrates, for the first time, how a simple comparison of two typical biologically distinct samples can be used to reliably calibrate experimental conditions for the optimal detection of differential gene expression, the predominant use of microarrays. for this purpose, a family of complementary quality measures is introduced that quantitatively reflect the amount of information that can be extracted from a set of microarray measurements. method bias is avoided by the complementary consideration of model-based performance measures and model-free diagnostics. running tests on arbitrary measurement subsets corresponding to samples with very different characteristics then verifies that the calibration is independent of the actual samples used for calibration. this is further confirmed using experiments with spiked-in rnas.

the general practical importance of robust calibration, finally, is highlighted by an examination of the detrimental effects of suboptimal conditions, considering in particular the severity of sensitivity loss across all types of genes and the measurement bias against low-copy-number molecules like transcription factors. in comparison to alternative genome scale high-throughput technologies, the quantitative assessment of low-copy-number transcripts is a particular strength of microarrays. to make the most of this strength, however, careful lab-oratory calibration is essential.

RESULTS
optimal hybridization temperature
for each probe, depending on its structure and that of its potential binding partners, there will be optimal conditions under which it binds the intended target strongly while minimally binding any non-targets. an essential property of a well designed probe set is its ability to uniquely target as many gene transcripts as possible. in the design of specific probes, strong sequence similarities between related transcripts often require the selection of oligonucleotides with a wide range of binding affinities. even for well designed probe sets, the hybridization temperatures that optimize the performance of individual probes can thus vary considerably. for maximizing overall array performance, the challenge is hence to find, by calibration, the optimal experimental conditions that form the best compromise for the entire probe set.

finding the optimal hybridization temperature constitutes a particularly important step. the hybridization temperature has an effect on the binding behavior of nucleotide strands, where the boltzmann factor   

describes the equilibrium temperature dependence  <cit> , with the boltzmann constant kb and the gibbs binding free energy Δgt  <  <dig> for a pair of nucleotide strands  that bind exergonically at the effective hybridization temperature t.

for a well designed probe set , the boltzmann factors γt  should be similar for all p ∈  and there exists a temperature t such that for most probes γt  ≫ γt  for all non-targets π' ≠ π. hybridization below this temperature will result in increased cross-hybridization with reduced signal specificity. probe cross-hybridization potential will, on average, affect all genes equally, independent of their expression levels and whether they are differentially expressed, with cross-hybridization depending on non-target concentration and the corresponding Δgt   <cit> . cross-hybridization at a lower than optimal temperature will reduce the specificity of a large number of probes. the biological samples which are used for calibration must therefore be chosen with care to avoid situations where cross-hybridization yields an apparent overall increase in differential expression. since cross-hybridization induced signals are an average response from many cross-hybridizing non-targets, a suitable biological experiment will have a sufficient number of strongly and non-differentially expressed targets , and avoid a clear bias towards either up- or down-regulated genes. cross-hybridization in a calibration experiment with largely balanced differential expression and many 'house-keeping genes' leads to a loss of differential signal when averaging over all probes. an increase in the detection of average differential signal is then an indication of measurement specificity.

hybridization above the optimal hybridization temperature, however, will yield reduced signal intensities, giving a degraded signal-to-noise ratio and lower sensitivity. this directly leads to a loss of power in the detection of differential expression at high temperatures, because genes of low expression level cannot be measured reliably, and subtle differences are drowned out by noise. if we choose a suitable biological experiment, both the sensitivity and the specificity of the measurement process can be assessed by quantifying the differential expression at different hybridization temperatures.

for calibration, we can thus use a comparison of two typical biologically distinct samples. these are chosen such that a large number of strongly and non-differentially expressed genes are expected, avoiding very different tissue or cell types or other situations where there are likely to be biased or strong global gene expression changes. overall probe sensitivity and specificity can then be assessed simultaneously by quantifying the amount of information about sample differences that can be extracted from the differential signal. an increased amount of information directly corresponds to greater power in the detection of differential expression , and thus yields more genes reliably detected as differentially expressed. several related quality measures are introduced and discussed below.

the above calibration approach and quantitative assessments form the basis of an objective optimization protocol. to ensure general validity and relevance of the optimum for arbitrary experimental conditions, we also demonstrate how we can confirm that the protocol assessment is independent of the particular samples studied.

quantitative objective measures
assessment measures for an optimization of protocols should be of direct relevance to typical microarray experiments. despite the flexibility of the platform, differential expression analysis is still the dominant application of microarrays. current computational methods for the identification of individual differentially expressed genes calculate significance tests separately for each gene  <cit> . the amount of information that a particular gene carries about sample differences is reflected by the corresponding p-value: large differences in expression levels relative to random noise result in small p-values, indicating the reliable identification of differential expression.

we can take two alternative approaches to relating  gene expression levels xg for a gene g to the labels y of the compared biological samples. the first of which arises from the p-value calculations in linear anova modelling:   

where  

and we have converted the binary label y into a row vector using a one-of-two target coding to simplify notation,  

for each gene g, the model relates the expression levels xg to the biological labels y. observing small p-values for a gene g in an anova test corresponds to obtaining large likelihoods for the linear model of eq. . the amount of information found in the expression levels xg about the biological label y can thus alternatively be assessed via the p-value of the anova significance test or the likelihood of the linear model eq. . to formalize the comparison of alternative protocols, we introduce a discrete protocol label k. the performance measure for assessing the effect of a hybridization protocol needs to be an adequate summary for all genes. the independence assumptions of typical p-value calculations are appropriately taken into account by regarding all gene specific models of eq.  as independent, when conditioning on the protocol indicator k. the likelihood function for protocol k is then a product of all gene specific likelihood functions. denoting all labels as  and the expression levels as , the linear model from eq.  thus leads to the protocol dependent likelihood   

as a suitable measure of information content. rather than applying this directly, however, we pursue a second approach, in which we introduce a dual representation that allows the derivation of complementary diagnostic measures that do not depend on modelling assumptions. the linear model eq.  can be interpreted as implying that, conditional on the sample label y, the expression level xg has a gaussian distribution with standard deviation  and mean μg,y:  

the joint density p is a product of the prior probability of the label p times the conditional density p:  

the prior probability p is given by the proportion of arrays measuring the respective biological sample and does not contribute to the information we gain from expression levels about the samples. that information is contained entirely in the conditional density p. using elementary rules of probability calculus, the joint density can also be expressed as the product of the unconditional density of expression patterns p and the conditional probability of a biological sample p:  

in this formulation, the amount of information about the samples encoded in expression levels determines the probability p with which we could predict the correct sample label y from the observed expression level xg.

the assumptions of a linear anova model correspond to class-conditional normal densities of different means and a common standard deviation. the posterior probability then takes the form of a logistic cumulative distribution function  <cit> :   

with  

and  

where μg, <dig> and μg, <dig> denote the means of the gaussian densities for the different biological samples. variants of this generalized linear model have successfully been used in the context of microarray analysis  <cit> . this dual representation of the linear model eq.  in particular also allows the derivation of model diagnostics for protocol assessment that are independent of the model eq. . these are introduced and further discussed in the next section.

within this paradigm we can derive a likelihood as a quantitative measure for assessing hybridization protocol performance: with gene independence follows the likelihood   

the likelihood function in eq.  is known in statistics and machine learning as the likelihood function of a naïve bayes classifier  <cit> , where 'const' represents a normalization constant which is independent of the yn.

for assessing the hybridization protocol k, we maximize the likelihood for all model coefficients to get the maximum likelihood  conditional on the protocol k used for measuring the microarray expression patterns .

to summarize, we have introduced two equivalent representations with identical modelling assumptions that allow an assessment of how much information the observed expression patterns provide about the measured biological samples. differential expression based assessment of hybridization conditions requires validation that cross-hybridization does not confound our conclusions. to this end, the following section provides an analysis of the behavior of the likelihood function, eq. , in dependence of sample characteristics and hybridization temperatures.

information content and sample characteristics
synthesized sample data could be used to demonstrate how reliable the proposed approach is for assessing hybridization conditions, while identifying potential limitations and requirements on sample characteristics. data was generated such as to study the effects of cross-hybridization on the proposed likelihood measure in eq. . first, we investigated the effects of cross-hybridization for samples with varying amounts of differential expression. cross-hybridization was studied by adding small off sets to the mean expression of some genes with low expression levels.

the results illustrated in figure  <dig> were obtained by selecting  <dig> genes each with zero, low, medium, and high differential expression . figure  <dig> illustrates the log likelihoods for nine samples with very different fold-change distributions. all likelihood measures are compared to the likelihood we observe in the non-contaminated case  constituting the baseline reference. for simulating cross-hybridization, signals for half of the weakly expressed genes in each of the groups were modified by adding a small off set. this was done for each individual group , for all possible pairs of groups and, finally, for all groups together . results allow us to draw two conclusions: the increased log likelihood we observe when considering non-differentially expressed genes only  indicates that unsuitably chosen biological samples can be susceptible to artefacts from cross-hybridization. this suggests that computations need safeguards for diagnosing this problem. on the other hand, the gain observed for non-differentially expressed genes is far outweighed by the loss incurred from genes with medium or high differential expression . as a consequence, in situations where cross-hybridization also affects genes with medium or high differential expression , cross-hybridization yields an overall reduction of the likelihood, eq. . this is due to an intrinsic property of likelihood functions and confirms that the proposed measure is not confounded by cross-hybridization as long as the differential expression introduced by cross-hybridization is balanced by a loss of differential expression for other probes. we further examine the resulting requirements on biological samples used for calibration by means of a langmuir model.

for this, we test the dependency of the temperature calibration on different expression scenarios. expression intensities are represented using a langmuir model , as function of physical binding properties , target concentrations, and the hybridization temperature. a microarray chip can then be characterized by a set of binding properties for the desired probe to target pairings and for the undesired probe to non-target pairings. different biological samples can be tested by varying the distributions of sample specific rna concentrations. after adding small random measurement noise, the generated data can be used to examine the response of the likelihood measure ) to the hybridization temperature for calibration samples of different properties. we studied a typical chip design with  <dig>  genes with random probe-to-target binding free energies. cross-hybridization is assumed to occur for 10% of the probes, with 1- <dig> non-targets, at a smaller scale than self binding and with random cross-binding affinities. for a randomly chosen chip design, we simulated calibration runs for five different types of calibration sample. here, genes were classified by their expression levels into z/l/m/h categories.

each simulation had varying fractions of genes assigned from these categories . different hybridization temperatures were considered by means of a temperature proportional coefficient in the langmuir equation. to investigate a condition susceptible to differential expression induced by cross-hybridization, we simulated a bias towards down-regulation with 20% of the genes being down-regulated, 70% being non-differentially expressed and 10% of the genes being up-regulated.

possibly confounding effects of cross-hybridization induced differential expression were examined using a langmuir model of microarray hybridization. samples of varying properties were considered by selecting different fractions of genes with zero , low , medium , and high  expression levels. each table row shows results for a different simulation. the obtained ranking robustly identified t <dig> as the best performing temperature for a wide range of sample properties.

nevertheless, the ranking of the six different temperatures was highly consistent , demonstrating that the same optimum is reliably found over a wide range of sample characteristics. our study of synthetically generated data therefore verifies that the proposed likelihood measure can be used for optimizing hybridization conditions with confidence as long as biological samples showing a strong unidirectional bias in differential expression and many weakly-expressed genes are avoided. in the following section we present computational safeguards for avoiding situations where cross-hybridization can confound results and which ensure that conclusions are independent of the examined calibration samples and any modelling assumptions.

computational evaluation strategies
we can introduce two strategies for ensuring that assessments are independent of the measured samples, and thus generalize to other experiments, and that results are not affected by modelling assumptions.

assessing biological bias
protocol assessment is independent of the measured samples if probe sequence specific binding properties are not correlated with measured fold-change. else, samples with different fold-change distributions would give different results. a validation strategy can thus examine the effects of samples with different distributions of fold-change on the assessment results, corresponding to laboratory experiments testing different sample pairs.

samples with different fold-change distributions are simulated by randomly selecting different pro-portions of genes with zero, low, medium, or high differential expression  from the original measurements, as is illustrated in figure  <dig> by the pie charts on the left. the performance of all protocols is then quantitatively assessed using an objective measure such as the likelihood of eq. . while likelihoods obtained for different samples cannot be compared in general, the protocols can be ranked independently for each set of samples. a robust assessment procedure will consistently reach a similar protocol ranking if protocol performances are sufficiently different. the distribution of ranks obtained from many samples actually indicates to what degree the observed ranking is independent of the samples used for calibration, and how well it will apply to future arbitrary measurements. the example shown in figure  <dig> illustrates this approach for five protocols labelled 'a' to 'e'. the fraction of times that protocols achieved a particular rank is represented through pie charts. in this example, protocol 'c' performed best, followed by protocols 'a' and 'b', with the lowest ranks shared by 'd' and 'e'. the overlaps in rank shown for protocols 'a' and 'b' and also for 'd' and 'e' reflect similar performances. in the context of temperature evaluation, such overlaps could typically occur for two protocols with hybridization temperatures that are on opposite sides of the optimum. when such an overlap in the optimal rank position is observed, the higher hybridization temperature should be selected, to minimize cross-hybridization potential for high specificity of the measurement process.

the nature of the rank distribution, however, can also identify inappropriate calibration samples, as resulting from a strong bias in up- or down-regulation. for such samples, randomly drawn subsets with large numbers of genes of low expression level will tend to underestimate the optimal hybridization temperature, whereas random subsamples with large numbers of strongly expressed genes will show higher temperatures as optimum. the resulting uncertain rank distribution indicates that a reliable temperature calibration cannot be based on the samples used.

assessing modelling bias
we now ensure that protocol assessments are free of modelling bias. above, we have derived a quantitative measure that directly reflects protocol performance in typical microarray applications. while based on a linear model, eq. , the validity of this measure can be confirmed by examining complementary diagnostic measures that are free of modelling assumptions.

to this end we adopt a technique that is commonly applied in the fields of machine learning and pattern recognition: we evaluate how well the selected model can predict the labels of 'test' samples. the classification accuracy is naturally obtained from the 'dual' representation of the linear model as a classifier, eq. , and can be estimated by n-fold cross-testing  <cit> . for this, the experiment is split into n blocks of similar numbers of microarrays. if n is chosen equal to the total number of arrays, each block consists of exactly one microarray. each one of the n blocks is used as the test case for a model built using the remaining n -  <dig> blocks. figure  <dig> illustrates six-fold cross-testing of a typical experiment with six replicates. performance is then assessed for the n tests.

for uniform misclassification costs, the generalization accuracy provides an immediate measure of classification performance,   

where the proportion of correct sample label predictions by each individual gene-specific model is averaged for a joint assessment of all genes g.

for the more general case, receiver-operator-characteristic  curves  <cit>  are considered. the area under the roc curve provides a summary measure independent of misclassification costs. importantly, both the generalization accuracy and roc curves are free of modelling assumptions  <cit>  and can thus be used as model diagnostics: agreement between the ranking of protocols by these criteria and the ranking by the linear model log-likelihood eq.  confirms the appropriateness of the model, eq. .

we therefore examined the consistency of protocol rankings achieved according to the following complementary criteria: the linear model log-likelihood eq. , the number of differentially expressed genes passing a significance test in the corresponding anova model for eq. , the generalization accuracy eq. , the area under the roc curves, and the mutual information. the last three criteria are model-free measures.

the number of differentially expressed genes is of immediate relevance to typical microarray applications. similarly, the mutual information  <cit> , a quantity directly related to the probabilities expressed in eq. ,   

is easily interpreted as the average amount of information obtained by the gene expression measurements xg about the biological samples y in form of a bit rate. bit rates are well known in the characterization of the capacity for information transfer, such as the bandwidth of an internet connection. for a joint assessment of all genes g we consider the average bit rate per gene,  

assessing the impact of suboptimal conditions on biologically relevant observations
calibration experiments constitute an investment. it is thus interesting to consider how measurements under suboptimal conditions affect the quality of biologically relevant observations. for this, we consider two complementary aspects: firstly, the quality measure eq.  was chosen to reflect how reliably differential gene expression can be identified for a particular protocol. consequently, under suboptimal conditions fewer differentially expressed genes are expected to pass significance tests under the corresponding anova model for eq. . to quantify this in the context of a typical application, we use the number of genes nsig that could be identified as differentially expressed by fspma  <cit> , a standard gene expression analysis tool using a balanced anova model  <cit>  for p-value calculation. raw p-values were obtained from vsn normalized  <cit>  expression values and converted to benjamini-hochberg corrected false discovery rates . gene counts reported refer to an fdr cut-off of q <  <dig> . the corresponding fspma gene lists are provided in the online supplement.

losing genes by these criteria is problematic in its own right. we can examine the type of genes affected to test for bias. specifically, we have mapped the genes lost in experiments 1°c above the optimal hybridization temperature to their flybase gene ontology  terms for a classification of the affected biological processes, molecular functions, and cellular components . we were particularly interested in transcription factors, which are often biologically active in low copy number  <cit> . subtle fold changes can therefore already indicate biologically relevant regulation of transcription factor activity. a reduced sensitivity for small changes in expression levels, as expected at suboptimal conditions, is thus likely to particularly affect results for these key regulatory molecules. annotation of drosophila transcription factors was downloaded from flytf october  <dig>  <cit> . significant enrichment of transcription factors in the set of lost genes was confirmed by fisher's exact test  <cit> .

protocol optimization
we have examined the effect of hybridization temperature on microarray measurements using a particular oligonucleotide probe set. a suitable hybridization temperature has to be high enough to avoid cross-hybridization affecting specificity and low enough to allow strong binding and, hence, bright signals and a good signal-to-noise ratio for high sensitivity. although modern algorithms design probes for a given temperature, experimental protocols need to be adjusted for unknown buffer and surface effects.

avoiding modelling bias as described, we evaluate several complementary objective quality measures for all hybridization temperatures . the generalization accuracy reflects protocol performance for equal misclassification costs. the more general case of variable misclassification costs could be examined by a comparison of roc curves .

the left part of the table shows results from the protocol assessment using biological samples for calibration . in comparison, the corresponding results for spiked-in exogenic rnas are shown on the right . column 'hyb. temp., k' lists the considered protocol k and its hybridization temperature. for each protocol, the table displays the achieved generalization accuracies , the average mutual information i, the log likelihoods log  and the number n of genes with differential expression calls by fspma anova at a 1% fdr threshold. the generalization accuracy reflects protocol performance for equal misclassification costs. roc curves are provided for the generic case . detailed results for each protocol can be found in the supplement.

the theoretical considerations presented here have shown that the log likelihood of a linear classifier, eq. , can be used for the direct assessment of different protocols. its maximum points to 51°c as the optimal hybridization temperature . all the examined complementary assessment criteria corroborate this. together, table  <dig> and figure  <dig> confirm 51°c as the robust optimum of the hybridization temperature. this also indicates that the modelling assumptions were met to good approximation, and it validates that the assessment was not adversely affected by modelling bias. results were independent of the chosen microarray data normalization methods .

general calibration validity, independent of the samples used
we have examined the effects of samples with different distributions of fold-change on the assessment results, corresponding to laboratory experiments testing different sample pairs. different proportions of genes with zero, low, medium, or high differential expression  were randomly selected from the original measurements . independently for each of the  <dig> drawn sub-samples, all hybridization temperatures were quantitatively assessed and ranked by their likelihood, eq. . we visualize the performance rank distributions of the eight tested temperatures as summary pie charts .

some random variation in the observed protocol rankings must be expected by random chance, just as small fluctuations in microarray measurements can result in large random variations in gene rankings  <cit> . for 90% of all rankings, however, the hybridization temperature of 51°c obtained the highest rank, with the remaining 10% split between the two 50°c hybridizations , confirming the robustness of the calibration. also the remaining ranking was very robust, with larger uncertainty only observed for the two hybridizations at 50°c, as would be expected. the high similarity of the two 50°c hybridizations further confirms the reproducibility of the calibration process. the obtained ranking and, in particular, the obtained calibration optimum have therefore been obtained robustly, independent of the biological samples used for calibration, and will equally apply to arbitrary future measurements with this platform.

the rank distributions shown by the pie charts in figure  <dig> further confirm that choosing too high a hybridization temperature is worse than hybridizing at a temperature that is too low. results in table  <dig> correspondingly indicate a steeper performance loss when moving to temperatures above the calibration optimum. this essentially means that, for a well designed array, the reduced signal sensitivity at higher temperatures is more of a problem than the loss of specificity at lower temperatures, which is also in line with the general temperature profile of the binding response, eq. .

finally, we could use spike in experiments for an independent validation of the calibration results. these employed the  <dig> replicate probes each for fourteen exogenic spike rnas provided by the fl002/ <dig> microarray platform. the right-hand side of table  <dig> shows the quantitative assessment of hybridization protocol performance for measurements of spiked-in rnas of known amounts . results provide further corroboration of the general validity of 51°c as the optimal hybridization temperature for the studied platform. the observed agreement in ranking moreover confirms the robustness and reliability of the presented combination of an experimental approach and the set of computational methods introduced for the generic calibration of microarray platforms.

the table shows the relative spike-in ratios of exogenous rnas that provided an independent test sample.

effects of protocol optimization on the quality of biologically relevant observations
we have shown that our methods for protocol assessment can robustly and reliably identify generally optimal measurement conditions, irrespective of the samples used for calibration, and validated by independent experiments. the excellent agreement of the complementary quality measures examined confirmed that modelling assumptions were met to good approximation, and that the assessment was not adversely affected by modelling bias.

considering the investment required for calibration experiments, it is interesting to consider how measurements under suboptimal conditions affect the quality of biologically relevant observations. firstly, a deviation from optimal conditions gave a considerable drop in the sensitivity of detecting differentially expressed genes . it is remarkable that measurements just one degree celsius above the optimum of 51°c already identified 44% fewer differentially expressed genes. deviation by one degree celsius below the optimum also identified considerably fewer differentially expressed genes . suboptimal hybridization protocols can thus lead to a considerable loss of biological evidence.

an examination of the involved gene ontology categories showed that this loss affected a large variety of genes: the  <dig>  genes missed in hybridizations at 52°c mapped to  <dig>  biological process terms,  <dig> for molecular function, and  <dig> specifying cellular components. deviation from the optimal hybridization temperature by just one degree celsius thus led to a substantial loss of information about the expression of genes across the entire spectrum of biology.

moreover, we could show that this loss of identified genes was not uniform, introducing a bias into results at suboptimal conditions. figure  <dig> compares the strength of differential expression of genes detected as significantly up-regulated at optimal and suboptimal hybridization conditions. the left-hand side shows the signal distribution from measurements one degree celsius above the optimal hybridization temperature. the right-hand side plots the distribution for the additional genes identified at the optimal temperature. subtle fold changes, in particular, were lost at the suboptimal hybridization temperature. similar observations hold for down-regulated genes and other temperatures .

many transcription factors are biologically active in low copy number  <cit> . subtle fold changes can therefore already reflect a biologically relevant regulation of transcription factor activity. examining the detection of differential expression at neighboring temperatures, the number of transcription factors compared to other genes identified  showed a significant enrichment of transcription factors in the set of genes missed under slightly sub-optimal conditions . indeed, transcription factors were almost twofold enriched in the set of genes missed one degree celsius above the optimal hybridization temperature.

the contingency table for the numbers of drosophila transcription factors and other genes identified as differentially expressed at optimal and suboptimal hybridization temperatures shows that transcription factors were strongly overrepresented amongst genes only detected at the optimal hybridization temperature of 51°c .

in summary, well calibrated hybridization conditions are necessary for the efficient detection of differential expression. well calibrated conditions are, moreover, essential for the sensitive profiling of low-copy-number molecules. this is particularly critical for studies of transcription factor expression, or the inference and study of regulatory networks.

discussion
while the importance of state-of-the-art probe design  <cit>  has been widely recognized as determining the quality of microarray measurements, we have shown that reliable measurements require empirical calibration of experimental conditions. the correct hybridization temperature is particularly crucial, because the effective reaction temperature is a major parameter for probe set design. this design temperature, however, differs considerably from the true physical temperature that optimizes the overall sensitivity and specificity of a microarray assay: thermodynamic calculations are based on effective parameters. surface interactions moderate effective local concentrations and buffer additives influence the effective hybridization temperature. these complex effects are only partly understood and the true parameters can hence not be calculated in advance. even when these effects are eventually better understood, most established microarray protocols rely on commercial buffer and slide chemistries, which are often not fully disclosed. empirical calibration is fully independent of these details, as it directly optimizes the desired objective - maximum information gain per experiment.

for this purpose, we have introduced and validated a combined experimental and computational approach for quantitatively assessing microarray measurement performance. direct calibration approaches based on extensive spike-in experiments are both costly and difficult  <cit> . although they can provide valuable complementary information about individual probes, they are not necessary for an identification of experimental conditions that are optimal overall, for the entire array, and that yield the largest possible amount of information in generic experiments. both the sensitivity and specificity of all probes on an array can be quantified simultaneously. in particular, we have shown that a simple comparison of two typical biologically distinct samples can be used to calibrate experimental conditions for the optimal detection of differential gene expression, the predominant application of microarrays. testing arbitrary measurement subsets corresponding to samples of very different properties, our approach moreover verifies that this calibration is independent of the actual samples used for calibration. an additional independent assessment using spike-in data confirmed that calibration results do not depend on the chosen experimental approach.

while traditional visualizations, like scatter plots, and summary statistics can give a first impression of the technical reproducibility achieved by a platform, they do not allow a quantitative assessment of sensitivity and specificity. consequently, they are also of limited use in optimizing array performance . meaningful performance relevant quantitative measures can, however, be obtained from the linear anova model in eq. . the corresponding dual representation as sample classification problem, eq. , leads to an alternative quantitative assessment. a major advantage of the dual formulation is that classification enables an evaluation of protocol performance that is free of assumptions. in this context, both roc curves and generalization accuracies  <cit>  provide valuable information in addition to the model likelihood eq. . the complementary consideration of both model-based and model-free quality measures avoids method bias.

this combined approach allows, for the first time, a fully quantitative assessment of microarray protocol performance. in particular, we have shown how this can be applied to reliably optimize generic microarray experiments of a laboratory. optimization results were shown to be remarkably robust. considering even extreme, arbitrary calibration samples, in more than 90% of tests the 51°c protocol performed best , with the most similar 50°c protocols making up the remainder. this confirmed the independence of calibration results from the chosen calibration samples. an additional assessment on spike-in data validated the general applicability of results for different experiments .

we have furthermore evaluated how and to what degree a deviation from the optimal hybridization conditions is detrimental. a hybridization at 52°c instead of the optimal 51°c reduced the mutual information from  <dig>  to  <dig>  bits per probe and sample. a deviation by only one degree celsius can therefore lose 14% of the information about differences between the samples compared. this is directly reflected in the reduced sensitivity detecting differentially expressed genes. while  <dig>  differentially expressed genes could be identified at the optimal temperature of 51°c, only  <dig>  genes were found at 52°c; that is a loss of 44%. at lower hybridization temperatures the effect is less pronounced, with 5% - 15% fewer genes identified. similar observations have been made in calibrating an array for two e. coli strains and another drosophila array .

a wide variety of genes were affected by the loss of sensitivity at non-optimal hybridization temperatures, as reflected in the large number of gene ontology terms involved. even assays deviating only 1°c from the optimal temperature lost evidence across the entire spectrum of functional classes.

moreover, this loss of genes identified is not uniform and introduces a bias into results from suboptimal conditions, disproportionately affecting genes with subtle fold changes. the most severe implication is the significantly reduced sensitivity in studies of transcription factors, which were almost twofold overrepresented in the set of genes missed at 52°c.

CONCLUSIONS
we have introduced and validated an approach for the reliable objective optimization of microarray protocols using two typical biologically distinct samples. several quantitative quality measures were complemented by simulations, corroborating the generic applicability of the calibration results. in addition to computational methods, validation experiments independently confirmed the robustness of calibration results.

while some strongly biased samples cannot be used for calibration, suitable samples were easily identified by verifying that there was a clear winner in the rank distributions from randomly drawn subsets. this moreover demonstrated the independence of calibration results from the particular chosen samples.

we have shown that objective protocol calibration is invaluable for every microarray laboratory, and should precede any larger or critical experiments. suboptimal conditions severely reduce the efficacy of all assays and introduce considerable bias. this is especially critical for studies of transcription factors and other low-copy-number transcripts. complementing sensitive novel approaches like targeted mrna sequencing  <cit> , the quantitative assessment of low-copy-number transcripts on a genomic scale is a particular strength of microarray technology. to make the most of this strength, however, careful laboratory calibration is essential.

calibration experiments also provide direct proof of the quality of a microarray platform, including its probe design. the quantitative assessment introduced and validated in this paper therefore allows the objective comparison of alternative platforms and measurement processes, supporting further technological advances.

