BACKGROUND
to date, most biosensors can be considered to be 'target-specific' systems in that their detection elements are built to respond to a fixed number of organisms, and are designed to be non-responsive in the absence of those organisms. in fielded sensors, pcr-based technologies are often selected for their specificity and low per-assay cost. while this targeted approach is very effective in an environment where specific biological events are expected, a biosensing infrastructure capable of rapidly responding to new or engineered biological threats while maintaining a low cost of operation requires increased flexibility. targeted platforms, like those using specific pcr primers for qualitative or quantitative amplification for detection, require creation of new physical capture reagents when new organisms are targeted  <cit> . these platforms are also often limited in the total possible number of parallel assays run at any one time as multiplexing tens or hundreds of pcr reactions greatly increases assay complexity. to mitigate the limitations of such approaches, there have been previous efforts to design high-density microarrays that are representative of groups or families of organisms and while these sensors would likely still offer information for novel threats, assured classification at the species or strain level would be impossible without re-engineering and re-deployment of sensing devices  <cit> .

microarray-based detection and identification approaches often consist of a series of probes designed with particular target genomes in mind; if a probe hybridizes, the analyst can be reasonably sure the organism or target represented by that probe is present in the original sample. in some cases, multiple probes can be used to create 'fingerprints' representative of particular organisms, but this requires a great deal of up-front probe design effort  <cit>  such as assuring specificity of probe sequence and lack of cross-hybridization. this approach has been used previously to detect viruses  <cit> ; in one example by designing 70-mer probes unique to each of more than  <dig> viral species  <cit> . microarrays with species- or strain-specific probes have also been designed to differentiate between strains of staphylococcus aureus by generating lists of thermodynamically-favorable probes from regions of sequence unique to particular strains  <cit> . additional efforts have also constructed systems for the design of probes specific at the level of individual gene families  <cit> , recognizing that some of these families will be specific for related pathogens.

while these approaches achieve an increase in robustness by using multiple, parallel measurements for each target organism, they still rely upon a priori knowledge of agent sequence. they are also limited in the scope of intended detection capability to only those organisms for which the individual arrays have been explicitly designed. however, the constraints placed on probes generated to match unique sequence regions in a family of organisms, by definition limit the capacity for these probes to hybridize to distinct novel or engineered organisms. an open-target design would provide data regardless of whether a particular biological event was expected, thus allowing new microorganisms to be recognized, characterized and managed in short order.

one presumed drawback in the design of an open-target biosensor, however, is that the greater the number of biological species to be detected, the larger the array size required. thus, to detect the presence of even a few microorganisms, conventional wisdom dictates that the microarray would have to be very large to capture distinct genomic patterns with high degree of specificity, an endeavour that is not cost effective in environmental monitoring.

it has recently been suggested that many natural phenomena are sparse in that they can be represented in a compressed format using the proper basis  <cit> . sparsity denotes that, to recover a signal of interest, the number of degrees of freedom needed to approximate the signal may, in principle, be much smaller than the length of the signal. this is the foundation for the new theory of sparse, or compressive sensing   <cit> . the main principle of cs is that for a signal x of length n, if x is k-sparse in some basis , which implies that it has k non-zero entries and n-k zero elements, then m linear measurements of x suffice to recover the signal, m  <n and m =o). let y be the vector of m measurements of x. then in matrix notation we have y = Φx. the key challenge in this framework lies in the design of a m × n sensing matrix Φ, which together with y and the sparsity condition imposed on x, would be capable of accurate recovery or detection of x. for cs to apply, in addition to the constraint that x must be sparse, the sensing matrix must satisfy the restricted isometry property   <cit>  which implies that the rows of Φ should be incoherent with respect to the signal sparsity basis.

recently, dai et al. have proposed that dna microarrays can be designed using the notion of cs  <cit> . they used the ncbi clusters of orthologous groups  database, which contains orthologous sets of proteins from  <dig> organisms corresponding to conserved protein domains. challenges of this approach include how to translate protein back to less conserved dna sequences and species which lack certain clustered proteins. species which dna encode these proteins differently than the array probe sequences would also not be detected.

in this paper, we put forward the notion that an open-target design is a viable approach to biosensing based on the principle of sparsity. using laboratory-generated data, we provide strong evidence that: first, the underlying genomic imprints of multiple biological organisms can be captured succinctly using a small codebook, or collection of microarray probes, not specifically designed to respond to the target organisms. and second, our design approach follows closely the principles of sparse sensing, and thus cs is an applicable and sensible notion for biological sensing.

methods
microarray probe design
potential probe sets were generated using variable-length markov chains   <cit> , implemented using the vlmc package in the r  <cit>  software environment. vlmcs were trained on genomic sequences from seven prokaryotic pathogens, listed in table  <dig>  and then used to emit 25-mer sequences for use as microarray probes. a sequence length of  <dig> had been previously identified as a good trade-off between hybridization specificity and diversity  <cit> . genomic sequences were downloaded from the ncbi genomes database in genbank  <cit> , and are described in table  <dig> 

genomes retrieved from genbank were used in the vlmc model to generate probes.

to investigate the impact of sequence sampling lengths and strategies on the final probe design, vlmcs for three different training sets were used to generate probes by sampling:

•  <dig> bp from each of  <dig> genomic sequences, resulting in a total of  <dig>  long input sequence

•  <dig> bp from each of  <dig> genome sequences, resulting in a total of  <dig> -long input sequence

•  <dig>  bp from each of  <dig> of the  <dig> sequences , resulting in  <dig> -long input sequence

samples were taken randomly from each genome without regard for higher-order genomic structure . for each training set, samples from individual genomes were concatenated end-to-end to produce single dna sequences to train a vlmc model.

training a vlmc model was performed using the context algorithm  <cit> , based on a previously developed data compression technique  <cit> , which requires a single parameter, k. a larger value for k results in more pruning of a vlmc-derived tree, which leads to a less complex tree, and thus a model of smaller dimension. to determine an optimal value for k, we applied an approach similar to that of mächler  <cit> . in brief, initial values of k , termed k <dig>  were used to create multiple vlmc models. for each k <dig>  pruned vlmc models were used to emit n+ <dig> base pairs. the first  <dig>  base pairs were discarded to allow the simulation model to stabilize. subsequent vlmc models were created for values of k from  <dig> to  <dig> in increments of  <dig>  and used to predict the th base pair from the initial vlmc output. this process was iterated  <dig>  times for each value of k <dig>  and the number of correct predictions was recorded.

bootstrapping with multiple values of k <dig> revealed a plateau maximum accuracy of n+ <dig> for values of k between  <dig> and  <dig> , as shown in figure  <dig>  k =  <dig>  was selected as the value for the pruning parameter to balance both overall accuracy as well as model parsimony. vlmc models, trained with k =  <dig> , were generated using the sampling strategy described above. these vlmcs were used to generate an initial set of  <dig>  25-mer probes. these probes were screened for a melting temperature, tm, between 58° and 68° c and a calculated free energy of self hybridization  greater than - <dig> . melting temperature calculations were carried out using the primer <dig> software package  <cit> . in addition, probes with mono-runs of guanine bases longer than three were eliminated due to their propensity to form g-tetrads or pseudo-knots  <cit>  which limit their availability for hybridization. the remaining probes were ranked by decreasing Δg of self-hybridization, and the top  <dig>  probes from each k set were selected. in addition to the three vlmc-derived sets of probes, a set of random probes was generated for comparison.  <dig>  unique 25-mer dna sequences were created from a uniform nucleotide distribution. this set of random sequences was then put through the same filtering and ranking process as the vlmc-derived probes, and the top  <dig>  random probes were selected.

finally, to evaluate the specificity of the random and vlmc-derived probes, we aligned each set of  <dig>  25-mer probes against a panel of twelve gram-positive and -negative prokaryotic organisms. this set consisted of the seven organisms used to train the vlmc, plus five additional genome sequences . alignment of probes to each genome was performed with segemehl  <cit> , an algorithm designed for the alignment of short reads from next-generation sequencing experiments with support for insertions and deletions. for each organism, we calculated the specificity of each probe, defined as the number of times the probe aligned to the target genome per kilobase of genomic sequence . as seen in figure  <dig>  the vlmc-derived probes have at least a  <dig> , and an average of  <dig> , fold increase in rate of alignment to each organism when compared to random probe sequences. the set of probes generated by sampling  <dig> base pairs, shown to perform slightly better in n+ <dig> prediction by bootstrapping than that by  <dig> base pairs, was selected to create a microarray for experimental testing. of the top  <dig>  probes, 18% were randomly duplicated for quality control purposes. the resulting  <dig>  probes were sent to agilent technologies  for synthesis on their  <dig> ×  <dig> k custom array format.

microarray hybridization
to hybridize against the vlmc-derived probe set and generate data, the purified genomic dna from  <dig> different simulant strains: bacillus cereus , bacillus subtilis  , and pantoea agglomerans  , was fragmented and amplified using a sigma genomeplex® whole genome amplification  kit.  <dig> ng of purified genomic dna was randomly fragmented using the wga kit to yield fragment lengths of  <dig> -  <dig> base pairs with an average fragment length of  <dig> base pairs. fragmented dna was then flanked by universal priming sites and amplified through  <dig> rounds of pcr. amplified dna was precipitated using 1/ <dig> volume of  <dig> m sodium acetate  and  <dig> volumes of 100% pure ethanol at -80°c for  <dig> hours. dna was fluorescently labeled by reacting with the n <dig> of guanine using the with ulysis alexa fluor®  <dig> nucleic acid labeling kit . excess dye was removed with an agilent genomic dna purification module spin kit. samples were then concentrated to  <dig> ng of dna in 7μl. labeled dna was prepared for hybridization with  <dig> μl agilent  <dig> × ge blocking agent and  <dig> μl agilent  <dig> x cgh hybridization buffer using an agilent oligo acgh hybridization kit. samples were denatured at 95°c for  <dig> minutes followed by  <dig> minutes at 37°c. 11μl of kreablock was added to each sample to reduce background fluorescence. 40μl of prepared sample was then loaded onto agilent  <dig> ×  <dig> k custom arrays which were hybridized for  <dig> hours at 42°c. arrays were washed  for  <dig> minutes and then scanned on a molecular devices genepix  <dig> a scanner. feature extraction was performed using agilent's feature extraction software v <dig> . <dig>  and samples underwent quantile normalization via the bioconductor limma package  <cit>  in r.

ten technical replicate arrays were generated for each of the three simulant species resulting in a total of  <dig> arrays for training and validation of the detection model . spike-in samples consisting of short oligos designed to bind to specific probes of the array were used as a positive control. two spike-in arrays were run for each of two different concentrations to determine an optimum: 1% and  <dig> % of total dna concentration. spike-in was then added at a 1% concentration to each single species array. finally,  <dig> mixed samples were prepared based on  <dig> possible combinations of three single genomes  in equal ratio for a total of  <dig> ng per array . the mixed samples were labeled as: bc/bs/pa_ <dig>  bc/bs/pa_ <dig>  bc/bs_ <dig>  bc/bs_ <dig>  bs/pa_ <dig>  bs/pa_ <dig>  bc/pa_ <dig>  and bc/pa_ <dig> 

whole genome amplified dna mixture concentrations were used to generate array data.

detection model
a multivariate mathematical model based on partial least squares regression  was developed to capture the signature of each simulant organism. briefly, given a number of predictors, or independent variables, plsr iteratively finds the best fit for one or more response, or dependent variables by maximizing the correlation between the two variables  <cit> . plsr seeks to maximize correlation between the response and predictor variables while capturing and explaining most of the variation within the covariate space by constructing new predictor variables, or latent variables, as linear combinations of the original predictor variables.

in this study, the covariate matrix, x = , is a  matrix of n =  <dig>  observations and, m =  <dig> predictor variables. each variable, xj, for j ∈ { <dig> ,3}, represents the vector of hybridization values, xij, i =  <dig> ...,n, averaged over  <dig> replicate arrays for the jth simulant species , and x <dig> represents that of the oligos averaged over two arrays . the response matrix, y = , is a  matrix of s =  <dig> dependent variables representing  <dig> possible combinations of the three simulant organisms, with two replicate arrays for each combination, hybridized against the probe set. both the predictor and response matrices were then standardized  before analysis was performed.

the predictor and response matrices are decomposed into the following forms:   

where t and u are the respective  score matrices of h latent variables, n ≤ s; pt and qt are the respective  and  transpose matrices of loadings, and e and f are  and  matrices of residuals. we used a variation of plsr called simpls algorithm  <cit>  to iteratively find the latent vectors that best explain the relationship between x and y matrices, by simultaneous decomposition of the two matrices. a diagonal matrix of regression coefficients, b, is estimated as the normalized inner product of the two score matrices, which describes the inner relationship between the predictor and response variables:   

to determine whether a simulant organism is present in a mixed sample, and the amount of its contribution to the sample, a  matrix of weights was estimated based on the diagonal matrix b ) and the loading matrices of the predictor and response variables:   

the goodness of fit of the model for each test sample was determined using the r <dig> statistic, which is the normalized value of the total squared error explained by the model. finally, to determine which probes are critical in differentiating between patterns of hybridization of the simulant species, the contributing value of each probe to the goodness of fit was assessed using the hotelling's t <dig> statistic  <cit> , a statistical measure of the multivariate distance of each observation score from the center of the observations per probe:   

where k is the number of sample observations per probe, ti is the vector of k sample observation scores in row i, for i =  <dig> ...,k, μi is the mean value of k observation scores in row i, and s- <dig> is the inverse of the sample covariance matrix. all scripts were written in matlab  <dig> . <dig> .

RESULTS
signal detection
the first three latent variables from the plsr model, h =  <dig>  achieved maximum correlation with the response variables while together they captured most of the variation in the predictor matrix  and response matrix . thus, the plsr model was calibrated using the first three components to build a predictive model of the response matrix.

the plsr model was first validated using the training data on single species arrays by iterative leave-one-out cross validation. in each round of iteration, one array, from the set of  <dig> single species arrays, was randomly selected as a test sample and excluded from the training phase. the model was then trained on the remaining  <dig> arrays and the two oligo spike-in arrays, and tested on the array that was left out. equation  was used to predict the outcome of each round of experiment, namely the amount of contribution of each simulant organism to the test array. these experiments were repeated  <dig> times and the average value was reported as the final predictive value. as illustrated in figure  <dig>  all three simulant organisms were classified correctly with high specificity ) =  <dig> , ci =  <dig> ). the percentage of contribution as depicted on the y-axis represents the specificity or amount of contribution of each organism to the test sample as explained by the model. to test its predictive power, the model was trained on  <dig> predictor variables consisting of the three simulant species and oligo spike-ins, representing the x matrix ), and tested on  <dig> mixed samples, representing the y matrix. as depicted in figure  <dig>  the signature of all contributing individual organisms in each mixture was captured correctly in all  <dig> samples, leading to a 100% true positive rate, or sensitivity, of the model  =  <dig> , ci =  <dig> ). in two bcpa samples , however, the signature of the third organism, bs, was incorrectly detected, leading to a  <dig> % false positive rate, or  <dig> % specificity. this is because  <dig> out of  <dig> samples report the presence of one additional organism out of four possible contributing organisms:  = 1/ <dig> =  <dig> .

to determine the contribution of each probe to the goodness of fit of the model, probe values were assessed using the hotelling's t <dig> statistic ). for each mixed sample, probes were sorted in descending order of their t <dig> statistic. the plsr model was then run iteratively, each time and for each mixed sample, adding the next top  <dig> probes and computing the r <dig> value up to that point until all  <dig>  probes were included in the model. at the end of each iteration, the average value of the r <dig> statistic of all samples was recorded. figure  <dig> illustrates the distribution of r <dig> statistic as a function of number of sorted probes included in the model.

sparse sampling and signal detection
the distribution of probes in figure  <dig> suggests that a relatively small subset of probes may be sufficient to generate, and differentiate between, the hybridization patterns that signify the genomic imprints of the three single species. in figure  <dig>   of the overall average r <dig> statistic is achieved using only about  <dig> probes, while using an additional  <dig>  probes contributes only about 5% to the average r <dig> value . to test the hypothesis that a smaller set of probes is capable of accurately capturing the signature of each organism, increase the detection specificity, and thus reduce the false positive rate observed in the previous section , the following sparse sampling algorithm was designed:

 <dig>  for each mixed sample

a. probes were sorted in decreasing order of their t <dig> values.

b. probes with high t <dig> values were selected for further investigation, if their value was greater than μt <dig> + cσt <dig> , where μt <dig> and σt <dig> are the respective mean and standard deviation of the sample t <dig> values, and c is a scalar.

 <dig>  probes with high t <dig> values shared by four out of eight samples  from step  <dig>  were selected as the final set for plsr analysis.

the plsr model was then run on data collected on the final probe set. for the scalar values  <dig> ≤ c ≤  <dig> , the size of the probe set varied from  <dig> to  <dig>  in all cases, the model was capable of accurately capturing the signature of single organisms in the mixed samples while the false positive rate was significantly reduced. here, we demonstrate the results for c =  <dig> , which generates the smallest probe set consisting of  <dig> probes capable of capturing the dna signature of the simulant organisms while achieving a significantly diminished false positive rate. figure  <dig> illustrates the result of the validation phase, where all three simulant organisms are classified correctly with high specificity  =  <dig> , ci =  <dig> ).

to test the predictive power of the model using the final set of  <dig> probes, the plsr was then tested on the eight mixed samples. as depicted in figure  <dig>  the signature of the single species was accurately captured in each mixture leading to a 100% true positive rate, or sensitivity, of the model  =  <dig> , ci =  <dig> ). note that the observed false positive in the two bcpa samples of figure  <dig> when all  <dig>  probes were used, is greatly diminished when the model is run using  <dig> probes.

sparse sensing
in this section we demonstrate that, in retrospect, the sparse sampling algorithm, developed in the previous section, closely follows the principles of compressive sensing when the matrix of intensity values is properly mapped to generate a sensing matrix. recall the main condition of cs--that for a signal to be compressively sensed, it must be sufficiently sparse . here, the target vector, x, has only three non-zero elements, namely the concentrations of the three simulant organisms in captured samples and the remaining n- <dig> entries are zero. because in principle, the number of potential organisms in a location at a point in time, n, is very large, x is considerably sparse . the vector of m measurements, y, consists of  <dig>  intensity values for each mixed sample. the key challenge in the application of sparse sensing is in the design of the sensing matrix that satisfies the rip and results in accurate recovery of x using the matrix notation y = Φx. it has been shown that sparse binary random matrices satisfy the rip  <cit> . here, we show how the results of our sparse sampling algorithm can be mapped to a sparse binary random sensing matrix that together with the hybridization measurements uniquely identifies the presence of each simulant organism in the mixed samples.

let s denote the set of  <dig> selected probes generated by the sparse sampling algorithm. define i as the intensity  value of the jth organism , against the ith probe, i =  <dig> ..m and j =  <dig> ..n. let μi denote the mean of the intensity values in row i, and φij be the th element of the sensing matrix. then we have:  

the above mapping results in a very sparse, random binary matrix. the structure of the sensing matrix is presented in figure  <dig>  where the positions and binary patterns of five out of  <dig> probes, covering seven possible binary combinations, are shown as examples. a "1" entry in the  position of the matrix indicates that the organism in column j has a relatively large intensity value when hybridized against the ith probe, and thus is present in the mixed sample in question. similarly, a "0" entry indicates that the organism is not present in the mixed sample. specific binary patterns uniquely correspond to a group of mixed samples. for instance, all rows with the binary pattern "101" map to a set of unique probes, not shared by other binary patterns, against which bc and pa are hybridized at a relatively high value but not bs. this pattern corresponds to the last two mixed samples in figure  <dig>  the vector of hybridization measurements, y, then consists of non-zero intensity values that correspond to each binary combination in rows pertaining to the final  <dig> probes.

finally, the distribution of the intensity values derived from hybridization against the  <dig> selected probes was compared to the average distribution of  <dig> runs of  <dig> randomly selected probes. the respective mean and standard deviation of the intensity values for the set of  <dig> selected probes were  <dig>  and  <dig> , while the average of those for  <dig> randomly selected sets of  <dig> probes were  <dig>  and  <dig> . the difference in the respective standard deviation values is not large, yet, the dichotomy is most apparent when the mean values are compared. as a result, the coefficient of variation  for the  <dig> selected probes is  <dig> , indicating close concentration of intensity values around the mean, and that of the randomly selected probes is  <dig> , indicating large dispersion of intensity values with respect to the mean. figure  <dig>  are the respective bar plots of the intensity values of the three single species hybridized against an instance of a set of  <dig> randomly selected set of probes and those of the  <dig> selected probes.

discussion
it is well understood that in spite of vast amount of shared sequences among biological organisms, most comprise unique sets of oligomers based on which they can be differentiated at various biological scales. this critical finding has enhanced the ability to design microarray-based biosensors capable of detecting multiple biological agents whose signatures are included in the array. as more viral and bacterial species are sequenced and their dna signatures are retrieved, microarray scalability presents a challenge to the design of target-specific biosensors. at the same time, such a targeted approach to biosensing is ill-equipped when a biological threat is due to the presence of an agent whose signature is not considered in the microarray design either because it was outside the realm of expectation  or is unknown . an open system approach to biosensing is a new concept. if properly designed, an open system biosensor can address the aforementioned challenges from which conventional biosensors suffer.

the equivalence of our sparse sampling algorithm and compressive sensing in the context of open-target sensing has important implications for biosensing. first, that the genomic imprints of biological organisms can be represented in a compressed format, and thus a relatively small dna microarray can be used to decode the signature of multiple organisms in mixed, and potentially complex environmental samples. second, that the sparsity condition likely applies to environmental sampling and detection of biological events, and thus the cost and size of the array can be kept in check. and third, that the previously un-encountered microorganisms can be detected if they are present in the environment at sufficient concentrations, even though their unique dna sequences are not explicitly accounted for in the array design.

two potential limitations of this study must be addressed for future consideration. first, despite relatively extensive laboratory experimentations performed for this study, the number of biological organisms tested and selected to generate mixed samples is small. to demonstrate the utility, efficiency, and robustness of an open system approach to biosensing, a greater spectrum of biological agents must be tested and their hybridization patterns evaluated against the microarray probes.

second, with respect to the probe design a set of evaluations were performed to select the final design of the probe set, where the specificity of the randomly generated and vlmc-derived probes were compared by aligning each set of  <dig>  25-mer probes against a panel of twelve gram-positive and -negative prokaryotic organisms . while the specificity of all three vlmc-derived probe sets was substantially higher than that of random probe sequences, the average performance of the three vlmc-derived sets of probes is relatively the same across all organisms. it is important to note, however, that we only generated one set of probes for each sampling strategy. in principle, the average outcome of multiple runs of simulations is required to arrive at statistically significant results. we selected the first sampling strategy, a random sampling of  <dig> bp from each of the seven pathogenic sequences, for designing the final probe set based on its slightly higher prediction accuracy than those of the two probe sets generated using the competing sampling strategies. a more comprehensive examination of these and other sampling strategies are needed to determine which strategy, or set of strategies, leads to the best probe sequences design for differentiating between the dna signatures of multiple organisms.

CONCLUSIONS
in this paper, we hypothesized and demonstrated that a relatively small non-specifically designed dna microarray was capable of identifying the presence of three test organisms in mixed dna samples with high sensitivity and specificity without specifically targeting these organisms. coupled with a multivariate detection model and sparse sampling of the microarray probes our prototype open-target biosensor was demonstrated to follow the design principles of cs.

three observations are worthy of note here, and should also be considered in future work. first, sparse sampling of  <dig>  probes, based on a two-layer filtering, led to the selection of the smallest set consisting of  <dig> probes capable of accurate identification of three simulant organisms in the mixed samples. this resulted in a considerable reduction in the array size, based on which a sparse, binary, random sensing matrix was designed. however, our goal was not to derive the minimum number of probes required to differentiate across three test organisms in mixed dna samples, but to demonstrate the feasibility of designing a small dna microarray for 'open-target' sensing of multiple organisms and applicability of sparse sampling to biosensing. it remains uncertain whether a mathematical function can be formulated that describes the relationship between the number of organisms to be sensed and the size of an 'open-target' microarray.

second, qualitative examination of the relationship between the size of the array and its detection specificity uncovers an important difference between 'open-target' and 'target-specific' microarray-based sensing platforms. in 'target-specific' sensing, as the size of the microarray is increased to include molecular signatures of newly sequenced organisms, the false-positive rate is expected to decrease, or equivalently the specificity is expected to increase. in 'open-target sparse sensing', the false-positive rate approached zero, or equivalently the specificity reached 100%, as the size of the array was substantially reduced by pruning the less informative probes. this observed dichotomy between 'open-target' and 'target-specific' sensing with respect to the relationship between the array size and detection specificity, while promising, will have to be further validated in future studies.

third, the distribution of the intensity values of the final set of  <dig> selected probes is qualitatively different than that of the average of  <dig> runs of  <dig> randomly selected probes . the sparse sampling algorithm was applied to  <dig>  probes without any constraint imposed on probe selection except that a selected probe would have a high t <dig> value. indeed, the application of sparse sampling algorithm resulted in the selection of high t <dig> probes which captured the difference in the hybridization patterns of bc and bs, and greatly reduced the false positive rate previously observed . this finding should be more closely examined by testing more organisms and by the sequence alignment of each selected probe against the genomic sequence of each organism.

to our knowledge, this is the first study to introduce an 'open-target' approach to dna microarray based biosensing, and demonstrate a proof of concept through three elements of probe design, laboratory data generation, and mathematical modelling. future directions of this work include improvement to the probe design as guided by the analysis and experiments, expansion of the reference library to encompass additional test organisms, and environmental testing by external air sampling to provide a more realistic and complex environmental background.

competing interests
the authors declare that they have no competing interests.

authors' contributions
mm performed the mathematical analysis and drafted the manuscript. dkw performed the array design, initial bioinformatic analysis, and assisted with drafting the manuscript. mwp contributed to the bioinformatic analysis and assisted with drafting the manuscript. hbs led laboratory method development and execution.

fns contributed to the laboratory experiment execution. jcd directed the study and assisted with drafting the manuscript. all authors read and approved the final manuscript.

