BACKGROUND
compound heterozygosity  in classical genetics is the presence of two different recessive mutations at a particular gene locus, one on each chromosome  <cit>  . the presence of ch has been found for nearly all autosomal recessive disorders as well as other phenotypes such as red hair color  <cit> . a relaxed form of ch, i.e., in which the genetic variants are not necessarily coding, rare, and deleterious, is likely involved in a wide range of human polygenic traits and is here referred to as generalized ch . however, individually analyzing a large number of dna sequence variants such as single nucleotide polymorphisms , as is the routine in genome-wide association studies , has limited power to detect genetic associations caused by gch. because gene variants detected from gwas together typically explain only a small proportion of the phenotypic variance , we expect that gch is an important source of the missing heritability.

existing methods designed for detecting ch alleles suffer from the lack of usable implementations  <cit>  and are not suitable for the analysis of densely imputed snp microarray data or whole genome/exome sequencing data. previously, we have developed a collapsed double heterozygosity  test for detecting the association between ch genotypes and binary traits by applying a chi-squared statistic to pseudo-genotypes collapsed from a pair of snps  <cit> , which has a sliding-window based implementation  in the genabel r package  <cit> . cdh has been shown to have an improved power in detecting genetic association due to ch compared to the conventional single-snp approach  <cit> , but the previous implementation has certain limitations, including:  it cannot analyze quantitative traits with covariates,  it cannot deal with densely imputed genome data due to memory limitations,  computational efficiency was not optimized for large datasets,  lack of user-friendly interface and facilitating functions for power and type-i error estimation. these issues are solved in the current extension. here we implement a generalized cdh  method to overcome previous limitations and allow  fast analysis of densely imputed snp data or whole genome sequencing data;  flexible analysis of binary and quantitative traits with covariates;  empirical power estimation and type-i error control; and  easy interface with plotting utilities. the complete analytical pipeline is implemented as an r package, called collapsabel, and publically available as part of the open-source collaborative genabel project for statistical genomics .

implementation
the analytical pipeline of collapsabel , as outlined in fig.  <dig>  starts with the shiftbed function for collapsing the genotypes of a pair of snps according to a user provided ch model, which results in a binary coded pseudo-genotype. considering an arbitrary pair of bi-allelic snps, there are  <dig> possible combinations, which can be organized into a  <dig> by  <dig> matrix, called the collapsing matrix. thus we implement the genotype collapsing function c as a 2d array lookup function: cg1g2=mg <dig> g <dig>  where g <dig>  g <dig> are the genotype codes of the snp pair. the default collapsing matrix  models the scenario where the allelic effect is caused by the homozygote form of either snp of a pair or the compound heterozygote form of two snps  <cit> . users can also supply alternative collapsing matrices. for efficient storage of genotype data we adopt the plink  <cit>  bed format, which stores each genotype into  <dig> bits, i.e.  <dig> genotypes in each byte. to speed up processing, we construct a 2d collapsing byte array from the given collapsing model and carry out the collapsing directly on pairs of bytes instead of extracting genotypes from each byte. genotype collapsing is conducted on whole genome data using a genome-shifting algorithm  with the function shiftbed. this function collapses each snp with the i-th snp downstream . each window represents the scope of pairwise collapsing in one iteration, i.e. the initial snp with k snps downstream. therefore, for window size k, shiftbed is called k times to produce k new shifted bed files consisting of collapsed genotypes, incrementing i by  <dig> at each iteration. all functions for reading, manipulating and writing bed files call java methods under the hood . genome-shifting produces the same results as the sliding-window approach , but is much faster for the following reasons:  avoidance of combinatorial calculations,  no duplicated computation,  higher throughput and fewer loops, and  once the collapsing matrix is given, the collapsing byte array can be generated only once, where all possible collapsing scenarios are pre-calculated according to the user-specified collapsing model and stored in a 2d array, making genotype collapsing practically as fast as array indexing, which is an o operation.fig.  <dig> collapsabel flowchart

 machine representation of the default collapsing matrix.  interpretation of the default collapsing matrix. coding of input genotype follows plink convention,  <dig>  for homozygote of minor allele,  <dig>  for missing,  <dig>  for heterozygote, and  <dig>  for homozygote of major allele. after collapsing, the output pseudo-genotype is either  <dig>   <dig> or missing. the collapsing matrix is customizable by users, for example , an alternative collapsing matrix  will produce different pseudo-genotypes with allele coding  <dig>   <dig>   <dig> or missing

fig.  <dig> genome-shifting algorithm compared with sliding-window algorithm. the genome-shifting algorithm starts with a plink binary genotype file , and shift the whole genome one snp at a time, each time generating a new bed file containing collapsed genotypes. the total number of new bed files is equal to the user-specified window size k. a shift by  <dig> snp. b shift by  <dig> snps. the sliding-window algorithm generates collapsed genotypes for all possible combinations of snp pairs within a window, and at each iteration slides the window forward by one snp. c 1st sliding window. d 2nd sliding window



once the collapsed genotypes are generated, the rungwas function conducts gwa scans over them by calling plink <dig>  <cit> . rungwas internally calls plink <dig> k times and uses linear or logistic regression models for the analysis of quantitative or binary traits, respectively, possibly also with covariates, generating k plink output files. the readgwasout function then calls c++ routines for fast text processing, which loads the summary statistics from each plink output file, and saves these intermediate results on the hard drive in big.matrix format  <cit> , allowing minimal ram consumption and processing of massive datasets that would not fit in memory. summary statistics are then extracted from these big.matrix files for both individual snps and collapsed genotypes of snp pairs, which are then merged with snp annotations and stored on the hard drive as an sqlite database , from which regions of interest can be queried without loading the whole file into memory. the gcdhregion function can be used to extract regions of interest from the bed file and conduct regional gcdh analysis over it.

collapsabel features built-in capabilities for type-i error control and power estimation. the runtypei function empirically derives the genome-wide significance threshold for gcdh by permutation analysis, i.e. the phenotype file is permuted n times and n gcdh analyses are done using these n permuted phenotype files, each gcdh analysis produces one global minimal p-value , then the α quantile  is used as the genome-wide significance threshold . the gcdhpower function simulates phenotypes according to user-specified allele effect sizes, range of allele frequencies and α-level, and conducts gcdh analysis on genotype data to empirically estimate the statistical power under these settings.

statistical results can be graphically summarized by the contrastplot function in the form of a contrast manhattan plot, where p-values from gcdh analyses are overlaid on those from the single-snp analysis. all plots are produced as ggplot objects  <cit> , which can be easily customized, annotated, and exported in various image file formats.

RESULTS
the rotterdam study
the rotterdam study  is a prospective population-based cohort study of  <dig>  participants aged 45 years and older, living in a suburb of rotterdam, the netherlands. details of the study design and objectives have been described elsewhere  <cit> . whole blood dna extraction, illumina 550–610 k genotyping, quality controls, and 1000-genomes based  <cit>  genotype imputation have been described in detail previously  <cit> . after all quality controls, the current study included a total of  <dig>  individuals and  <dig> , <dig> autosomal snps. the rotterdam study has been approved by the medical ethics committee according to the wet bevolkingsonderzoek ergo, executed by the ministry of health, welfare and sports of the netherlands and all participants provided written informed consent.

power analysis using imputed microarray data
we conducted extensive power analyses based on snp pairs under  <dig> combinations of allele effect sizes , minor allele frequencies  and sample sizes  using the rotterdam study imputed genetic data as the genotype pool. under each combination of β, maf and n, genotypes of  <dig> pairs of snps are drawn from the pool conditioned on the physical distance between each snp of a pair . for each pair of snps , a quantitative phenotype vector  is simulated according to their collapsed genotypes , y = βx + ε, ε ~ n, where x is the collapsed genotype. three generalized linear models are fitted using the simulated phenotype vector as dependent variable and genotypes of snp a, genotypes of snp b, or the collapsed genotypes as the explanatory variable. power is calculated using p-value vectors from these three models under different significance thresholds .

in every category of n, maf, and β, p-values from gcdh are consistently more significant than those from single-snp approach ; gcdh also has higher power than the single-snp approach . even when we use a much more stringent threshold of 5 × 10- <dig>  gcdh is still more powerful compared with using 5 × 10- <dig> as the threshold for the single snp approach . power of gcdh increases with maf, n and β; for example, if we fix n =  <dig>  β =  <dig> , then as maf changes from  <dig>  to  <dig> , the power of gcdh increases from  <dig> to 100 %. when β =  <dig> , maf =  <dig>  and n increases from  <dig> to  <dig> , power of gcdh increases from  <dig> to 85 %, and when n =  <dig> , maf =  <dig> , and β changes from  <dig>  to  <dig> , power of gcdh increases from  <dig> to 100 % . similar observations can be made when using the more stringent 5 × 10- <dig> threshold.fig.  <dig> relationship between n, maf, β and median p-value from the gcdh analysis and single snp association analysis. snp pairs with different mafs are drawn from 1000-genomes imputed rotterdam study microarray data. sample sizes are fixed at  <dig> or  <dig> . allele effect sizes β ranges from  <dig>  to  <dig> . median p-values for snps from different maf groups are distinguished using different colors. in total  <dig> simulations are conducted


n
β
maf
a: power estimates for causal snp a

b: power estimates for causal snp b


n: sample size

gcdh: power estimates for the collapsed genotypes of a and b


β: coefficient used for simulation of phenotypes



power analysis using whole exome-sequencing data
in the rotterdam study whole exome-sequencing data were available for  <dig> individuals and  <dig>  coding variants. regions of width  <dig> to 50 kb are drawn randomly, and in each region two snps satisfying certain maf criteria  are randomly set as causal, a phenotype is simulated according to the collapsed genotype model as described above. due to the small sample size in the exome-sequencing data, we take larger effect sizes  and mafs  to demonstrate the differences between gcdh and single-snp approach. additionally, the two causal snps are selected to be in low ld  assuming that they are on different haplotypes, otherwise the region is discarded a new one is drawn. these two causal snps are included or excluded depending on the purpose of the analysis . a null-phenotype consisting of only a standard normal noise term is also simulated for the purpose of monitoring the null distribution of the test statistics and controlling for type-i error.

for each region, two single-snp gwa and two gcdh scans are done, one using the associated phenotype and the other using the null-phenotype, both with window size set at  <dig> snps. in each scan using the associated phenotype, we obtain two regional minimal p values, one with the results from causal snps included, one with them excluded. thus each loop generates six p values: ps,d , pg,d , ps , pg , ps,n , pg,n . in total  <dig>  such scans are conducted according to different combinations of effect size and maf interval, around  <dig> loops for each combination. at the end of the simulation, we obtained six vectors of p-values, ps,d, pg,d, ps, pg, ps,n, pg,n, each of length  <dig> . for each of ps,d and pg,d we derived the 5 % quantile, which represents two thresholds ts and tg under the null . the power of single-snp approach is the proportion of p-values in ps that are smaller than ts and the power of gcdh is the proportion of p-values in pg which are smaller than ts. similarly, power estimations of single-snp approach and gcdh when causal snps are excluded from the region, i.e. assuming causal snps untyped, are derived from ps,n and pg,n.

the results clearly demonstrated that when maf is above  <dig> , gcdh has consistently higher power than the single-snp approach, whether the causal snps are present or not. for example, when maf is between  <dig>  and  <dig> , β =  <dig>  power of single-snp method is  <dig>  while that of gcdh is  <dig> ; when the causal snps are untyped, these numbers drop to  <dig>  and  <dig>  respectively, still giving a nearly two-fold increase in gcdh. similar to what we observed in the simulation done with imputed microarray data, power of gcdh increases with β and maf, for instance, when β =  <dig> and maf interval changes from  to , power of gcdh changes from  <dig> to 83 % when causal snps are typed and from 11 % to 46 % when they are not .table  <dig> comparison of power between gcdh and single-snp approaches in analysis of exome-sequencing data from the rotterdam study


β
maf
the simulation analyses are conducted based on the exom sequencing data from rotterdam study  <dig> , consisting of  <dig> individuals and  <dig>  snps. power estimates are calculated from  <dig>  simulations. type-i error rate for single-snp and gcdh analyses are controlled at 5 %



example gcdh analysis using a simulated phenotype
as a demonstration, we simulate a phenotype  according to the collapsed genotype of two randomly selected two causal snps . we conducted a gcdh analysis with window size set at  <dig> and p-value filter set at  <dig> , so that a total of  <dig>  snps were included. when the causal snps are available, gcdh detects strong signals in and only in the corresponding region , while the single-snp approach fails to do so . when the two causal snps are removed from the analysis, the genome-wide gcdh scan still picks-up the correct locus, although with less significant p-values , and single snp analysis gives the same result as before.fig.  <dig> gcdh analysis using a simulated phenotype. genotype data is from rotterdam study . phenotype is simulated with effect size  <dig>  plus a random error term from the standard normal distribution according to the collapsed genotype of two randomly selected snps , and run gcdh using this as the phenotype. genome-wide significance threshold  is set at  <dig>  × 10- <dig> for the single-snp approach, for gcdh  it is set empirically at  <dig>  × 10- <dig> by permutation analysis . window size is set  <dig>  a genome-wide scan with causal snps available. b genome-wide scan without genotypes of causal snps. c regional gcdh with causal snps available. d regional gcdh without genotypes of causal snps



we further conducted a regional gcdh analysis using all imputed snps within 250 kb flanking rs <dig>  including  <dig> snps in total. the regional scan’s signal still weakens when causal snps are untyped, but is much more significant than what we got from the genome-wide scan . this is because in the genome-wide scan we applied a fairly aggressive p-value filter here , i.e. all snps that do not pass the association test with a p-value more significant than  <dig>  are filtered out. this example clearly illustrates that applying a p-value filter could remove a considerable number of snps that individually are not significantly associated with the phenotype but may be so when collapsed with other snps.

using the top  <dig> pairs of snps from the genome-wide scan, gcdh can explain  <dig>  % of the phenotypic variation, while the single-snp method only explains  <dig>  % .table  <dig> percentage of variation explained with gcdh or single-snp method using simulated phenotype

r
r


performance and memory consumption
using a segment from the rs genotype data consisting of  <dig>  snps and  <dig> individuals, we measured the time and space performance of the rungcdh function on a macbook pro with  <dig>  ghz intel core i7-4850hq and 16 gb 1600 mhz ddr <dig> ram . running time goes up linearly as window size increases, and given a dataset with  <dig> million snps and  <dig>  individuals, it is estimated to take about 130 h, which agrees with our experience in practice. memory consumption grows much slower than running time—in this benchmark, when window size was increased from  <dig> to  <dig> , ram usage grew by only 18 %.table  <dig> benchmarks of the rungcdh function using a dataset of  <dig>  snps and  <dig> individuals and a simulated phenotype



discussion
collapsabel offers an increased power in detecting genetic associations caused by ch-like interactions compared to traditional single snp-based gwa approach. computational efficiency of our method is optimized by  using java and c++ for critical tasks,  using genome-shifting algorithm for high-throughput genotype collapsing, and  using the already optimized plink <dig> for statistical tests. the computational burden may be greatly reduced by applying a p-value filter in the initial scan to keep only the snps with some marginal effects. however, in our simulation example we illustrate that this filter should be used with caution, as marginally non-significant snps may be highly significant when interacting with other snps in the ch form. this also implies that collapsabel has a high potential in helping to solve the missing heritability problem currently faced in gene mapping of complex traits. we recommend not using p-value filter, but when computational time is expected to be too high, a p-value filter can be useful .

collapsabel operates on plink bed files with java file streams and therefore can deal with large datasets that do not fit into ram. pairwise genotype collapsing does potentially introduce a challenging computational burden, depending on the parameters used. window size is a major contributor to computational burden; it should be just large enough to cover the desired range in terms of base pairs, which depends on the genotype density used. maf is an important factor affecting whether any positive collapsed genotype can be found at all; our simulation studies clearly demonstrated that the gcdh method has limited power when the maf is less than 1 % for relative large sample sizes .

there has been some software tools developed for epistasis analysis, such as biforce  <cit> , iloci  <cit> , boost  <cit> , snpharvester  <cit> , and snpruler  <cit> . these tools have been highly optimized to handle substantial computational burden and often use novel screening methods to reduce the number of pairwise interactions to be tested. however, these tools are designed to detect general forms of snp interactions at the genome-wide level in a pair-wise manner, while collapsabel focuses on detecting gch in each genomic region using a sliding window approach. therefore, these previously developed tools are not directly comparable with collapsabel considering that their analysis scope and targets, total numbers of tests, and levels of type-i error rate are substantially different.

future improvements of collapsabel will focus on  dynamic window-size determination using a user-supplied base-pair range ;  deriving genome-wide type-i error thresholds analytically. currently we use 5×10−8k as threshold for genome-wide significance and use permutation analysis to empirically estimate type-i error rates, the threshold is conservative and permutation analysis is overly time-consuming;  better handling missing values;  customizable filter function. currently we allow users to filter snps by providing a threshold for marginal p-values, this can be generalized to a function that returns a boolean, so that users can choose snps based on any criteria;  analysis of related subjects. at the moment population substructure can be adjusted by using genetic principle components as covariates, we plan to include mixed models in a future version. some limitations will persist, though:  the gcdh approach identifies pairs of snps in the discovery cohort, the chance of finding both exact snps in other replication cohorts is smaller than finding only one snp as required in conventional gwas; this makes it more difficult for exact replication studies and meta-analysis of gwas results;  the current implementation is ignorant of the scenario where ch-like association involves more than  <dig> causal variants because considering higher order interactions will quickly overload the capacity of existing supercomputing facilities. however, in our extensive simulations, we found that when multiple such variants exist, using an alternative collapsing matrix  instead of the default one  has improved power in finding the ch-like association caused by multiple variants. this is likely explained by the fact that the noted pair of interacting variants is additionally in compound heterozygote with some other unknown variants. in our recent gwas of perceived age  <cit> , we found that testing a compound marker collapsed from four missense variants in the mc1r gene resulted in a drastically improved association signal  than testing the four variants individually . applying collapsabel to the perceived age dataset using the alternative collapsing matrix identifies the mc1r locus with a genome-wide significant signal as expected , even though only pairwise collapsing was performed. therefore, in case of the presence of multiple ch alleles we recommend to first run the initial scan using the alternative collapsing matrix and then conduct higher order interaction analysis only in the promising regions. we plan to add regional analysis functions for this in the next versions;  gch still has a limited power to detect rare causal variants  as demonstrated by our simulations which can only be overcome by extremely large sample sizes .

CONCLUSIONS
collapsabel is powerful, flexible, and computationally efficient for detecting gch in genome-wide association studies using  snp microarray data or whole genome/whole exome sequencing studies. collapsabel may help finding novel gene variants that explain additional proportions of the missing heritability for a wide range of human complex traits and diseases.

availability and requirements
project name: collapsabel

availability: http://www.genabel.org; https://cran.r-project.org/web/packages/collapsabel

operating systems: linux/mac os x 

programming languages: r, java, and c++

other requirements: java  <dig> +, plink2

license: gnu gplv3

any restrictions to use by non-academics: gnu gplv3

the source package collapsabel and its auxiliary package collutils  are also submitted along with this manuscript. installation guide and sample code using a simulated dataset with  <dig> snps and  <dig> individuals are provided in additional file  <dig> 

additional files
additional file 1: diagram for ch and pseudo-code for the genome-shifting algorithm. 

additional file 2: source code of collapsabel the auxiliary package collutils including documentation. 

additional file 3: installation guide for collapsabel and sample code using a simulated dataset with  <dig> snps and  <dig> individuals. 



competing interests

lck discloses that he is co-owner of polyomica, which is the main sponsor of the free and open source genabel project for statistical genomics. all other authors declare that they have no conflicts of interest in the authorship or publication of this contribution.

authors’ contributions

kz and fl developed the software and conducted data analyses; kz, mk, and fl mainly drafted the manuscript. lck provided critical input in software implementation. mk acquired data; fl and mk conceived the study; all authors read and approved the final manuscript.

