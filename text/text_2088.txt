BACKGROUND
knowledge-based potential energy functions are extracted from protein structures. most often a statistical analysis of database protein structures is performed. the potential involving a variable  is estimated from the distribution of that variable in the database, compared with that in a reference state or a null model  <cit> . such potentials are often referred to as statistical effective energy functions .

another class of knowledge-based potentials is based on optimization, that is the set of parameters for the potential functions are optimized, for instance, by maximizing the energy gap between the known native conformation and a set of alternative  conformations  <cit> . this approach is strongly dependent on the methods used for building up decoys, and do not rely on an exact estimation of the energy gap existing between native and decoy structures.

the successful application of seefs to protein structure prediction tasks has been repeatedly demonstrated .

the statistical approach to the derivation of energy functions will be followed here. the structural representation of a protein s can be reduced to the coordinates of cα, cβ, or side-chain centers which can be used to represent the location of a residue  <cit> . once its amino acid sequence a is given, a function f mapping from the  space to the d-dimensional space of descriptors is needed in order to allow a proper reduced protein description. a descriptor can be, e. g. the contact map between non-bonded residues, the solvent accessible surface area, a backbone or sidechain dihedral angle, the packing density and/or any other feature of protein structure. in practice the values that a variable  can assume are discretized. the descriptors associated with that variable describe the possible discretized values of that variable and assume value  <dig> if the current value is within the bin associated to the descriptor and  <dig> otherwise. the potential function becomes therefore a map of the d-dimensional descriptors c to a real energy value. the energy is commonly computed as a linearly weighted sum of descriptors :

 h)=h=w⋅c=∑iwici,
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwgibascqggoaakcqwgmbgzcqggoaakiewacqwfzbwccqggsaalcqwfhbqycqggpaqkcqggpaqkcqgh9aqpcqwgibascqggoaakcqwfjbwycqggpaqkcqgh9aqpcqwf3bwdcqghfly1cqwfjbwycqgh9aqpdaaeqbqaaiabdeha3naabaaaleaacqwgpbqaaeqaaogaem4yam2aasbaasqaaiabdmgapbqabagccqggsaalasqaaiabdmgapbqab0gaeyyeiuoaaaa@4c92@ 

where "·" denotes inner product of vectors and ci is the number of occurrence of the i-th type of descriptor. for statistical knowledge-based potential functions, the weight vector w for linear potential is derived by characterization of the frequency distributions of structural descriptors in a database of experimentally determined protein structures.

statistical effective energy functions
the boltzmann's principle is usually invoked in order to obtain empirical free energies out of the observed statistical frequencies of various protein structural features, assumed to correspond to low energy states  <cit> . these energy functions can include pairwise contact terms  <cit>  but also solvent terms  <cit> , short-range and long-range pairwise interactions  <cit> , dihedral angles  <cit> , solvent accessibility, hydrogen-bonding  <cit>  up to higher-order interactions  <cit>  and three-body nonadditive interactions  <cit> .

according to the boltzmann principle, the distribution of protein molecules among the microscopic states at the equilibrium connects the potential function h for a microstate γ to its probability of occupancy π. this probability π can be written as:

 π = exp/z, 

where k and t are the boltzmann constant and the absolute temperature measured in kelvin, respectively, and z is the partition function. following from eq.  the knowledge-based potential function h corresponding to the boltzmann distribution π is:

 h = -kt ln π - kt ln z. 

in order to obtain a knowledge-based potential function, the background energetic interactions h' in the reference state must be defined. the effective potential energy is then:

 Δh=h−h′=−ktln⁡−ktln⁡,
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqqhuoarcqwgibascqggoaakiigacqwfzowzcqggpaqkcqgh9aqpcqwgibascqggoaakcqwfzowzcqggpaqkcqghsislcuwgibasgaqbaiabcicaoiab=n7anjabcmcapiabg2da9iabgkhitiabdugarjabdsfaujgbcygasjabc6gaujabcufabnaalaaabagae8hwdanaeiikagiae83sdcmaeiykakcabagaf8hwdanbauaacqggoaakcqwfzowzcqggpaqkaagaeiyxa0laeyoei0iaem4aasmaemivaqlagiibawmaeioba4maei4was1aasaaaeaacqwgabgwaeaacuwgabgwgaqbaaaacqggdbqxcqggsaalaaa@5d9a@ 

where π' is the probability of the descriptor γ in the reference state. z and z' are both constants. following sipple, it is usually assumed that z ≈ z', so that eq.  becomes  <cit> :

 Δh=−ktln⁡
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqqhuoarcqwgibascqggoaakiigacqwfzowzcqggpaqkcqgh9aqpcqghsislcqwgrbwacqwgubavcyggsbabcqggubgbcqggbbwwdawcaaqaaiab=b8awjabcicaoiab=n7anjabcmcapaqaaiqb=b8awzaafagaeiikagiae83sdcmaeiykakcaaiabc2fadbaa@4688@ 

due to the high dimensionality of the space of descriptors a reasonable factorization of the probability ratio is sought. different variables are typically treated independently of each other, resulting thus in an energy function that is the sum of many independent contributions. for each descriptor ci the contribution to the energy is given by wi = -kt ln. whether they are formalized in a discretized or analytical way, contibutions to the energy functions derived in this way are technically potentials of mean force  <cit> . the effectiveness and the drawbacks of the approach have been repeatedly pointed out  <cit> . first, it is straightfoward that the choice of the reference state is critical for developing knowledge-based statistical potential function. the reference state problem has been clearly stated by jernigan and bahar  <cit>  and discussed by skolnick and coworkers  <cit>  who derived a potential for a compact reference state with a bias for buried hydrophobic residues and compared it with previous contact potentials.

second the choice of descriptor must catch most aspects of protein energetics, i.e. only native-like models should be assigned low energy by the potential.

third, the assumption of independence of different potentials of mean force is clearly unrealistic. notwithstanding all limitations, statistical effective energy functions are currently the most successful potential available for describing protein conformations .

many statistical effective energy functions have been derived according to different level of representation of the protein, the features selected for defining the potential, the reference state and the actual way of derivation of the potential. since excellent reviews on this subject are available in the literature we will not attempt an extensive coverage of all the works published so far, but rather we aim at discussing general aspects on this issue with respect to the work presented here  <cit> .

earlier works focused on the preference of contacts between specific residues in the database of available experimental structures  <cit> . these and other works pointed out that preferential interactions are one of the most relevant features that must be taken into account for describing protein energetics  <cit> .

the demonstrated unlearnability of optimal potential on simplified models of proteins points out that most likely  <cit> :

i) the chosen protein representation requires a higher level of detail;

ii) the actual residue-residue contact definition is crucial for the accuracy of the potential  <cit> 

iii) other features, like local conformational preferences, must be taken into account for discriminating native structure among decoys;

another important result, which is worth mentioning here, obtained by park and levitt is that smoothing the contact energy function improves the performance of the potential in native structure discrimination among decoys  <cit> .

the derivation of statistical potentials requires the definition of a reference state. the finite size of database proteins and the diversity of sidechains makes this task not straightforward. this problem has been repeatedly pointed out and recently novel approaches have been proposed  <cit> .

concerning other features, like local conformational preferences, it is well known that such preferences exist and actually they form the basis of the success of secondary structure prediction algorithms  <cit>  and current single sequence algorithm are able to predict secondary structure with a 3-state accuracy of  <dig> %  <cit> .

recently convincing evidence has been provided that, for high resolution structures, the distribution of backbone and sidechain dihedral angles may be used for assessing the quality of predictive models  <cit>  and may be successfully used for supplementing contact potentials . moreover it has been pointed out that dihedral angles are strongly correlated with the identity of adjacent residues  <cit> .

the development of the potential presented here was motivated by lack of a reliable potential employing a coarse grained representation of protein structures with the following features:

- only two  centers of interaction per residues;

- smooth interactions e.g. by binning a range interval;

- off-lattice representation with a continuum range for all conformational variables;

- inclusion of residue-dependent local conformational potential term favoring observed preferences;

- inclusion of  nearest neighbor correlation which could reproduce local conformation correlation.

this term is fundamental for obtaining the proper average length of helices, similar to nearest-neighbor coupling in one-dimensional ising models and it is not usually considered in available potentials.

although most of the above listed elements are found in available empirical potentials, an empirical potential that includes all these features at the same time is missing in the literature. there are a number of empirical potentials available, which are similar in spirit. for instance a similar model, but including up to three centers of interactions per sidechain, has been used successfully by betancourt  <cit> . the distance-based potential developed by zhou and coworkers achieves good performance with an even coarser grained representation  <cit> .

other potentials include structural features of interaction centers like orientational parameters for interactions . other potentials, used for simplified model simulations in physics, include all backbone atoms as reviewed by  <cit> . the statistical potential of dehouck et al. includes all backbone torsion angles  and a center of interaction for each sidechain  <cit> .

usage of the correlation between local amino acid conformations has been shown to improve the native structure recognition capability of scoring functions by  <cit> . recently correlation between different sequence and structure descriptors  has been built in a general framework by dehouck and coworkers. the best seef developed according to this framework, entailing  <dig> energy terms, compares well or better with most popular seefs  <cit> .

the reduced representation proposed here consists of two centers of interaction per residue, one for the backbone, centered on cα atom and one for the sidechain  centered on the center of mass of the sidechain atoms.

the potential function entails energy terms for the pseudo bonds between two consecutive cα's and between a cα and the center of mass of the relative sidechain, angular energy terms for all three pseudo-bonded centers of interaction, torsional energy terms for all four pseudo-bonded centers of interaction, a pseudo-torsional energy terms to mantain proper chirality of sidechain orientation with respect to the main chain, an energy term dependent on the torsional angles of adjacent quartets of consecutive cα's and energy terms for all pairwise non-bonded interactions. the pairwise interactions between centers of interaction is derived here from database analysis and it employs a reference state which takes into account the finite size of proteins. the model and energy definition are detailed in the materials and methods section.

we termed this reduced representation of proteins pc2ca, an acronym for pseudocovalent structure with  <dig> centers of interaction per amino acid.

the performance of this potential on all multiple decoy sets in the decoys'r'us database  <cit>  is tested and the results obtained in the critical assessment of structural predictions  model quality assessment  category are summarized.

RESULTS
analysis of the different energy terms
the average and standard deviation values of the different energy terms have been evaluated on the top500h database structures. for what concerns the covalent energy terms ), only few structures, notably with short sequences, had significant deviations in the energy terms connected with the positioning of the sidechain center of mass .

particular attention has been paid to the torsional term dependent on the local chain conformation and the term describing the correlation between adjacent local conformations. in order to make sure that these two terms could describe reasonably well the known preferences for secondary structure elements, a monte carlo simulation was run on the sequences of all the structures in the top500h datasets. the energy was just the sum of the torsional  and correlation energy  and the temperature factor kt was set to  <dig>  in order to match the derivation of the potential.

the range  <dig> to  <dig> degrees was assigned to helical conformation, the range  <dig> to  <dig> was assigned to extended conformation and all other conformations were assigned to coil conformations. every residue was assigned to the most populated conformational range . the experimental secondary structure was obtained using the program dssp  <cit>  and converting the result into three states : the 'e' state was left as the extended conformation; the 'h', 'g' and 'i' states were converted into helix, and all other states into coil. no post-processing of the results was performed.

although this test is run on the same structures used for deriving the potential, making it invalid for any quantitative assessment, the three-state accuracy of this simple prediction procedure is  <dig>  which is more or less what expected for a single sequence method using only nearest neighbor information.

it is interesting to assess the relative contribution of the correlation term to this accuracy. the same test has been repeated setting the correlation term to zero. the accuracy dropped to  <dig> . this was a confirmation that the correlation term is indeed important for properly reproducing local conformational propensities.

test on the multiple decoy datasets
the decoy sets available in the decoys'r'us database under the category 'multiple' are sets where many alternative conformations are given for a single native structure. the models are obtained with widely different methods and offer therefore a significant challenge for free energy estimators. the sets have different features which make different measures of performance appropriate. the ten sets which are currently available are shortly described hereafter.

the set 4state_reduced contains alternative models for  <dig> different proteins. for each protein native-like conformations are present in the set and therefore some correlation between rmsd and energy should witness the accuracy of the energy function  <cit> .

the two sets fisa and fisa_casp <dig> have been assembled by the group of baker using fragments via a simulated annealing protocol  <cit> . for the protein  <dig> the structure with pdb code 1ck <dig> has been used as the native structure.

the sets ig_structal, hg_structal and ig_structal_hires are sets containing few models for many immunoglobulins  or globins  built by homology modeling. most of the models have very low rmsd from native.

the set lattice_ssfit has been generated selecting and refining with an all-atom energy function coarse lattice models  <cit> . the rmsd from native in the set is larger than  <dig> Å for all the eight proteins modeled.

the lmds set was built including information on secondary structure and models have been refined using a soft core all atom model  <cit> . the set includes models with rmsd from native lower than  <dig>  Å for  <dig> proteins.

the semfold test has been produced apparently by a fragment insertion method  <cit> . this includes a very large number  of decoys for each of the  <dig> proteins. some models have rmsds from native in the range  <dig> to  <dig> Å.

the vhp_mcmd decoy set has been obtained by taking snapshots of long molecular dynamics simulations starting from the native structure and from four coarse grained models obtained by monte carlo simulations. all conformations have been energy minimized using the molecular mechanics/generalized born model  <cit> .

the results obtained on the decoy sets are summarized in tables  <dig> to  <dig>  since many of the target structures have homologues in the top500h database, those which do not have a significant similarity with the top500h set are indicated by boldface characters . no significant difference is apparent based on the presence or absence of homologues in the top500h dataset.

an energy versus rmsd plot for the 4state decoy sets is reported in figure  <dig> 

there are a number of plausible reasons for failure in native structure recognition, even for the best quality scoring functions, as discussed by shen and sali  <cit> . in the present case, in the few cases where the native structure is not recognized the covalent energy of the pseudocovalent structure is large showing that most likely the experimental model is not optimally refined. for instance in the native structure of protein with pdb code 4rxn there the distance between the cα of glu  <dig> and the cα of asp  <dig> is  <dig>  Å, much shorter than the average distance causing the highest energy in the set for the corresponding energy term. similarly there are distorted geometries in the proteins with pdb code 1ctf, 1bba and 1dtk.

another likely reason for failure of native structure recognition is the presence in the crystal structure of other chains. this is the case for the short fragment of protein a  which is bound in the crystal to an immunoglobulin domain.

in general nmr structures are more difficult to be recognized. refinement of nmr structures is strongly dependent on the forcefield and protocol used, and this may result in minor structural features which are not typical of protein structures and give rise, in turn, to large energies in the statistical effective energy function.

the most challenging decoy set appears to be the semfold set which includes six targets and more than  <dig> decoys for each target. for five of the decoys native or low rmsd decoys could be recognized, but the z-score is rather low. for the structure with pdb code 1khm the lowest energy structure has a high rmsd from native, although there are decoys with rmsd from native as low as  <dig>  or  <dig>  Å. it is remarkable that the term for ca cm interactions attains the third lowest energy for the native structure but the overall energy is only the tenth lowest energy beyond structures with rmsd from native larger than  <dig> Å. the number of native-like structures  in the set is however limited, so it is difficult to assess whether the failure can be ascribed to the quality of the native structure, of the decoys or of the energy function itself. for this reason we considered other structures deposited in the pdb with the same sequence. for the structure with pdb code 1zzj the energy  is lower than the energy of all decoys. this result witnesses the quality of the energy function although the low energy assigned to very different conformations poses an issue on the robustness of the methodology. it is worth mentioning that the protein is associated with single stranded rna in the crystallographic structure, and this feature is not modelled by the statistical effective potential.

the energy function performs also well on decoys which are mostly native-like as in the decoy sets hg_structal, ig_structal, ig_structal_hires where the native conformation is recognized  <dig> times on  <dig> cases.

moreover very low rmsd decoys are mostly selected as the lowest energy conformations. for this sets it is interesting that the correlation coefficient between energy and rmsd is on average high  and for the hg_structal set it is on average equal to  <dig> .

the correlation between energy and rmsd is typically found only at low rmsds, in other words the energy for grossly misfolded structures is not correlated with the rmsd from the native structure, but should be correlated with the rmsd from the local minimum energy conformation. for sets where the whole range of rmsds is represented the correlation coefficient should be positive and significantly different from  <dig>  and similarly the fraction enrichment should be significantly larger than  <dig> percent. indeed this is the case for all 4state_reduced decoy sets and for the vhp_mcmd sets, and on average for the hg_structal, ig_structal, ig_structal_hires.

the overall ability of recognizing the native structure among decoys including native-like structures is outstanding for a model entailing only two centers of interaction per amino acid, and compares well or is superior to more complex models as judged by the results obtained with many model quality assessment programs and reported by tosatto . we report in table  <dig> a summary of the data reported in the cited study by tosatto including the best performing potentials together with our results, for the sake of comparison. the best model quality assessment programs  considered here are proq  <cit> , prosa ii  <cit> , verify3d  <cit> , akbp  <cit> , dfire  <cit> , rapdf  <cit>  and frst  <cit> .

test on conformations generated by rosetta
a test was performed by generating  <dig> conformations for the small thermostable domain of the chicken villin headpiece using the software rosetta which is one of the best tools for ab-initio protein structure prediction.  <dig> structures have been generated and refined using the same software. the average rmsd of the conformations with respect to native is  <dig>  Å with a standard deviation of  <dig>  Å. the best model selected by the energy model proposed here has  <dig>  Å rmsd from native. perhaps more significant is the correlation between the rank according to the energy and the rank according to the rmsd which is  <dig> .

pc2ca in casp7
at the time this paper is being written the casp <dig> experiment has just closed . for  <dig> out of the  <dig> targets experimental structures have been released. the quality assessement category has been recently introduced in the casp experiment in order to evaluate by scoring functions the quality of the predictive models obtained by servers. the discussion reported hereafter is connected with the methods adopted for assessment in this community-wide experiment .

unfortunately models submitted by servers and evaluated by quality assessement programs differ in the number of residues modeled and in the level of detail, ranging from only cα's to all atoms for each amino acid. for this reason a choice must be adopted for ranking the models which takes into account these aspects.

evaluation of predictions may be conducted using different legitimate criteria. we discuss in the following the ability of pc2ca to select native-like structures among decoys.

in order to assess the performance of pc2ca we evaluate the quality of best ranking models using the widely accepted global distance test total score  criterion  <cit> . in particular the "loss in gdt_ts" of the best ranked model  compared to the best available model   gives a good idea of the performance of an energy or scoring model.

we wish to remark that no selection has been applied nor on targets nor on models: all models were scored for all targets by our group. no consensus method nor alignment or template modeling has been used for scoring models. the average loss in gdt_ts may be greatly reduced by selecting homology modeling targets. considering the consensus among predictors improves results in many categories of predictions, as demonstrated in recent casp experiments.

another important issue is that residues with incomplete backbone or sidechain have been simply ignored in our quality assessment predictions and therefore a large number of models received very low score. in the deposited quality assessments we ranked models according to the energy per residue with a cutoff on the percentage of modeled residues for half of the targets and according to global energy for the remaining half. the energies for models with different level of completeness are not directly comparable and the chosen criterion had only the purpose to single out best and most complete models.

here we will discuss predictions based on the global energy, but the results described here are however largely overlapping with those deposited.

the presence of heterogeneous  predictions made the correlation between ranking and gdt_ts insignificant and, in general, it impaired safe comparison of models.

the global energy appeared a reasonable criterion for scoring best models but it was not designed in order to maximize correlation of score rank with gdt_ts rank.

when the gdt_ts of the best models obtained from servers is compared with the gdt_ts of the best scoring model according to pc2ca the results are outstanding when one considers that the energy model employs only two centers of interaction per residue. the average loss in gdt_ts is  <dig>  for all targets . when the best scoring model is compared to the first model submitted by most successful servers like zhang server and robetta server the difference in gdt_ts is as low as  <dig>  and  <dig> , respectively, and in general the average loss in gdt_ts compared to the best mqap predictor is  <dig> . comparison with other mqap predictors in casp <dig> is not straightforward because only  <dig> groups  deposited predictions for all targets. when we compare the average gdt_ts of the best pc2ca scoring models with that of other predictors  pc2ca ranks 15th out of  <dig> for template free modeling and 18th out of  <dig> for all models. the average loss in gdt_ts computed is  <dig> , smaller than the average of  <dig>  of all quality assessment methods.

the best pc2ca scoring models have consistently higher gdt_ts than the average gdt_ts computed on all models for each target .

discussion
the reduced representation of proteins presented in this work has two features which makes it attractive for application in biophysical areas: it is simple and it is capable of discerning native-like models among non native-like models produced using a wide variety of methods. a blind test performed in the casp <dig> quality assessment category confirms this conclusion and, in spite of its granularity, our scoring potential ranks in the average of methods using finer granularity and applying consensus procedures.

the good scoring properties of the model however do not guarantee that the same model can be used for folding small proteins e. g. by monte carlo simulated annealing. indeed, the potential could have lower minima for conformations that are not explored by the algorithms used for generating decoys or predictive models in casp <dig>  the range of values for terms involving bonds, angles and pseudodihedrals in the systems tested is limited. it is likely that it would be possible to slightly increase the energy of these terms, reaching non-physical conformations, and simultaneously decrease other, e. g. non-bonded energy terms.

an obvious correction to the potential for model generation applications is the replacement of flat high energy regions at large distances with increasing potential, in order to prevent bonds to break. a less obvious issue is that the weights of the different terms, in particular those which have less variability in the decoy test sets, could have to be changed when using the potential to generate models. it is also likely that the correlation found between torsional and bending energy terms in native structures will need proper treatment. such correlations are somehow taken into account by the attractive potential between ca's.

another important point is that the pseudo-minimization used in this work is a very rough approximation of a real energy minimization procedure.

the ultimate test for a scoring potential function is however recognition of native-like structures among decoys generated with the task of minimizing the same potential function.

all these issues above are being considered for using the potential in model generation applications under development in our laboratories.

CONCLUSIONS
the results obtained on decoy sets and those obtained in the blind casp <dig> quality assessment experiment suggest that the energetic model proposed here is suited for scoring predictive protein models. in spite of its simplicity the potential compares well with scoring potentials with much finer granularity. tests are underway in order to assess its application for fast exploration of conformational space.

