BACKGROUND
gas chromatography  coupled with mass spectrometry  is frequently used in metabolomics  <cit> . gc-ms is best suited for the analysis of compounds of low-to-medium polarity, and can directly analyze naturally occurring volatile metabolites, as well as semi-volatile and non-volatile metabolites after derivatization  <cit> ; the most widely used derivatization methods being either trimethylsilylation or tert-butyldimethylsilylation with oximation of keto-groups  <cit> . the type of ionization most often used in gc-ms is electron impact . this type of ionization produces unstable charged molecules that undergo complex cascades of fragmentation; the m/z ratios of resulting charged fragments give the observed mass spectra. the ei mass spectra at standard  <dig> ev employed by most gc-ms instruments are moderately reproducible, facilitating library searches for analyte identification  <cit> . gc-ms has a long history in metabolic profiling of biological material  <cit> , and currently is widely used in biochemical  <cit> , agricultural  <cit> , environmental  <cit> , and biomedical research  <cit> , as well as in a variety of industrial applications  <cit> .

the principles for processing of ms-based metabolomic data are well established  <cit> . gc-ms data is acquired as a time series of mass spectral scans, where each scan consists of a series of  pairs. typically, the raw data is transformed into a two-dimensional matrix by binning raw scans at equidistant m/z intervals. the resulting data intensity matrix is populated with binned m/z intensities, where its indices represent scan numbers  and m/z values. subsequent processing steps may involve any combination of noise smoothing, baseline correction, peak detection, alignment, normalization, library matching, and optionally visualization. a variety of software tools have been developed for the processing of gc-ms data. these tools can generally be divided into two categories:  commercial software, either provided by the manufacturers of ms equipment or by independent vendors;  freely available software packages developed by academic groups. examples of the commercial ms software include masslynx , chromatof , chemstation , analyzerpro , clearview , and ionsignature . typically, this type of software is mature, puts emphasis on the graphical user interface  and the overall ease of use. many commercial ms software packages come bundled with ms hardware, thus ensuring their wide exposure to the research community. in recent years a number of freely available software packages for gc-ms data processing has been developed by the academic community. this type of software is increasingly provided under open source license  <cit> .

in recent years, several ms processing/analysis software platforms that operate through the web interface were proposed. this type of software includes spectconnect  <cit> , metaboanalyst  <cit> , xcms online  <cit> , and metabolomeexpress  <cit> . spectconnect aims for finding of conserved components and biomarkers  <cit> , and on the input takes putative components pre-extracted by amdis  <cit> . the xcms online project provides access to pre-processing of lc-ms data by xcms  <cit>  through web-interface. metaboanalyst provides the entire pipeline for high-throughput metabolomics studies  <cit> , from raw data processing to statistical analyses, and for data pre-processing relies on xcms  <cit> . web-based software offers an immediate access to the processing functions with the availability of internet, this being its greatest advantage. for such software the available computing power  can be a bottleneck for large processing tasks. furthermore, if many simultaneous users are requesting the service the available computing power may be exhausted, as well as data transfer bandwidth if large data sets are required to be uploaded for processing.

amdis is one of the oldest, freely available stand-alone software package for the processing of gc-ms data  <cit> . recently several extensions to amdis were proposed to improve its mode of operation  <cit> . msfacts  <cit> , its successor met-idea  <cit> , as well as tagfinder  <cit>  are specialist tools for gc-ms data analysis that combine elements of traditional pre-processing with data analysis, and in some cases spectral matching for component identification. the software packages mzmine  <cit> , metaquant  <cit> , metalign  <cit> , metabolitedetector  <cit> , and openchrom  <cit>  incorporate both advanced algorithms and a graphical user interface , therefore being particularly suitable for interactive processing work. mzmine  <cit> , metaquant  <cit> , maltcms/chroma  <cit> , and openchrom  <cit>  were developed in java, ensuring a high level of cross-platform compatibility. metabolitedetector was developed in c++, and relies on the qt development framework to ensure cross-platform compatibility  <cit> . xcms  <cit> , targetsearch  <cit> , and centwave  <cit>  operate within the r statistical environment . meddl is a software prototype developed within the matlab environment , with the idea to be subsequently translated into the general purpose, object oriented scripting language python  <cit> . mmass is a recent software package also developed in python, with the focus on lc-ms data  <cit> .

most software for gc-ms data processing is stand-alone, providing a tight integration of processing methods with gui-based components, best suited for interactive data processing  <cit> . alternatively, some prominent software packages consist of a collection of scripts integrated with well established computing environments, such are r or matlab  <cit> . yet an alternative approach was taken by maltcms/chroma: maltcms provides a java-based data processing engine, and chroma is an implementation of a gui-based interface that allows easy access to the maltcms data processing capabilities  <cit> . this approach offers advantages when high-throughput, custom processing pipelines are required because the data processing engine is decoupled from gui components and can be easily scripted.

here we describe pyms, a novel gc-ms processing software that decouples data processing methods from gui-based interface. pyms currently implements a complete set of methods required in typical gc-ms data processing, including reading of standard data formats, baseline correction, nose filtering, peak detection, peak deconvolution, peak integration, and peak alignment based on dynamic programming described previously  <cit> . we present details of the pyms implementation, give an overview of current data processing capabilities, and analyze real-life data analysis scenarios based on custom data sets. for the purpose of pyms evaluation we have designed several experiments, including a mixture of  <dig> metabolites representing a variety of chemical classes , and a series of experiments where the sample was foetal calf serum spiked with quantitative amounts of metabolite standards. the performance of pyms was compared to several leading software packages, including amdis  <cit> , one of the most widely used freely available software for gc-ms data processing  <cit> ; xcms  <cit> , representing the new generation software for ms data processing implemented in r; and analyzerpro  a widely used commercial gc-ms software package. we show that when considered in realistic data processing scenarios pyms performance is robust, and compares favorably to these software packages.

implementation
data processing capabilities
instrument data input
pyms supports two standard data formats for data input, andi-ms  <cit>  and jcamp-dx  <cit> . jcamp-dx format for chromatography and ms was developed by the iupac electronic data standards sub-committee  <cit> . the andi-ms format  <cit> , developed by the analytical instrument association  and the american society for testing and materials , is currently one of the most widely used vendor-neutral formats in gc-ms  <cit> . andi-ms is a binary format which relies on the network common data form  specification  <cit>  while jcamp-dx is a flat-file ascii format  <cit>  . most vendors of ms instrumentation provide software that supports export to one or both of these formats, and third party software packages can convert data stored in proprietary formats to andi-ms or jcamp-dx .

raw data object
most gc-ms data processing software performs automated binning of raw data on-the-fly, while reading the raw data file. this prevents a user from accessing raw mass spectral scans at all. however, the ability to access and manipulate raw gc-ms data may be important in many advanced data processing scenarios. reading the raw data in pyms results in an object designed for the optimal representation of raw instrument data named "gcms_data" . pyms internal data structures have been optimized to wrap tightly around the natural structure of raw instrument data, and to provide a significant flexibility for downstream processing .

>> > from pyms.gcms.io.andi.function import andi_reader

>> > raw_data = andi_reader

- > reading netcdf file ‘gc01_0812_ <dig> cdf’

listing  <dig>  an interactive reading of a raw data file from the command line of the python interpreter. the resulting variable named "raw_data" is a "gcms_data" object, and holds the raw data as a list of mass spectral scans, thus closely supporting the native structure of raw data.

the "gcms_data" object exposes key attributes of raw data, and has several special methods for accessing and manipulating the data. for example, the user can retrieve an individual raw mass spectral scan either by index or by retention time, and then retrieve the list of m/z values or measured intensities associated with this scan. in addition, the user can retrieve the entire vector of retention times, calculate the tic , or request a compact data description to be printed out .

>> > raw_data.info()

data retention time range:  <dig>  min --  <dig>  min

time step:  <dig>  s 

number of scans: 9865

minimum m/z measured:  <dig> 

maximum m/z measured:  <dig> 

mean number of m/z values per scan: 56

median number of m/z values per scan: 40

listing  <dig>  the example output when the "info()" method of the raw data object is invoked. it is assumed that that object "raw_data" was created as shown in the listing  <dig> 

the "trim()" method allows one to trim the data between scans, specified either as scan numbers or as retention times . these are examples of methods not readily available in standard gc-ms processing software.

>> > raw_data.trim # trim between scans  <dig> and 2000

>> > raw_data.trim # trim between  <dig>  and  <dig> minutes

listing  <dig>  example of trimming the raw data. trimming can be achieved either by scan number or by specifying the retention time in seconds or minutes. in this example, the first command will trim the raw data between scans  <dig> and  <dig>  the second command will trim the raw data between  <dig>  min and  <dig>  min. the result of these operations is again a "gcms_data" object, with all mass spectral scans outside the specified range removed. it is assumed that that object "raw_data" was created as shown in the listing  <dig> 

once gc-ms raw data is read by the processing software, it is rarely necessary to export the raw data again; rather, the ability to output binned, processed, and extracted data becomes critical. pyms supports export of raw data to csv format, while binned and processed data can be exported to several vendor neutral formats .

raw data binning
raw gc-ms data stored by ms instruments consists of a series of mass spectral scans taken at equidistant time points along the retention time axis, where each scan is a vector of  pairs . the acquisition hardware associated computer typically performs centroiding on-the-fly, and as a result mass spectral scans have a non-uniform sampling in the m/z domain. therefore the length of individual mass scan vectors may vary from scan to scan, and data in such arrangement is difficult to process. a widely accepted procedure is to bin the raw data to fixed m/z intervals  <cit> , and this is particularly suitable for gc-ms data recorded at nominal mass resolution  <cit> . quadrupole ms, most often used in gc-ms, generally acquire data at low resolution and the accurate mass of a metabolite can be slightly larger or slightly smaller compared to its nominal mass, depending on metabolites' exact atomic composition. therefore, a concern in any m/z binning procedure is that chosen bin boundaries may be close to m/z of many observed metabolite fragments, as small inaccuracies in measurement may shift the fragment between different bins. a simple consideration of typical atomic composition shows that accurate mass of most metabolites is likely to be slightly larger than its nearest integer value. for this reason, commonly accepted boundaries for the unit-resolution binning are bins centered at around + <dig>  to + <dig>  of the unit mass, implying the bin boundaries near − <dig>   and + <dig>  . this of course is a good choice only on average, and specific compound classes may have a different distribution of accurate masses . pyms provides flexible binning functions that allow user to specify the desired binning parameters. by default, the data will be binned at nominal mass with bin boundaries set at − <dig>  and + <dig> , conforming to the behavior of most gc-ms data processing programs. however, user can specify different binning parameters by invoking optional arguments . the result of binning is always a "intensitymatrix" object which has a number of special methods . in addition, the "intensitymatrix" object also provides methods that can manipulate the data, for example crop mass spectral range between certain m/z values, or set intensities of certain masses to zero. the latter is useful for eliminating masses which are known to be uninformative .

im = build_intensity_matrix_i

im = build_intensity_matrix

listing  <dig>  examples of building of the intensity matrix from raw data . in the above examples the variable "raw_data" is the "gcms_data" object, and the variable "im" holds the binned data . in the first command, the default binning is invoked . the second command shows an advanced binning . in pyms binning of raw data results in an "intensitymatrix" object, designed to capture and provide convenient access to binned data. the binned data takes a center stage in subsequent processing, and it is particularly important that the structure of this object is well suited for downstream data processing.

conceptually, binned data can be viewed as a two dimensional matrix whose rows represent mass spectral scans, and columns represent ion chromatograms . most of the subsequent processing workflow requires handling of individual rows and/or columns of this matrix. elementary examples include time-domain noise smoothing of an ic , and mass spectral library matching . to allow efficient data handling, the "intensitymatrix" object itself implements two kinds of objects: mass spectral scans  and ics , and provides methods for manipulation of these objects .

> > ms = im.get_ms_at_index

> > ic = im.get_ic_at_index

listing  <dig>  examples of retrieving an individual ion chromatogram and mass spectrum from the intensity matrix object . in this example the variable "ms" is a "massspectrum" object, while the variable "ic" is the "ionchromatogram" object. these objects have their own attributes and methods that allow specific access to underlying data. it is assumed that that object "im" was created as shown in the listing  <dig> 

pyms allows the binned data to be exported to three ascii formats: as a space delimited two-dimensional matrix, as generic comma separated values  file, and as a leco csv file. these formats can facilitate exchange of binned data with external programs. for example, the space delimited csv format allows import of a two-dimensional matrix into matlab, while leco csv file is suitable for data import into other gc-ms processing software.

most of the standard gc-ms data processing steps are performed by traversing the binned data either by mass spectra or by ion chromatograms. combining the pyms binned data structure with the general capabilities of the python programming language allows one to build flexible yet powerful processing pipeline. for example, if the binned data is stored in the variable "im", each ic can be retrieved and processed as shown in listing  <dig>  an analogous loop would allow one to traverse through mass spectra instead of ion chromatograms .

n_scan, n_mz = im.get_size()

for i in range:

 ic = im.get_ic_at_index

 # do something with ion chromatogram

listing  <dig>  looping over all ion chromatograms of binned data. it is assumed that that object "im" was created as shown in the listing  <dig> 

n_scan, n_mz = im.get_size()

for i in range:

 scan = im.get_scan_at_index

 # do something with mass spectrum

listing  <dig>  looping over all mass spectra of binned data. it is assumed that that object "im" was created as shown in the listing  <dig> 

these examples show how to construct elementary data processing paradigms in pyms. additional flexibility is attained by combining pyms data types with the general capabilities of the python programming language. for example, if only certain ics  need to be processed, target ics can be collected into a list , and the resulting list can be processed by looping over all items in the list . this is an example of a data processing scenario that is simple to implement in pyms, yet difficult to achieve with conventional gc-ms data processing software.

noise filtering
signals obtained from gc-ms instruments contain both high-frequency and low-frequency noise, and noise filtering is an essential step in routine processing of gc-ms data. the noise in gc-ms data can generally be divided into true noise  and chemical noise  <cit> . the representative true noise originates from limitations in instrument electronics , and is typically manifested as high-frequency fluctuations with zero long-time average. on the other hand, chemical noise originates from chemical components introduced into the chromatography column/ms detector system, either during the sample preparation or because of instrument imperfections   <cit> . this type of noise often results in low-frequency signals, also known as baseline distortions. the detector noise is approximately constant within each mass trace , however, in practice the detector threshold is routinely applied resulting in blocks of zero intensities  <cit> . the nature of chemical noise is highly sample and method dependent; this kind of noise may manifest itself as a continuous, linear or irregular  contribution to the baseline. therefore, in-depth analysis of noise in gc-ms experiments requires analysis of individual mass traces, taking into account blocks of zero data introduced by the detector threshold, and also analysis of noise as a function of time within each mass trace  <cit> .

pyms implements several methods for noise filtering. high-frequency noise filters  include moving-average and savitzky-golay filters  <cit> . savitzky-golay filters are based on least-squares polynomial smoothing, and this type of noise filtering is one the most commonly used in spectral data processing  <cit> . the moving-average filters are suitable for reducing random noise while retaining a steep response  <cit> . in pyms, the width of the moving average window in both mean- and median-average filters is user controlled. with the savitzky-golay filter, both the widow width and the polynomial degree are user specified. as noise smoothing filters are applied to an "ionchromatogram" object, they can be applied to both individual mass traces and tics. the application of a noise filter to an "ionchromatogram" object results in another object of the same kind, and therefore multi-pass filters can be easily applied.

baseline distortion is often observed in gc-ms data , and therefore baseline correction or low-frequency noise filtering is routinely required in gc-ms data processing. approaches to baseline correction include a simple offset correction and methods that explicitly model the baseline . methods for baseline correction are also an active area of research, with several advanced methods reported recently, including the wavelet-based method developed for the electrophysiological data  <cit>  and an automated parametric smoothing method developed for nmr  <cit> . pyms implements an efficient baseline corrector based on mathematical morphology  <cit> .

peak object
the concept of signal peak is of fundamental importance in gc-ms data analysis  <cit> , yet little discussion of data structures that can optimally support storage and handling of peak objects can be found in the literature. from the analytical perspective, the most important properties of a signal peak include peak elution time , peak mass spectrum , and the peak area . in gc-ms, peak elution time and the peak mass spectrum are indicators of the component's chemical identity, while the peak area provides a quantitative measure of the component's abundance. in pyms, a signal peak is stored in a special data structure  that captures all important aspects of signal peaks, including peak retention time and peak mass spectrum, peak boundaries, and signal areas. it also assigns a unique id to each peak at the time of peak object creation.

peak detection and deconvolution
gc-ms is frequently applied for the analysis of complex samples resulting in heavy overlap of chromatographic peaks. this in turn poses significant challenges for the extraction of pure component mass spectra required for unambiguous component identification  <cit> . a number of methods for the extraction of pure component mass spectra from gc-ms data have been proposed in the past . these methods vary in their performance, accuracy, and suitability to specific features of gc-ms data, and to date no method has been accepted as standard  <cit> . pyms implements peak deconvolution based on the ideas of biller and biemann  <cit> , with several modifications. the pyms peak deconvolution algorithm first identifies all local maxima that are above certain, user specified threshold. then the neighboring apexing ions are combined, and initially considered to belong to the same signal peak. the allowed distance between the apexing ions to combine into the same pure component, the intensity threshold and the width of the window over which local maxima are detected are all user adjustable parameters. pyms allows two types of signal peak quantitation: all ions found to belong to a single component can be used for quantitation; alternatively, a specific ion can be automatically selected for consistent quantitation when experimental replicates are available . to calculate the area of a single m/z trace , the intensities are added from the apex of the mass peak outwards. edge values are progressively added until the added intensity contributes less than a certain threshold relative to the accumulated intensity , or the intensities start to increase. this prevents the accumulation of intensities from the neighboring signals, as the increase in intensities is an indication that the overlapping signal is present.

peak alignment by dynamic programming
when a number of related gc-ms experiments are analyzed it is essential to account for retention time drifts between individual runs  <cit> . this is typically achieved either by aligning chromatographic profiles prior to peak detection  or by matching signal peaks between the experimental runs post-peak detection  <cit> . pyms implements a post-peak detection alignment approach based on dynamic programming , described in detail elsewhere  <cit> . here we briefly review only the most fundamental aspects of the dp peak alignment. the best alignment is achieved by minimizing the alignment score by dp, where the individual peak-to-peak scoring function is chosen to take into account similarities in both peak retention times and mass spectra  <cit> . the final alignment is built progressively, by adding one experiment at a time, based on the guide-tree derived from all possible pairwise alignments  <cit> . the final peak alignment table relates signal peaks obtained in individual experimental runs across the entire set of experiments and this may involve a set of replicate experiments on a single biological state, or several biological states each characterized by a number of replicate experiments. in the final alignment matrix the positions of individual peaks are replaced with respective peak areas that quantify the concentrations of individual metabolites. this method can be used to align peaks across large numbers  of gc-ms runs.

single ion quantitation
a common scenario in metabolomic gc-ms studies is non-targeted analysis of multiple  experimental runs. when many signals are considered across a number of experimental runs, and a prior knowledge of component mass spectra is not available, the key challenge is to ensure that each peak is quantified with exactly the same set of ions. a common approach to this is to base the quantitation on a single ion, and then use the selected ion consistently across different samples. this works well when characteristic ions for compounds of interest are known beforehand . in non-targeted studies characteristic ions may not be known for all components beforehand. to address this we have developed an approach that automatically selects an ion for quantitation across all samples for each unknown peak . the starting point for non-targeted single ion quantitation is the peak alignment table. it should be noted that the alignment table produced by dp incorporates the full peak mass spectra taken at the peak apexes. then, as a part of single ion quantitation algorithm, the most n abundant ions are selected for each peak position, and the peaks in the alignment table are examined to find a single ion common to all peaks aligned at that position. for each peak, the area of this single ion is integrated across the retention time limits determined by the peak area calculation algorithm described above and used for quantitation across multiple samples. this approach achieves a consistent quantitation in multiple-experiment scenarios where the compound characteristic ions are not known beforehand . since this approach relies on the most abundant m/z ions for each peak, it excludes any noise arising from other m/z channels, as well as interference from neighboring peaks. in addition, this approach implicitly checks the validity of the peak alignment table: if the quantitation ion is not present in a specific occurrence of the peak, the peak is probably misaligned.

design and implementation
organization of the pyms project
the pyms project consists of three related parts hosted as independent projects on the publicly accessible google code repository, and test data repository hosted on our own servers . the google code repositories includes a source code repository , an extensive set of ready to run tests and examples , and user guide .

the project "pyms-test" contains  <dig> ready-to-run scripts that illustrate all aspects of current pyms functionality. because of space restrictions on the google code public web server, the example data sets used by the test scripts in "pyms-test" are provided separately, and can be obtained from http://bioinformatics.bio <dig> unimelb.edu.au/pyms/data/.

modularity
pyms is implemented as a hierarchy of python sub-packages, allowing any functionality to be selectively invoked as required. the overall architecture of pyms is explained in the user guide. the individual pyms functions focus on specific, well-defined processing tasks, while each function is designed to be as flexible as possible by using optional and named arguments to handle optional parameters. to illustrate this, consider the savitzky-golay filter module. this module is represented by the file "savitzkygolay.py" which defines the function "savitzky_golay()" . to achieve savitzky-golay filtering one needs to load the "savitzky_golay()" function from the pyms package hierarchy at runtime, and then apply the function to a suitable object. the user is able to change function parameters by specifying the optional, named arguments on the command line. this example illustrates the general principles used throughout the pyms implementation.

def savitzky_golay

listing  <dig>  the definition of the function "savitzky_golay" within the module "savitzkygolay.py". the argument "ic" is the ion chromatogram passed to the function, while the named parameters "window" and "degree" are optional. if the optional named parameters are not specified when in the function call they take default values specified above.

parallelization
a typical gc-ms data may consist of  <dig> - <dig>  mass spectral scans with ~ <dig> m/z values collected in each scan. standard gc-ms data processing involves processing of series of ics or mass spectra, as iterative column-wise  or row-wise  processing of the binned intensity matrix. pyms implements parallel processing based on mpi , a language-independent communications protocol for parallel processing. pyms uses mpi for python , a python package that provides bindings of the mpi standard. at present pyms is able to harvest multiple cpus only for by-row and by-column data processing tasks .

methods
sample preparation
metabolite mix analysis by gc-ms
a mixture of  <dig> metabolites representing a variety of chemical , organic acids, amino acids, sugar phosphates ) was prepared for gc-ms analysis. specifically,  <dig> μl of the mixture was transferred to a gc-ms vial insert and evaporated to dryness in vacuo. samples were methoximated in  <dig> mg/ml methoxyamine in pyridine  with continuous shaking, and then derivatized with bstfa + 1% tmcs  using a gerstel mps <dig> autosampler robot. samples  were injected onto an agilent 7890a gc interfaced with a  <dig> c mass selective detector. gc was performed on a  <dig> m vf5-ms column with  <dig>  mm inner diameter and  <dig>  mm film thickness . injection temperature was 250°c, the interface set at 280°c, and the ion source adjusted to 250°c. the carrier gas was helium . the temperature program was  <dig> min isothermal heating at 70°c, followed by a 1°c/min oven temperature ramp to 76°c, then 5°c/min to 325°c and held for  <dig> min. mass spectra were recorded at  <dig>  scans/s .

foetal calf serum analysis by gc-ms. foetal calf serum samples were spiked with 2-fold increasing amounts of a mix of metabolite standards , organic acids , amino acids ). samples  were extracted by the addition of  <dig> μl ice-cold chloroform:methanol , followed by vigorous mixing and incubation on ice for  <dig> min. samples were centrifuged at 4°c for  <dig> min at  <dig>  rpm to enable biphasic separation. the upper aqueous phase  was transferred to gc-ms vial inserts and dried in vacuo. samples were prepared for gc-ms analysis as above and injected . gc-ms settings were as above, but temperature program was  <dig> minutes isothermal heating at 35°c, followed by a 25°c/min oven temperature ramp to 325°c and held for  <dig> minutes. mass spectra were recorded at  <dig>  scans/s .

data analysis
a comparative data analysis was performed with four software packages: analyzerpro , amdis  <cit> , xcms  <cit> , and pyms . firstly, the two data sets described above  were analyzed with a combination of these packages and with the assistance of experienced analysts to determine the number of components in each data set. subsequently, each software package was applied to each data set. for each software package optimization of processing parameters was performed independently by comparing the results with the manually determined component content. although certain processing parameters are similar between these software packages, no effort was made to make them consistent between the packages. this is because other, non-similar parameters also influence the quality of results. therefore we have focused on optimizing the parameters for each package in absolute terms, by comparing the results to the manually determined components. three out of four compared software packages , amdis  <cit> , and pyms, but not xcms  <cit> ) give the option to ignore the ion chromatograms  of certain ions, allowing the user to introduce prior knowledge about the experimental setup to improve data analysis. as the ei mass spectrum of tms derivatized metabolites contain the ions m/z =  <dig> and  <dig>  these ions were ignored in the analysis by analyzerpro , amdis  <cit> , and pyms.

amdis
amdis is most frequently used in connection with the nist database of metabolites for detection of compounds in gc-ms data. in this study, only the peak detection ability of amdis was tested, with no evaluation of its library matching ability. amdis parameter 'shape requirements', used for shape matching in the peak detection algorithm was set to 'medium'. sensitivity was also set to 'medium', and the 'type of analysis' parameter was set to 'simple'. amdis has a spectral resolution parameter 'adjacent peak subtraction' and this was set to  <dig>  the component width was set to  <dig>  and this was found to give the best results for analysis of both the metabolite mix and spiked foetal calf serum.

xcms
we used the xcms 'matched peak' method  <cit> . the signal to noise ratio must also be set, and a value of  <dig> was found to give the best results. the 'fwhm'  parameter was set to  <dig>  minutes.

analyzerpro
analyzerpro is a commercial, specialized gc-ms data tool . many of analyzerpro data processing parameters can be set from knowledge of the raw data acquisition parameters. manual optimization suggested slightly different parameters for the two data sets  to give optimal results. in the processing of metabolite mix, the following parameters were used: area threshold =  <dig>  ions =  <dig>  scans =  <dig>  height threshold =  <dig>  signal to noise =  <dig>  smoothing = gaussian  <dig> points, width threshold =  <dig>  minutes. in the processing of foetal calf serum data, the following parameters were used: area threshold =  <dig>  ions =  <dig>  scans =  <dig>  height threshold =  <dig>  signal to noise =  <dig>  smoothing = gaussian  <dig> points, width threshold =  <dig>  minutes.

pyms
although pyms has many parameters which can be set by the user, only five parameters were used for optimization of peak finding in the processing of metabolite mix and foetal calf serum data. other parameters  were left at default values. the five parameters optimized for peak detection in pyms were: window width , threshold , ions , scans , and r . for the processing of metabolite mix data, the following parameters were used: window =  <dig>  ions =  <dig>  scans =  <dig>  threshold =  <dig>  r = 2%. for the processing of foetal calf serum data, the following parameters were used: window =  <dig>  ions =  <dig>  scans =  <dig>  threshold =  <dig>  r = 2%.

RESULTS
we performed comparative analysis of pyms with several well established software packages, on in-house generated data under different conditions and experiments specifically designed for this purpose. the software packages included in the comparative analysis were amdis  <cit> , xcms  <cit> , and analyzerpro . two different experiments were designed to generate the optimally informative data: a mix of  <dig> metabolites representing a variety of chemical classes , and foetal calf serum spiked with metabolite standards, representing a sample with complex biological matrix . each data set was scrutinized manually by analytical experts, and the signal peaks were manually picked and deconvoluted. the results of manual analyses served as the best approximation of the desired answer against which we benchmarked the automated peak detection. all four software packages  were applied starting from the raw data, and for each software package an effort was made to optimize the processing parameters so to obtain the closest result relative to the manually obtained results .

quantitation in metabolomics can be either relative or absolute: relative quantitation is typically used in non-targeted metabolic profiling, while absolute quantitation is most often used in targeted studies. in relative quantitation the signal intensities are normalized by another signal observed within the same experiment , or with a suitable function of several signals . in absolute quantitation the samples are spiked with reference compounds of known concentration prior to the gc-ms run  <cit> .

the assessment of software quantitative capabilities requires analysis over a range of concentrations in a specifically designed set of experiments. we have chosen to focus on pyms and analyzerpro for the assessment of quantitative capabilities. to assess relative quantitation, experiments with  <dig> compounds metabolite mix were used because of well resolved peaks and low-complexity background matrix. both the linearity and correlation in raw areas, as reported by pyms and analyzerpro, was assessed. the peaks detected by both programs on the segment shown in figure  <dig> were selected , and peaks were quantitated by both analyzerpro and pyms. this particular segment is populated with well-resolved peaks thereby minimizing any contributions from errors that may be introduced by peak deconvolution algorithms. a good linear relationship between the results was obtained by two software packages , with the correlation coefficient of  <dig> .

to assess absolute quantitation, experiments that involved spiking quantitative amounts of reference compounds in foetal calf serum were analyzed. figure  <dig> shows quantitation results for four reference metabolites, namely methionine, trehalose, aspartate, and valine. in these experiments metabolites were spiked in two-fold increasing concentrations, thereby allowing one to assess absolute quantitation. when ordered by decreasing concentrations of the reference compounds, successive experiments are expected to have half the concentration of the previous experiment. a good agreement between results obtained by analyzerpro and pyms was observed. furthermore, the expected fold-increase in spiked reference compounds was closely reproduced .

discussion
it is estimated that about half of published gc-ms metabolic profiling studies is dedicated to methods development  <cit> . a substantial portion of this is relevant to various aspects of data processing, analysis, and information management . a recent surge in academic work focusing on gc/lc-ms data analysis has significantly increased available software tools, providing a variety of choices for raw gc/lc-ms data processing  <cit> . in spite of this, the field of gc-ms data processing remains highly dynamic, and new tools are likely to profoundly influence the field and established processing protocols.

here we report the development of pyms, a library of functions for processing of gc-ms data developed in python. python is an object-oriented, general purpose scripting language widely used in scientific applications, that is gaining attention of the ms data processing community  <cit> . pyms currently provides a complete set of gc-ms processing functions, including reading of standard data formats , noise smoothing, baseline correction, peak detection, peak deconvolution, peak integration, and peak alignment by dynamic programming described previously  <cit> . a novel common ion single quantitation algorithm allows automated, accurate quantitation of gc-ms electron impact  fragmentation spectra when a large number of experiments are analyzed . pyms implements parallel processing based on message passing interface , and is able to harvest multiple cpus for by-row and by-column data processing tasks , allowing processing to scale on multiple cpus in distributed computing environments.

here we report a comparative evaluation of pyms peak detection and quantitation, together with three well established software packages ). for this purpose a specific set of experiments was designed, and we used experimental data acquired in-house. for each software package the parameters were optimized by comparing the results to manual peak detection performed by an experienced analyst familiar with the samples and experimental design. in peak detection and deconvolution pyms and analyzerpro achieved overall the most consistent results with manual analyses. we note that in a recently reported comparative study of gc-tof-ms data, analyzerpro outperformed amdis and a commercial software package chromatof   <cit> .

the observed performance of amdis and xcms can be consolidated with the reported literature. xcms was primarily developed for the processing of lc-ms data, and is highly tuned to the information content of lc-ms data  <cit> . xcms looks for signal peaks on individual m/z traces by finding signal maxima within  <dig>  m/z slices, matched filtration, and signal-to-noise ratio cutoff  <cit> . consistently, in our studies xcms accurately detected signals in single gc-ms ion traces, but without an attempt to assemble individual ion signals into fragmentation mass spectra characteristic of gc-ms with ei ionization. this is the main reason for the large number of signals detected by xcms . we note that this may have implications for several recent studies that used xcms for gc-ms data processing  <cit> .

in contrast to xcms, amdis was specifically developed for the processing of gc-ms data  <cit> . the tendency of amdis to overestimate the number of signals was reported previously  <cit> . in a comparative study of gc-tof-ms data, amdis reported up to 70–80% artefactual components  <cit> . we note that recently developed complementary software packages assist in data correction and filtering required when processing data with amdis  <cit> . these complementary software packages are relatively new, and therefore the native capabilities of amdis as used in our study account for the vast majority of amdis applications.

pyms specifically aims to decouple processing methods from visualization, and to expose processing methods through the command line interface. therefore the main strength of pyms is non-interactive gc-ms data processing, where commands are packaged into scripts and executed in the batch mode. pyms can also be used in interactive data processing and exploratory data analysis, and provides limited graphical capabilities . a number of ms software packages with advanced graphical interfaces exist, providing a high complementarity. often, the aim of intuitive use dictates a high level of integration between the processing methods and gui components  <cit> . while gui-based software remains highly important in ms data processing, command line tools provide advantages in certain scenarios. for example, a previously developed processing pipeline is much easier to apply in a repetitive fashion with suitable command line tools. furthermore, a decoupling of processing methods from gui allows implementation of additional algorithms without the need to address  interaction of processing methods with gui components. this in turn facilitates rapid prototyping and implementation of new processing algorithms.

pyms is essentially a library of processing functions implemented in python , and in this regards is similar to xcms, a library of processing functions implemented in r . while r is an integrated, interactive environment for statistical analysis, python is a general-purpose programming language. the latter is an obvious advantage when general programming problems are involved, as is the case in many aspects of ms data processing and analysis . however, in later stages of most processing/analysis workflows statistical analysis becomes important. because pyms operates fully within the python environment, statistical capabilities of r can be integrated with the pyms capabilities through a suitable python interface .

two aspects not addressed in the current work are integration with lims  and metabolite identification. while the problem of data management is recognized as important in the field of metabolomics, a standard or widely accepted lims is currently lacking  <cit> . one of the most promising systems is sesame, originally developed for structural genomics, whose component lamp provides lims for metabolomic data  <cit> . possible future extensions of pyms include linking with a standard lims to achieve integrated data processing and management  <cit> . metabolite identification is widely recognized as one of the key challenges in metabolomics  <cit> . a number of standard databases for small molecule identification exists  <cit> , and in recent years ms databases focused on metabolites are emerging  <cit> . we are currently working on pyms modules for gc-ms spectral matching and metabolite identification, as the priority for future development.

CONCLUSIONS
pyms is modular software for processing of chromatography-mass spectrometry data developed in python, an object oriented language widely used in scientific computing. pyms is a library of functions written in python, thus seamlessly integrating ms data processing with the capabilities of a general purpose programming language. pyms currently implements a complete pipeline for the processing of gc-ms data, including reading of standard data formats , noise smoothing, baseline correction, peak detection, peak deconvolution, peak integration, and peak alignment by dynamic programming. pyms is implemented as a nested hierarchy of python sub-packages, allowing any functionality to be selectively invoked, disregarding any other functionality, i.e., required functions are loaded and then executed within the python programming environment as needed. pyms aims to decouple processing methods from interactive processing and visualization, to allow effective scripting and processing in batch mode.

availability and requirements
pyms is released as open source , and is provided with an extensive user guide, tutorials, and the library of ready-to-run scripts including the sample data . a web-based documentation system accessible over the internet provides descriptions of pyms apis. the data used in this study, together with suitable metadata, has been deposited into the embl-ebi metabolights database .

project name: pyms

project home page:http://code.google.com/p/pyms/

operating system: platform independent

programming language: python

other requirements: numpy, netcdf, pycdf, pycluster, matplotlib, tcl, tk

license: gnu gpl2

any restrictions to use by non-academics: no

competing interests
the authors declare that they have no competing interests.

authors’ contributions
soc, ai, qw, lh, mo, te, and val were involved in code development, implementation, and testing. dds, dlt, ab, ur, and mjm contributed to the design of experiments. dds prepared the samples, performed gc-ms experiments, and analyzed the data. soc and dds performed comparative analyses of different software packages. lh and ba developed mpi parallel capabilities. val drafted the manuscript, with contribution from soc, dds, ab, and mjm. all authors read and approved the final manuscript.

supplementary material
additional file 1
 table of signals shown in figure  <dig>  the table lists signals shown in figure  <dig>  the tables lists signals present in the data as delineated by manual analysis and shown in figure  <dig>  for each signal  the retention time and five top m/z ions are given;  it was marked whether it was found by each of the programs .

click here for file

 additional file 2
 table of signals shown in figure  <dig>  the table lists signals shown in figure  <dig>  the tables lists signals present in the data as delineated by manual analysis and shown in figure  <dig>  for each signal  the retention time and five top m/z ions are given;  it was marked whether it was found by each of the programs .

click here for file

 additional file 3
 table of signals shown in figure  <dig>  the tables lists signals present in the data as delineated by manual analysis and shown in figure  <dig>  for each signal  the retention time and five top m/z ions are given;  it was marked whether it was found by each of the programs .

click here for file

 additional file 4
 table of signals shown in figure  <dig>  the table lists signals shown in figure  <dig>  the tables lists signals present in the data as delineated by manual analysis and shown in figure  <dig>  for each signal  the retention time and five top m/z ions are given;  it wasmarked whether it was found by each of the programs .

click here for file

 acknowledgements
the authors are grateful to the victorian node of metabolomics australia which is funded through bioplatforms australia pty ltd, a national collaborative research infrastructure strategy,  <dig>  evolving biomolecular platforms and informatics investment and co-investment from the victorian state government and the university of melbourne ur thanks the australian centre for plant functional genomics which is funded by grants from the australian research council  and the grains research and development corporation, the south australian government, and the university of adelaide, the university of queensland, and the university of melbourne. ab acknowledges the support of the arc centre of excellence in plant cell walls. mjm is a national health and medical research council  principal research fellow. mjm and val acknowledge funding from the nhmrc project grant  <dig> and the arc discovery grant dp <dig> 
