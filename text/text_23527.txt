BACKGROUND
to adequately perceive and respond to the environment, our brain has to integrate information relayed by the different senses. for the integration of meaningful information, content-based associations are important to determine which inputs belong together  <cit> , in addition to more basic binding cues like temporal and spatial coherence  <cit> . content-based associations refer to inputs of different sensory modalities that closely correspond in content  <cit> , in other words, are semantically matching or congruent  <cit> .

functional magnetic resonance imaging  studies consistently propose the  superior temporal sulcus  and gyrus  as the key structure for integrating meaningful audiovisual information in humans . a still open question, however, is how content-based multisensory associations are encoded in sts/stg, as studies that compared brain activation to semantically matching  versus nonmatching  inputs report inconsistent results. although some fmri studies report congruency effects in sts/stg  <cit> , other studies do not  <cit> , or to a much weaker extent than in "unisensory" auditory regions  <cit> . some studies report effects in the opposite direction, i.e., stronger activation for incongruent than congruent multisensory information  <cit> . these discrepancies may in some cases be explained by different task demands. as we showed recently, the task to explicitly match audiovisual information may overrule perceptual congruency effects observed in passive viewing/listening conditions  <cit> . also, the studies that report stronger activation for incongruent stimulus pairs presented the stimuli sequentially rather than simultaneously, indicating potential repetition suppression effects for congruent pairs .

importantly, the inconsistent findings on congruency effects may, at least partially, also be due to limitations inherent to the method of fmri. since the blood oxygenation level dependent  signal reflects an averaged response over all  neurons in a voxel and its amplitude is subject to hemodynamic saturation effects  <cit> , fmri may lack the spatial precision and dynamic range to reflect differential neural responses to congruent and incongruent audiovisual information. convergence and interaction of visual and auditory input on single neurons in monkey sts has been demonstrated by electrophysiological recordings  <cit> , and, more recently, these interactions have been shown to depend on the congruency between both inputs  <cit> . moreover, recent high-resolution fmri evidence suggests that the human sts is composed of a patchy distribution of unisensory and multisensory neuronal subpopulations, at a resolution below the typical fmri voxel size . the neuronal basis of this spatial layout has recently been provided by dahl and colleagues  <cit> . these findings predict that at standard fmri-resolution, some voxels in sts consist of a mixture of unisensory and multisensory subpopulations, others only of unisensory subpopulations. since only the multisensory subpopulations within sts would be sensitive to audiovisual relatedness, potential congruency effects on the neuronal level have a high chance to be averaged out at the voxel level at standard resolution. furthermore, even if the differential multisensory response is strong enough when averaged over all neuronal responses in a voxel, the bold response might saturate, i.e., lack enough dynamic range to reflect the different neuronal responses to congruent and incongruent information in its amplitude. as unisensory neurons also drive the bold response in a mixed voxel without being sensitive to the cross-modal relation, the putative selective response of multisensory neurons might disappear in the ceiling level of the fmri response.

here, we explored an alternative approach to study human multisensory integration of meaningful information by employing a variation of the fmr-adaptation  paradigm. fmr-a refers to a reduced fmri signal to stimulus repetitions, and is based on the phenomenon of reduced neural activity to repetitions   <cit> . it hypothesizes that by targeting specific neuronal subpopulations within voxels, their functional properties can be measured at subvoxel resolution since it circumvents spatial averaging. adaptation effects have robustly been demonstrated by single unit recordings, eeg and fmri in many cortical regions  <cit> . the typical fmr-a procedure is to compare adaptation conditions in which repetitions of identical stimuli or stimuli with one property varied are presented, to a no-adaptation condition, in which different stimuli are presented sequentially . in voxels containing neurons that are responsive to the repeated stimulus, repetition of identical stimuli leads to a reduced fmri signal relative to the unadapted response. critically for studying the functional properties of the adapted neuronal subpopulation, repeated stimuli with one property varied are presented, and the effect on adaptation strength is assessed. if adaptation remains , the adapted neurons are assumed to be insensitive to the manipulated property. in contrast, an increased  fmri signal indicates sensitivity to the varied property as neurons no longer stay adapted and other neurons will be activated. some studies applied a similar approach to study cross-modal processes, for instance the neural coding of audiovisual speech  <cit>  and visual-tactile object processing  <cit> . also, the studies of noppeney et al.  <cit>  and hocking et al.  <cit>  presented the cross-modal stimulus pairs sequentially; therefore, the weaker response to congruent pairs they report may be due to repetition suppression.

in the present study, we aimed to address the still open question of how multisensory content relatedness is encoded in the human superior temporal cortex  using an fmr-a design. as multisensory fmr-a designs using sequential presentation of different modalities as varied property are not straightforward , we used fmr-a in a slightly different way. we presented epochs of repeated identical audiovisual  stimuli  and varied the associative relation  between the auditory and visual inputs, but across blocks rather than within . there were two adaptation conditions: adaptation-congruent  epochs in which we presented corresponding letter-sound pairs, and adaptation-incongruent  epochs in which unrelated pairs were presented . as the no-adaptation condition, we presented epochs of different av-pairs.

we predicted that if multisensory neurons in sts/stg encode audiovisual content relatedness, adaptation in voxels containing multisensory neuronal subpopulations will be affected by the manipulated av-relation, i.e., adapt stronger to repeated congruent than to repeated incongruent pairs. furthermore, unisensory subpopulations are assumed to respond only to their preferred modality and therefore predicted to be insensitive to the av-relation, and thus would adapt equally strong to repetitions of congruent and incongruent av-pairs. this design therefore has the potential to distinguish between: 1) voxels consisting only  of unisensory subpopulations, which will not show different adaptation ; and 2) voxels in which at least a strong subpopulation of multisensory neurons is present, which is sensitive to the associative relation between the auditory and visual stimuli, and will therefore show differential adaptation . moreover, in comparison with conventional stimulus presentation, the present adaptation design is predicted to be more sensitive to reveal congruency effects because they will not occur within the ceiling range of the bold response.

methods
subjects
sixteen healthy volunteers  participated in the present study. all subjects were recruited from an academic environment and had no history of reading/language problems or neurological/psychiatric disorders. all were right-handed dutch native speakers, had normal or corrected-to-normal vision and normal hearing capacity. subjects gave informed written consent and all procedures were approved by the local ethics committee .

stimuli
stimuli were pairs of letters  and speech sounds  that were presented simultaneously . these stimuli showed multisensory integration effects in superior temporal cortex in our previous fmri studies  <cit>  and have the advantage that they can easily be presented in associated  and non-associated  combinations. speech sounds were presented phonetically  and were digitally recorded  from a female native dutch speaker. recordings were band-pass filtered  and resampled at  <dig>  khz. average duration of the speech sounds was  <dig>  ms, average sound intensity level was approximately  <dig> db spl. white lower case letters  were presented for  <dig> ms on a black background. for the subject's task , target stimuli were prepared consisting of a pure tone of  <dig> hz  and a white star symbol of equal size as the letters  and were also presented for  <dig> ms. visual stimuli were projected onto a frosted screen positioned at the rear end of the scanner bore, and viewed by the participants through a mirror mounted onto the head coil. auditory stimuli were presented with an mr-compatible intercom commander xg audio system . stimuli were presented and synchronized with the scanner pulses using the software package "presentation" . participants' responses were registered by a handheld fiber-optic response system .

adaptation procedure
stimuli were presented in epochs of three main conditions: no-adaptation , adaptation-congruent  and adaptation-incongruent . each condition was repeated  <dig> times per run, two runs were acquired per subject. subjects performed a target detection task  to obtain equal attention levels during no-adaptation and adaptation epochs. in nine additional stimulation epochs ,  <dig> of each main condition, one stimulus was randomly replaced by an auditory or visual target. occurrence of targets was unpredictable for the subjects; their task was to press the button whenever they would hear a beep or see a star, so they had to attend all epochs. the epochs containing a target stimulus were included in the model but not further analyzed in the main statistical comparisons .

in total, this resulted in  <dig> stimulation-epochs per run , interspersed with rest/baseline periods in which only a white fixation cross was presented. in each stimulation epoch ,  <dig> av stimuli were presented sequentially at a rate of  <dig>  hz. the interval between the onset of  <dig> subsequent stimulation epochs was  <dig> or  <dig>  s ). the rest periods between the stimulus epochs were  <dig>  or  <dig>  s, the first and last rest periods  <dig>  s.

during no-ad epochs,  <dig> different congruent av stimuli were presented, randomly sampled from all consonant and vowel exemplars. during adaptation epochs,  <dig> identical av stimuli were presented, pseudo-randomly sampled from the vowels, in congruent  or incongruent  combinations . because stimuli for ad-c and ad-i were sampled from a limited set , we selected three different vowels per run , and used the other three in the second run , to avoid unnecessary repetitions. the subset of vowels in each run was varied across subjects, as well as the av-combinations presented in ad-i. importantly, in each run, each letter and each speech sound was equally often presented in a congruent  as in an incongruent av-pair . for example, in a-e-o runs, we presented  <dig> a/a-epochs,  <dig> o/o,  <dig> e/e,  <dig> a/o,  <dig> o/e, and  <dig> e/a-epochs. this counterbalances potentially different unisensory response/adaptation strengths for the different stimulus exemplars across ad-c and ad-i. see figure  <dig> for a schematic of the stimulus presentation.

fmri scanning and analysis
imaging was performed on a  <dig> tesla head scanner  located at the maastricht brain imaging centre  in maastricht, the netherlands. a bold-sensitive epi sequence was used for the functional scans .  <dig> volumes were acquired per run. to optimize spatial and temporal resolution, we scanned a slab of  <dig>  cm positioned to cover the temporal and occipital lobes including the entire sts . in figure  <dig>  the coverage of functional volumes in a representative subject is shown. an intra-session high-resolution structural scan  was collected for each subject using a t1-weighted 3d adni mprage sequence .

brainvoyager qx  was used for data analysis. standard preprocessing was performed on the functional data: slice scan time correction, linear trend removal, temporal high pass filtering , 3d motion correction , and mean intensity adjustment . this latter step scales the global intensity of the repeatedly measured volumes to the average of the first volume; however, we only used the resulting time-courses of  volume intensity for data modelling  to avoid wrongly correcting activation effects. functional slices were co-registered to the anatomical volume using position parameters from the scanner and intensity-driven fine-tuning, and transformed into talairach space. for data presentation, an averaged anatomical volume was created from the  <dig> individual anatomical volumes. all individual anatomical data-sets were segmented at the gray/white matter boundary using a semi-automatic procedure based on edge-preserving filtering and intensity histogram analysis, and the cortical surfaces were reconstructed. to improve the spatial correspondence between subjects' brains beyond talairach space, the reconstructed cortices were aligned based on individual curvature information reflecting the gyral/sulcal folding pattern, using a "moving target" group averaging approach . cortical functional time-series  were subsequently aligned across subjects using the resulting correspondence information. a shape-averaged  folded cortical mesh was created for both hemispheres for projection of the cortex-based aligned statistical maps.

functional time-series were analyzed using a random-effects multi-subjects general linear model . in the first level analysis, all experimental conditions in all subjects were modelled as separate predictors; in addition, the mia time-course was added after z-normalization as a confound predictor to the design matrix of each run. the resulting glm, thus, contained five predictors per subject: no-ad, ad-c, ad-i, tar and mia. predictor time-courses were adjusted for the hemodynamic response delay by convolution with a double-gamma hemodynamic response function. to explore adaptation effects, we calculated two second-level random-effects contrasts:

1) general adaptation 

2) specific adaptation 

the second contrast was critical to assess sensitivity to the av-relation. since our aim was to find voxels showing a different adaptation effect for ad-i and ad-c, and not a different response per se, we used the first contrast  as a search constraint for the specific adaptation contrast: either by using a functional mask created from the general adaptation contrast , or as a conjunction of the first and second contrast . volume data were modestly spatially smoothed using a gaussian filter of  <dig> mm fwhm. statistical maps shown in the volume domain were corrected for multiple comparisons using cluster-size thresholding  <cit> . maps thresholded at an initial voxel-level p-value were submitted to a whole-data correction criterion based on the estimate of the map's spatial smoothness and on an iterative procedure  for estimating cluster-level false-positive rates. after  <dig>  iterations, the minimum cluster-size corresponding to a corrected false positive probability of  <dig>  or less is applied to the statistical maps. statistical maps on the surface are shown at the same t-values. in addition to statistical maps, averaged bold response time-courses for no-ad, ad-c and ad-i were extracted from regions-of-interest  showing general or specific adaptation effects. to further quantify adaptation strength, adaptation ratios  <cit>  were calculated for the different adaptation conditions: estimated % signal change adaptation/no-adaptation. a ratio of one indicates no adaptation, whereas ratios between zero and one indicate different adaptation strengths and thus different levels of sensitivity to the varied property.

RESULTS
all subjects detected all auditory and visual target stimuli, which ensures a similar attention level during the adaptation and no-adaptation epochs. figure  <dig> shows the statistical random-effects group maps of the two contrasts of interest: no-adaptation vs. adaptation in yellow , and adaptation-incongruent vs. adaptation-congruent in red . in the left panel, volume maps are shown on transversal and sagittal slices of the averaged anatomical image. both contrasts were cluster-level corrected at p <  <dig>  . in the right panel, cortex-based aligned group maps are shown at the same t-values on the inflated averaged cortical meshes of both hemispheres, to provide a better overview of both maps.

a general adaptation effect was found bilaterally on the transverse temporal plane, middle  and superior temporal gyrus and sulcus , and the lateral and inferior occipito-temporal cortex . within this network, several smaller sts/stg clusters adapted stronger to ad-c than to ad-i, as reflected by a weaker fmri response for ad-c vs. ad-i . this indicates sensitivity to the manipulated audiovisual relation in those sts/stg clusters. no clusters showed this specific adaptation effect in the reverse direction. table  <dig> summarizes the cluster volumes and talairach coordinates of regions identified by the general and specific adaptation contrasts .

for more precise macro-anatomical localization, figure  <dig> shows the same cortex-based aligned group maps on the folded, shape-averaged cortical surface. this reveals that clusters adapting stronger to ad-c were located on the upper bank of the sts and the lower bank of the stg. the line graphs in figure  <dig> show the averaged bold response time-courses within rois extracted from both maps. the bold response to both adaptation conditions  was equally reduced compared to the no-adaptation responses  in the regions selected from the general adaptation map . the time-courses from the significant regions of the specific adaptation contrast showed more suppression  to ad-c  than to ad-i , especially in the early phase of the response . this immediate decrease for repeated stimuli is a typical finding for bold adaptation  <cit>  and resembles simulated bold responses based on neuronal adaptation  <cit> . in addition, the bar graphs show the adaptation ratio in the same rois, calculated by dividing the estimated signal level during ad-c and ad-i by that during no-ad. the adaptation ratios in the clusters showing specific adaptation , also reveal stronger adaptation for congruent than for incongruent repeated letter-sound pairs, or in other words, partial recovery from adaptation during the incongruent pairs.

discussion
in the present study, we addressed the still open question of how content relatedness is encoded in the human superior temporal cortex . we used a variation of the fmr-adaptation design and relatively high-resolution voxels  to decrease susceptibility to potential bold spatial averaging and saturation confounds. we measured bold adaptation to repeated audiovisual  stimuli  and manipulated the associative relation between the visual  and auditory  inputs . our key finding was that within a larger occipital-temporal network that adapted independently of the av-relation , several smaller clusters distributed over sts/stg adapted stronger to repetitions of congruent than of incongruent av-stimuli . since unisensory neurons are assumed to respond only to their preferred modality and therefore to be insensitive to the relation between the v and a inputs, this finding suggests that in these clusters, multisensory neurons are present that encode content relatedness by selectively responding to congruent av-stimuli.

general adaptation to letter-sound pairs
voxels in which the fmri response to either adaptation condition was significantly weaker than the unadapted response to letter-sound pairs were found on the transverse temporal plane, middle and superior temporal gyrus and sulcus , and the lateral/inferior occipital-temporal cortex . time-courses and adaptation ratios in figure  <dig>  demonstrate that the bold response to both adaptation conditions was equally suppressed in this network. this indicates that neurons in these voxels respond and adapt to letters, speech sounds, or both. the revealed regions are consistent with other reports of letter and speech sound processing .

specific adaptation to the associative relation of letter-sound pairs
within the network showing general adaptation, several clusters in sts/stg adapted stronger to repetitions of congruent than to repetitions of incongruent av-pairs. interestingly, no voxels showed the effect in the opposite direction. assuming that stimuli initially eliciting the strongest response in a neuron also induce the largest response reduction by repetition  <cit> , our findings support the prediction that subpopulations of multisensory neurons in distributed clusters in sts/stg encode audiovisual content-based relatedness by responding selectively to congruent stimulus pairs. this is in line with single-cell findings of congruency-selective audiovisual neurons in monkey sts  <cit> .

important for our interpretation is that we counterbalanced the unisensory inputs across both adaptation conditions: each letter and each speech sound exemplar was presented equally often in congruent and incongruent av-pairs . this equalizes the averaged purely unisensory responses across both adaptation conditions, so the demonstrated differential adaptation strengths can be attributed to sensitivity to the varied av-relation . therefore, we propose that the observed adaptation differences indicate selectivity to congruent av-stimuli on the level of multisensory neurons.

as adaptation is thought to reflect selectivity at the input rather than at the output level of neurons  <cit> , several speculations towards a neuronal mechanisms for congruency-selectivity can be made: either more synaptic inputs converge on multisensory sts/stg neurons for congruent av-inputs compared to incongruent inputs, or in different excitatory/inhibitory convergence patterns  <cit> , or only congruent inputs converge. in any of these mechanisms, these multisensory neurons will adapt stronger  to congruent av-stimuli.

the neural mechanism for letter-speech sound integration
interestingly, the present results reveal a response pattern that is different from our previous studies on letter-sound integration using the same stimuli but non-repeated presentation. in these studies, congruency effects were most pronounced in early stages of the auditory cortex, and less consistently observed in sts/stg  <cit> . the sts/stg did show a heteromodal response pattern and enhanced responses to av stimuli compared to both a and v responses. we therefore interpreted the sts/stg as integrator, and the congruency effect in auditory cortex as feedback modulation, which was supported by effective connectivity analyses  <cit> . however, it remained unresolved why the sts/stg in that case did not show sensitivity to the congruency of the letter-sound pairs, as it is assumed to provide differential feedback. the present results complement these previous findings by showing that distributed clusters in sts/stg clearly are sensitive to content congruency, expressed by differential adaptation strengths rather than bold amplitude per se. the latter might not be sensitive enough to reflect these differences due to saturation effects, as outlined in the introduction. but why was adaptation in early auditory regions not sensitive to congruency in the present study? the strong congruency effect in auditory cortex observed during non-repeated stimulation may be the result of amplification of neural activity  by the feedback from sts  <cit> , which is likely to be cancelled out when sts activity is suppressed by stimulus repetitions.

organization of human multisensory superior temporal cortex
the present results suggest that several clusters within the human sts/stg contain multisensory neuronal subpopulations that are sensitive to the associative relation between audiovisual inputs. using cortex-based alignment of anatomical and functional data, we were able to localize these clusters precisely and reliably on the upper bank of the sts and lower bank of the stg ;  <dig>   <dig>   <dig> mm <dig> ), which is consistent with the location of multisensory neurons in the superior temporal polysensory area  in monkeys . since the fmri signal in the incongruent adaptation condition recovered only partially, these clusters are likely to be composed of a mixture of uni- and multisensory neuronal subpopulations, rather than only of multisensory neurons. our results therefore corroborate the reported patchy distribution of unisensory and multisensory neuronal subpopulations in human sts  <cit>  which was recently supported by electrophysiology in macaques  <cit> , and the neuronal organization within transitional multisensory zones in rats  <cit> . moreover, even though the patchy organization of uni- and multisensory neurons may differ between individuals  <cit> , there seems to be enough overlap of voxels containing multisensory clusters to be robustly revealed on the group-level using macro-anatomical intersubject alignment methods.

fmr-a as a new approach to study human multisensory integration?
the present study shows the feasibility of fmr-adaptation to provide insights in human multisensory integration by circumventing some of the limitations imposed by the coarse spatial resolution and limited dynamic range of the fmri signal. this is much needed since other approaches to deal with results from large neuronal samples, such as the super-additivity metric, are not satisfactory  <cit> . using the current design, other stimulus types and other manipulations of the multisensory relation  can be investigated in future studies. other fmr-a designs can be employed as well, for example, it would be very interesting to present visual and auditory stimuli in alternation instead of simultaneous, which has been used to investigate feature integration within modalities  <cit>  and is the more typical fmr-a design . in such a design, cross-adaptation between modalities might reveal multisensory convergence on the neuronal level in more detail. however, there are several potential pitfalls for such designs , which all result from the putatively mixed unisensory-multisensory organization of "multisensory" brain regions like sts/stg  <cit> . one complication is the observation that neurons adapt despite intervening stimuli  <cit> , so stimulus repetitions in alternating modalities will also adapt unisensory neurons, although probably to a weaker extent. another problem is that a cross-modal repetition  may suppress activity of multisensory neurons, but will also activate new pools of unisensory neurons  in the same voxel, which may counteract the cross-modal suppression.

it should also be kept in mind that the exact neuronal mechanism underlying bold adaptation is still uncertain  <cit> . for example, a factor that complicates the interpretation of bold adaptation results is that it may reflect only the outcome of more complex changes within networks, such as inherited adaptation from distant regions disturbing the normally balanced input  <cit> . our data show the specific adaptation effect exclusively in sts/stg clusters; therefore it seems unlikely that this pattern is inherited from upstream sensory regions.

CONCLUSIONS
we demonstrated that bold adaptation in distributed superior temporal clusters is sensitive to the associative relation between visual and auditory inputs, which indicates the presence of multisensory neuronal subpopulations in human sts/stg that encode content congruency. these findings extend our previously revealed mechanism for the integration of letters and speech sounds and demonstrate that fmr-a is sensitive to multisensory congruency effects that may not be revealed in bold amplitude per se.

authors' contributions
nmva conceived of the study, developed the design, conducted the measurements, performed the statistical analysis and drafted the manuscript. vcb contributed to developing the design, participated in conducting the measurements and helped to draft the manuscript. lb contributed to conception of the study, participated in coordination and helped to draft the manuscript. rg contributed to conception and design, advising on statistical analysis and contributing the appropriate analysis tools. all authors read and approved the final manuscript.

