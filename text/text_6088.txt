BACKGROUND
in our previous study, we developed a bayesian neural network type of model - bayespi - to study protein-dna interactions, using chip-based high-throughput data  <cit> . in bayespi, the model error function  is interpreted as defining a likelihood function, and the model regularizer  corresponds to a prior probability distribution over the weights, and such a framework is considered as a bayesian hierarchical model. in addition to the common model parameters, bayespi includes unknown hyperparameters  that need to be learned from the data. there are three possible implementations to control the model hyperparameters when using bayesian neural networks to infer the model parameters: 1) using markov chain monte carlo methods to simulate the probability distribution - mcmc  <cit> ; 2) integrating out the model hyperparameters analytically before the application of gaussian approximation of posterior distribution, and subsequently maximizing the true posterior over the model parameters - maximum a posterior probability   <cit> ; and 3) integrating out the model parameters first, and then maximizing the resulting evidence over the hyperparameters - the evidence approximation  <cit> . descriptions of the first two implementations can be found in the earlier papers  <cit> , and in this study, we will focus only on the last approach  implemented in bayespi.

three motivations inspired us to pursue an investigation on the effect of prior assumptions over the weights  in bayesian neural networks to study protein-dna interactions from chip-based high-throughput data: 1) with regard to others' concern, before bayespi paper was published, we received some criticisms about the treatment of hyperparameters in bayesian neural networks. for example, do alternative definitions of hyperparameters according to the model parameters  strongly influence the model inference? 2) with regard to our own interest, how significant will a different assignment of prior distribution  to weights affect the outcome of bayesian neural networks ? 3) with respect to a general survey of the application of bayesian inferences in chip-based experiments, we searched pubmed using the keywords "bayesian, chip" or "bayesian, chip-chip," and then downloaded the search results that had been recorded before may  <dig>   <dig>  from this search, we obtained  <dig> papers that contained the above-mentioned keywords. subsequently, we carried out a literature study of these  <dig> papers. to our surprise, only  <dig> of the  <dig> papers had applied bayesian methods on issues related to motif discovery  by using chip-based high-throughput data, and the remaining  <dig> papers had applied bayesian methods in data integration, clustering and network reconstructions, etc. a detailed examination of the  <dig> papers relevant to protein-dna interaction study reveal that bayespi applied used evidence approximation to solve the posterior distribution in bayesian inference, while the remaining  <dig> papers utilized the sampling methods  to simulate the posterior distribution of the bayesian models . though the present implementation  in bayespi for handling hyperparameters has been rarely applied earlier, there are clear advantages of using it to solve the data mining problems  <cit> . thus, by being motivated by the last finding along with the earlier two inspirations, we decided to carry out a follow-up study on the effect of prior assumption over the weights in bayespi. our study may pave the way for the future development of evidence approximation in bayesian inferences as well as for the further application of the bayesian methods in bioinformatics research.

RESULTS
performance comparisons from simulated chip-chip datasets
to evaluate the performance of bayespi under  different prior assumptions over the weights, we first tried each of them on the same set of simulated chip-chip experiments , where the synthetic dna sequences and chip-chip log ratios were generated using matlab bay net toolbox and matlab build-in random number generator, respectively  <cit> . the accuracy of the predictions was accessed from motif similarity scores by comparing the predicted motif energy matrix with the corresponding sgd consensus sequences  <cit> . in figure  <dig>  we have illustrated the outcomes of the above-mentioned simulations in  <dig> different prior assumptions, where both the cpu hours required for the calculation and distribution of the motif similarity scores among all the tests are shown. the results are very interesting because no significant changes of the prediction quality could be observed across the tests after changing either the prior probability assumption or the number of subclasses for α hyperparameters, except for the tests with gaussian approximation . however, the cpu hours used for various tests differed significantly. particularly, the selection of prior probability assumption over the weights in bayesian neural networks had a much stronger impact on the cost of cpu hours than that by tuning the number of subclasses of hyperparameters. for examples, by using a laplace assumption over the weights in bayespi, the cpu hours used for the calculations were shortened by almost two to five times when compared with the assumptions of the weights by the other two probability distributions . it is worth noting that the assignment of laplace prior probability to weights utilizes the least cpu hours for the calculation, but provides the best prediction accuracy. thus, we can expect laplace approximation over the weights to provide the most efficient computation for bayespi if real chip-chip datasets are used.

performance comparisons from real chip-chip datasets
after testing the effect of prior assumptions over the weights in bayespi using the synthetic chip-chip datasets, we tried it on the real protein-dna interaction datasets from chip-chip experiments. we collected chip-chip datasets for nine yeast tfs in rich medium condition  <cit> , among which four  had the same consensus sequences as the tfs in the synthetic datasets. in the earlier tests, we neither found a significant variation in the prediction accuracy nor observed a strong perturbation of the computational time cost  through tuning the number of subclasses of α hyperparameters: hence, we decided to select only four subclasses for the hyperparameters in the rest of the studies. the results of these tests both with and without the inclusion of nucleosome information are presented in figure  <dig> that shows that there is little difference in the prediction accuracies among the tests regarding the selection of prior probability assumptions and the inclusion of the nucleosome information. a comparison between the motif similarity scores provided by the three prior weight assumptions in bayespi and those obtained by matrixreduce is presented in table  <dig>  the results indicate that all poor predictions are caused by stress-induced transcription factors . though bayespi may provide some reasonable answers to tfs that are nonfunctional under certain growth conditions , its computational speed is much slower than that by the popular program matrixreduce  <cit> . nevertheless, the cpu hours used by bayespi among the three prior weight assumptions differ significantly . furthermore, we found that the cost of the cpu hours for the computation was slightly reduced with regard to the nucleosome information. taken together, it can be concluded that the computational efficiency of the laplace prior assumption over the weights in the bayesian neural networks clearly surpasses that of the other two weight priors, and that the laplace prior may be suitable for the further improvement of bayespi algorithm.

for the nine yeast tfs, the chip-chip datasets were obtained from  <cit> ; the regularization constants α in bayespi were divided into four classes; matrixreduce program was downloaded from the publication  <cit>  and its default parameters were used in the present study. here, the motif similarity scores greater than  <dig>  represents a good match between the prediction and the sgd consensus sequences  <cit> . poor predictions are marked by bold text. na indicates that no results are available owing to the program reason. all the programs were applied on the same datasets and were run under a pc cluster .

performance comparisons from human chip-seq datasets
after the successful application of the earlier tests on chip-chip datasets, we tried the new bayespi program on three human chip-seq datasets  <cit>  by applying three different prior assumptions  over the weights with predefined four groups of regularization constants α. here, the inputs to bayespi were pre-processed raw chip-seq measurements, which are a set of putative protein binding sites , and the corresponding tag densities obtained from sissrs method  <cit> . the results of these tests are shown in figure  <dig>  which demonstrates that the laplace prior requires much less cpu hours when compared with that required by the other two assumptions. for instance, to complete the same calculation, laplace approximation needs only  <dig> percent to  <dig> percent of the cpu hours that is used by either cauchy or gaussian approximation. however, interestingly, the accuracy of the predictions does not differ significantly among various prior assumptions similar to the previous tests that employed the chip-chip datasets: tuning of the prior assumption over the weights does not seem to affect the quality of the predictions, but is rather observed to bring strong impact on the cpu requirement. thus, a careful design of the weight priors in a bayesian model may significantly reduce the computational cost for the calculation.

discussion
nowadays, chromatin immunoprecipitation followed by massively paralleled sequencing  is being used widely in various molecular biological researches such as investigating genome-wide protein-dna interactions  <cit>  and histone modification studies  <cit> . it is possible that the chip-seq experiment may replace chip-chip technology completely  <cit>  in future. that is because the chip-seq experiment produces higher quality and higher resolution data than the chip-chip, which also avoids several pitfalls that accompany with the chip-chip technology: for example, array probe-specific behavior and dye bias  <cit> . in this work, we studied the effect of prior assumptions over the weight in bayespi to predict the protein binding energy matrices from chip-based high-throughput datasets. the results on both synthetic and real experimental datasets were consistent: in general, the prior assumptions over the weights and the classification of regularization constants  into several classes did not strongly affect the final outcome of bayespi  if sufficient training datasets were provided; particularly, a change in the number of classes over the regularization constants had a much weaker impact on the requirement of computational resource than a change in the weight prior in bayespi; nevertheless, the selection of prior approximation over the weights had the most significant influence on the cpu hours that were used for calculation  thus, the present study reveals the importance of defining a right weight prior to a bayesian hierarchical model, which may dramatically speed up the calculation when the program is applied to a large dataset.

in addition to the above-mentioned findings that the computation efficiency of bayespi is highly associated with prior assumptions over the weights, we also provided a detailed illustration of the hyperparameter re-estimation technique by using the evidence approximation method. we presume that the evidence method may become a popular approximate method for computational implementation of bayesian hierarchical model , as well as become an alternative to monte carlo methods that are currently being widely used in bioinformatics research fields  <cit> . particularly, the evidence method can overcome some of the inherent limitations of the sampling approaches, such as nonreproducible results, long burning period, and unknown stopping time.

CONCLUSIONS
the present study has clarified several doubts in the early implementation of bayespi: 1) prediction accuracy of bayespi is robust against dividing the hyperparameters  into multiple distinct groups; 2) there is a minor effect on the quality of predictions by selecting alternative prior assumptions over the weights in bayespi; 3) however, there is a strong impact on the computational requirement for calculation when a proper weight prior is chosen. overall, we have derived the new re-estimation formulas for both laplace prior and cauchy prior over the weights in the bayesian neural networks, and the new implements have been tested successfully in both synthetic and real chip-based high-throughput datasets.

