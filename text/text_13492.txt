BACKGROUND
in biological complexity generation, the as mechanism is a major contributor to the diversity of proteome  <cit> . although it has long been presumed that only 5% of human genes was alternatively spliced, more recent estimates - based on experimental evidence and computational approaches using ests mapped onto mrna sequences - showed a much higher rate of the phenomenon in human genes: the actual percentage of genes that exhibit as events has grown up to 95%  <cit> . the as mechanism is usually categorized into five basic modes: exon skipping of cassette exons, mutually exclusive exons, alternative donor site, alternative acceptor site, and intron retention. exon skipping of cassette exons is the most common mode in mammalian pre-mrnas, and it occurs when an exon is spliced out of the primary transcript or retained. in some cases, multiple cassette exons are mutually exclusive, producing mrna that always includes only one of several exon choices. defects in the as mechanism have been involved in many diseases  <cit> . exon array technology is a new type of microarray offering a more fine-grained chip to support global inference about gene expression at the level of individual isoforms and exons. it allows a more comprehensive analysis of the transcriptome, as well as the study of alternative splicing. one of the first uses of the affymetrix genechip human exon  <dig>  st array  <cit>  was the study of the aberrant splice variants involved in the initiation and/or progression of glial brain tumor  <cit> . numerous studies followed, including amyotrophic lateral sclerosis and multifocal motor neuropathy  <cit> , cystic fibrosis and several human cancers  <cit> .

exon arrays are one of the first available chips to survey both gene expression and as patterns on the whole-genome scale on a single array. one exon array is a chip containing about  <dig>  million probes grouped in  <dig>  million probesets, each one designed to map at most a single exon. probesets are grouped into transcript clusters that are portions of the genome roughly corresponding to genes.

the output of an affymetrix exon array is a binary cel file containing probe level intensities from a single array. affymetrix offers a toolbox essential for cel files analysis, the affymetrix power tools   <cit> , and a set of library files with information useful for the preprocessing of raw data and the annotation of probesets and transcript clusters. using apt, we extract numerical expression intensities for each probeset , a summarization of transcript cluster expression intensity computed from its probesets , a quality assessment of each probeset value  and a statistical value for the as detection . for the analysis of as events in the comparison between normal and pathological tissues, affymetrix suggests as a standard analysis his midas and classical t-test statistics. the evaluation of the as trend is computed by the splicing index, a ratio between normal and pathological exon expression, each of them normalized on the overall gene level expression.

other statistical algorithms, such as mads  <cit>  and firma  <cit> , have also been proposed. these methods focus their analysis on statistical computations, providing the users with command-line applications and requiring prior knowledge of statistical programming languages like r. altanalyze  <cit> , easyexon  <cit>  and exon array analyzer  <cit>  are the most recent tools for exon array analysis. altanalyze, when installed with domaingraph plug-in of cytoscape, is a complex software workflow for the statistical and visual analysis of exon expression data, and it requires a minimum of  <dig> gb of ram and from  <dig> up to  <dig> gb free hard-drive space for species gene databases, affymetrix libraries and annotation files. another stand-alone software is the java-based easyexon, which offers fewer facilities, as it provides expression statistics results with only a few biological annotations such as gene and go annotations for probesets. exon array analyzer is a web tool that allows the user to upload his cel files and shows tabular exon and gene level expression results, together with midas and firma output.

the heaviest drawback of stand-alone software packages for exon array analysis is the huge requirement in ram and hard disk space. they ensure privacy of data but they need an expensive setup and advanced programming skills for a flexible analysis. the available web tools, for their part, are not very complete as they lack in advanced analysis instruments. the most important limit of all the existing tools providing a graphical interface is forcing the user to input also some analysis parameters such as p-value thresholds and as extraction algorithm option during the upload of cel files. it means that the user must choose his analysis parameters even when he does not know how they will influence the results, and even if he wants to change just one parameter, he must restart the entire analysis process.

the aim of beat, the platform we describe in this paper, is to provide the scientific community with a user-friendly platform to analyze exon array datasets with rigorous statistical methods and an easy-to-use graphical user front-end. beat has been developed as a web tool because we think that the internet is the most important means for spreading research results, using only a browser and the internet connection . at the same time we put attention on the security and privacy of data and result transfer. beat simplifies the exon array analysis workflow asking no preliminary parameters and displaying the results by interactive plots and tables. furthermore, it introduces some new instruments to obtain very useful and easily interpretable results for each case study, such as the novel use of meta statistics and the possibility to exploit other clinical information about the patients for a multivariate analysis of exon expression intensities.

implementation
architecture of the platform
a top-level view of beat has the same structure of a classical web application, since the platform was designed according to the typical three tier architecture. this approach allows a modular, scalable, extensible, and easily administrable system architecture, in order to guarantee the interoperability among the components.

 <dig>  data. the first tier consists of a data warehouse. the data warehouse stores all data sources and statistical processed data allowing smart data storing and efficient data retrieving. it consists of more than one relational database, a repository/staging area and data marts. it is described in detail in the "data warehouse" section and in the additional file  <dig> 

 <dig>  service-integration. the second tier consists of an application server  dedicated to the deployment of the web interface and a set of applications. such applications perform both exon and gene level analysis through the apt and the statistics and meta statistics using complex r routines, as described in the "analysis workflow" section.

 <dig>  web front-end. the third tier consists of the web query interface, which is developed for displaying the analysis results and browsing the data contained in the data warehouse, in order to provide interactive plots and a flexible and advanced query system.

from the user perspective, the platform is designed to analyze a user "case study" in a workflow that starts from a set of affymetrix exon array experiment output files  and ends with the visualization of the statistical analyses of gene differential expressions and exon splice variants.

data sources
the data sources used by beat are stored as relational tables in the data-warehouse component and they can be classified in different types:

- user data file: the outputs of affymetrix exon array experiments , which are binary files containing probe-level intensities from a single array; a text file filled by the user through a web wizard containing metadata for each cel file, including medical record information about a patient, such as gender, age of disease onset, tumor type and tissue, etc. these files are interpreted and elaborated by affymetrix apt tools.

- affymetrix annotation files: text files contain both design-time information and netaffx  <cit>  mapping between probesets and public mrna sequences . these annotations include statistical information specific to the probeset composition and sequence annotations at both exon and transcript level extracted from public databases. in the platform we have used the relese <dig> - hg <dig> version.

- public database: different public biological databases stored in the data warehouse come from structured and unstructured sources like external database dump or text/csv files. they are: hugo gene nomenclature committee  database  <cit>  reporting information about official human gene names and aliases; kegg  <cit> , biocyc  <cit>  and biocarta pathways  <cit>  for the association among genes and biological pathways involved; gene ontology  database  <cit> , that provides a controlled vocabulary of terms which describe gene product characteristics and gene product annotation data.

- specialized database: aspicdb  <cit> , a database designed to provide information and reliable annotations of the as pattern of human genes; featdb, a custom database reporting chromosomal location about known  human transcripts extracted from ucsc genome browser  <cit> .

analysis workflow
each probeset is designed to map only one exon or a part of it and it can be used for the exon level analysis. the transcript cluster represents groups of transcripts falling in the same portion of a chromosome. these summarization expression values are used for the exon level analysis, because values of the same probeset coming from different cel files can be compared normalizing them on their transcript cluster expression.

the transcript cluster values are not very accurate metrics for gene level analysis, because they often group together different genes sharing only a few probesets, assigning them the same expression value. for this reason, we have slightly modified rma parameters in order to obtain a more correct gene expression profile, computing the expression of each gene using only the probesets mapped to its known isoforms.

unlike the other existing exon array tools, in our workflow the exon level and the gene level results merge into the use of meta statistics that are introduced to evaluate the results and to explore the data. the following paragraphs describe all these steps in detail.

exon level analysis
in exon level analysis, the normalized probeset expression intensities are used to study changes in exon expression when comparing two or more experimental groups in order to find out the as events correlated to the groups.

the most common studies compare normal to pathological tissues. for this type of analysis in which only one variable is involved, we perform all the standard statistics on each probeset: the splicing index , useful to evaluate the trend of the expression changes; the student's t-test; the midas, the affymetrix algorithm to extract the p-value. we also compute the fold change on probeset intensities not normalized for the overall gene expression level.

for a deeper analysis of the as events, we provide alternative isoforms of the gene under investigation, for both known and predicted alternative transcripts.

in order to perform a quality estimation of each statistical result obtained at exon level, we allow the user to filter data according to the affymetrix dabg p-value estimation.

multivariate as analysis
another interesting study in alternative splicing is multivariate analysis, in which as events are evaluated in relation to more than one clinical variable, such as gender, stage of the pathology or age of disease onset. affymetrix proposes the use of anova  <cit> , which is widely used by biologists and clinicians in several experiments as prognostic significance of tumor states. in exon array experiments the multivariate analysis is often set aside, mainly because of the lack of data on cel files variables other than normal-pathological information and the complexity of repeating the anova test and its p-value correction on thousands of probesets at the same time.

in our platform, we have included a component for multivariate analysis that simplifies the application of anova, providing an easily interpretable output of the multivariate analysis. the methodology is based on a well-known data mining paradigm: the decision tree algorithm  <cit> . in order to manage both numerical and symbolic data, we use a conditional inference decision tree  <cit> , training it on normalized expression intensities. conditional inference trees estimate a regression relationship by binary recursive partitioning in a conditional inference framework. roughly speaking, the algorithm works recursively repeating the following steps: it tests the global null hypothesis of independence among any of the input variables and the response; it stops if this hypothesis cannot be rejected, otherwise it selects the input variable with the strongest association to the response, measured by a p-value corresponding to a test for the partial null hypothesis of a single input variable and the response; it implements a split in the selected input variable. the implementation uses a unified framework for conditional inference, or permutation tests  <cit> .

the output of the algorithm is a tree graph in which each node is a variable that influences the changes in expression intensities. if the variable is binary, the node splits the data according to its two values, while if the variable is numerical, the node indicates a threshold correlated to a significant change in expression intensity. the rules for the generation of nodes and for the pruning of the tree are based on anova.

for example, if expression signal of a probeset reveals a correlation both to male/female comparison and to a threshold of  <dig> as age of disease onset value, the tree highlights in its output the two variables and the threshold, suggesting to the user as events correlated to non pathological characteristics.

gene level analysis
gene expression intensities are summarization values computed from probeset intensities. in order to evaluate the changes in gene expression profile, we compute the fold change ratio to compare normal to pathological issues, validated by means of the t-test p-value.

the gene level value is not a very informative index in the as events discovery, as it characterizes the whole gene differential expression. we introduce the use of meta statistics to overcome this drawback and to obtain a method to compare genes having different characteristics.

meta statistics
meta statistics are descriptive metrics used to provide interpretable information describing the expression profile of all probesets belonging to one gene. for example, if a gene is subjected to an as event, we will see a very low p-value for the probesets involved in the as, and higher values for the unaltered probesets. in terms of meta statistics, this can be represented with a minimum p-value tending to  <dig> and a mean p-value tending to  <dig> 

therefore, the meta statistics are defined as minimum, maximum, mean, and variance values, which are computed on the standard exon level statistics results. the default values of the search for as events are given into the search page of beat. together with gene level results, the meta statistics have been used with a sorting algorithm in order to cluster together genes according to their characteristics.

this method has been borrowed from the application of clustering algorithm as used in many bioinformatics approaches. when we have to process a huge number of data, it is often useful to group the ones with similar characteristics into clusters. similarity is evaluated by means of a distance metric. our idea was to exploit such a distance metric to extract genes with specific characteristics, i.e. choosing the center of the cluster and analyzing the nearest genes. meta statistics have been designed to be used for this type of distance comparison, and the distance metrics used is the euclidean distance with variables scaling, because it allows a very quick distance computation for thousands of multi-dimensional points  <cit> .

meta statistics and the sorting by euclidean distance have been applied in the beat platform both to optimize the search tools provided for result exploration and to analyze the expression profile of genes belonging to the same pathway or mapped to the same gene ontology term.

the data warehouse
the data management in beat is delegated to a data warehouse . a dw is defined as "a subject-oriented, integrated, non-volatile and time-variant collection of data in support of management's decisions"  <cit> . the data in the warehouse are filtered, aggregated and stored in smaller data storages, usually called data marts , properly designed for specialised purposes. a dw is frequently used in business applications but in the last years it is often used also in the biomedical  domain  <cit> . the choice of a dw for beat data management was driven by the following aspects:

- the dw is a consolidated database technique, suitable for storing the large quantity of experimental data produced by exon array experiments. a single case study produces  <dig>  million probeset signals for each chip  and the same number of results for each statistical analysis performed on these signals.

- the dw architecture facilitates integration of locally produced experimental data with public bioinformatics databases used as functional annotation extensions , with the aim of easily producing new knowledge.

- a dw allows multidimensional on line analytical processing  techniques to support data mining, statistical analyses and reporting functionalities that are normally not feasible with typical transactional databases approaches . the olap functionality adapts well to the complex analytical procedures implemented in this tool.

beat dw complies a three-tier architecture. the statistical analysis design implemented in beat has led to the definition of two data marts  that support the analytical processes of the exon and gene level analyses described in the previous section. in addition, a repository was implemented , where the input data sources  are stored, processed, homogenized, and reconciled in order to facilitate the data mart population.

the physical tables belonging to the data marts and the repository have been populated through the use of an extract/transformation/load  tool usually used for this purpose in dw systems.

for the development of the dw we used mysql rel.  <dig> × and infobright  <cit>  ice  <dig>   relational database management systems , while to implement the etl process we used the open source tool pentaho data integration , a component of the pentaho open source business intelligence.

the data marts were designed using the fact constellation schema conceptual model and adopting the standard dimensional fact model graphical annotation  <cit> .

supplementary information about the repository and the data marts can be found in additional file  <dig> 

system deployment process
in beat, the analysis of a user case study corresponds to an execution of a pipeline process to deploy all data transformation and statistical analyses performed by beat components starting from the users' experimental data . the entire process of setup, initialization, deployment and commissioning of a case study is described by the beat deploy system lifecycle business process diagram shown in figure  <dig>  it is structured in a hierarchical way where each block can be blown-up in sub-diagrams. the process diagram is composed by the following macro steps:

 <dig>  data source input process. it is the process delegated to extract all the data sources needed by a case study: cel files, medical record file, affymetrix exon array annotation files and all the public and specialized database listed in the "data sources" paragraph. the files and database extracted are used by the etl process to populate the repository and data marts .

 <dig>  setup file system environment process. this process initializes all the environment variables and creates the directory tree that will contain all input and processed case study files .

 <dig>  setup db environment process. this process creates the new two empty beatdm_exp#_exonlevel and beatdm_exp#_genelevel data marts related to a particular case study identified by the "#" id in the casestudy metadata table .

 <dig>  beat statistical application process. it manages the statistics and meta statistics process analyses for gene and exon level. it is composed by two sub-processes: apt process and r process . the process starting from the input dataflow  produces the statistical analysis files  that will populate the fact tables of the data marts .

 <dig>  beat etl system process. it contains all etl sub-processes that, starting from the input dataflow , populate the tables of the beat repository, beat_exp#_exonlevel and beat_exp#_genelevel data marts .

the processes described in the beat deploy system lifecycle business process diagram have been implemented by means of software components, named "job" and "transformation", using kettle . the whole process of input data extraction, statistical analysis and data warehouse population, is run by a single kettle master job launched by the beat system, after cel files uploading. the master job, where the right sequence of etl components is highlighted, is graphically presented in figure  <dig> 

the web front-end
beat provides an easy-to-use interface for the affymetrix exon array datasets submission, a storage and retrieval system, and interpretable outputs in terms of figures and tabular data, using a web browser and the internet connection.

the platform has been developed using the zkoss framework  <cit> , which is a client-server java-based technology. zkoss shields from the complexities in classical ajax/javascript approaches, focusing the developer on the application logic, and delivering the user interfaces within standard web browsers.

it runs on apache tomcat at the server side as a cross-browser client engine responsible for the rendering of the front-end, which interacts with the application server and handles events, communication and ajax duties. the client interface is also compatible with various mobile browsers.

the user interfaces are defined using a xml markup language, and their functionalities can be extended with embedded java code and/or integrated with many popular frameworks such as spring, jasperrepors, hibernate and so on.

cel files uploading
if the user wants to upload exon array files, he needs to be registered with a valid e-mail address. once logged in, he can start the upload procedure that guides the user in sending cel files to the system. clinical data can be associated to each cel file by filling a form: the user must specify at least if the cel file comes from normal or pathological tissue and, if available, he can add information about gender, age of onset of the pathology, stage of the disease.

once successfully loaded all the data, the user can set the start of the analysis. cel files and clinical data will be preprocessed and analyzed, and the analysis results will be loaded into the data warehouse. once the process is completed, the user will be notified by e-mail.

each user is allowed to see only the results of his own provided cel files, unless these files have been marked for public release during the upload phase.

in order to ensure the compliance with the national laws and decisions from the italian data protection authority, submitters are not allowed to provide any personal information  and they can only associate a numerical id with each cel file, if they need to create a link with their patient's clinical record.

a daily backup of submitted data is performed, in order to prevent data-loss on hardware faults. an important aspect we have implemented in our case study creation process is that the user is not asked to insert any analysis parameters, such as p-value thresholds, or to choose the as extraction algorithm. in fact, the tool performs all the standard analyses on the data and provides all the results, showed using interactive plots and summary tables. all private case studies will be deleted if they have not been accessed for  <dig> months.

once the automated analysis process performed on the case study is completed, the user can explore the results starting from the search page. the result visualization, in fact, is organized in just two steps: in the first step we offer an advanced search tool to provide the user with an intuitive and comprehensive way to search through the data and to choose a list of interesting genes; in the second step, the user can visualize all the results of the analysis performed on a gene, at both exon and gene level.

the search page
beat search page is a comprehensive instrument for exploring the results of the analysis carried out on each case study. as figure  <dig> shows, it offers two main instruments useful in the as events mining: a search form for retrieving genes with selected properties, and a set of sliders for meta statistics values, provided to order data by a selected statistical behavior. the activation of meta statistics sorts the results according to the previously described euclidean distance. the exon level meta statistics, initialized with default values, help to find out interesting as events: the user has just to check all the exon level meta statistics and start the search, to obtain a list of genes with potentially interesting splicing events, sorted by relevance.

for example, if the user wants to investigate the results of a particular gene, he can insert in the annotation form one or more information useful to retrieve it or if he wants to analyze all the gene with differential expression belonging to a particular pathway, he can select the pathway and order the data activating meta statistics by inserting a high fold change value and a low t-test p-value. to search for isolated as splicing events in all genes belonging to chromosome  <dig>  the user can select the chromosome leaving start and stop position blank, and exploit meta statistics to bring out data with a low p-value for t-test and midas and only one or two probesets revealing as events. the search results are visualized in a table with one gene by line satisfying the search criteria, on the bottom of the page. each row of the table is linked to a page containing the detailed results of the analyses carried out on the selected gene.

gene result page
each gene result page is composed by three sections, as shown in figure  <dig>  on the top of the page we have a summary of the information of the gene, such as name, position on chromosome, affymetrix identifications with links to affymetrix website, a list of pathways in which the gene is involved and the gene ontology terms.

in the second section we show the exon level analysis results and statistics about probeset expression intensities. for probeset normalized expression comparison among experimental groups, we have chosen boxplot representations, because they offer an intuitive visualization of the distribution of data with identification of outliers. the probesets that show a statistically significant discrepancy in expression intensity are highlighted in yellow. the second plot shows the trend of the splicing index or fold change, showing positive peaks where the normal data signal is higher than the pathological one, and negative peaks for the converse. as index values are drawn with a traffic light coloring that indicates the p-value support of the data separation.

these plots are interactive and can be managed using the button panel on the left. for example, it allows applying dabg filter on the data used in the plots. we can also choose experimental groups exploiting medical record variables, in order to visualize boxplot separation into user defined classes. to make a two class comparison  we can choose the proper as index in the second plot. the parameters for the classes  are not fixed: they are automatically generated using supplementary information entered during cel file uploading.

in the second section we also report, aligned to their portion of chromosome, the representation of probesets, refseq isoforms and aspic predicted isoforms. these images are useful for an immediate interpretation of as events, highlighted in the previous plots, and their possible influence on different isoforms.

a summary of all the evaluation carried out on each probeset is given in a table. in the last column, we propose statistically significant class separations computed by the conditional inference decision tree, with a button that updates probeset expression plots applying the suggested experimental groups.

in the last section of the gene page we have the results of the gene-level analysis and the values of the meta statistics computed for the gene and for a cluster containing genes belonging to the same pathway or gene ontology.

using a drop-down menu, the user can select a pathway in which the gene is involved. the system shows the other genes belonging to the same pathway, sorted by euclidean distance, so the genes that  behave similarly to the gene under examination are listed in the first rows.

we have the same table also for gene ontology terms. each gene name is a web link that opens its detail page in a new window, to facilitate the comparison with the first gene examined.

RESULTS
beat has been tested on two new datasets of exon array experiments coming from colorectal cancer and renal cell cancer experiments, produced at medical genetics unit of irccs casa sollievo della sofferenza. the colorectal cancer dataset is composed by pairs of normal and tumor colon specimens from  <dig> colorectal cancer  patients undergoing curative resection at the irccs casa sollievo della sofferenza. none of the patients suffered from hereditary crc or had received preoperative chemo-radiotherapy. the renal cell cancer dataset is composed by pairs of normal and tumor renal specimens from  <dig> renal cell carcinoma  patients.

all patients gave their informed consent to take part in this study. the study was approved by the hospital ethics committee.

both the datasets were profiled by the affymetrix human exon  <dig>  st array  and anonymous information about gender, age and cancer grading were collected from the medical records of the patients.

in order to test the performances of the platform, we have also uploaded a third case study containing  <dig> cel files from colorectal cancer samples. this is a public dataset and it has been downloaded from arrayexpress .

the three case studies have been imported in beat and their analysis results are publicly accessible and allow the user to explore all the features of the platform.

using the dropdown menu on the top right of the page, the user can easily switch between all his "public" or "private" case studies to monitor the different behavior of a selected gene.

discussion
since the very first requirement analysis designed with biologists and clinicians, it emerged that the main features of the tool would have been ease of use and rapid access to interpretable statistical analysis results.

we have kept in mind these requirements developing a web application  in which the user could perform each process of his study through few steps. in the case study loading procedure, for example, the user has only to upload his cel file and the available clinical information, while all the other existent exon array tools ask for some analysis parameters immediately after cel file selection. for instance, during the cel file uploading in exon array analyzer , the user must define three sets of initial parameters: at first he has to map each cel to non intersecting groups, then he has to define comparisons between coupled groups, and at least he must choose some threshold for the analysis algorithms. then the analysis flow starts and the initial parameters can be changed only restarting the entire uploading procedure. our analysis flow does not require initial parameters because it is designed to include all the statistical examinations. threshold values can be chosen from the user when visualizing the final interactive plots, in order to see how the results change when varying the thresholds without reiterating all the analysis workflow.

a quick access to all the data is enabled by the data warehouse architecture underlying the tool. it integrates pre-calculation steps exploiting the use of data marts and fact tables. a comprehensive search page is provided to help the user retrieving the most important analysis results. all the other tools working with exon array lack in this feature; eaa, for instance, allows the user to search through the data only by gene symbol and by platform dependent identifiers defined by affymetrix.

finally, the architecture of beat has been conceived to manage scalability of data and analysis tools. data scalability is guaranteed by the architecture of the data warehouse, in which each case study is stored in independent data marts and the system performances are not influenced by the growth in size of the data warehouse.

at the same time, the analysis workflow design allows an easy inclusion of new statistical tools that could became standard in exon array experiments.

CONCLUSIONS
with the progress of massive production of biological data, the bioinformatics community has to deal with a growing need of easy-to-use applications for managing a huge number of data.

beat provides a user-friendly application for a comprehensive study of affymetrix exon array data about human diseases. it offers useful analysis tools requiring no programming knowledge, and it shows the results with easily interpretable and interactive tables and graphics. the analysis workflow provides rigorous statistical methods performed on exon array data, and the results are stored in a data warehouse to ensure the optimization of the data retrieval process. the introduction of meta statistics offers a novel means of exploring results through a set of metrics that summarize gene and exon level expression statistics. as events can be studied by comparing normal to pathological tissues and by performing a multivariate analysis on available medical record information, allowing biologists and clinicians to investigate changes in splicing patterns from a wider point of view.

the architecture chosen for the development of beat allows the improving of the platform with additional features and with a minimum programming effort. some future developments are: integrating new statistical methods for as analysis ; improving gene level analysis, in order to allow comparisons between exon arrays and microarrays results; extending the analyses to other exon array platforms and organisms.

availability and requirements
beat is a web platform and it is freely accessible at http://beat.ba.itb.cnr.it.

the application has been tested with the latest versions of the following internet browsers: firefox  <dig>  chrome  <dig>  internet explorer  <dig>  safari  <dig>  opera  <dig> 

list of abbreviations used
apt: affymetrix power tools; as: alternative splicing; beat: bioinformatics exon array tool; cel: affymetrix exon array output file extension; crc: colorectal cancer; db: data base; dm: data mart; dw: data warehouse; etl: extraction, transformation, loading; r: is a language and environment for statistical computing and graphics; rcc: renal cell carcinoma; rma: robust multi-chip analysis.

competing interests
the authors declare that they have no competing interests.

authors' contributions
conceiving of the study: sl. coordination of the work: ac, sl, fl. software architecture design: ac, fl, gg, mi, cg. statistical analysis integration: ac. data warehouse design and development: fl, gg, gdf, gdc. web front-end design and development: ac, mi, cg, gg. exon array laboratory experiments: mc, op, ap, er. draft contribution: ac, sl, fl, gg, gdf, mi, cg, mc. all authors read and approved the final manuscript.

supplementary material
additional file 1
pdf file containing supplementary documentation about the data warehouse. in particular, we report a more detailed description of the repository and data marts, and four tables with a detailed description of fact tables, hierarchies and dimensional tables.

click here for file

 acknowledgements
this work was supported by grants from progetto strategico regionale ps_ <dig> delibera g.r. n.1171/ <dig> and miur mblab dm <dig>  we would like to thank ernesto picardi for his helpful comments and discussions about exon array statistical analysis, nicola losito for helping us with servers and data base management, raffaella stallone for her contribution in exon array experiment, anna panza for crc sample collection, cristina consiglio and maria silvestri for proofreading the paper.

this article has been published as part of bmc bioinformatics volume  <dig> supplement  <dig>  2012: italian society of bioinformatics : annual meeting  <dig>  the full contents of the supplement are available online at http://www.biomedcentral.com/bmcbioinformatics/supplements/13/s <dig> 
