BACKGROUND
thanks to the advent of the next generation sequencing technologies, we have assisted to an exponential increase in sequence data generation  <cit> . the task to assign a curator-reviewed function to every single sequence is unworkable, calling for efficient/effective methods to assign automatic annotation are necessary as a first analysis step to support working hypotheses and drive experimental validations of biological functions.

computational approaches can be rather imprecise because functional inference is not as straightforward as one would expect, due to the unevenness of the classical paradigm "sequence-structure-function". some authors suggest that for sequences sharing less than 30% of identity, the functional transfer may be highly inaccurate or completely wrong  <cit> : in particular enzyme classification  numbers tend to be conserved only for proteins with sequence identity above 80%. other authors report different figures  <cit>  confirming the difficulty to agree on a unique view due to a certain unpredictability of biological systems.

in the category of sequence-based methods, the simple search for homologous sequences is considered a common practice for function prediction based on annotation transfer, and blast  <cit>  can be considered a gold standard. if its classical pairwise alignment engine fails, the profile based psi-blast  <cit>  is able to identify relationship among distantly related proteins.

another widely accepted approach relies on functional domains assignments. hmmer  <cit> , which is based on hidden markov models , is among the most known tools falling in this category. hmmer is mainly used to query the pfam hmm models  <cit>  and search for functional patterns and domains in the target sequences.

recently, the gene ontology  consortium  <cit>  has revolutionized the way to access knowledge data and has rapidly become a standard de facto. the go is organized in a hierarchical directed acyclic graph that greatly facilitates the mining of biological information by computational algorithms.

with the advent of go and uniprotkb-goa database   <cit>  of functionally annotated proteins, several algorithms have been developed to improve functional inference based on the plain use of blast  <cit> . among these solutions, blast2go  <cit>  can be considered one of the best platforms to assist the user in annotating sequences.

in this paper, we present argot <dig> , a tool designed for high-throughput annotation of large sequence data sets with high efficiency and precision. argot <dig> is born for in-house needs to annotate predicted genes from large-scale sequencing projects; now it has a free and fully functional web interface and its engine has been completely revisited. it has been extensively tested during highly challenging endeavours as grape  <cit>  and apple  <cit>  genome annotations and it has been continuously refined from its early version, argot  <cit> , to reach a high flexibility and confidence in extracting fruitful knowledge from different sources of information. the web server version is computationally efficient, highly scalable, and it is able to address the different needs of basic and advanced users in annotating small sets of proteins up to entire genomes. here we also report the assessment of argot <dig> tested in four different configurations and in comparison with blast2go.

methods
algorithm description
argot <dig> processes the go annotations of the hits retrieved by blast and hmmer searches. a weighting scheme and a clustering approach are applied to select the most accurate go terms for annotating the target proteins.

argot <dig> takes a list of go terms belonging to the go graph g as input and weights them according to the e-value score of the hits. assuming that the set v is ordered, it is possible to establish a one-to-one correspondence between the ith go term gi ∈ v used for the annotation, its weight wi and the e-value scores si and si' given by blast and hmmer. the weights are computed as follows:

  wi=-logforblast 

  wi=-log⋅f1pngiforhmmer 

as pfam2go  <cit>  provides a minimal coverage of go terms for each pfam model, we extract from goa the go annotations of all proteins belonging to each pfam entry to enrich these assignments. in eq.  <dig> 1pngi is the frequency of the go term gi calculated over the total number p of proteins in the model and f is a logistic curve introduced to reward highly frequent terms and to penalize those that are sparse and likely false positives.

all the possible paths starting from the input go terms and leading to the root node are reconstructed and the go nodes not included in any of these paths are discarded from the analysis, obtaining the so-called "go-slim" .

the remaining go terms are grouped together in sets grk ∈ ℘; according to their semantic similarity  <cit> : the nodes that share a strong biological relationship form a unique informative group, and only the most specific and high scoring annotations are considered.

given two generic go terms gi, gj ∈ v, we use the lin's formula  <cit>   as a semantic similarity measure. this metric has been chosen since it gave the best results in clustering annotations with respect to other existing methods  <cit> .

the lin's formula is defined as:

  sim=2⋅simresic+ic 

in this formula, the function simres : v × v → ℜ defined as: simres=maxg∈s{ic} represents the highest information content ic among the subsumers of the terms gi and gj. using the notation gi ↦ gj to mean that a path from the term gi to the term gj exists, the set of the subsumers can be defined through the function s: v × v → ℘ as s = {g ∈ v:g ↦ gi ^ g ↦ gj}.

the function ic : v → ℜ is the information content of the ith go term calculated according to the resnik formula  <cit>  as:

 ic=-log{g:gi↦g}{g:g∈goa} 

where |{g:gi ↦ g}| indicates the total number of occurrences of go terms descending from go term i and |{g: g ∈ goa}| is the total number of go terms in the goa database.

three scores are then introduced to filter isolated go terms and to rank the remaining ones. the first one, the group score grs : n → ℜ, is the sum of the cumulative internal confidence inc of the nodes gj belonging to the kth group grk, being n the set of the natural numbers:

 grs= ∑{j:gj∈grk}inc 

the internal confidence inc : v → ℜ is a cumulative measure that takes into account the global cumulative weight distributions w: v → ℜ defined as w= ∑{j:g↦gj}wj, that is the sum of the weight w of a go term g  plus the weights of its children, and the sum of the cumulative weight of the root node :

  inc=∑{j:gi↦gj}wj∑{j:groot↦gj}wj=ww 

the second score z: v → ℜ, called z-score, is calculated for each extracted go term gi as follows:

 z=w-w¯σ 

where w¯is the weight of the root node divided by the total number of the retrieved go nodes, while σ is the standard deviation of all the weights.

if the z-score and the group score are below a certain threshold, the corresponding go terms are discarded. these filtering steps reward those paths, up to the root, that are statistically significant discarding the branches of the go graph containing nodes with low weights .

after the filtering phases, the algorithm assigns the third score, the total score ts : v → ℜ, to each culled go term gi, according to the following formula:

  ts=ic⋅incnc⋅incncgrsnc⋅wi 

where incnc: v → ℜ is the non-cumulative internal confidence, calculated as

  incnc=wi∑{j:groot↦gj}wj=wiw 

differently from the cumulative internal confidence inc defined by , it estimates the local non-cumulative weight distribution, which considers only the weight of the term under analysis.

the function grsnc : n → ℜ is the non-cumulative group score associated to the kth group grk. it is calculated as the sum of the non cumulative internal confidence incnc  of the nodes belonging to that group:

 grsnc= ∑{gj∈grk}incnc 

the go terms with ts above a chosen threshold are extracted and reported.

the score rewards those hits that are particularly significant and specific, thanks to the contribution of the information content .

the non cumulative measures incnc and grsnc have been introduced to guarantee that no biases are introduced due to the scores of child nodes.

web server functionalities and features
argot <dig> has been completely reengineered to speed up and improve the annotation process. the algorithm has undergone several adjustments to easily merge the go annotations retrieved from different databases. uniprot  <cit>  and pfam are presently used as reference databases and queried using blast and hmmer respectively.

the server can be accessed in three ways addressing different needs from small to large scale function predictions .

a) in the "interactive analysis" the user simply inputs up to  <dig> dna/protein sequences in fasta format. for every sequence, a table is shown containing: predicted annotations with scores, hyperlinks to external sources, lists of proteins contributing to the final annotation, and a graphical position map of the retrieved hits into the go graph.

b) the "batch analysis" is addressed to researchers interested in the annotation of entire genomes. since this process is highly demanding, due to the long computational time required by blast and hmmer, we ask users to perform blast and hmmer searches locally and then upload search results into argot <dig> 

c) the last access option is called "consensus analysis" as users may provide their own weighted go terms for each protein; these annotations can be obtained by any other method or database, in addition or in alternative to the "default" blast and hmmer searches used by the web server. the outputs of the analyses of type b and c are excel or tab separated values  files listing the retrieved annotations along with specific metrics: total score, information content and internal confidence. finally, predictions can be automatically clustered in functional classes by using the goclass tool  and viewed as pie-charts. the argot <dig> algorithm steps are mainly based on the original idea published in  <cit> . important changes have been applied to the procedure to filter potential false positive hits out during the evaluation of the predicted terms. the raw measure total score  has also been redefined. the server is freely accessible at the url in  <cit> .

argot <dig> assessment
argot <dig> has been benchmarked in four different conditions to test how proteins  influence the results, and which is the impact of domain based hmm searches. the four different configurations are indicated in the following as: a) bh_with, b) b_with, c) bh_without, d) b_without. the prefix "bh" means that argot <dig> has been tested on blast and hmmer searches, whereas "b" only on blast searches. the suffix "with" means that the proteins of the test set are present in the databank and "without" means they have been eliminated. argot <dig> has been also compared with blast2go.

the assessment of argot <dig> was based on the guidelines of the "critical assessment of function annotations"  experiment  <cit>  . we tested over  <dig> proteins with already available go annotations in goa, both from eukaryota  and prokaryota , randomly extracted from about  <dig> sequences released for the cafa challenge. in addition, the well annotated yeast genome, comprising  <dig> annotated proteins, has also been used as a test set. the details and statistics of the test sets are available in additional files  <dig>   <dig>   <dig>   <dig> and on our web site  <cit> .

the evaluation has been carried out at a protein-centric level using the following criteria. let n be a pool of unknown target proteins. for each given protein p, the go terms predicted by each method are retrieved and ranked accordingly to the corresponding total score tsp .

for a given threshold t applied to the total score tsp the four different configurations are assessed based on precision and recall, calculated for each protein p as:

  prpt=tppttppt+fppt;rcpt=tppttppt+fnpt 

the number of true positives  is the size of the intersection between the sets of benchmark  and predicted go terms with score tsp > t. the number of false positives  is the size of the difference between the sets of predicted and true go terms. the number of false negatives  is the size of the difference between the sets of true and predicted go terms. the denominators of  and  represent the total number of predicted terms and the number of true terms, respectively. if, for a given threshold t, a protein has not any annotated term, its precision is not calculated.

assessment method  <dig>  with sliding threshold
we consider a set of threshold scores t ranging from  <dig> to the maximum observed score tmax. for each t, precision and recall are averaged across the n proteins of the pool, obtaining:

 prt=1n ∑p=1nprpt;rct=1n ∑p=1nrcpt 

each pair of values  represents a point of the precision/recall curve.

assessment method  <dig>  with sliding threshold
we calculate precision and recall as in the case of m <dig> method, but all the go terms retrieved by the different tools  and those originally annotated on the benchmark proteins  are first propagated to the root. thus, all go terms standing in the paths of the predicted/true terms up to the root are considered in the assessment. the idea is that a predicted go term, though not exact, may share some of its parent nodes with some parent nodes of one true go term. this term cannot be considered completely wrong but rather closely related and, consequently, its shared parent nodes are included in the evaluation. see additional file  <dig> for details and extensive explanation of assessment m <dig> and m <dig> 

RESULTS
precision/recall curves for molecular function  and biological process  have been calculated with method m <dig> and m <dig> for yeast , eukaryota, and prokaryota test sets . the first outcome of our benchmarking provides evidence of the effectiveness of the combination of blast and hmmer weighted hits  in recovering a large number of go terms , without significantly affecting precision, and outperforming the use of blast alone.

one potential bias in the assessment of all methods is that 84% and 99% of the proteins, in euk and pro test sets respectively , are annotated without manual validation  and an over-estimation of tool performance may occur due to the use of predicted terms for functional inference  <cit> . to investigate the influence of this potential bias, the yeast proteome was used as benchmark, since a wealth of experimental data is available for this organism . though this is a challenging task involving  <dig> sequences, the assessment gives an idea of what argot <dig> is expected to do on a genome scale, namely to obtain a precise and thorough picture of molecular functions and biological processes of an entire organism. the general trends and the robustness shown in pro and euk test sets are confirmed . nonetheless, a minor decrease in performance can be observed in yeast. this is due to the fact that yeast is mainly annotated with highly informative non-iea go terms, whose frequency in goa databank is very low and consequently their retrieval may be a hard task. in particular it is possible to observe that the recall worsen, whereas the precision is only marginally affected proving that argot <dig> is able to retrieve reliable and even low-frequent go terms .

this trend is confirmed when target proteins are removed from the databanks used to train argot <dig> . this issue is not present in pro and euk test sets, which mainly include highly frequent iea go terms. as expected, results of pro and euk test sets get slightly worse , but yeast is more affected and argot <dig> finds more difficulties in extracting the right go terms . nevertheless, method m <dig> reveals that, in these critical situations, argot <dig> tends to be conservative rather than inaccurate, i.e. to show a lower recall but still a good precision . in conclusion, the lower performance is due to shallowness rather than inaccuracy. this means that most of the predicted nodes, though approximate, fall into the path of the correct annotations.

finally, some interesting conclusions can be drawn in the "one-to-one" comparison with blast2go using the b_with argot <dig> version that exploits the same blast data of blast2go. according to benchmark "m2", the recall is generally higher for argot <dig> whereas the precision is comparable, to some extent, between the two tools. however, argot <dig> is more effective in retrieving the exact original annotations, as evidenced by the use of assessment method m <dig> . the irregular contour trend of blast2go may be due to the sliding "annotation cut-off" parameter, which does not seem to be a well discriminating score. fine tuning may be required, even though the default value suggested for the parameter "annotation cut-off", i.e.  <dig>  gives the best trade-off between precision and recall. moreover, argot <dig> is fairly more computationally efficient compared to blast2go. starting from blast and hmmer results, which remain the limiting steps of the process, argot <dig> takes only few hours to annotate an entire genome.

CONCLUSIONS
argot has been revisited to increase both accuracy and precision, thanks to an improved weighting scheme and the introduction of pfam models. the server automatically downloads new releases of the used databanks uniprotkb-goa, uniprot, gene ontology, and pfam on a monthly basis to give end users an updated access to the tool. presently, in our testing conditions argot <dig> performs reasonably well in terms of both precision and recall, showing that ts score can effectively discriminate among false and true positives. the main rationale has been to create a tool able to favour the precision with respect to the recall. this is critical when annotating very large genome data sets, since reducing the false positives rate is definitely desirable. this can prevent biased information from impacting negatively on post-genome studies and statistics. in addition, we plan to associate a p-value to the raw score ts and to add new sources of information, trying to give an answer to non-trivial cases that lie in the twilight zone beyond similarity based evidences. in future releases we could explore other metrics, for example to assess different semantic similarity measures and to compare their performances with lin's formula currently used by argot <dig> .

list of abbreviations used
all abbreviations in the text excluded from the following list are specific of this paper and have been defined in the main text.

blast: basic local alignment search tool; go: gene ontology; goa: gene ontology annotation; ec: enzyme classification; psi-blast: position-specific iterative basic local alignment search tool; hmm: hidden markov model; tsv: tab separated values; url: uniform resource locator; cafa: critical assessment of function annotations; tp: true positive; fp: false positive; fn: false negative; mf: molecular function; bp: biological process; iea: inferred by electronic annotation.

competing interests
the authors declare that they have no competing interests.

authors' contributions
critical revision of the manuscript for important intellectual input: st, rv, pf, bdc. technical and material support: mf, ec, el, af. study supervision: pf and st. study concept: st, mf, bdc, pf. architectural design: mf, st. software development: mf, pf, ap and ec. drafting of the manuscript: st, bdc and pf. all authors read and approved the final manuscript.

supplementary material
additional file 1
goclass algorithm details. details of the goclass algorithm used to cluster the go terms, and more general views of the results obtained by argot <dig> 

click here for file

 additional file 2
datasets statistics. parameters used in the benchmarks and some statistics about the datasets.

click here for file

 additional file 3
precision/recall curves for the eukaryota dataset. precision/recall curves for molecular function , biological process  and cellular component  calculated with methods m <dig> and m <dig> for eukaryota test set.

click here for file

 additional file 4
precision/recall curves for the prokaryota dataset. precision/recall curves for molecular function , biological process  and cellular component  calculated with methods m <dig> and m <dig> for prokaryota test set.

click here for file

 additional file 5
precision/recall curves for the yeast dataset. precision/recall curves for molecular function , biological process  and cellular component  calculated with methods m <dig> and m <dig> for yeast test set.

click here for file

 additional file 6
precision/recall curves for the euk, pro and yeast datasets. precision/recall curves for molecular function  and biological process  calculated with methods m <dig> and m <dig> for euk, pro and yeast test sets.

click here for file

 additional file 7
cafa guidelines explanation. document that explains m <dig> and m <dig> methods using a simple example.

click here for file

 acknowledgements
we thank luca bianco for critical reading of the paper and for fruitful suggestions.

this article has been published as part of bmc bioinformatics volume  <dig> supplement  <dig>  2012: italian society of bioinformatics : annual meeting  <dig>  the full contents of the supplement are available online at http://www.biomedcentral.com/bmcbioinformatics/supplements/13/s <dig> 
