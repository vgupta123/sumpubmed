BACKGROUND
it is well understood that proteins are made up of structural and functional subunits or 'domains'. ever since domains were first described
 <cit> , numerous methods have been proposed to identify domains within protein structures. these approaches can vary widely depending on whether the assignments are made from sequence alone or from the 3d structure, and often involve partial or complete manual intervention. the domain identification problem is somewhat unique in structural biology in that it is at least in some cases subjective. different authors have different, though not mutually exclusive, ideas about what a domain should be - a functional unit which is reused over and over
 <cit> ; a segment of a structure which has been conserved and reused genetically across different families of proteins
 <cit> ; or simply a compact region of the protein where intra-atom contacts outweigh contacts to atoms outside the domain, for rapid self-assembly
 <cit> . domain definitions are also separated into 'genetic domains' which may be comprised of pieces from multiple chains, and regular ones which are completely contained within a single chain.

as a result of these different paradigms, there still does not exist a precise definition for a protein domain, nor do experts always agree on the number or location of domains within a given structure. this makes it extremely difficult to come up with a fully automated algorithm, then, to assign domain boundaries. that said, the scop
 <cit>  and cath
 <cit>  databases are typically used for the problem. we found that these agree only 80% of the time on number of domains however, over  <dig>  chains that they have in common ! despite these problems, splitting a protein into domains is often desirable. for example when performing homology modelling, one often seeks a template to model parts of the structure from. in this case it makes the most sense to find and use similar domains from known structures, which may provide useful templates when searching for similarity to the entire chain may not. knowledge of domain boundaries can also be used to improve the accuracy of sequence alignments. many different approaches have been used to split proteins into domains, and these can be divided into sequence-based and structure-based approaches.

sequence-based domain identification usually involves comparing the sequence in question to a database of protein sequences where the domains have already been defined  using an alignment tool such as blast
 <cit> . more advanced methods such as hmmer
 <cit>  make use of multiple sequence alignments of domain families, such as those compiled by interpro
 <cit> , and use hidden markov models  or other approaches to compare a query sequence against them, recording hits to the various domain families. examples of sequence-based domain databases include pfam
 <cit>  and smart
 <cit> . these methods work quite well when sequence identity to known folds is medium to high  but they fail on novel or unusual folds, or those with only very distant homologs. the precise boundaries may be off by quite a bit as well if there are large insertions or deletions in the sequence relative to the rest of the family.

structure-based algorithms should in theory be simple and straightforward, and often to the human eye it is obvious where domain boundaries should be drawn when viewing a 3d structure. nevertheless, it has proved a difficult computational problem and no automated algorithm agrees more than about 80% of the time with scop or cath assignments. a wide variety of methods exist, some based on graph theory and contact maps, some based on secondary structure layout. some allow only single cuts to be made resulting in domains made of contiguous segments only and a maximum of  <dig> or  <dig> domains per chain, others do not have this restriction. puu
 <cit>  builds a contact matrix and tries to maximize interactions within each unit and minimize them between units, through a series of cuts to the sequence. pdp
 <cit>  also attempts to make a series of cuts to maximize interactions but normalized the contact count by the expected number of contacts, based on surface area of the proposed domain. ddomain
 <cit>  is also based on a series of recursive cuts to try to maximize intra-domain contacts, and also employs a pairwise statistical potential instead of a simple contact count which slightly improves performance. domainparser
 <cit>  uses network flow algorithms, hydrophobic moment profile and neural networks to produce its domain partitioning. ncbi's vast algorithm
 <cit> , though not fully described anywhere, makes use of domains identified as compact structural units within protein 3d structures using purely geometric criteria. domainica
 <cit>  uses graph theory with secondary structure elements as the nodes and edges determined by proximity. the algorithm partitions the graph to maximize cycle distributions, and its simplicity is appealing. dconsensus
 <cit>  provides a means for rapidly comparing assignments by the different approaches.

despite the number of algorithms that have been described, most of comparable performance, it seems each has certain disadvantages. as mentioned some methods cannot deal with domains comprised of multiple contiguous segments, and most cannot deal with genetic domains . some methods are very slow, and some cannot place boundaries midway through secondary structure elements. this study investigates a novel, intuitive algorithm for domain identification by simply clustering α-carbon positions or secondary structure vectors in space. it is very fast, taking under one second for all but the largest proteins, and intuitively obvious. by its nature it has no maximum number of domains it can define, nor limitation on where domain boundaries can occur. even domains comprised of pieces from multiple chains, such as when domain swapping occurs
 <cit> , are detected without changes to the algorithm.

RESULTS
two distinct but related algorithms were studied, as described in methods: the α-carbon based algorithm  and the secondary structure element based algorithm . both make use of average-linkage clustering to produce and then cut a dendrogram; they differ only in the objects that they cluster. the main data set used to optimize the algorithms was the astral <dig> set, consisting of  <dig> domains in  <dig> non-redundant protein chains. only  <dig> of these chains actually still existed in the current protein data bank  however and so comprised the training set used in this study for the ca algorithm. only  <dig> of these had sufficient secondary structure to use the ss algorithm, so this slightly smaller training set was used in that case. both algorithms have only two adjustable parameters: the minimum value for cutting the cluster dendrogram, m, and the step size to determine whether to make a cut, s.

for the ca algorithm, a range of these values were tested, and the performance on the training set recorded for each of 1-, 2-, 3-, and 4-domain chains, summarized in table
 <dig>  an assignment was considered correct when it agreed with scop, since astral is based on the scop domain database. the matthews correlation coefficient  was also computed, which gives a statistically less biased measure  of classification success given the large proportion of single domain proteins in the data set. the most obvious effect was that increasing m or s increased the success rate on single-domain proteins, but generally decreased success in the multiple-domain assignments. this is logical as larger values of m and s make it less likely that a cut will be made in the dendrogram, so that a single domain is assigned more often. assigning a single domain all of the time would of course result in 100% success in single domain protein assignments and 75% success overall which corresponds to the fraction of single domain proteins in the set – as good as any of the parameter sets tested here – however the mcc would be poor. thus it is important not to put too much value on the overall assignment success, as tempting as it may be to do so. a random assigner was also employed, which chose a number of domains based on the distribution of domains-per-chain in scop  <dig> , and simply split the sequence equally along its length. as seen in table
 <dig>  this random approach did quite well on single domain proteins but quite poorly on the multi-domain proteins – the ca algorithm clearly does better than chance. the values of m=22Å, s=5Å were chosen because they gave the best compromise of success rates and mcc for multi-domain proteins while still having reasonable performance on the single-domain ones. only 4% of the 2-domain proteins, and no structures with more than  <dig> domains, in the astral set had their corresponding cut in the dendrogram at a value of m < 22Å so this is a reasonable choice.

only buried α-carbons were clustered, and adjacency constraint was enforced in all cases. success given on the astral <dig> data set as a function of m and s. matthews correlation coefficient is given in parentheses. 1total, regardless of number of domains.

similar runs for the ss algorithm are shown in table
 <dig>  again increasing m and s generally improved single domain success at the cost of multi-domain assignments. for this method complete-linkage clustering was also tested , and two distance metrics to be used for clustering were tested: closest approach distance of the secondary structure elements, and midpoint distance. while results were comparable, the average-linkage using midpoint distance performed best on multi-domain proteins, with m=22Å and s=5Å having the best compromise on single- and multi-domain success rates. these settings were used for the remainder of the study.

given on the astral <dig> data set as a function of m and s. linkage refers to the clustering technique used in determining the domains. metric is either midpt, meaning distances between secondary structure elements were taken between their midpoints, or closest, meaning the closest approach distance was used. the optimal combination of m and s are shown in bold for each section of the table. matthews correlation coefficient is given in parentheses.

for each algorithm we also tested removing the adjacency constraint - i.e. enforcing a distance of 4Å for cαs in the same secondary structure element, for the ca algorithm, or a distance of 4Å between consecutive secondary structure elements in the ss algorithm. in both cases removing this had a slight detrimental effect on the success rate , so the constraints were left in.

for the ca algorithm, initial tests were done clustering all α-carbons. using the buried α-carbons only  resulted in marked improvement however, increasing single, 2-, 3- and 4-domain proteins from 70%, 55%, 41% and 24%  to 75%, 58%, 45% and 32%, respectively . focusing only on the more buried residues helps make the domain boundaries more clear to the clustering algorithm and so became a permanent part of the algorithm.

the effect of the ‘gold standard’ chosen was also investigated. as mentioned, the success rates in tables
 <dig> and
 <dig> all used scop as the source for the correct answer to each domain splitting problem. however, switching to cath instead  increased the success for the ss algorithm at single domain proteins by 8%, and 2-domain proteins by 7%, while 3- and 4-domain success rates remained about the same . overall success increases from 70% to 74%. thus the ss algorithm agrees better with cath than scop. this is to be expected since scop tends to assign domains with some regard to function, while cath, like the algorithms in this study, looks at domains from a more structural perspective. if we allow the assignments to match either scop or cath, when they differ, performance increases even further by 0%, 8%, 17% and 21% on 1-, 2-, 3-, and 4-domain proteins respectively . lastly as an interesting test, if we choose m and s to produce the same number of clusters as that given by scop and compare to scop, so that we are only judging the boundary assignments of the algorithm , we see 99%, 86%, 71% and 75% success on 1-, 2-, 3- and 4-domain proteins respectively . this is the best we can hope to achieve with perfect choice of cut for every structure. any further improvement in the algorithm would need to come from better choice of clustering technique. this indicates that the method chooses well where to cut, once the number of cuts to make is known.

all runs are with m=22Å and s=5Å, and with adjacency constraint enforced, on the astral <dig> data set. 1ca refers to the α-carbon based algorithm and ss the secondary structure based one. 2total, regardless of number of domains. 3where scop and cath differ, the choice which matched closest to our assignment was chosen in these runs. 4the algorithms were forced to cut into the number of domains specified by scop for each structure.

doing the same for the ca algorithm , again it was found that when comparing to cath instead of scop, success on single domain proteins increased by 6% and 2-domain and 4-domain proteins each had 9% higher success, while 3-domain proteins were largely unchanged . so as before, the ca algorithm produces assignments which are more in line with the philosophy adopted by cath. allowing the assignments to match either scop or cath when they differ yields significant further increases of 1%, 7%, 19% and 19% for 1-, 2-, 3- and 4-domain proteins respectively  and given the number of domains to test the quality of boundary assignments resulted in 100%, 84%, 81% and 69% for 1-, 2-, 3- and 4-domain proteins respectively, or 95% overall. these results were very comparable to those found with the ss algorithm.

table
 <dig> compares the above results with some of the best available domain assignment algorithms currently available, as well as a random assigner, on the astral <dig> database. ddomain offers three assignments using different sets of parameters, but the authors parameters performed best so only these are reported. all the algorithms clearly perform better than random, and all have very similar performance within a few percentage points of each other, making it difficult to single out one as better than the rest, except on 4-domain proteins where ddomain and pdp excel.

present work compared to ddomain
 <cit>  , domainparser2
 <cit>  and pdp
 <cit> . 1ca refers to the α-carbon based algorithm and ss the secondary structure based one. 2total, regardless of number of domains.

with optimization complete, the algorithms were then run on the benchmark_ <dig> test set. this set  is significant in that the distribution of number of domains is intended to match that of the genome, and not the over-weighting of single domain proteins found in the pdb. additionally, scop and cath, as well as the structure authors, agree on the number of domains for all structures in this data set making the correct result less ambiguous. note that this test set only contains  <dig> proteins with  <dig> domains, so reporting success rates for these is not statistically meaningful.

table
 <dig> compares the performance on benchmark_ <dig> to other published methods, and we find the ca algorithm is highly competitive  at only 3% less overall than the best method  and roughly tied with domainparser <dig>  the random assigner performed significantly worse with averages of 71%, 15%, 1% and 0% correct for single, 2-, 3- and 4-domain proteins respectively  over  <dig> trials. all the methods are clearly better than random. again for ddomain, the authors settings were used. the ss algorithm does not fare as well on this set, performing significantly more poorly with success rates of 86%, 64%, 60% and 0% for 1-, 2-, 3-, and 4-domain proteins . the overall rate of over-cutting for ca was  <dig> % while for under-cutting it was  <dig> %, comparable to that observed with the other methods except pdp which showed a stronger tendency to overcut rather than undercut . the mcc for each assignment is also provided in table
 <dig>  to again help compensate for the large bias towards single-domain structures in the data set. this produced the same ranking as the raw success rates however, if the 1-, 2- and 3-domain mccs are just averaged. in terms of execution speed, the ca algorithm is over  <dig> times faster than either domainparser <dig> or ddomain, and about  <dig> times faster than pdp, while the ss algorithm is faster than the ca by a further factor of  <dig> 

present work compared to ddomain
 <cit>  , domainparser2
 <cit>  and pdp
 <cit>  on the benchmark  <dig> data set. matthews correlation coefficient is given in parentheses. 1ca refers to the α-carbon based algorithm and ss the secondary structure based one. 2time taken for the actual execution of the binaries or detection algorithms over the full dataset on a single  <dig>  ghz i <dig> cpu. 3total, regardless of number of domains.

lastly we tested the present methods on the benchmark_ <dig> set requiring 90% or better overlap. benchmark_ <dig> is a subset of the benchmark_ <dig> structures in which both scop and cath also agree upon the exact boundaries of the domains, within a small tolerance, suggesting that the domain boundaries are sharply defined in this set. as seen in table
 <dig>  the ca algorithm achieved 77% correct assignment . removing the constraint that prevents domain boundaries midway through secondary structure elements increased the performance to 79%, demonstrating that it is not always advisable to enforce this condition. again the ss algorithm did not perform too well on this data set. the best method, pdp, did slightly better at 80% success. the mcc values show a similar trend in performance with ca just marginally behind domainparser <dig> and pdp.

present work compared to ddomain
 <cit>  , domainparser2
 <cit>  and pdp
 <cit>  on the benchmark  <dig> data set. matthews correlation coefficient is given in parentheses. 1ca refers to the α-carbon based algorithm and ss the secondary structure based one. 2total, regardless of number of domains.

discussion
it is instructive to look at the types of mistakes made by the ca algorithm, which performed best overall on the test data sets, of the two methods developed in this work. there have already been detailed comparisons of scop and cath published
 <cit>  so we will focus on the benchmark_ <dig> set where both databases agree. of the  <dig> failures, only  <dig> were due to the overlap being less than  <dig>  . the  <dig> single domain proteins that were missed were assigned as 2- or 3-domain. there were also  <dig> 2-domain proteins assigned as single domain, and another  <dig> assigned to have 3-domains. the other common error was assigning 3-domain proteins as 2-domain, with  <dig> occurrences. an example from each of these failure classes is shown in the following figures.

2pcd chain m is a single domain assigned as two domains . however the second domain  involves less than 10% of the chain and is in a very loopy region at the n-terminus which indeed is not close to anything else except a paired ß-strand at the c-terminus, also isolated from the rest of the protein. the present method does not pay any special attention to ß-strand pairing however, and perhaps enforcing that members of a single ß-sheet be in the same domain might improve the performance further. this particular structure is actually a dimer in nature 
 <cit> , and so running our assigner on the dimer  does indeed result in two domains: chain a and the first  <dig> residues of chain m form the first domain , and the remainder of chain m the second . thus the ‘second domain’ assigned for chain m was actually just part of the larger domain formed by chain a, its partner. this example highlights the potential danger of only looking at single chains for evaluating domain assignments. in this case ignoring chain a here causes a correct assignment to appear incorrect. unfortunately most assignment methods cannot deal with domains spanning multiple chains, and so for the purposes of comparison and benchmarking, such a simplification is necessary. ideally however, domain splitting should be performed on the full biological unit and we expect the present method to excel in its ability to do so. over 54% of the benchmark_ <dig> structures are annotated as multimers by their authors however only  <dig> of the  <dig> failures  occur in multimers so this does not appear to be the only factor with impact on the overall performance of the method. 

a more clear failure of the algorithm is 1yua chain a, which is a two domain protein assigned to be a single domain. visually the protein is clearly two distinct domains, and the problem here is that they are just very small. lowering our minimum cut value, m, to 19Å and running the assignment again  gets it exactly correct . our algorithm as parameterized is simply biased towards slightly larger domains than seen here, and so may produce incorrect assignments for very small domains.

1gdd chain a is a two-domain protein assigned as three domains - the smaller domain location is assigned correctly, but the larger one is split in two . the ss algorithm correctly assigns two domains  so it is interesting to investigate why the ca algorithm decides on making an extra cut. again this extra cut breaks up a six-stranded ß-sheet. it seems the lower density of cαs around the sheet ‘fools’ the algorithm into splitting it up. some sort of constraint to keep ß-sheets together would help - putting all cαs within the same ß-sheet at distance 4Å from each other in the distance matrix results in a correct assignment of two domains .

1pky chain a is an example of a three-domain protein we assign as two-domain . this pyruvate kinase structure is a homo-tetramer. the ca algorithm here lumps the c-terminal domain together with the large central domain. however, using instead chain b results in a perfect split. chains c and d are cut the same as chain a. the ss algorithm, which is less sensitive to small perturbations in coordinates since it only depends on the secondary structure elements, correctly splits all four chains into three domains. so in this case the ca algorithm proves to be too sensitive to the precise 3d coordinates used. although the pairwise rmsd between chains a and b is only  <dig> Å, this is apparently sufficient to make the difference between a correct and incorrect assignment - this is just an unfortunate borderline case and investigation of the clustering dendrogram  shows that this structure is close to the cutoff of m=22Å.

finally, 5eau chain a was correctly assigned as 2-domain but had an overlap of only 73% . this is a large all-helical protein, and while the cores of the two domains are essentially correct, it is the border region which is in dispute, shown in green in figure
 <dig>  there is a long helix from residue 220– <dig> which serves to link the two domains together, and we assign it, along with a few neighboring helices, to one domain while scop and cath assign it to the other. interestingly the ss algorithm fares better on this one, with 89% overlap on its 2-domain assignments, only classifying the n-terminal helix in the ‘wrong’ domain  – this assignment for the helix does match scop however.

the above examples demonstrate several of the shortcomings of the ca algorithm, where improvement could be made in the future. it tends to perform best when the full biological assembly is provided, and may partition the complex differently depending how many copies of each chain are included. it is sensitive to quite small perturbations in coordinates for structures that are close to the cutting boundary ; and for very small domains it will tend to undercut. ddomain, domainparser <dig> and pdp also fail mostly due to incorrect number of domains rather than overlap under 75%, and in each case roughly half the incorrect assignments overlap with the ca method’s failures. thus the ca algorithm correctly assigns about half the failures of each of the other ones. in total  <dig> failed assignments are unique to the ca method including 2pcd, 1gdd and 5eau above. interestingly there are  <dig> structures that none of the algorithms assign correctly .

an example where the ca algorithm assigned two domains correctly while the others all assigned three domains is 1fmt chain a . this is a monomeric trna formyltransferase protein, and although the split into  <dig> domains does not appear unreasonable visually, the two domains on the left of figure
6a are actually only one domain. it is not clear why the other programs all fail on this example, but it does demonstrate again that no one of the methods is always the most correct.

CONCLUSIONS
this work presents two novel, related, domain assignment algorithms, one based on clustering buried α-carbons and one clustering secondary structure elements. they are appealing due to their intuitiveness, speed and extreme simplicity – having only two adjustable parameters – and are able to perform competitively with the best algorithms available. the ca algorithm is several times faster than other methods, and comes within a few percent of the top performer on all the data sets investigated, making its use appealing. it is worth noting that no one algorithm performed best on the astral <dig> and the benchmark data sets. the algorithms in this study also have the advantage that they can be run on arbitrary numbers of chains, and have no artificial limitations on how many domains or segments they may assign. the ca algorithm is not limited to assigning cuts only at secondary structure boundaries, either.

the examples studied indicate that the ca algorithm should not be used when very small domains are expected. also when multiple copies of a chain exist in the asymmetric unit, it should be run on each separately and perhaps the consensus assignment taken due to its sensitivity to small perturbations in coordinates. keeping these limitations in mind, it is encouraging that such simple, fast methods can perform as well as they do.

domain assignment within 3d protein structures is a difficult subject to tackle, due to it being an ill-defined problem to begin with. different people have different definitions of what a domain is, and this definition might change depending on the intended application. thus measuring the performance of a particular method, and comparing it to others, is difficult at best. that said, in some cases there is a clear and unambiguous split and the data sets from holland et al. <cit>  go a long way towards providing a fair set to test on. the one important thing they have overlooked is the importance of considering the biological unit. assignments need to be run on the full biological unit of a protein which should allow more accurate assignments for multimers, or else those structures which are not monomers should be further excluded from the test set.

even the best methods are still far from perfect, and this is in part due to the subjective nature of the problem. with a problem like domain assignment, rather than focusing on which method is a few percent closer to scop or cath, for example, it is perhaps more prudent to simply look at the cases where assignments differ from the ‘correct’ answer and ask ‘is this reasonable’?

