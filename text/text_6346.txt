BACKGROUND
a central task in molecular systems biology is to build and analyze genetic and biochemical networks in order to decipher the properties of cellular phenomena. the emphasis is not on investigating in detail one or a few molecules at a time, as is done traditionally in molecular biology, but rather on focusing on the network level.

we are specifically interested here in gene regulatory networks  formalized as discrete genetic networks as defined by r. thomas  <cit> . the main goal of this formalism is to obtain a qualitative understanding of the network dynamics by reasoning on discrete entities. in grns the molecular players are the genes and the proteins they produce. a genetic interaction corresponds to the fact that a gene gi produces a protein pi which influences the expression rate of another gene gj, or gi itself. the set of all these genetic interactions constitute the interaction graph, to be defined formally later. in a given state of the network, each gene has a certain expression rate  which depends on the presence or absence of a subset of proteins, the activators or repressors of the considered gene. the expression rate of a gene is maximum when all its activators are present and all its repressors are absent. in this context a basic objective is to analyze the temporal evolution of the protein concentrations in given external conditions. this can be done when the values of the model parameters have been measured. when this is not the case, the problem is then to exploit the knowledge about network behaviour  to deduce the possible values of the parameters. a frequently used method consists in performing a large number of simulations by varying some parameters  and selecting a posteriori the set of values that is consistent with the observed behaviour. as explained below, we propose a different approach for this inference problem.

beyond these basic functionalities , the construction of grn models consistent with experimental data requires more sophisticated tools. it often occurs that a proposed model displays inconsistencies with part of the data. in such cases it is necessary to critically analyze the hypotheses used in building the model and to revise them. this analysis can be done "by hand" for small networks, e.g. up to three genes, but requires the use of computational tools to cope with the complexity of larger networks. in still other situations the observational constraints are weak with respect to the number of variables, and the number of solutions is very large. in such cases, it is interesting to derive properties that are shared by all the solutions, or subsets of them, in order to get a better understanding of the model properties and to design new experiments having the potential to substantially reduce the set of solutions.

fundamentally, we want to provide the biologist studying grns with a software environment allowing to perform such tasks. the available knowledge is partial and bears on both the structure of the network of interest  and the behaviour of the network in various conditions. the first kind of knowledge is said to be structural, or local , whereas the second kind is said to be behavioural, or global . the network architecture and its behaviour are closely inter-related. this relation is implemented formally as a set of constraints in a straightforward manner in our software environment, named gnbox . more precisely, the philosophy of this approach is to represent a given problem, or set of problems, as a set of formulae linking variables. in our case this entails the specification of  the rules defining the updating scheme ;  the network architecture ;  the observations about the behaviours of the network , or any working hypothese about the system;  the query itself . the set of constraints thus defined is then submitted to a solver whether there exists solutions or not. a distinctive feature of the constraint approach is constraint propagation. it implements deduction rules and allows in favorable conditions to reduce drastically the search space, thus limiting enumeration. of course some amount of enumeration is usually still necessary, but the aim of the game is to reduce it as much as possible. this formal relation is "executable" and allows not only to perform basic functionalities such as simulation or reverse-engineering, but also to assert and obtain properties on both the behaviours and the interactions. more specifically, we implemented in this constraint-based setting four main functionalities:  proof of consistency or inconsistency of a constraint pool,  constraint relaxation in case of inconsistency ,  prediction of properties in case of consistency,  search for minimal models, with respect to the number of thresholds, for example.

in this article we present our approach and we show how it can be applied successfully to the analysis of three different biological problems. in the section methods we present the formalism we developped. we present the formal definition of interaction graphs and of the evolution rules of thomas networks. these notions are required to express the queries implementing the functionalities mentionned above. other notions related the specification of interaction compositions facilitate the expression of properties involving kinetic parameters. the implementation is discussed in  <cit> . in the section results and discussion we present three applications which differ by both the type of knowledge available and the type of biological questions asked. these applications permit  to illustrate the different functionalities of gnbox,  to show the feasibility of this constraint-based approach on realistic biological problems, and  to support the idea that a formal and declarative approach is very interesting to decipher the properties of grns, in order to assist in their construction.

methods
we present briefly in this section the constraint technology, the constraint-based formalization of thomas networks, the constraint-based formalization of biological properties of these networks, and the features of our software environment gnbox to elucidate grns.

below we use the following mathematical notations: an integer x taking values between min and max is denoted x ∈ min..max, a boolean b is an integer such as b ∈  <dig> . <dig>  b <dig> ⇔ b <dig> means that the boolean b <dig> is equal  to the boolean b <dig>  b <dig> implies b <dig> is denoted b <dig> ⇒ b <dig>  the boolean equal to b <dig> and b <dig> is denoted b <dig> ∧ b <dig>  the boolean equal to b <dig> or b <dig> is denoted b <dig> ∨ b <dig>  the boolean equal to the conjunction of a list of boolean bi is denoted ∧ i bi, the boolean equal to the disjunction of a list of boolean bi is denoted ∨i bi.

constraint technology
we propose to implement the approach  using constraint logic programming  technology, with a finite domain solver. clp is a programming paradigm based on first order logic. clp considers specific classes of logical terms and proposes efficient resolution methods of equations over these terms . a clp program is a logic formula, and its execution is the construction of a proof of consistency  of this formula. the formula is consistent when it is possible to find an instantiation of the variables which satisfies the formula. logicians call such an instantiation a model. a clp program is reversible in the sense that it permits to impose and obtain partial knowledge over all the variables of the formula . for example, let say that p is a predicate defining a relationship between two entities x and y. if a measurement allows to reduce the domain of values of x, this information can be added as an additional constraint, and a query can be submitted about the possible values of y. the solver will try to propagate the additional information on x to reduce the domain of y, taking into account p. conversely, if the measurement has been performed on y, this information can be propagated to x through p. this is reversibility. it must be said that different kinds of solvers exist, characterized by the type of variables  and the type of propagation rules used, among other things.

as all the variables describing interactions and behaviours have finite integer domains in the discrete framework used, the use of a constraint solver over finite domains is very well suited. in addition, the expressive power of first order logic and constraints over integers allows the definition of very general properties and functionalities. finally, in order to be able to take advantage of the very efficient boolean satisfiability  solvers available, the gnbox environment is able to translate the clp formalization into a boolean formula in conjunctive normal form . details on the translation into cnf can be found in  <cit> . in this way we combine the expressive power of clp with the efficiency of sat solvers.

formalization of thomas networks
in this subsection we present a constraint-based formalism to impose, check and infer properties about discrete genetic networks as defined by r. thomas. we first introduce the notions needed to define and formalize the interaction graph and the evolution rules of thomas networks. we define in the next subsection the notions of composition of interactions, additivity and observability properties which are useful to express hypotheses about kinetic parameters. all the presented notions of this subsection and the next one are illustrated with the example of figure  <dig> and figure  <dig>  and will be put into use in the biological applications of the section results.

the structure of a grn is represented in an abstract way by an interaction graph . the nodes of  are genes. each node is associated to a concentration variable representing the concentration of the protein produced by the corresponding gene. the oriented edges of  represent interactions between these genes, denoted by  for the interaction on the gene  c of index r, r ∈  <dig> .rc, where rc is the number of interactions on c. an integer variable representing a discrete threshold labels each edge. in papers using the formalism of r. thomas edges in interaction graphs are also labeled by a sign  <cit> . we choose more primitive interaction graphs without these labels in order to generalize the formalization and to facilitate the expression of hypotheses about the way interactions compose on target nodes. the presence of an interaction from gene a to gene b  indicates that protein a can potentially modify the expression rate of gene b. furthermore, this change in expression rate, when it actually exists, takes place when concentration of a crosses threshold t. in other words, this interaction indicates that the rate of production of protein b can be influenced by the position of protein a with respect to threshold t. it has to be noted that such an interaction does not actually impose a difference in production rate. rather, the absence of such an interaction forbids the existence of such a difference in production rate. such an interaction is represented by the triplet  . in the example in figure  <dig>  the rows "" and "interactions" give respectively the definition of the interaction graph  and the sets of interactions for the target genes x and y.

the network structure being defined, the next step is to define the network state and dynamics. a state s of the network is a list of gene product concentrations . the concentrations are discretized according to the thresholds appearing in . the concentration of the product of gene c in state s is the integer sc ∈  <dig> .maxc, where maxc is the maximal value of the discrete concentration of protein c. the threshold of component c of index p is  ∈  <dig> .maxc, where the index p takes its values in  <dig> .maxc . for a given system with n genes, ci, i ∈  <dig> .n, is the variable associated to the ith gene, and state s is the ordered list . so, the discrete concentration space contains  states.

we are now in a position to explain how the successor states of a given state are computed. each state s is associated to a so-called focal state, denoted by , and belonging to the same state space. the focal state gives the direction of evolution  for each concentration. consider for instance s = ⟨ <dig>  0⟩ and fs = ⟨ <dig>  1⟩ in a 2-dimensional system. the successor of s is not ⟨ <dig>  1⟩ as is the case in synchronous updating schemes. rather fs = ⟨ <dig>  1⟩ indicates the direction of evolution of each component taken separately. here both are increasing and s = ⟨ <dig>  0⟩ has  <dig> successors, ⟨ <dig>  0⟩ and ⟨ <dig>  1⟩. in other words two transitions are possible from s, and this type of updating scheme is often called asynchronous, but nondeterministic is a better term. what is the basis of this non-determinism? if the numerical values  of the initial concentrations, together with those of the model parameters were known, it would be possible to determine the exact successor. in the discrete abstraction considered here this information is not available and consequently both possibilities must be taken into account. non-determinism is a fundamental property of this abstraction due to the information loss induced by the partition of concentration space into rectangular domains. we chose this formalism in this study because it is well founded and it is a good match to the qualitative knowledge generally available in systems biology at present. nevertheless, it should be kept in mind that our constraint approach is not tied to thomas networks. other types of discrete dynamical rules could be implemented, e.g. kauffman-like boolean networks with parallel   <cit>  or block-sequential updating scheme  <cit> .

to implement the thomas evolution rules we need first to specify the equations which link a state s to its focal state fs. these equations are named focal equations. a set of rules then links state s, the focal state fs associated to s, and the successor states of s. we stress here that these rules must be viewed as relationships linking different kinds of unknowns. as explained above , the use of these relationships depends on the available information in a given state of knowledge. if the concentration values making state s are all known, together with the position of its focal state, then the successors of s can be computed. but the relationships can be exploited in other ways, too.

the system of focal equations contains different kinds of parameters: constant concentrations associated to input genes , parameters related to reaction kinetics , and thresholds . the set of all these parameters is denoted by p. the parameters are amongs the unknowns of the system of constraints because their values are in general not known, or only partially known. the evolution rules, once formalized , lend to a first set of logical constraints. to this first set are added structural constraints over the parameters derived from experimental data, and working hypotheses. the set of solutions of such a system of constraints defines a set of instantiated models . the couple composed of a focal equation system and a set of structural constraints is called a parameterized constrained model m, or just model. a typical query includes one or several structurally-related models , and some additional behavioural constraints. if the resulting system  is under-constrained this set contains a large number of solutions. if it is over-constrained it is empty. in our context, this last case is interpreted as a contradiction between, on one hand, the experimental evidence and, on the other hand, the network structure or the hypotheses. more sophisticated queries are presented in the application part below, to illustrate the high-level functionalities mentioned in the introduction.

the parameterized focal equation system of a model m is completely defined by an interaction graph . in fact these two entities contain exactly the same information . the set of interactions of  having the gene c as target induces a partition of the concentration space according to the thresholds  of these interactions. this partition defines a set of regions called the cellular contexts of c. as long as the concentration of the proteins c' regulating c do not cross one of the  thresholds, the system stays in the same cellular context, because from the viewpoint of gene c the regulatory conditions have not changed. this means that all the states s belonging to the same cellular context of c have the same focal component fc,s of the focal state fs. the value of fc,s being generally unknown, a formal parameter  called discrete kinetic parameter is introduced for each cellular context of c with index l. these parameters are the discrete version of the ratio of protein production rate over degradation rate. when the value of  is high in some cellular context, this is interpreted by saying that in the states belonging to that context the production rate of the protein associated to gene c is high, and/or its degradation rate low. but in the qualitative setting of thomas formalism it should be kept in mind that we have only access to a discretized version of the production rate to degradation rate ratio. the number of cellular contexts for a given gene c is , and so is the number of  parameters.

we have introduced the main notions unformally , and will now present formal definitions which are directly usable in constraint form.

definition  <dig> let c be a component, and let s be a state. the focal component of c in s, denoted by fc,s, is defined by the following focal equation of c:.  

where  is the discrete kinetic parameter of c with index l, l ∈  <dig> .lc, and  is a condition true if s belongs to the cellular context of c with index l. the indexing convention is the following: l is equal to v +  <dig> where v is the decimal value of the binary number composed of the booleans  with , these booleans being arranged in increasing order of r .

the above formula means that if state s' belongs to the cellular context of index l' for gene c  then the focal component fc,s' is equal to .

example  <dig> the row "cellular contexts" in figure  <dig> describes formally and graphically, for a given order of thresholds, the cellular contexts for each component x and y of the considered example. component x is the target of only one interaction and is thus associated to two cellular contexts, y is the target of two interactions and has  <dig> cellular contexts. the row "discrete kinetic parameters" gives the list of these parameters. the subscripts and superscripts make the correspondence with the associated cellular contexts . finally the row "focal component" gives the equations describing the focal components fx, s and fy, s of a state s. the row "focal state" in figure  <dig> describes the focal state fs = ⟨fx,s, fy,s⟩ of s.

the focal state defines the direction of the dynamic transitions starting in s. in the thomas networks, the authorized transitions are such that:.

 <dig>  s' and s are the same state or are neighbors,

 <dig>  s' and s differ on at most one component.

 <dig>  s' is in the "direction" of the focal state fs.

the first property  is due to the fact that the concentrations evolve continuously, thus jumps over states are not allowed. the second is commonly called asynchronicity. the third one is specific to the discretization of evolution equations due to thomas. we explained above that when two concentrations are increasing in a given state, it is not known in this kind of abstraction which will reach first its next threshold, and consequently which transition will occur first. in this situation both transitions are taken into account leading to two successors for the state considered . this is intimately connected to the non-determinism inherent to abstractions based on phase space partition.

the rules have the following consequences: s = s' ⇔ fs = s ,  = sc +  <dig> ⇒ fc,s >sc  and  = sc -  <dig> ⇒ fc,s <sc .

it is possible to specify a knock-out or ectopic expression mutation. for each non-input mutated gene c set to a constant value v, the constraint ∧l = v must be introduced. for a mutated input gene to the value v the input parameter of the model is set to this value v. in some cases it is necessary to use several models in the same query, one model corresponding to the wild type and the others to mutants. in such cases we introduce constraints specifying that for all couples of models  the thresholds of mα are equal to those of mβ, and the parameters  of mα associated to genes c which are not mutated in mα and mβ are equal to those of mβ. the constraints between the input parameters of mα and mβ depends of the considered biological application .

a user of gnbox must describe the structure of the studied grn , and can use the language lg <dig> to specify the existence of a behaviour. the language lg <dig> is composed of the predicate path which is true if path is a succession of l states authorized by the model m , and a language to impose arithmetic constraints between variables of path. language lg <dig> is used to formalize observations on the behaviour of the system. our approach allows to specify  partial information. for example only a few concentrations may have been measured. absence of information is absence of constraints.

interaction compositions
the interaction graph  lists the interactions individually but does not contain information on the manner in which different interactions are composed when they have the same target gene. the information about the way to compose interactions is embodied in relationships linking the parameters contained in . however, the manual interpretation of instantiations or properties over parameters of p is not convenient, especially for users not acquainted with the formalism of thomas networks. for this reason we designed a higher level language lg <dig> to impose, check and infer properties about the way to compose the interactions in  in the manner of the traditional notion of the logic of regulation . it should be understood that this is not fundamental to the approach but merely a facility to handle relationships between parameters induced by the composition of interactions. the user always has the choice to work directly on these relationships.

we explained above that the specification of a set of interactions for a gene c partitions  the concentration space by hyperplanes . lg <dig> permits, for every c, to partition the concentration space in union of cellular contexts of c, named compositions of cellular contexts, via the definition of interaction compositions. any union of cellular contexts can be specified, and in particular an union of disconnected regions. similarly to the semantic of a set of interactions, the semantic of a set of interaction compositions is the following: all the states belonging to a given composition of cellular contexts of c have the same evolution tendency of the concentration of protein c. the borders between these regions are constituted of parts of threshold hyperplanes of interactions taking part in the composition. we name these borders interaction compositions. an interaction composition for c, denoted by , rc ∈  <dig> .rcc, rcc being the number of interaction composition on c, permits to indicate where it is possible to have a change in the evolution trend of component c. informally, one can see an interaction composition as a new artificial species which interacts on c and which induces a new partition of state space into two regions. first, let us remark again that an interaction  induces a partition of state space into two regions by the hyperplane associated to the threshold . by convention, the part where the states s are such that  is true is said to satisfy . an interaction composition also partition the state space into two regions, but the border is not necessarily a hyper-plane defined by a single threshold. an interaction composition can have the following forms:

• an interaction .

• . the region where the state s are such that  is said to satisfy .

• , where ic and ic' are interaction compositions. the region where the states s satisfies both ic and ic' is said to satisfy .

• , where ic and ic' are interaction compositions. the region where the states s satisfies ic, or ic', or both, is said to satisfy .

example  <dig> the sixth row in figure  <dig> gives three possible sets of interactions compositions for y, related to the example in figure  <dig>  the four first rows recall the context of example in figure  <dig>  the fifth row gives the set of interaction compositions over x. the seventh row shows for each of these couple of sets a graphical representation of the detailed structure of the network, with signs + and - over interactions and bridges, denoted by and, to express a conjunction between two interaction compositions. finally, the last row shows the resulting compositions of cellular contexts for y.

the first case  leads to the same partition of the discrete concentration space of y .

the second case expresses with the sole interaction composition on y, , that either the concentration of x and y are above  and , respectively , or the concentration of x or y are below  and , respectively .

the third case expresses quite the same of the second case but permits that x interacts on y whatever the concentration of y. so, we obtain three compositions of cellular contexts because the fact that x can interact on y all along the border of the threshold .

example  <dig> the figure  <dig> gives an example of a set of interaction compositions and resulting composition of cellular contexts. in the first column, we can see an interaction graph  with two components a and b, a set of four interactions over b, and a partition of the concentration space into nine non empty cellular contexts. the indexes l of the conditions cell appear in circles. the other cellular contexts are empty according to the order of the values of the thresholds . note that usually this order is not known and the values of thresholds for a same species can be equal. in the second column  we assumed to have two interaction compositions. we obtain a partition of the concentration space into four non empty compositions of cellular contexts .

additivity and observability properties
the language lg <dig> allows to define specific effects of an interaction composition on a component c. here by effect we mean a shift in the position of the focal component fc when the border associated to the interaction composition is crossed. biologically, an increase of the tendency of c can be due to an increase of the expression rate of gene c, or a decrease of the degradation rate of the corresponding protein. in other formalisms these effects are specified by labelling the arcs of the interaction graph with signs . a + sign  for an interaction of a gene a on b in the signed interaction graph means informally that the interaction of a on b is an activation . however, the exact meaning of the terms activation and inhibition is not clear, especially when several interactions combine on a gene: does an activation of b by a forbid an inhibition of b by a or not? is an activation of b by a necessarily observed all along the border associated to the interaction or not? two properties are used to clarify formally these questions.

the first one, called additivity, is the systematic non-strict increase of tendency of c when a border is crossed in some predefined direction. in other words the effect on c of the interaction composition adds to the effect of all other interaction compositions on c. the direction in which the border is crossed for this property is the one given by the passage from a state where the interaction composition is not satisfied to a state where it is satisfied.

the second property, called observability, is the existence of a strict increase of the tendency on c. this means that the effect on the tendency of c exists at least at one crossing point . in contrast to the additivity property, observability property requires only the existence of an effect somewhere along the border.

to define these effects more formally we introduce for each interaction composition  on c a set, denoted by , containing all couples of states  such that  s <dig> is adjacent to s <dig>   s <dig> is a state in the region where  is not satisfied, and  s <dig> is a state in the region where  is satisfied.

example  <dig> for the interaction composition  of the example given in figure  <dig> we get  = {, , , , , }. each of the couples  of this set is represented in figure  <dig> by a kind of arrow symbol, where the 'o' end is associated to state s <dig>  and the '|' end to state s <dig> 

lg <dig> allows to specify that an interaction composition  has an additive effect, denoted by , i.e. that the difference of trend of c is positive or zero all along the border defined by . the exact semantics of  is: for every couple  of  the trend of c in s <dig> is less than or equal to the trend of c in s <dig>  since the trend of a state is equal to the trend of all the states in the same cellular context, the additivity constraints are expressed as relations between discrete kinetic parameters .

example  <dig> for the example in figure  <dig>  we have  = {, , ⟨ <dig> ⟩), }, and  due to the negative sign associated to the interaction of y on x.

for the first case of interaction compositions on  = {, }, , and  = {, }, .

for the second case of interaction compositions on y,  = {, } and . if this additivity property is true, the only case of activation of y is when x and y are above and  respectively.

for the third case   and  . if these aditivity are true, there are two cases of activation of y, one above  and one above  and . moreover, the second case of activation is greater than the first one, due to the additivity property .

if multi-arcs are present in the interaction graph  the cellular contexts on each side of the border defined by the interaction composition  are not the same depending on the values of the thresholds associated to the multi-arc. in that case the additivity constraints are relations involving also thresholds. briefly, the additivity constraint of the interaction composition  is: ∧ ⇒  ≥ ) with adj true if it exists a couple  of  such that  .

example  <dig> for the example in figure  <dig>  the additivity constraint of the composition  is:.  

according to the identifiers l of cellular contexts for b . it can be checked with the graphic representation of cellular contexts of b in figure  <dig> that for  we obtain . this example shows that specifying additivity properties can be much more compact than working at the level of parameters. without language lg <dig> we would have to write the above formula.

in addition to the additivity property, lg <dig> allows to specify that an interaction composition  has an observable effect, denoted by , i.e. that the difference of trend of c is strictly positive at least at one position along the border defined by . the exact semantics of  is: for at least one couple  of  the trend of c in s <dig> is strictly less than the trend of c in s <dig>  to be more explicit, an interaction  can be removed from the interaction graph if neither the interaction composition  , nor its negation  is observable. briefly the observability constraint of the interaction composition  is:  with adj true if it exists a couple  of  such that .

example  <dig> for the example in figure  <dig> with  the constraint  is .

gnbox features
the core functionality of the gnbox environment is to test, for a given structure of a grn, the consistency of a set of hypotheses about the behaviours of this grn  for several mutant types, about the interaction compositions , and even directly about the parameters in p. gn-box is able to identify consistent solutions in terms of state variables that define the behaviour  and in terms of parameters of p. in cases where the set of hypotheses is inconsistent, it is desirable to determine the possible relaxations of hypotheses to remove the inconsistency. gnbox can identify automatically, among a defined set of questionable hypotheses, all subsets of hypotheses whose relaxation removes the inconsistency . these subsets are represented as disjunctions of conjunctions of negations of hypotheses. for example, the hypotheses h <dig> and h <dig> must be relaxed or the hypothesis h <dig> must be relaxed:  v ¬h <dig>  also gnbox automatically identifies, among a defined set of hypotheses, all subsets of hypotheses necessarily true. these subsets are represented by disjunctions of conjunctions of hypotheses. for example, the hypotheses h <dig> and h <dig> are true or the hypothesis h <dig> is true:  ∨ h <dig> 

RESULTS
application to the immunity control by the λ bacteriophage
the analysis of this network adapted from  <cit>  illustrates mainly the capability of gnbox  to express constraints about reachability of states, and  to find the minimal interaction graph consistent with observations.

the λ bacteriophage  is a virus that infects the bacterium escherichia coli. the infection starts by the injection of the genetic material of the virus into the cytoplasm of the bacterium. we focus here on two simple observations about the evolution of the bacterium after infection: either the viral dna is integrated in the genetic material of the bacterium, and the cells continue to divide normally , or the genetic material replicates in the cytoplasm of the bacterial cell to create new viral particles and then new viruses until lysis  of the cell, which leads to the release of new virus particles in the extracellular medium. the first case corresponds to the lysogenic phase while the second corresponds to the lytic phase. the decision between these two phases is made by a network of viral genes.

the model proposed in  <cit>  contains four viral genes denoted by ci, cro, cii and n. the gene ci is expressed only in the lysogenic phase, cro is expressed only in the lytic phase and genes cii and n are not expressed in both phases. the graph  of interactions between these genes is given in figure  <dig>  interactions and interaction compositions  are given in table  <dig>  we consider the set of all additivity and observability constraints for all these interaction compositions , etc.). in the following we assume that the thresholds  are ordered so that . according to the previous section the set of interactions, the hypotheses about interaction compositions  and the hypotheses on threshold values define a parameterized constrained model . we call it mλ and it is defined formally by the predicate model_λ. a state s for this model is represented by an ordered list ⟨sci, scro, scii, sn⟩ of discrete protein concentrations. according to  and hypotheses on threshold values, we have maxci =  <dig>  maxcro =  <dig>  maxcii =  <dig>  maxn =  <dig>  so the concentration space contains *** =  <dig> states.

the uninfected cell does not have any viral protein and can therefore be represented by the state s <dig> = ⟨s0ci, s0cro, s0cii, s0n⟩ = ⟨ <dig>   <dig>   <dig>  0⟩ in the lysogenic phase of the virus-host system the only viral gene expressed is ci. this phase is represented by the state s <dig> = ⟨s1ci, s1cro, s1cii, s1n⟩ = ⟨ <dig>   <dig>   <dig>  0⟩ such that the concentration of protein ci remains equal to its highest value. in the lytic phase the only viral gene expressed is cro. in a continuous description this phase is represented by a state which is not contained within a domain, but which is at the border between two adjacent domains. we could introduce in our formalism additional states corresponding to borders between domains. such states are called singular states in  <cit> . we choose here to stick to the simpler formalism, and we represent the lytic phase as a cycle between the two following states: s <dig> = ⟨ <dig>   <dig>   <dig>  0⟩ and s <dig> = ⟨ <dig>   <dig>   <dig>  0⟩, such that the concentration of the protein cro remains around the highest values  <dig> and  <dig>  <cit> . biological observations tell us that these two phases must be attractors of the network dynamics, and that they are reachable from the initial conditions. these observations are formalized by constraint  <dig> where the lengths of the third and fourth paths for the reachability of the two phases are equal to  <dig> states,  <dig> being the total number of states of the state space.

constraint 1
the gnbox environment proves the consistency of this pool of constraints in  <dig> seconds. all run times mentioned in this article are obtained on a laptop with  <dig> gb of ram and running at  <dig>  ghz. moreover gnbox can provide the instantiations of the parameters of p that satisfy the pool of constraints.

example  <dig> an example of instantiation is:  

. the set of transitions from s to s', denoted by s ↠ s', for this instantiation is represented in figure  <dig> 

an interesting question, akin to reverse-engineering of the network, is: what are the minimal numbers of interaction compositions necessary to get a model consistent with constraint  <dig> without specifying any additivity or observability constraints? in other words, we search for the minimal interaction graphs, in terms of interactions, which satisfy the observed behaviors. from a constraint point of view, this problem is specified and implemented in the following way. for each interaction composition on a gene c, a boolean variable is created which means "all pairs of states separated only by this interaction composition have the same evolution tendency for c". then gnbox searches for consistent models such that the number of these boolean variables which are true is maximized. gnbox finds that only two interactions on cro are necessary . so, the minimal interaction graph contains only two interactions on cro and no interactions on the other genes. the result is surprising at first sight, but it should be borne in mind that the query contains only poor information about behaviours and no information on the interaction graph , the goal being to infer the minimum graph implied by this information. this does not preclude the existence of other interactions, but means that those are not necessary to account for the behaviours included in the query.

finally this application lead us to the interesting question of the length l of the longest path without cycle in the state space for a given set of hypotheses set. we call this length the diameter of the network for set. this knowledge permits to restrict the length of paths in subsequent queries considering a set of hypotheses including set. in our case set is constraint  <dig>  the diameter for set is  <dig>  this highly combinatorial problem is answered in two queries: one to prove the existence of a solution for a length l of  <dig> in  <dig> seconds, the other showing inconsistency for a length l of  <dig> in  <dig> seconds.

application to the carbon nutritional stress response in the bacterium escherichia coli
the modeling and analysis of this network is adapted from  <cit> . it illustrates a case of model revision coming from an inconsistency of the initial set of hypotheses. we performed a similar and more exhaustive study reported in  <cit> . we show that by an automatic relaxation method over biological constraints we can suggest lines of research to the biologist or, said differently, generate new hypotheses.

populations of the bacterium escherichia coli grow exponentially in favorable conditions. this state is called the exponential phase. in stressing conditions, when food  starts to be lacking, the populations stop growing and they enter in a state called stationary phase, with altered physiology and morphology. the phenomenon is reversible: the population can return to the exponential phase if the conditions become favorable again.

the model, proposed in  <cit>  and adapted to our formalism, contains one input node sig  and five species: crp, cya, fis, gyr and top. the interaction graph  is given in figure  <dig> where the input sig is represented by a dotted circle filled in blue. interactions and interaction compositions are given in table  <dig>  moreover we consider the set of all additivity and observability constraints for all interaction compositions. as before, the thresholds  are ordered and equal to p. the model obtained from all these hypotheses is denoted by mcoli. thus we have maxcrp =  <dig>  maxcya =  <dig>  maxfis =  <dig>  maxgyr =  <dig> and maxtop =  <dig> . we obtain a concentration space of  *  *  *  *  =  <dig> states.

the exponential phase and the stationary phase are modeled by two states, respectively sns  and ss . as stated in  <cit> , there exists partial knowledge about these states:

constraint 2
note that only three components are instantiated in each state and that there is a relationship between the two others which expresses the fact that the super-coiling of dna is higher in the exponential phase. to model the presence or the absence of stress we use two models: a model  without stress  and a model  with stress . these two models are the same biological model mcoli in different conditions. so they share the same discrete kinetic parameters . in absence of stress the system beginning in the stressed state ss can reach the non-stressed state sns, which is steady. in presence of stress the system beginning in sns can reach ss, which is steady. we formalize that by:

constraint 3
where l is the length of the third and fourth paths for the reachability of the two steady states. in the following queries we choose l =  <dig> and l =  <dig> to compare performance, but if we want a general query without any limitation on l we should choose l =  <dig>  but the amount of memory needed to generate the pool of constraints becomes very large. we point out here that for such queries involving paths, this approach is limited to networks of medium size.

with gnbox we prove that the pool of constraints composed of constraints for models  and  constraint  <dig> and constraint  <dig> is inconsistent in  <dig> seconds for path length l =  <dig> states, and  <dig> seconds for path length l =  <dig>  in fact just imposing the existence of two steady states gives an inconsistency in less than  <dig> second, thus proving that the constraint pool is inconsistent whatever the value of l. in  <cit>  it is noted that the proposed instantiated model is indeed inconsistent. here we prove in addition that there exists no other instantiation of the discrete kinetic parameters  able to restore consistency. in other words it is proved that this network architecture with these hypotheses on interaction compositions is incompatible with the observations. it is thus necessary to revise the model. in  <cit>  the authors suggest that a regulator or an interaction may be missing in the model. here, instead, we keep the interaction graph  as it is, and try to change the way interactions are composed. the set of unreliable hypotheses is the set of all additivity and observability properties about interaction compositions. we allow the relaxation of these hypotheses and we obtain the property  in  <dig> seconds with a path length l =  <dig>  and in  <dig> seconds with a path length l =  <dig>  discussions with the biologist lead to the conclusion that it is not acceptable to relax the additivity property of the first composition on gyr, . this suggests that the composition on top, , is the one which is not additive and consequently that it is possible to observe an inhibition of top by fis. this inhibition effect is actually observed for another kind of stress. in  <cit>  it is said: "when fis levels are low, hydrogen peroxide treatment results in topa activation". this means that fis acts in some cellular contexts as an inhibitor of top. this paper shows that the protein fis can indeed play an inhibitory role on top in some contexts, and it thus gives support to the new hypothesis that fis plays an inhibitory role in the response to nutritional stress. it is remarkable that this pool of constraints is inconsistent given that the number of adjustable parameters is relatively high. we insist here on the fact that inspection of the constraint pool did not allow to resolve manually this inconsistency.

finally, it appears that the hypotheses of interaction compositions on top are not well supported by experiments, and we propose to determine the necessarily observable compositions of the type  and (). the rationale for limiting the compositions to basic types  is to provide easily interpretable results in terms of the interaction graph  complemented with interaction signs . this allows to determine for example whether there are unnecessary arcs in . on the other hand this restriction still allows to guide the user in the choice of hypotheses about interaction compositions. we conserve all the previous hypotheses except the ones about the interaction compositions on top. we consider a new set of these six interaction compositions for top: . finally we challenge the observability constraints onto them to find which of them are necessary for these hypotheses. gnbox returns the property   in  <dig> seconds with a length of path l =  <dig>  and the same formula in  <dig> seconds with a length of path l =  <dig>  this indicates that any solution of all constraints  has the property  or the property . this result provides an essential information to help the biologist to make additional hypotheses about interaction compositions.

application to the gap-gene module of the segmentation of the drosophila melanogaster embryo
in the first hours after fertilization, the embryo of the fly drosophila melanogaster undergoes segmentation along the anteroposterior axis . the embryo is partitioned into segments, each segment being made of cells characterized by specific levels of a set of proteins. segmentation takes place in several successive stages controlled by distinct genetic modules. here we focus on the gap-gene regulatory module.

the modeling and analysis of this network illustrates the expression of steady states in several segments of the embryo for the wild type and several mutant types, and the search for the minimum number of thresholds necessary to account for all the observations. the initial model is adapted from  <cit> . although this model is not the most recent available, it is convenient for our purpose. the resolution of this query provides a set of minimal models  consistent with a set of very diverse observations. the connection between the observations for all these models  adds a new level of complexity.

the model, proposed in  <cit> , controlling the gap-gene module contains seven genes: giant denoted by gt, hunchback zygotic denoted by hbz, hunchback maternal denoted by hbm, krüppel denoted by kr, knirps denoted by kni, bicoid denoted by bcd, and caudal denoted by cad. the genes bcd, hbm and cad are input genes: they influence other genes but are not influenced by any gene. stocks of maternal mrna and proteins are accumulated at specific places of the egg before fertilization. these molecules generate gradients along the anteroposterior axis. in the model these quantities are represented by input parameters . the interaction graph  between these genes is given in figure  <dig> where input genes are represented by dotted circles filled in blue. interactions and interaction compositions are given in table  <dig>  moreover we consider the set of all additivity and observability constraints for all interaction compositions. the modeling in  <cit>  takes into account four adjacent segments along the anteroposterior axis, denoted by a, b, c and d. genetic experiments produced information on the concentration of the gap-gene proteins for the wild type, denoted by wt, and nine mutants. the mutants are: knock-out  on gt  denoted by gt <dig>  ko on both hbz and hbm denoted by hb <dig>  ko on kr denoted by kr <dig>  ko on kni denoted by kni <dig>  ko on bcd denoted by bcd <dig>  ko on hbm denoted by hbm <dig>  ko on cad denoted by cad <dig>  ectopic expression equal to  <dig> on gt  denoted by gt <dig>  ectopic expression equal to  <dig> on kni denoted by kni <dig>  we define a model mr,t for each segment r∈ {a, b, c, d} and each type t ∈ {wt, gt <dig>  hb <dig>  kr <dig>  kni <dig>  bcd <dig>  cad <dig>  hbm <dig>  gt <dig>  kni}. for example, mb,gt <dig> corresponds to the model of the mutant type gt <dig> in segment b. the input parameters, discrete kinetic parameters and threshold parameters, between models are linked by introducing equality constraints between them, as explained in the section on the formalization of thomas networks. thus it would be redundant to impose constraints about interaction compositions for mutant types . obviously, these constraints lead to exactly the same threshold and discrete kinetic parameters for the four models associated to the four segments and each mutant.

the concentrations of the proteins produced by input genes bcd, hbm and cad for each region r and each mutant type t are respectively denoted by  and . we impose in constraint  <dig> that the inputs in the mutant types are equal to those of the wild type, except in the cases where some input genes themselves are mutated. this exception is due to the fact that the inputs come from the mother system, so only a mutation in this system can change the concentration value of the corresponding input.

constraint 4
moreover, we have inequality constraints between the thresholds for this model:

constraint 5
the observations relate to the existence of one steady state by mutant type and by segment with some properties between these states. the steady states are represented by ordered lists of four protein concentrations:  for each region r and each mutant type t. the constraint associated to the observation of the steady state of each region r and each type t is:

constraint 6
the gradients of maternal origin mentioned above are used by the cell to derive positional information. to represent these gradients, the antero-posterior axis is partitioned into segments, each segment being identified by a combination of values of the input molecules bcd, hbm and cad. we impose that the combinations of input quantities are different for all pairs of segments for the wild type:

constraint 7
we note in the following cgap the set of constraints associated to the existence of the steady states of the  <dig> regions for each of the  <dig> types .

if we add to cgap the constraint represented in table  <dig> about the instantiation of steady states for all types, input parameters for the wild type according to the second table of  <cit> , and the constraint ∧c ∧p  we obtain a consistency in  <dig> seconds.

it appears in the second figure of  <cit>  that there is no auto-interaction onto hbz. in fact, after discussion with d. thieffry, a synergy between hunchback and bicoid on the activation of hunchback has been reported, and hbm and hbz are the same species in distinct compartments. this explain the interaction compositions onto hbz with indexes  <dig>   <dig> and  <dig>  if we do not consider this auto-interaction in cgap by replacing the last three interaction compositions onto hbz by  and , and we still consider the constraint in table  <dig> and the constraint ∧c ∧p , we obtain an inconsistency in  <dig> seconds.

so we consider in the following the proposed model with this auto-interaction onto hbz . obviously, cgap alone  is consistent according to the first query.

in previous applications the thresholds  are instantiated and equal to p, p taking a value between  <dig> and maxc. this implies that the concentrations of c can take values between  <dig> and maxc. insofar as the subdivision of the concentration space is only speculative, it is interesting to ask what is the smallest number of distinct thresholds necessary to get a model consistent with the observations. the extreme case would be the satisfaction of all observations and hypotheses with one threshold per component, i.e. with a boolean model. it appears that cgap plus ∧c ∧p  is inconsistent in  <dig> seconds. we can check easily this inconsistency: the constraint  is inconsistent with the observability constraint of  because no state s satisfies  i.e. the condition .

to identify the minimum number of different thresholds needed to satisfy all the observations and hypotheses, we must build a query using the method of relaxation of constraints. but in this case, the relaxation takes place on the number of thresholds in  <dig> .maxc for each component c.

to summarize, we challenge the hypotheses about the number of thresholds for all components. from a constraint point of view, this problem is specified and implemented in the following way. we introduce boolean variables bj,c equivalent to "the number of thresholds for c is less or equal to j", j being an integer in the interval  <dig> .maxc - <dig>  so we get six boolean variables in our case:  and  for hbz, b <dig>  kr for kr, b <dig>  bcd and b <dig>  bcd for bcd, b <dig>  cad for cad. then gnbox searches for models consistent with the set of constraints defined above such that the number of these boolean variables which are true is maximum. gnbox finds in  <dig> seconds that the only boolean variables to be false are  and b <dig>  cad. this indicates that hbz must have at least  <dig> different values of thresholds, and cad must have at least  <dig> different values of thresholds.

the last query gives, in  <dig> seconds, two possible instantiations of the  accepting cgap and the minimal number of thresholds given by the previous query: . one remarks that the three thresholds of hbz share only two values.

CONCLUSIONS
our methodology is composed of two parts:  a declarative constraint-based approach;  a formalism for the description of the dynamics of discrete networks. we have presented here applications involving gene regulatory networks whose behaviour is satisfactorily represented in the formalism of r. thomas. but it is important to note that the methodology can be applied to many other types of dynamical rules, such as hopfield-like networks, boolean networks with parallel, sequential or block-sequential updating. the only requirement is that the dynamical rules should be expressed as constraints on finite-domain variables. the potential domain of application of this methodology is thus much larger than just gene regulatory networks.

the thomas' networks have largely been applied to the analysis of grns, for example those described in  <cit>  or those described in  <cit>  which use a very similar qualitative formalism.

several modeling and simulation tools of biological regulatory networks  are used in combination with model checkers  and based on diverse formalisms . the idea is to add to the simulation functionality a formal verification functionality to check, or optimize  <cit> , the fitness between the simulated and the observed behaviours.

three types of abstractions are available in biocham, among which ordinary differential equations and boolean networks. the inference of parameters is based on the technique of model-checking and the definition of a continuous degree of satisfaction of a temporal logic formula formalizing some observation on behaviour. this permits to find biochemical kinetic parameter values which are optimal with respect to a set of biological properties. moreover it is possible to find the effect of parameter variations on the robustness of a behaviour specification  <cit> . our work differs significantly in that it focuses to face the problem of incomplete knowledge to produce, by a constraint-based process, a class of models from which it is expected to design new experiments.

a steady state search module, including the so-called singular states, exists in gna based on an integration of the sat solver sat4j  <cit> . this integration of a constraint approach avoids the generation of all the transitions to identify the steady states. but in contrast to our work aiming at providing general queries,  <cit>  focus on the search of steady states, and only in the case of completely instantiated models . the work in  <cit>  search the same steady states with a csp  formalization, the performances are worse than in  <cit> . in our work, we can write easily queries to identify steady states, and even cycles of length smaller than some predefined value. in addition in our case the kinetic parameters and the orders between thresholds can be only partially known. as explained here, other much more sophisticated queries are available, although in the current version we do not include singular states.

the formal approach proposed here modifies deeply the way to proceed in the building and in the exploration of genetic and biochemical networks, first by avoiding the usual trial-and-error procedure, and second by putting the emphasis on sets of solutions, rather than a single consistent solution arbitrarily chosen in a set. last, the constraint approach lends to a unified description of network architecture and network behaviour, as both are described in terms on formal constraints. the knowledge available to initiate the modeling of a given phenomenon is generally sparse with respect to the complexity of the behaviour of the underlying networks. it is thus essential to exploit consistently, efficiently, and in a joint manner, every bit of experimental information. the representation of knowledge in terms of constraints is a way to achieve, at least to some extent, this goal.

our environment gnbox implements a wide panel of functionalities: simulations, consistency proof, relaxation in case of inconsistency, search for a minimal model, prediction of properties in case of consistency. this last functionality generates properties which are verified by all solutions of the constraint pool. in line with what we said above, note that such properties are really supported by data. this contrasts with the usual practice of using just one solution to make prediction, neglecting the existence of other solutions. properties of the selected single model should not be considered as true predictions.

we have presented three biological applications illustrating the use of most of these functionalities. these applications involve networks containing about  <dig> species and  <dig> possible interactions, and with set of hypotheses and observations without systematic instantiation of threshold parameters, with a large range of types of behaviours. in the third application the queries involve several structurally related models in order to incorporate knowledge about wild-type and mutant behaviour, in four segments of the embryo. the set of constraints generates a dense network of dependencies between the variables. the performances of gnbox are good for the different types of queries presented in the three applications. the most computer-intensive queries are those involving paths. for such queries our approach is limited to networks of medium size.

the perspectives are governed by the biological problems. the methodologies and technologies employed must be chosen according to these problems. a first perspective is to prioritize biological experiments. for example, consider a situation in which the state of knowledge is such that the number of consistent instantiated models is still large, and it is possible to perform double knock-out experiments. in such situation it would be interesting to be able to determine the most informative choice of pairs of genes to target for knock-out, an informative experiment being one which will potentially add non redundant constraints and thus reduce the set of solutions. another perspective is to refine the abstraction of the discrete behaviours: for example by taking into account the trajectories sliding along the thresholds  <cit> , and taking into account the difference of delays of chemical reactions  <cit> . another perspective is the extended repairing consistency techniques adding species, related to the problem of composing networks  <cit> .

authors' contributions
the methods and applications was mainly developed by fc on theoretical foundation and ideas provided by ef and lt. all authors equally wrote this manuscript and approved it.

supplementary material
additional file 1
gnbox.

click here for file

 acknowledgements
this work was performed at the timc-imag laboratory. final editing of the manuscript was made while fc was at irisa-inria. the work was supported by microsoft research through its phd scholarship programme with a grant to fc. ef thanks ixxi  for partial financial support. we thank denis thieffry for helpful clarifications on the drosophila embryo segmentation model.
