BACKGROUND
the concept of a core collection was first introduced in  <cit>  and is defined as a representative subset of a given collection sampled with the goal of maximizing diversity and minimizing redundancy. today, very large germplasm collections numbering hundreds of thousands of accessions of cultivated species and their wild relatives are stored in gene banks throughout the world to preserve crop diversity for further research and application. due to the size of these collections maintaining all accessions in the active collection and thus in significant quantities to be accessible by researchers and plant breeders is economically prohibitive. creating core subsets for working collections offers an efficient way of characterizing and utilizing genetic resources without the need of maintaining the entire collection accessible for practical use.

to be able to generate diverse core sets we need evaluation measures that express the diversity of a given collection. these measures are based on a variety of criteria including phenotypic traits or genetic marker data  <cit> , or a combination of both  <cit> . many algorithms for core set selection have been proposed, including stratified sampling techniques. these stratified sampling strategies first perform a clustering of the entire collection and then sample accessions from each cluster, based on some allocation method. the clustering procedure may be based on criteria such as geographical origin, or some phenotypic or genetic distance measure and often hierarchical clustering methods, such as upgma  <cit> , are used for this purpose, e.g. in  <cit> . several allocation methods have been proposed including the p-, l- and d-methods.

the first two of these allocation methods were proposed by brown in  <cit>  and depend only on the size of the clusters, not on the diversity within each cluster. the p-method and l-method sample accessions from each cluster  proportionally to the cluster size and  proportionally to the logarithm of the cluster size, respectively. the d-method was later introduced in  <cit>  as a new allocation method which samples accessions proportionally to the diversity within each cluster so that more diverse clusters contribute more accessions, in order to obtain a high overall diversity in the resulting core. the authors showed that the d-method produced significantly more diverse core collections than other allocation methods.

another allocation method, the m-method, was proposed by schoen and brown in  <cit> . this method aims at maximizing the number of observed alleles at each marker locus  and determines sample sizes for each cluster according to this objective. the m-method is very useful for preserving rare, low-frequency alleles from the original collection when creating core sets. in fact, this strategy can also be implemented as a non-stratified procedure which samples a core subset directly from the entire collection, optimizing allelic richness. this strategy is employed by the mstrat computer program  <cit>  which uses the following steepest descent heuristic algorithm to guide the search:  a random initial core set of the desired size n is sampled from the entire collection of size n,  all possible subsets of size n− <dig> of the current core are evaluated and the subset retaining the highest allelic richness score is selected, and  from all currently unselected accessions, the accession bringing the highest increase in allelic richness is added to the core, again resulting in a core of size n. steps  and  are then repeated until no more improvement is observed or until a maximum number of steps have been performed.

it should be noted that the objectives of the d-method and mstrat differ. while mstrat aims at including rare and localized alleles by maximizing allelic richness, the goal of the d-method is a high representation of the original genetic diversity in the core by including widely adapted accessions that are genetically distant from each other. the former approach is favored by taxonomists and geneticists while the latter corresponds more to the breeder’s preference.

other non-stratified methods include genetic distance sampling and least distance stepwise sampling. genetic distance sampling  <cit>  constructs core sets where no two accessions are closer to each other than a given minimum distance threshold, according to some genetic distance measure. this method avoids the need to specify a desired core size, but introduces the threshold as a new input parameter. least distance stepwise sampling   <cit>  iteratively uses hierarchical clustering to determine which accessions to include or exclude from the core in each search step, until the desired core size has been reached. both of these methods actively use genetic distances during search, but none of them directly optimizes them.

all of the previously mentioned methods assume that the desired core size  is known in advance and given as input to the sampling strategy, and then try to create a good core set of the desired size according to the specific objective used. however, a related problem is that of finding the smallest possible core set that retains all unique alleles from the original collection. the powercore algorithm was presented in  <cit>  to solve this problem, using a heuristic version of the a∗ shortest path search algorithm. the authors showed that powercore was able to find quite small core sets which retained all of the original alleles.

core hunter was developed as a new, very flexible framework for selecting core collections  <cit> . like mstrat, core hunter treats core selection as a formal optimization problem by directly sampling from the entire collection, optimizing a given diversity measure. however, core hunter uses a more advanced local search technique, replica exchange monte carlo  search, to prevent the search stalling in local optima. remc uses the same criteria as a simulated annealing  <cit>  algorithm for accepting new solutions, except that here several replica solutions are being evaluated at any one time, each with a fixed temperature. solutions are swapped between neighboring replicas to push the most promising cores towards the coolest replicas, for the sake of convergence. we refer the reader to the original core hunter article  <cit>  for a detailed description of this technique. core hunter also allows the user to choose which diversity measure will be used for optimization, offering seven widely used genetic evaluation measures including two  genetic distance measures, three diversity indices and two auxiliary measures. furthermore, it is possible to optimize several measures at once by optimizing a pseudo-index which consists of a linear combination of several of these measures, where the user assigns a weight to each measure according to its importance. in this way one can find core sets with high average genetic distance between accessions and high overall diversity, bringing the breeder’s concept and taxonomist’s perspective closer together. core hunter is able to find as good or better core subsets than both mstrat and the d-method when optimizing a single measure. furthermore, when simultaneously optimizing several genetic measures, core hunter is often able to construct core sets which simultaneously have higher average genetic distance and overall diversity than any core reported by each of the other two methods. finally, core hunter is able to select smaller core sets than powercore that preserve all alleles from the original collection.

in this paper we present core hunter ii as an extension to the original core hunter framework. first we investigate if minimum distance measures, in addition to the available mean distances, ensure that accessions in the core will be sufficiently distant from each other. a second objective is to gain more insight into the performance of the remc search engine by comparing it with several other heuristic optimization methods implemented in the same flexible core hunter framework. in the original core hunter article  <cit> , the remc algorithm was only compared to external methods , which were implemented in different frameworks and did not allow the user to choose a specific optimization measure. implementing several techniques in the same framework allows us to make a fair comparison of the performance of these search techniques. finally, we assess if the performance of core hunter can be further improved in terms of the diversity of selected core sets or the runtime needed to compute them, by switching to a new advanced search technique that uses heterogeneous search replicas: mixed replica search .

methods
we use the same formal definition of the core subset selection problem and multi-objective pseudo-index as in  <cit> . here we give only a brief explanation of both concepts. for more details we refer the reader to  <cit> .

the core subset selection problem
given some collection s, a sampling intensity γ,  <dig> ≤ γ≤ <dig> and some diversity measure f , denote c as the set of all possible subsets of s of size n=γ∗|s|. we want to select an optimala core c∗∈c such that f=max{f|c∈c}.

the multi-objective pseudo-index
given any k measures fiand weights 0≤ai≤ <dig> i=1…kwith 

 ∑i=1kai= <dig> 

 the corresponding pseudo-index is defined as 

 f=a1·f1+a2·f2+…+ak·fk 

this pseudo-index has no biological meaning at all but just serves as a mean to optimize several measures at once according to their importance .

evaluation measures
the original version of core hunter only supports genetic marker data  and offers seven diversity measures, including two genetic distance measures, three allelic diversity indices and two auxiliary measures. we briefly discuss these here and refer to  <cit>  and  <cit>  for more details about these and other genetic diversity measures.

genetic distance measures are defined on pairs of accessions and express their similarity. the higher the distance between two accessions, the more genetically different they are and conversely highly similar accessions can be identified as those being very close to each other. to assess the diversity of an entire collection using a genetic distance measure, it is customary to report the mean distance between all pairs of accessions contained in this collection. these measures are especially useful for breeders who want to ensure that each accession in the selected core set is sufficiently different from the others. core hunter offers the modified rogers   <cit>  and cavalli-sforza and edwards   <cit>  distances which are both euclidean distances at the allelic level. while mr just treats each allele as a separate dimension using the allelic frequencies as coordinates, ce adopts the square roots of the allelic frequencies as an accession’s coordinates.

the allelic diversity indices are directly computed on the entire core set and are particularly useful for preserving rare alleles, which makes them very well suited for applications aimed at genetic conservation, such as sampling core collections from germplasm resources. three such diversity indices are available in core hunter:  shannon’s diversity index   <cit> ,  the expected proportion of heterozygous loci   <cit> , and  the number of effective alleles   <cit> . the sh diversity index aims for high allelic diversity in the entire sample, regardless of how different alleles correspond to certain markers, while both he and ne specifically consider diversity within marker loci.

finally, two auxiliary measures are also available, expressing the extent to which the original alleles from the entire collection are still present in the core. the allele coverage   <cit>  simply reports the percentage of preserved alleles and the proportion of non-informative alleles   <cit>  is defined as the complement of cv measuring the amount of alleles which were completely lost by going from the entire collection to the selected core set. note that pn is in fact a measure we want to minimize, while maximization is the goal for all six other measures. these auxiliary measures are generally not used as a single objective but as an extra constraint, where the primary goal is optimization of one or more other measures, through the use of a mixed pseudo-index. for precise definitions and formulations of each of these seven measures, we refer to  <cit>  and  <cit> .

minimum distance measures
when expressing the diversity of a collection using the mean distance between all pairs of accessions, it is not clear whether optimizing this mean value will in fact lead to cores in which all accessions are sufficiently distant from each other. high mean distance does not a priori imply high minimum distance too, so we have extended the core hunter framework with two additional distance measures which report the minimum instead of mean distance between all pairs of accessions:  minimum modified rogers  and  minimum cavalli-sforza and edwards . we will first assess to what extent optimizing only mean distance leads to high minimum distances and then we will investigate whether it could be beneficial to include these minimum distances in the objective function, either as a replacement for mean distance measures, or in combination with them.

performance of remc
to gain more insight into the performance of the remc search algorithm that is implemented in the core hunter software, we compared its results with those of several simpler methods, implemented in the same flexible core hunter framework. all of these are well known basic heuristic search methods: 

 <dig>  standard local search  starts with a random solution and then iteratively samples random neighbor solutions, accepting them as the new solution if and only if they are better than the current solution. for our application, we use a so called single perturbation neighborhood, which contains all core sets differing in at most one accession from the current core. possible operations are addition, deletion and swap of one accession.

 <dig>  mstrat steepest descent: as mentioned before, core hunter was previously compared with the external mstrat program  <cit> , which did not allow the user to choose a specific optimization measure. we have implemented the corresponding steepest descent technique from mstrat  <cit>  within the core hunter framework for a more fair comparison of the remc and mstrat search engines.

 <dig>  lr greedy search is a deterministic algorithm that does not take any randomized decision  <cit> . lr search starts with the empty solution and then iteratively  adds the accession that gives rise to the highest increase in diversity, repeated l times,  removes an accession while retaining as much of the diversity as possible, repeated r times, and  loops back to step . the search terminates when the desired core size has been reached. for our experiments, we set l= <dig> and r= <dig>  resulting in the deterministic lr algorithmb that always performs n steps of first adding  <dig> and then again removing  <dig> accession, where n=|core|=γ·|s|.

for the first two methods and remc, the stop criteria that decide when to terminate the searchc are:  maximum runtime –  <dig> seconds by default,  minimum progression, and  maximum time without improvement . the lr method does not accept such stop criteria as it simply terminates when the desired core size has been reached. for our experiments we set a maximum runtime limit for each randomized algorithm and record both the diversity of the resulting core sets and the corresponding convergence time, which is defined as the point in time from which no more improvement was observed when all figures were rounded to  <dig> decimal places.

the goal of the comparison is to find out when simple methods break down and where it would be better to turn to more advanced methods such as remc. these results will give us more insight into the specific characteristics of those problems on which simple methods do or do not fail.

mixed replica search
in addition to our comparison of remc with these simpler methods, we also present a new advanced search engine that is inspired by the replicated approach of remc, but uses heterogeneous instead of homogeneous replicas, which implement different search techniques. we experimented with several simple methods, including those explained in the previous section, and several more advanced heuristics to assess whether we could improve on the results of remc. we observed that different methods outperformed remc in several experiments in respect to either the runtime or diversity score, but each method had some drawbacks. thus, we decided to design one robust mixed replica search engine  which combines the strength of several search techniques, to be able to tackle different problems with different techniques without the need of determining in advance which technique is more suited to a specific problem.

the mixrep algorithm is based on four different types of replicas, consisting of two simple and two more advanced search techniques: 

 <dig>  lr semi replica : a modified version of the deterministic lr search avoiding the overhead of exhaustively sampling the first pair of accessions. this replica starts with two randomly chosen accessions and thus introduces a small random effect making the resulting technique no longer purely deterministic.

 <dig>  local search replica : this replica performs standard local search using the previously described single perturbation neighborhood.

 <dig>  tabu search replica : a more advanced technique, based on steepest descent, which always continues with the best neighbor of the current solution even if it is worse than the current solution, but skipping those neighbors that have been declared tabu. in theory all previously visited solutions should be declared tabu. this technique prevents the search from continuously revisiting previous solutions and from traversing cycles within the search space. our implementation of tabu search uses the steepest descent technique from mstrat to construct neighbors.

 <dig>  simple monte carlo replica : these replicas are exactly the same as those used in the remc search algorithm  <cit> , except that solutions are not exchanged between replicas as the search progresses and temperatures are chosen that are rather low because these advanced replicas are only used in areas containing solutions that are already quite promisingd.

the algorithm uses only one single lr replica as this method is deterministic  so its results show little to no variation. the other three replicas are used repeatedly with different initial solutions. the search process can be described as follows: 

 <dig>  one lr replica is created, initialized with a random pair of accessions and activated to run in the background until its search process is complete.

 <dig>  several ls replicas are created and randomly initialized with core sets of the desired size.

 <dig>  until some stop criterion is met, consecutive search rounds are performed containing the following steps: 

 all replicas perform some search steps, independently of the other replicas.

 the best solution over all replicas is tracked and improvements are reported.

 regularly, new advanced replicas are created  and initialized with new cores, obtained by merging promising solutions from the current replicas.

 replicas which did not improve on their current solution during their last couple of search steps are considered to be stuck and subsequently removed.

 if the global improvement drops below a certain threshold or if there was no improvement at all for some time, the search is boosted by adding several new randomly initialized ls replicas to provide new variation.

note that in step  replicas perform their search steps independently from each other, which is in fact also the case in the replicated remc algorithm  <cit> . however in the original core hunter implementation of remc the different replicas performed their steps sequentially without taking advantage of this independency. we developed an implementation of step  of the mixrep algorithm that allows the different replicas to be run in parallel in order to achieve an additional improvement in runtimes when computing core sets on machines that have multiple cores and/or processors. in step  initial solutions for the new replicas are created by selecting two promising parent solutions from the current replicas and randomly merging these together, an idea inspired by genetic algorithms  <cit>  combining several current solutions into new children.

for specific details concerning the mc replicas we refer to  <cit>  as these are the same as those used by remc, except here they are set with rather low temperatures. the tabu replicas perform a modified version of the theoretic tabu ideology that was explained before. in practice declaring all previously visited solutions tabu both requires  a lot of memory to store the history containing all these solutions and  many computations to check whether some new solution is already present in the history and therefore tabu. this check is especially complex and time consuming because every solution is in fact a set of accessions that needs to be compared for equality and not just a singe accession. therefore, a limited history  is maintained that only remembers the most recent solutions and forgets everything that happened before. the scope of the history is controlled by the tabu list size which defines how many previous steps are remembered. even then, storing and comparing entire core sets in this history is highly impractical. therefore, instead of declaring the exact solutions tabu, we declare some specific actions tabu, which are well chosen to prevent returning to these previously visited solutionse. when the current solution has been perturbed into one of its neighbors by changing the accession at index i, changes at this index are no longer allowed as long as the tabu list contains the index i. this way we only need to store a list of integers, which uses less memory and allows for fast comparison, and still fulfills the requirement that previously visited solutions are defined as tabu. however, this method also declares some other solutions tabu, which may not yet have been visited at all, making this approach too restrictive and possibly prohibiting some very promising solutions. therefore, we add an aspiration criterion that overrides the tabu in case of a neighbor having a higher score than the currently-known best solution. in this case such solution is clearly only tabu due to the index approach and cannot have been visited before. it has to be noted however that this is still more restrictive than storing all previously visited solutions in a tabu list.

in summary, the mixed replica algorithm starts with some simple, fast methods to perform an initial exploration of the search space. afterwards, more advanced methods take over, starting in these areas where the simple methods had arrived. on average these areas of the search space contain generally better solutions, thus presenting a more difficult task of further improving on the current solution. as soon as little or no more improvement is being made the search is boosted by introducing new simple, fast methods, starting from new random points in the search space to supply new variation. the best solution over all replicas is tracked at all times and reported when some stop criterion is met, by default after a maximum total runtime of  <dig> seconds.

datasets
we performed intensive experiments using five different realistic datasets, including the larger two datasets used in the original core hunter article  <cit> : the bulk  <cit>  and accession  <cit>  maize datasets. in addition to these maize datasets we also performed experiments for three larger sets including one flax  <cit>  and two pea  <cit>  datasets. details concerning these five datasets are given below: 

● ‘bulk maize data set’  <cit> : 

  –  <dig> samples, genotyped at  <dig> ssr loci with  <dig> total alleles

  – obtained by fingerprinting  <dig> bulks of maize landrace populations, each containing multiple maize individuals from the americas and europe using  <dig> multi-allelic ssr markers

● ‘accession maize data set’  <cit> : 

  –  <dig> samples, genotyped at  <dig> ssr loci with  <dig> total alleles

  – obtained by fingerprinting  <dig> maize individuals from  <dig> different populations using  <dig> multi-allelic ssr markers

● ‘flax data set’  <cit> : 

  –  <dig> samples, genotyped at  <dig> irap loci with  <dig> total ‘alleles’

  – obtained by fingerprinting  <dig> bulks of  <dig> flax individuals each using  <dig> irap markers ; only two possible states occur for each bulk at each marker locus:  presence of allele and  absence or marker failure, where it is not possible to distinguish between these last two states

● ‘pea data set’  <cit> : 

  –  <dig> samples, genotyped at  <dig> rbip loci with  <dig> total ‘alleles’

  – obtained by fingerprinting  <dig> bulks of  <dig> pea individuals each using  <dig> rbip markers, with  <dig> different possible states for each bulk at each maker locus:  presence of allele in each individual,  absence in each individual,  mixed state having both individuals with presence and absence in the same bulk, and finally  the zero state which means no data is available

● ‘large pea data set’  <cit> : 

  –  <dig> samples, genotyped at  <dig> rbip loci with  <dig> total ‘alleles’

  – obtained in the same setting as the previous dataset, but containing significantly more samples 

implementation and hardware
extensions to the original core hunter software were implemented in java , starting from the original code which was kindly provided by the authors. all of our main experiments were performed on a  <dig>  ghz intel core i <dig> dual core macbook pro with  <dig> gb of ram and  <dig> kb of cpu cache per core. some additional experiments were run on the ugent ‘helios’ computing server, a  <dig> ×  <dig> core machine which has two 6-core  <dig>  ghz intel xeon x <dig> processors,  <dig> gb of ram and  <dig> mb cache for each cpu, running debian linux. we will explicitly note which experiments were run on this helios server.

the statistical r software was used to produce all visualizations of datasets and sampled cores. principal component analyses were performed using the built-in r command prcomp.

RESULTS
first we will present results of a comparison of remc with the more simple methods described in the previous section, using the original core hunter evaluation measures. then we will illustrate a possible problem regarding minimum distances if mean distances are optimized alone, using some generated toy example datasets of low dimensionf. next, the impact of including these newly introduced minimum distances in the objective function when sampling from the realistic datasets will be discussed.

based on these results, we will give further motivation of the specific composition of our new mixed replica algorithm and then we will discuss this method’s performance regarding both the diversity of the constructed core sets and the runtimes until convergence. to investigate the impact of the sampling intensity on the performance of our algorithms, all experiments have been repeated for two different sampling intensities : 20%  and 5% , both within the range of sampling intensities proposed in previous research  <cit> .

performance of remc using original measures
*for each combination of algorithm, dataset and evaluation measure,  <dig> independent runs were performed from which averaged results are reported. by default runs were limited by a runtime of  <dig> seconds, except for the large pea dataset where a runtime limit of  <dig> minutes was applied. furthermore the lr method does not accept a runtime limit but continues search until the desired core size has been reached.

**results shown are those of a pseudo-index containing all seven measures with equal weights.

▾these results were computed on the helios server.

as we can see, results are very similar for each of the four algorithms. the advanced remc algorithm never outperforms all of the simple methods when comparing the diversity scores of the constructed core sets for a specific dataset and evaluation measure. more accurately, remc never outperforms lr search and only occasionally presents slightly better results than local search and/or mstrat. except for the smallest  maize dataset, some or even all simple methods often slightly outperform remc. however differences in diversity are never significant. the largest difference is observed when optimizing the mixed objective function for the large pea dataset, where both local search and lr outperform remc with a relative improvement of about 4%. it should be noted that in this case lr takes much more time than the runtime limit imposed on the other methods.

for the large pea dataset in general both remc and mstrat result in somewhat worse scores than local search and lr. furthermore simple local search is much faster than any other method including remc, with convergence times below one minute for each single measure and of about  <dig> minutes in case of a mixed objective. although lr reaches very similar or the same scores as local search for this large dataset, it is a lot slower with runtimes up to several hours. this longer runtime is due to the fact that lr starts with an empty solution and has to perform a fixed number of steps relative to the core size, which depends on the original dataset size and given sampling intensity. for large datasets and intensities, this process becomes slower and for the evaluation measures used it clearly does not offer any gain in diversity compared with the very fast local search. a similar speed issue also applies for mstrat, as this method evaluates many neighbors in each step, again relative to the dataset size. furthermore, mstrat sometimes results in lower scores than local search, for example in the case when analyzing the large pea dataset.

for the smaller datasets runtimes of local search are also often significantly lower than those of the advanced remc method, which is not surprising since remc performs computations for several search replicas. it is mainly due to this reduced runtime that local search is sometimes able to construct slightly more diverse core sets than remc, within the imposed time limit. by performing some informal experiments with higher runtime limits, we learned that in most cases remc finds these results too when given more time.

*for each combination of algorithm, dataset and evaluation measure,  <dig> independent runs were performed from which averaged results are reported. by default runs were limited by a runtime of  <dig> seconds, except for the large pea dataset where a runtime limit of  <dig> minutes was applied. furthermore the lr method does not accept a runtime limit but continues search until the desired core size has been reached.

**results shown are those of a pseudo-index containing all seven measures with equal weights.

▾these results were computed on the helios server.

we conclude that for the original core hunter evaluation measures, simple methods perform very well. in most of our experiments at least one and often all simple methods were able to construct equal or slightly more diverse core sets than remc, while their runtimes are often significantly lower, especially those of simple local search. runtimes of both lr and mstrat are very sensitive to the dataset and core size, so these methods become slower for large datasets and intensities. in case of fairly low sampling intensities it is harder for the simple methods to create good core sets and in this case they are sometimes just outperformed by remc, but differences are never significant. so in conclusion for these measures simple methods present very similar results while often using less computation time. simple local search is clearly the fastest of all considered methods and often it also gives the best results. it should be noted however that when comparing the results of the simple methods, it is not always the same method that outperforms all the others.

minimum distance measures
when sampling core collections from these datasets with the objective of optimizing mean mr distance , remc constructed the core sets displayed in figure  <dig> and  <dig>  it is clear that both of these cores have a very low minimum distance and that they are not at all representative of the structure of the original collections, although high mean distances have indeed been obtained. the selected core shown in figure  <dig>  which is sampled from the clustered dataset, simply consists of several very dense extreme clusters but to create a representative core we should in fact sample accessions from many different clusters. optimizing only the mean distance seems to select accessions near extremes along the various dimensions, which indeed leads to high mean scores. in our examples this effect results in sampling some very similar or even identical accessions, where the latter are defined as accessions for which all available allelic frequencies are equal. one possible problem is that selecting extremes is not sufficient to reach high minimum distances when the size of the sampled core is significantly larger than the dimension of the dataset. in addition to selecting extremes, we should sample many accessions in between the extremes to keep them sufficiently distant from each other. although both of these toy examples are clearly extreme cases, datasets with many accessions and relatively few total alleles do in fact also occur in practice  and therefore we should be careful when only optimizing mean distances. furthermore, many possible core subsets have highly similar mean distances and it might very well be possible to select one which does have high minimum distance, while still retaining high mean distance.

figures  <dig> and  <dig> display core sets that were constructed by remc optimizing minimum instead of mean mr distance . both of these cores are more representative for the original collection than those obtained by optimizing mean distance. the core displayed in figure  <dig> clearly contains accessions from many or even all different clusters instead of just some extreme clusters. by optimizing minimum distance the extremes are still included in the cores, but many accessions in between these extremes were also sampled. these results indicate that it is useful to include minimum distances in the objective function, possibly replacing mean distances or in combination with them, to create cores with high distance between each pair of accessions.

performance of remc using minimum distances
now we will present results of using these new minimum distance measures when sampling from realistic datasets. table  <dig> presents results of optimizing minimum versus mean mr distances with a sampling intensity of 20%, for remc and the three simple methods. for each combination of dataset and algorithm, three different experiments were performed:  optimizing mean mr alone ,  optimizing minimum mr alone , and  optimizing a mixed objective which contains both, with an equal weight of  <dig>  . for the first two cases, averages of the other measure’s score  are also shown, which were computed afterwards on the constructed cores and were not used during optimization. in case of the mixed objective, the mrmin and mr components are presented so we can compare both the mean and minimum distances of these cores with those constructed in other experiments.

*for each combination of algorithm, dataset and evaluation measure,  <dig> independent runs were performed from which averaged results are reported. by default runs were limited by a runtime of  <dig> seconds, except for the large pea dataset where a runtime limit of  <dig> minutes was applied. furthermore the lr method does not accept a runtime limit but continues search until the desired core size has been reached.

**results shown are those of a pseudo-index containing both minimum and mean mr distance, with equal weight =  <dig> .

∙not used during optimization, but computed afterwards on the constructed core sets.

∘components of mixed mr measure.

▾these results were computed on the helios server.

the results show that differences between diversity scores reported by the different algorithms are generally much bigger here than for the original core hunter measures discussed before. local search and mstrat perform worse than lr and remc in all experiments using either mrmin or the mixed mr objective. the differences are more obvious for the larger datasets where it is more difficult to obtain high minimum distances because more accessions have to be selected. in this case both local search and mstrat break down when minimum distances are included in the objective. as this effect was already clearly visible from the results of the first four datasets, local search and mstrat were not used for the large pea dataset experiments. interestingly it is not the advanced remc, but lr which leads to the highest minimum distances for the larger datasets. only for the smallest dataset  does remc outperform lr and differences between their results increase for larger datasets.

when using mean mr alone, sampling from both pea sets leads to a minimum distance of zero for all algorithms, which means that accessions that are identicali have been selected. in fact these datasets suffer from the same problem as the toy examples presented before, having many accessions and only few total alleles. the size of the selected core  is significantly larger than the dimension of the dataset . optimizing only mean distance is not enough to guarantee high minimum distance and for these sets some identical accessions were selected in the core. yet, by using the mixed mr objective, the lr method is able to sample cores from the smallest pea dataset with a quite high minimum mr distance of  <dig>  while retaining a mean mr of  <dig> , only less than 2% lower than the value of  <dig>  which was obtained when optimizing mean mr alone. even for the large pea dataset, lr reports a fairly large minimum distance of  <dig>  together with only a small decrease of less than 3% in mean distance score. note that remc – even when using the mixed objective – reports much lower minimum distances for these pea sets. for the large pea dataset remc still samples cores with zero minimum distance. these results suggest that much higher minimum distances can be reached, while retaining similar mean distances, by including both measures in the objective function and using a well chosen, suitable algorithm.

for the smaller datasets, this same conclusion holds. although these datasets don’t suffer from the dimensionality problem and already reach acceptable minimum distances with mean mr alone, using the mixed mr objective still results in higher minimum distances while retaining most of the mean score, compared to mean mr alone. across all experiments, gains in minimum distance range from  <dig> % to  <dig> % , while losses in mean are always smaller than  <dig> %. for these datasets therefore it might also be useful to include minimum distances in the objective.

optimizing minimum distance alone however would not be a good idea, because this presents two problems originating from the fact that many sets have exactly the same minimum mr distance. first, some of these sets might very well have higher mean values than others and we want to favor these. second, having many possible cores with equal score makes finding a good solution more difficult to solve with optimization algorithms. this effect can be noticed in our results, as the obtained minimum distance values are often higher when optimizing the mixed mr objective compared to optimizing minimum distance alone. minimum distances should therefore be used as additional constraints by including them in the objective without leaving out the original mean distance measures.

finally it should again be noted that although lr seems to be very well suited for optimization of minimum distances this method becomes slower for large datasets. this problem with lr is most obvious in the case of large datasets and intensities leading to large core sizes, because of its deterministic nature, starting with an empty solution. for the large pea dataset lr requires much more time than the runtime limit applied to remc. because of this big difference in runtimes for the large pea dataset we experimented with applying higher runtime limits to remc, but even when going up to a limit of  <dig> hours instead of  <dig> minutes results of remc almost do not improve compared to the results shown in table  <dig>  and remc still does not succeed in sampling cores with non-zero minimum distance . so it is clear that lr is indeed more suited for optimizing minimum distances than any of the other methods. however if minimum distances are not important the lr method should not be used in favor of simple local search, as then local search samples similar cores quicker. only when high minimum distances are required it might be worth running lr and waiting somewhat longer for the results.

to investigate the results in greater detail we performed a principal component analysis  of several core sets selected from the large pea dataset and compared the distribution of the distances between these selected accessions and those of the entire collection. figure  <dig> presents pca plots of cores  selected by the lr method optimizing mean mr alone  and 2) and the mixed mr objective  and 2) with a sampling intensity of 20%. the core plots only show the first two principal components for clarity. however, some of the additional components still showed significant variance after pca analysis, so we filtered both the original dataset and selected cores by removing all accessions which had extreme values in at least one of these dropped components, where extreme means beyond the inner 75% of its total range, to get a clear view of the structure of the selected cores regarding only these first two principal components.

these plots indicate that both the selected core accessions and their corresponding distances are quite similar for both objective functions, with two important differences. first, the core plots clearly show that when optimizing mean mr alone, several identical accessions are selected , while none of these are selected using the mixed distance measure. second, using mixed mr leads to the selection of more intermediate accessions, while mean mr leaves more of a gap near to the center of the space. similar differences can be observed from the corresponding distance distributions. the histogram in figure  <dig>  shows a small peak at the zero distance indicating some identical accessions are present inside the core. even though relatively few identical accessions were selected with respect to the total core size, these are still of no practical use and should be avoided if possible. figure  <dig> again shows that these identical accessions have been successfully avoided by using the mixed objective and in return some more intermediate accessions were selected as indicated by the slightly higher peaks near the mean of the distribution. besides these small but yet important differences, both distributions are similar which explains the similar mean distance scores of both approaches. furthermore, the mean of both distributions has been successfully shifted to a significantly larger value than that of the original distribution, shown in the background.

*for each combination of algorithm, dataset and evaluation measure,  <dig> independent runs were performed from which averaged results are reported. by default runs were limited by a runtime of  <dig> seconds, except for the large pea dataset where a runtime limit of  <dig> minutes was applied. furthermore the lr method does not accept a runtime limit but continues search until the desired core size has been reached.

**results shown are those of a pseudo-index containing both minimum and mean mr distance, with equal weight =  <dig> .

∙not used during optimization, but computed afterwards on the constructed core sets.

∘components of mixed mr measure.

▾these results were computed on the helios server.

we conclude that local search is no longer the most promising method when minimum distances are included in the objective. as minimum distances are much more sensitive to the exact composition of the core than mean distances, we need better methods in this case. the lr method seemed to be very well suited for these more difficult problems, and was often much better than the advanced remc method. lr can become quite slow, especially in case of large datasets and intensities, but depending on the application this significant increase in minimum distance could be worth the extra runtime. however, in cases where high minimum distance is not required, the performance of lr over local search does not warrant the extra runtime required by lr.

mixed replica search motivation
based on the results from the previous subsections we are now able to give further motivation for the specific composition of our new mixed replica search  algorithm. we showed that the simple methods performed very well in many experiments, but it was not always the same method that was the most promising and each of the simple methods has its drawbacks. local search and mstrat clearly cannot cope with minimum distance measures, and both mstrat and lr search become slower when run on relatively large datasets. including several methods in one robust algorithm avoids the need of selecting the most suitable method. as local search is the fastest method and lr is better when including minimum distances in the objective, we decided to use both these methods in the initial search phase. however, the results showed that in some cases the advanced remc slightly outperformed the other methods in terms of diversity scores. to benefit from advantages of both the simple methods and remc we used a mixed replica approach, which contains lr and local search replicas at the start. additional advanced search engines are then included in later stages of the search  to find better scores not obtainable by the simpler methods, if such scores are possible in the dataset. in this way our method will be able to tackle different problems in an efficient way, with fast computation on simple problems and yet very good results in more difficult settings, if additional runtime is available.

performance of mixed replica search
now we will present results for our new robust mixed replica search and compare these with the results of the original remc core hunter algorithm. table  <dig> shows diversity scores and runtimes for both methods with a sampling intensity of 20%, using the original core hunter evaluation measures, either single or mixed where the mixed measure again also includes both auxiliary measures . as we can see, mixrep always samples cores with equal or even slightly higher diversity scores than remc within the applied time limit. the largest increase in diversity  is observed when optimizing the mixed objective on the large pea dataset. more importantly, overall runtimes are significantly lower for the mixrep algorithm than for remc.

*for each combination of algorithm, dataset and evaluation measure,  <dig> independent runs were performed from which averaged results are reported. by default runs were limited by a runtime of  <dig> seconds, except for the large pea dataset where a runtime limit of  <dig> minutes was applied.

**results shown are those of a pseudo-index containing all seven measures with equal weights.

▾these results were computed on the helios server.

results for the same experiments, but now with a sampling intensity of only 5%, are reported in table  <dig> and for this lower sampling intensity the same observations hold. here, in most cases mixrep and remc sample cores with exactly the same diversity scores. only for the large pea dataset is there a small but consistent improvement of mixrep over remc. again the most important observation is that mixrep is clearly the faster method. we conclude that for the original core hunter measures mixrep is much faster than remc and yet samples cores with equal or sometimes slightly higher diversity scores. for these measures mixrep leads to results very similar to those of local search, which were discussed in the previous subsections, and therefore is generally faster than the other methods with only a small time overhead caused by the other replicas  in the advanced mixrep algorithm.

*for each combination of algorithm, dataset and evaluation measure,  <dig> independent runs were performed from which averaged results are reported. by default runs were limited by a runtime of  <dig> seconds, except for the large pea dataset where a runtime limit of  <dig> minutes was applied.

**results shown are those of a pseudo-index containing all seven measures with equal weights.

▾these results were computed on the helios server.

our previous results showed that including the new minimum distance measures in the objective function, together with the original mean distances, can lead to cores with higher minimum distance while retaining similar means. table  <dig> compares results of mixrep and remc when optimizing such a mixed objective, which includes both mean and minimum mr with equal weight. with a sampling intensity of 20%, mixrep selects cores with higher minimum distances than remc for all datasets, except the smallest maize  dataset for which scores are almost equal, while retaining similar mean distances. for the large pea dataset mixrep even leads to a larger mean component than remc in addition to a significant increase in minimum score. the highest increase in mixed score  is observed for the large pea dataset. this dataset, which is the largest of those tested, also has a relatively low dimension and thus presents a difficult problem when high minimum distances are desired. runtimes of both methods are often similar. mixrep is occasionally faster than remc, e.g. for the accession maize and flax datasets, but mixrep is slower for large datasets because of its lr component. for the large pea dataset, mixrep is significantly slower than remc, but again here it does lead to the highest improvement.

*for each combination of algorithm, dataset and evaluation measure,  <dig> independent runs were performed from which averaged results are reported. by default runs were limited by a runtime of  <dig> seconds, with some exceptions. for the small pea dataset with an intensity of 20%, a runtime limit of  <dig> seconds was applied. for the large pea dataset runtime limits were set to  <dig> minutes for the 5% intensity and  <dig> hours for the 20% intensity.

**results shown are those of a pseudo-index containing both minimum and mean mr distance, with equal weight =  <dig> .

∘components of mixed mr measure.

▾these results were computed on the helios server.

in case of a lower sampling intensity of only 5%, results of both methods are similar in most cases. only for the pea datasets does mixrep lead to higher scores than remc with a significant relative improvement in mixed score  for the large pea set, caused by a large increase of the minimum component while again retaining most of the mean component. it is interesting to note that for this large pea dataset, remc samples cores with zero minimum distance in all experiments, including some identical accessions in the core, while mixrep always leads to non-zero minimum distances. similar results for a mixed measure containing both minimum and mean ce are reported in .

we conclude that when aiming at high minimum distances the results of mixrep are very similar to those of the lr method and therefore often significantly better than those of all other methods . the new mixrep algorithm is often able to sample cores with much higher minimum distances than remc, especially for these datasets where it is more difficult to reach these high minimum values e.g. datasets with large size and/or low dimension. however for these larger datasets, mixrep is slower than remc but then gains in minimum distance are very high.

CONCLUSIONS
our results show that when aiming at core subsets in which all accessions are sufficiently distant from each other including minimum distance measures in the objective function, in combination with the original mean distance measures, improves performance. this additional measure often leads to cores with significantly higher minimum distances while retaining very similar mean distance scores compared to optimizing mean distance alone.

with core hunter ii we have introduced a new advanced search algorithm – mixed replica search  which uses heterogeneous replicas, an approach inspired by the results of a comparison of several algorithms – and showed that this new method improves on the results of the original remc algorithm in two different ways. when optimizing the original core hunter evaluation measures  the new mixrep algorithm samples cores with equal or slightly higher diversity scores than remc, while being much faster. secondly, when minimum distances  are included in the objective to avoid selection of identical or very similar accessions inside the core, using mixrep instead of the original remc often leads to significantly higher minimum distance scores. this effect is most obvious in case of large collections with relatively low dimension when sampling with fairly large intensities. for these large datasets, it does take more time to reach high minimum distances so it is important to apply higher runtime limits to achieve this goal. however the beauty of the mixrep algorithm is that in the case where minimum distances are not important, one can simply apply lower runtime limits and the same algorithm will quickly sample very good cores in terms of the remaining evaluation measures.

future work concerning new versions of core hunter includes adding support for phenotypic variables, as for now only genetic marker data are supported. furthermore, core hunter is currently freely available, but only as a command-line tool so development on a rich graphical user interface has already begun to provide user-friendly access to this core selection tool. finally it might also be interesting to try to further improve results by plugging in new search engines inside the mixrep replicas. for example the current lr replica is quite slow for large core sizes, although including this replica does lead to significantly better results in terms of minimum distance scores. it may be useful to look for faster search replicas which also have this interesting property, to speed up the mixrep algorithm when aiming at high minimum distances.

endnotes
aoptimal only in theory for large datasets, where evaluating all possible subsets is computationally infeasible. in practice we turn to heuristic methods that cannot guarantee an optimal solution, to keep the search process feasible.bbecause our distance measures cannot be computed on sets containing less than two accessions, we have slightly modified this approach by exhaustively selecting the best first pair and then proceeding with the lr scheme. selecting two accessions by exhaustive search is still computationally feasible.cthese same stop criteria are available for all randomized heuristics introduced in this paper.dtemperatures of newly created mc replicas are chosen randomly between a given minimum and maximum temperature. by default these are set to  <dig>  and  <dig>  respectively, and if desired the user can specify other minimum and maximum values using the advanced search options.emodifications of this kind are frequently applied when using tabu search in practice, to avoid excessive memory usage and computation time.fas noted before, distance measures treat each allele as one dimension so the dimension of a dataset is defined as the total number of alleles over all marker loci.gthe actual runtimes might slightly exceed this limit as the elapsed runtime is only checked after each search round and some algorithms implement quite intensive search rounds performing several search steps, possibly for several replicas.hnote that these convergence times are bounded by the runtime limit and it is always possible that further improved would have been made beyond this limit.iby identical we mean that the accessions can not be distinguished from one another using the available data. the accessions have the same alleles for all available markers used within the dataset.

competing interests
the authors declare that they have no competing interests.

authors’ contributions
hdb proposed the algorithm, implemented it, and performed all new experiments under the supervision of vf. ps provided data, advice on experiments and biological interpretation of the results. gd provided advice on algorithm development. hdb wrote the initial manuscript with all authors contributing to the final version. all authors read and approved the final manuscript.

supplementary material
additional file 1
“supplementary_results.pdf” — supplementary results. this file contains some supplementary tables which are numbered with prefix s . these tables contain results of additional experiments that are similar to those which have been included in the main article itself .

click here for file

 acknowledgements
ps acknowledges funding from bioversity international aegis loa10/ <dig> and the ministry of education, youth and sports of the czech republic . data contributing to the pea dataset was provided by noel ellis from aberystwyth university, uk and r. redden from atfc, australia. chris thachuk, university of british columbia, canada kindly provided the source code for the original core hunter software.
