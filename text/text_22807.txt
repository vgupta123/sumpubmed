BACKGROUND
optimization plays a key role in computational biology and bioinformatics  <cit> . dynamic optimization, also known as open-loop optimal control, seeks the maximization or minimization of a suitable performance index  of a dynamic system taking into account possible equality or inequality constraints. the solution is represented by the optimal decision variables, which can be continuous , discrete , or both. continuous variables can be used to encode time-varying stimuli, while discrete variables usually represent events  or configurations. an overview of optimization in the context of computational systems biology was given by  <cit>  and more recently by  <cit> , the latter highlighting the need of robust and efficient dynamic optimization methods. examples of relevant problems covered there include optimal control for modification of self-organized dynamics, optimal experimental design, dynamic flux balance analysis, the discovery of biological network design strategies and computational design of integrated biological circuits .

a popular numerical approach for solving dynamic optimization problems is the control vector parameterization  method  <cit> , which transforms the original problem into an outer non-linear programming  or mixed-integer non-linear programming  problem, with an inner initial value problem . solving the outer problem requires a suitable nlp solver. since most biological systems are non-linear, the resulting optimization problems are frequently multimodal and very challenging to solve, so it is necessary to use proper global optimization methods  <cit> .

this work presents dotcvpsb, a user friendly matlab dynamic optimization toolbox based on the cvp method, which provides an easy to use environment while ensuring a good numerical performance. users only need to define their dynamic optimization problems via a simple and compact input file which is close to the standard mathematical notation. advanced users can tweak many configuration options for the different solvers in order to fine-tune the solution process. although other existing toolboxes and software packages allow the definition and solution of optimization problems in systems biology , they are restricted to problems where the decision variables are static . dotcvpsb allows the definition and solution of dynamic optimization problems where decision variables are time-dependent, thus reaching a much broader class of optimization problems.

implementation
in this section, we first describe the class of problems considered and the framework chosen for its numerical solution. next, we describe the organization and capabilities of the toolbox, highlighting its key features and modules.

mixed-integer optimal control problem
the mixed-integer optimal control problem, also called mixed-integer dynamic optimization  problem, considers the computation of time dependent operating conditions , discrete – binary or integer- decisions and time-independent parameters so as to minimize  a performance index  while keeping a set of constraints coming from safety and/or quality demands and environmental regulations. mathematically this is formulated as follows:

find u, i, p and tf so as to minimize :

   

subject to:

   

   

   

   

   

where  is the vector of state variables,  is the vector of real valued control variables,  is the vector of integer control variables,  is the vector of time-independent parameters, tf is the final time of the process, me, mi represent the number of equality and inequality constraints, respectively and g collects all state constraints, pathway, pointwise and final time constraints and ul, il, pl, uu, iu, pu correspond to the lower and upper bounds for the control variables and the time-independent parameters.

control vector parameterization
dotcvpsb is based on the control vector parameterization  framework to solve the class of problems stated above. the cvp methodology proceeds dividing the control variables  and i) into a number of elements and then approximating each element by means of different basis functions, usually low order polynomials. in this way the control variables are parameterized using wu ∈ rρ and wi ∈ zρ, which become decision variables. this parameterization transforms the original infinite dimensional problem into a finite dimension  non-linear programming problem that may be solved by a suitable nlp solver. note that the evaluation of the objective function and constraints requires the solution of the system dynamics by solving an inner initial value problem .

if the outer nlp problem is convex, deterministic  local methods are the best alternative to efficiently solve it. in this regard,  sequential quadratic programming methods, such as misqp  <cit> , can be considered the state-of-the-art. nevertheless, in presence of non-convexities, local methods usually present convergence to local minima, thus requiring the use of global optimization methods.

global optimization methods can be roughly classified in two major groups: deterministic and stochastic methods. certain deterministic global methods can guarantee global optimality for particular classes of problems, although the computational cost becomes infeasible for problems of realistic size. they have been recently applied for the solution of mido problems  <cit> . regarding stochastic methods, several works, as reviewed by  <cit> , have illustrated their potential for dynamic optimization  and, more recently, for mixed-integer dynamic optimization   <cit> . stochastic methods usually locate the vicinity of global solutions with reasonable efficiency, but the cost to pay is that global optimality can not be guaranteed. alternatives such as global-local hybrid methods have been presented both for do  <cit>  and mido  <cit> , significantly improving the computational efficiency. thus, we could summarize the current state-of-the-art in this domain by concluding that there is no silver bullet for global optimization of arbitrary mido problems. and this is why dotcvpsb includes a suite of optimization solvers, following a "swiss army knife" approach.

many of these optimization methods require the computation of the gradient of the objective and/or constraints with respect to the decision variables. vassiliadis  <cit>  proposed the use of first order parametric sensitivities to compute such information. the sensitivity equations result from a chain rule differentiation applied to the system defined in eqns.  <dig> with respect to the decision variables and may be solved in combination with the original system. for this purpose, the use of backward differentiation formulas  methods is very attractive since they are able to exploit the fact that the original system and the sensitivities share the same jacobian.

toolbox description
dotcvpsb has been implemented in matlab  following the scheme presented in figure  <dig>  the original dynamic optimization or mixed-integer dynamic optimization problem is solved numerically by the use of a suitable optimizer  which requires the solution of an ivp  which will in general consist on a set of odes plus a set of sensitivities to compute gradient information. the solution of the inner ivp is accomplished by calls to tailored solvers from the suite of nonlinear and differential/algebraic equation solvers   <cit> , more specifically cvodes. since these simulations are the most computationally demanding task in the cvp method, our toolbox can automatically create compiled dynamically linked subroutines  for the odes, jacobian, and sensitivities, thus ensuring high performance.

key features
the core capabilities of the toolbox can be summarized as follows:

• handling of a wide class of dynamic optimization problems, including constrained, unconstrained, fixed, and free terminal time problems described by ordinary differential equations , as well as continuous and mixed integer decision variables;

• the inner initial value problem  is solved using the state-of-the-art methods available in sundials  <cit> ;

• the outer nlp problem can be solved using a number of advanced solvers, including local deterministic methods, stochastic global optimization methods, and hybrid metaheuristics;

• in addition to the traditional single optimization approach, the toolbox also offers more sophisticated strategies, like multistart, sucessive re-optimization  <cit> , and hybrid strategies  <cit> ;

• a graphical user interface  which makes the definition and edition of a problem more easy and clear;

• possibility of importing sbml models  <cit> ;

• many output options for the results, including detailed figures.

description of main modules
the toolbox contains a number of modules  which can be grouped in two categories:

• utility modules: graphical user interface , simulation, and sbml-import modules;

• optimization modules: offering several optimization strategies, namely single optimization, multi-start, successive re-optimization, and hybrid optimization modules.

utility modules
the utility modules offer several facilities for the definition, checking, and handling of problems. the toolbox can be operated through two equivalent approaches: by the use of the gui, or directly from the command line . it also offers a module to import dynamic models from sbml files, and the imported models can be checked by a simulation module.

• graphical user interface  module: this module was developed in order to help users in the definition and execution of problems. with the help of this module, which follows an intuitive wizard-like approach, problem definitions and modifications are guided in an easy and convenient stepwise manner, especially indicated for entry users.

• simulation module: this module carries out the dynamic simulation of the user-defined dynamics  generating the corresponding state trajectories. this module is especially useful for checking the model correctness during the definition phase, which is particularly error-prone. typical errors like those related with units inconsistencies can be readily identified with this procedure.

• sbml to dotcvpsb module: this module allows dotcvpsb to import the systems dynamics from sbml  models  <cit> . once a dynamic model is imported, it is necessary to check the model correctness by simulation . if everything works correctly, the user can proceed with the definition of the other terms of the dynamic optimization problem  and, finally, with its numerical solution.

optimization modules
the optimization modules offers a suite of four different optimization strategies, each one with different options for the optimization solvers, following the "swiss army knife" approach mentioned previously. all these modules are described in more detail below.

• single optimization module: this module makes a single call to one of the optimization solvers, which can be either a local deterministic or global stochastic method . this procedure can be sufficient for well conditioned, convex problems, or non-convex problems which are cheap to evaluate. in any case, it is recommended as the first strategy to try with any new problem.

• multi-start optimization module: this modules runs a selected optimization solver  repeatedly. the set of solutions  obtained can then be analyzed  in order to check the multimodality of the problem.

• sucessive re-optimization module: sucessive re-optimization can be used to speed up the convergence for problems where a high discretization level is desired . this procedure runs several successive single optimizations automatically increasing the control discretization, nlp, and ivp tolerances after each run.

• hybrid optimization module: hybrid optimization is characterized by the combination of a stochastic global method plus a deterministic local method. this procedures ensures a compromise between the robustness of global methods and the efficiency of local ones. this module is especially indicated for difficult multimodal problems. in any case, tweaking the hybrid method requires a deep knowledge of the solvers, and this approach will be almost always more costly  than the single optimization procedures using local methods .

numerical optimization methods 
the toolbox provides interfaces to several optimization state-of-the-art solvers:

• local deterministic

 <dig>  ipopt  <cit>  implements a primal-dual interior point method, and uses line searches based on filter methods;

 <dig>  fmincon  <cit>  is a part of the matlab optimization toolbox which uses sequential quadratic programming ;

 <dig>  misqp  <cit>  solves mixed-integer non-linear programming problems by a modified sequential quadratic programming method;

• stochastic global

 <dig>  de  <cit>  uses population based approach for minimizing the performance index;

 <dig>  sres  <cit>  uses an evolution strategy combined with an approach to balance objective and penalty functions;

• and hybrid metaheuristics

 <dig>  acomi  <cit>  is inspired by ants foraging behavior, using misqp for local searches;

 <dig>  mits  <cit>  is based on extensions of the tabu search metaheuristic, using misqp for local searches;

where the deterministic misqp solver and all hybrid solvers are able to handle mixed-integer problems directly. users can change solvers by simply changing an option in the input data structure, thus requiring no problem reformulation.

numerical simulation method 
forward integration of the ode, jacobian, and sensitivities  is ensured by cvodes, a part of sundials  <cit> , which is also able to perform simultaneous or staggered sensitivity analysis. the ivp problem can be solved with the newton or functional iteration module and with the adams or bdf linear multistep method . the adams method is recommended for solving of the non-stiff problems while bdf is recommended for solving of the stiff problems. note that the sensitivity equations are provided analytically and the error control strategy for the sensitivity variables could be enabled.

recommended operating procedure
it should be noted that, for a general mido formulation, there is no a priori way to distinguish if the resulting minlp will be convex or not inside the search space considered, so the user has no clue on which optimization strategy should be using. thus, we recommend that, for any new problem, the user follows this protocol:

• step 1: try solving the problem with the single optimization strategy and a local deterministic method, such as fmincon or ipopt for do problems, or misqp for mido problems, using a rather crude control discretization . after obtaining a solution, repeat changing the initial guess for the control variable. if a rather different solution is obtained, suspect multimodality and go to step  <dig> below. if not, solve the problem again using a finer discretization. for faster and more satisfactory results regarding control discretization, use the successive re-optimization module.

• step 2: solve the problem using the multi-start optimization module. in general  <dig> runs is a sensible number for this task, but for costly problems the user might want to reduce this. plotting an histogram of the resulting set of solutions will give a good view of the problem multimodality. for clearly multimodal problems, go to step  <dig>  if not, stop, or go back to step  <dig> if e.g. more refined control levels are desired.

• step 3: use the single optimization strategy as in step  <dig>  but use a global stochastic method, like de or sres for do problems, or acomi or mits for mido problems. if satisfactory results are obtained in reasonable computation times, stop. if the computational cost is excessive, go to step  <dig> 

• step 4: use a hybrid global-local strategy. more advanced users can tweak the different options to increase efficiency and/or robustness.

this protocol is especially recommended for novel users who are not familiar with numerical optimization methods. advanced users can tweak the hybrid strategy options, or even create their own strategies combining calls to the different solvers in a matlab script.

RESULTS
this section illustrates the usage and performance of the different modules of dotcvpsb considering several illustrative examples.

importing and checking a sbml dynamic model
for illustrative purposes, a dynamic model of the cell cycle  <cit>  was chosen and imported into the dotcvpsb toolbox. the problem is marked as biomd <dig>  tyson1991_cellcycle_6var,  <dig> can be downloaded as an '.xml' file from the biomodels database web page: .

after importing it using function dotcvp_sbml2dotcvpsb, the user should perform a dynamic simulation using the simulation module to check the model. figure  <dig> shows all state trajectories of the cdc2-cyclin model simulated with the constant parameters supplied in the above version.

single optimization
here we solve a relatively simple problem to illustrate the usage of the single optimization strategy with a local deterministic solver.

drug displacement problem
the problem consists of finding the optimal rate of injection of a phenylbutazone infusion to minimize the time needed to reach in a patient's bloodstream a desired level of two drugs  <cit> . the system dynamics is described by  <dig> non-linear differential equations where the state variables represent the concentration of warfarin  and phenylbutazone . these drugs must achieve a desired value at final time, a requirement which is mathematically formulated as two end-point constraints. table  <dig> shows a typical input script to solve this problem with dotcvpsb. alternatively, the problem can be defined  using the gui, as presented in figure  <dig>  mathematically, this is a constrained minimum time problem stated as:

this table shows a typical input file for dotcvpsb. many more options can be set, otherwise their values will be taken from defaults .

   

subject to

   

   

with  defined as follows

   

   

   

   

where the decision variable ) is constrained with lower and upper bounds set at values of  <dig>  and  <dig> . the desired concentrations of the drugs in the blood at final time should be equal to  <dig>  and  <dig> , respectively.

the problem was successfully solved with dotcvpsb using the single optimization strategy with a control discretization level ρ =  <dig> and ipopt as the nlp solver. the optimal solution found corresponds to a minimum time of  <dig>  which is in good agreement with the best published result of  <dig>   <cit> . the optimal control profile and the corresponding state trajectories are shown in the figure  <dig> 

successive re-optimization
here we show how to use the successive re-optimization module in order to obtain refined optimal control profiles.

lee-ramirez bioreactor
this example considers the optimal control of a fed-batch bioreactor for induced foreign protein production by recombinant bacteria. this problem was first presented by lee et al  <cit> , slightly modified by tholudur et al  <cit> , and later solved using a second order sensitivities approach  <cit> . the objective is to maximize the profitability of the process using the nutrient  and the inducer feeding rates  as control variables. several different values for the ratio of the cost of inducer to the value of the protein production  were published in the literature, but here we consider the particular case of q =  <dig> . mathematically, the statement is to find the control trajectories that maximize the performance index at the fixed final time

   

subject to

   

   

   

   

   

   

   

where the state variables represent the reactor volume , the cell density , the nutrient concentration , the foreign protein concentration , the inducer concentration , the inducer shock factor on cell growth rate , and the inducer recovery factor on cell growth rate . the final time is specified as  <dig> h. the additional constrains at the decision variables are lower and upper bounds set at the value of  <dig>  and  <dig> .

we successfully solved this problem using the successive re-optimization strategy from dotcvpsb and fmincon as nlp solver, setting the initial control discretization at ρ =  <dig>  the mesh increasing factor and the number of mesh refinements were set at values of  <dig> and  <dig>  respectively. the results for the increasing ρ values are shown in figure  <dig>  which have the following performance index values:  <dig> ,  <dig> ,  <dig> , and  <dig> . these performance indexes are in very good agreement with those published in the literature.

hybrid optimization
here we solve a multimodal problem using the powerful hybrid strategy, where the adequate combination of an stochastic global and a deterministic local solver allows reaching the vicinity of global solution in a reasonable computation time.

drug displacement problem with path constraint
here we consider a modified formulation of the drug displacement problem  adding an state path constraint, which is set to ensure that the warfarin concentration in the patient's blood does not exceed a dangerous level. the constraint is defined as follows

   

this problem has been reported to be highly multimodal, therefore its solution must be approached by the use of a suitable global method. on the other hand, a combination of a global and a local method  should be more efficient. to illustrate this, we solved this problem using  the global de solver  and  a hybrid combining de and misqp solver. using ρ =  <dig> free time intervals, both approaches converged to a similar solution, with a performance index  of  <dig> . in addition, the inequality and all equality constraints were violated less than the pre-set tolerance of 10- <dig>  but the hybrid approach was approximately  <dig> times faster than de in obtaining equivalent results. it should be mentioned that these results are again in very close agreement with those presented in the above cited literature. the optimal trajectories are shown in figure  <dig> 

multistart and single optimization with a global method
the multistart strategy is a good way of checking the possible non-convexity of problems. when the multimodality of a problem has been confirmed, users can choose a global or a hybrid strategy to find a solution in the close vicinity of the global one. we illustrate all this here considering a challenging mido problem.

phase resetting of a calcium oscillator problem: a mixed-integer dynamic optimization problem
we have considered a calcium oscillator model describing intracellular calcium spiking in hepatocytes induced by an extracellular increase in adenosine triphosphate  concentration, as originally proposed in  <cit>  and later slightly modified and solved in  <cit> . the aim of the optimization is to minimize the intracellular oscillations behavior with the help of two binary control variables . the values of these variables and the time of the switching from one mode to another, together with the time-independent parameter , are the decision variables. the performance index is formulated as the minimization of the state variables deviations with respect to certain desired values  over a fixed time horizon:

   

subject to

   

   

   

   

and the time-independent parameter:  <dig> ≤ p <dig> ≤  <dig> , where state variables represent the concentration of activated g-protein , active phospholipase c , intracellular calcium , and intra-er calcium . the time-fixed parameters together with the initial concentrations, desired values of the state variables and weighted coefficients are described in detail in the table  <dig>  the control variables are chosen binaries , which refer to the concentrations of an uncompetitive inhibitor of the pmca  ion pump and the inhibitor of plc activation by the g-protein. the influence of the first inhibitor is modeled according to michaelis-menten kinetics while that of the second inhibitor is modelled with the help of the term , where i <dig> =  <dig> corresponds with the maximum amount of the inhibitor. an additional equality constraint was added to fix the final time at the fixed value . the best performance index reported in  <cit>  was  <dig> , where this reported cost function corresponds to the term . these authors reported that the system is extremely sensitive to small perturbations in the stimulus.

we first solved this problem using the multistart module of the dotcvpsb toolbox, using misqp as local solver. the control discretization level was set to a value of ρ =  <dig> with free transition times and two binary decision variables for the controls. the multistart number of runs was set to  <dig>  with randomly generated initial values for all the decision variables in each run. the set of solutions found were spread in a quite wide range, a clear sign of multimodality. the histogram of these solutions is shown in figure  <dig>  where performance index values worse than  <dig>  are not shown. the best value  obtained by the multistart was  <dig> , which is still far from the published solution reported above.

in a second step, we solved this problem using the mits hybrid strategy, while keeping all the other settings as stated above. the best solution found by mits was  <dig> , which is very close to the value reported in  <cit> . the corresponding optimal trajectories are shown in figure  <dig> where it can be seen how the optimal control policies rapidly cancel the oscillations.

CONCLUSIONS
here we have presented dotcvpsb, a matlab toolbox for solving dynamic optimization problems from the domain of systems biology. this toolbox is able to handle very general mixed-integer dynamic optimization formulations, thus providing the opportunity to state and solve complex problems, such as e.g. optimal control for obtaining a desired biological performance, dynamic analysis of network designs or computer aided design of biological units. problems are easily defined via a compact input structure, or optionally using a graphical user interface.

this toolbox has been developed placing particular care in providing state-of-the-art solvers in order to ensure a good compromise between computational robustness and efficiency. dotcvpsb offers two key and unique advantages:

• it incorporates a suite of local and global optimization solvers so as to handle a wide range of problems, including non-convex  ones.

• it offers several optimization strategies, including single, multistart, sucessive reoptimization and hybrid methods. these strategies can be effectively used to enhance the solution of difficult multimodal problems.

the capabilities and performance of dotcvpsb were successfully tested using several challenging benchmarks problems taken from the open literature. the results confirmed that the toolbox was able to get excellent results in reasonable computation times, showing a good compromise between robustness and efficiency.

availability and requirements
project name: dotcvpsb, a software toolbox for dynamic optimization in systems biology

project homepage: the toolbox can be downloaded from the following website, which also offers documentation : 

operating system: windows. a linux version is planned for the near future.

programming language: matlab versions  <dig> – <dig>   is required, and the matlab optimisation toolbox and symbolic math toolbox are highly recommended.

other requirements: the toolbox distribution includes most of the needed external solvers: ivp solver cvode , and nlp solvers acomi, de, ipopt, misqp, mits and sres. the optimization toolbox is needed if the user wants to use fmincon as a nlp solver. fortran compilation to speed-up computations is secured by a combination of gnumex and mingw, packages which are distributed with the toolbox as well. on the other hand, the symbolic math toolbox is needed if automatic generation of sensitivities and jacobian are desired . users must install the sbml and libsmbl toolboxes in order to be able to import sbml models.

license: the toolbox can be obtained and used for free for academic purposes, and is under the creative commons license. the conditions of the license can be found on: 

any restrictions to use by non-academics: following the previous license.

abbreviations
acomi: ant colony optimization for mixed integer non-linear programming problems; atp: adenosine triphosphate; bdf: backward differentiation formula; cvp: control vector parameterization; de: differential evolution; fmincon: find minimum of constrained non-linear multivariable function; misqp: mixed-integer sequential quadratic programming; gui: graphical user interface; ipopt: interior point optimizer; ivp: initial value problem; lmm: linear multistep method; mi: mixed-integer; mido: mixed-integer dynamic optimization; minlp: mixed-integer non-linear programming; mits: mixed-integer tabu search algorithm; nlp: non-linear programming; odes: ordinary differential equations; sbml: systems biology markup language; sres: stochastic ranking evolution strategy.

authors' contributions
th wrote the source code, designed the gui interface, and implemented the test problems. ebc and jrb conceived the algorithms, guided their implementation, and tested the toolbox. th, ebc, and jrb wrote the manuscript and tested the final version of the software. all authors have read and approved the final manuscript.

