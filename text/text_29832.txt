BACKGROUND
next generation sequencing  of whole genomes or exomes has been a transformational tool for discovering causal variants in human diseases and uncovering new relationships between genes and disease mechanisms. sequencing the exome or genome yields thousands to millions of variant changes from a human reference sequence, ranging from a single nucleotide variant to more complex variants . analysis and identification of causal variants in these large data sets can be difficult due to the presence of many false positive variants that are commonly due to sequencing chemistry errors  <cit>  and/or alignment errors. differentiating between true variants and false positive variants is an outstanding challenge in causal variant discovery efforts and a robust method for prioritization of true variants over false positive variants would decrease analysis time and increase confidence in the results of variant discovery projects. this requires a balance between removal of false positive variants  while retaining true variants   <cit> .

sequencing accuracy of illumina's ngs instruments have improved over time with the majority of sequencing chemistry errors being base substitution errors  <cit> . although base substitution error rates are on average relatively low , sequence-specific errors occur at higher rates  <cit> . these sequence-specific error sources include homopolymer tracks that are often followed by an error matching the homopolymer base. homopolymers as short as two nucleotides may cause increased sequencing error at the next nucleotide. particularly ggt and gga sequence motifs commonly lead to a miscall of the last base as a g  <cit> . however, these known problematic sequences do not always coincide with increased sequencing error rates, and cannot be relied on alone to confirm or disprove an error. alignment errors, typically associated with repetitive or homologous sequence regions, are also a source for false positive variant calls and can lead to single to several base substitutions, insertion, and deletion errors  <cit> . since both sequencing errors and alignment errors can be associated with certain sequence motifs, these errors can be consistent between samples sequenced on the same instrument using the same sequencing chemistry and alignment methods, as demonstrated in several studies  <cit> .

basic alignment and variant calling parameters within the genome analysis tool kit  and other variant calling software have been developed to help identify and reduce false positive variants  <cit> . these include the probabilistic base quality and alignment mapping quality score, the aligned read coverage for possible alleles, and, more recently, the base alignment quality score  <cit> . these parameters can be used to apply variant hard filters but are more often used in a statistical model to generate a probabilistic, phred-scaled, variant quality score . this score is an estimated probability of a false positive variant but can be incorrect at sites prone to sequencing and/or alignment errors. to identify and address inherent error in the qual score, additional alignment parameters have been derived including several bias values that compare reference matching reads versus variant containing reads for systematic differences in base quality, mapping quality, mapping position, and mapping direction. the simplest use of these parameters is to screen variants using a set of filter values chosen for each bias parameter. a more sophisticated implementation is employed in the gatk software as variant quality score recalibration  in which a multidimensional gaussian mixture model is trained and then used to infer variant truth likelihood based on each variant's parameter combination  <cit> . vqsr evaluates variants from many different sites across the entire sequence area simultaneously but because the characteristics of error from site to site can differ and are difficult to characterize, site specific issues are not fully captured by the current set of parameters used in the vqsr method. other methods incorporate additional information to more accurately identify error prone positions. these include methods for detection of false positive variants around repetitive or homologous sequence  <cit> , or methods that utilize cross-sample error information by requiring multiple background samples  <cit> . these cross-sample methods evaluate characteristics of reads from multiple samples that likely contain similar errors at the variant site of interest.

this report presents varbin, a novel analytical method for classifying variants as true or false positive in illumina ngs data. varbin is a variant likelihood binning method for heterozygous variants of types including single nucleotide variants , insertion, and deletion variants, as well as variants in homopolymer and repeat regions. the varbin method evaluates each variant site individually to focus on site-specific alignment information for false positive variant determination. also, this method uses multiple background samples to take advantage of the cross-sample error characteristics that show similar trends between samples sequenced on the same platform with the same chemistry and alignment method. varbin uses genotype likelihood scores  to generate plrd , a value affected by alignment and sequencing error. varbin compares the plrd calculated for the proband variant to those calculated for multiple background samples for each variant change and position.. this report describes the varbin method and its performance characteristics.

methods
whole genome or exome next-generation sequencing
one family that was illumina whole genome sequenced was chosen as the test case for analysis and consists of a male proband and his unaffected mother, father, and brother. an additional  <dig> samples were either whole genome  or exome sequenced  and used as the background ngs data for analysis. this set of samples consists of  <dig> family groups  as well as  <dig> unrelated individuals. each family was unrelated to each other  sequencing data used for this study were generated in studies approved by the university of utah institutional review board.

for each family member,  <dig>  ug of genomic dna was fragmented to a  <dig> -  <dig> bp size distribution, using the covaris™ instrument . illumina specific libraries were generated using the automated spri-te instrument , then amplified using illumina pcr primers  <dig>  and  <dig> . for the exome libraries only, the in solution capture was performed according to the roche nimblegen seqcap ez human exome library v <dig>  or v <dig>   instructions with the following exceptions. the adapter ligated libraries were pcr amplified prior to probe hybridization by splitting the library volume across eight individual pcr tubes each with a  <dig> μl total volume. following pcr, the reactions were pooled and purified according to the manufacturer's instructions and subsequently used for probe hybridization. genome or exome libraries were then gel purified in the range of  <dig> +/-  <dig> bp and the library concentrations were determined using qpcr . the illumina cbot instrument was used for cluster generation, followed by sequencing on the hiseqtm  <dig> instrument with  <dig> base length paired-end reads.

ngs alignments and variant calling
fastq file sequencing reads for each sample were aligned using the bwa aligner . this initial alignment was followed by local realignment around indels   <cit> . the preliminary variant calls and dbsnp  <dig> were used to identify potential sites for local realignment. duplicate read removal was performed using samtools . base quality recalibration was performed with gatk using known variant sites identified by dbsnp  <dig> and the variant calls from the initial alignment. base quality covariates used were base quality score, cycle number, and the proceeding dinucleotide. the final alignment files  were used to make initial variant calls in the vcf file format  with only the following non-default settings. maximum coverage was set to  <dig>  stand_call_conf was  <dig>  std_emit_conf was  <dig> and base alignment quality option  was set to calculate_as_necessary. variant quality score recalibration  in gatk was used to update the vcf files with estimated false positive likelihood odds ratios . optional variant hard filter values, defined in the gatk best practices, were applied  for snvs as qd <  <dig> , mq <  <dig> , fs >  <dig> , haplotypescore >  <dig> , mqranksum < - <dig> , or readposranksum < - <dig>  and flagged in the filter fields as failing. similarly, indel hard filter limits were qd <  <dig> , readposranksum < - <dig> , or fs >  <dig> . only the preliminary called variants that passed these hard filters were considered a variant in the vcf file, while those that did not pass these variant calling filters are termed non-variants. these optional hard filters were used to remove many of the lowest quality variants.

varbin: variant heterozygous likelihood binning method
the phred-scaled, genotype likelihood values for the possible genotypes, pl , pl , and pl  are found in the gatk unifiedgentyper vcf file, are derived from mapping, alignment, and base qualities, allele read percentage, and read coverage at a given putative variant site. these pl values tend to show erroneously increased variant likelihoods at positions prone to sequencing and alignment errors. varbin takes advantage of this systematic error in the pl values as an indicator of false positive variant calls, by first calculating a phred-scaled, genotype likelihood ratio ,

  plr=-10⋅log10plaalinearplablinear+plbblinear 

where pllinear, pllinear, and pllinear are pl, converted from a phred to a linear scale. to focus on the effects of alignment and sequencing error in plr, its strong linear correlation to read coverage depth is minimized through conversion to a more coverage-independent parameter, plr by depth 

  plrd=plrdp 

where dp is the raw, read coverage depth . the plrd value for each proband variant of interest was then compared to plrd values for the same variant change and position from each background sample alignment .

to generate the needed data for these plrd calculations and comparisons, the gatk unifiedgenotyper was employed. nonstandard unifiedgenotyper settings were needed to force vcf file values to be created at "non-variant" sites . the genotype_likelihoods_model was set to both. the stand_call_conf was set to  <dig> . the stand_emit_conf option was set to  <dig> . the max_deletion_fraction was set to  <dig> . the min_base_quality_score option was set to  <dig>  the genotyping_mode option was set to genotype_given_alleles and the associated alleles option was set using a variant file  containing the variants of interest that had previously been identified in the proband sample. the output_mode option was set to emit_all_sites.

the resulting single proband and multiple background vcf files each contained entries for the same set of variant changes and positions of interest. variant filters defined in the gatk recommended best practices and listed above were then applied to the background samplevariants. note that this filtration process provided an imperfect but useful estimated separation of wilt type/non-variants from true variants. variants not passing these filters were marked as wild type/non-variant in the vcf file filter field. vcftools  was then used to extract pertinent data from the proband vcf file and all background sample vcf files .

each variant of interest was analyzed independently of all others. first, the distribution of plrd values from all background samples for the same variant change and position, that were called wild type/non-variants, as stated in the vcf file, was analyzed. this included calculation of the medians and inter-quartile distances . a  <dig> *iqd was used as a proxy for one standard deviation in a gaussian distribution.

this study focused on the heterozygous variants, which are more likely to contain false positives variants than homozygous calls . homozygous variants were excluded from further analysis, but were given a plrd value of zero for plotting purposes only. a variant was considered homozygous if pl was larger than pl or pl.

for varbin analysis of each variant of interest, the proband plrd value was compared to the background sample plrd distribution values and classified or "binned" based on a heuristic that was an automation of the original manual visual interpretation of alignment data as an indicator of sequencing or alignment error. bin  <dig> includes proband variants that have a plrd value greater than  <dig> and greater than the distribution median plus  <dig> proxy standard deviations . bin  <dig> includes proband variants with a plrd value greater than  <dig> or greater than the distribution median plus  <dig> proxy standard deviations but not both. bin  <dig> contains variants with a plrd value less than the distribution median plus  <dig> *iqd but greater than the distribution median plus  <dig> proxy standard deviations . bin  <dig> contains variants with a plrd value less than the distribution median plus  <dig> proxy standard deviations. the likelihood of a true variant is highest in bin  <dig> and lowest in bin  <dig> 

cross-sample annotation methods
in addition to varbin's primary binning procedure, other valuable information about proband variant accuracy is gained from the cross-sample comparison with multiple background samples. multiple parameters for each variant change and position were tracked in the proband, family members, as well as in the background files. these included lists of which background files had the corresponding variant call and zygosity, low read coverage depth , high strand bias, high base quality bias, mapping quality bias, and base position bias. these parameters helped track inheritance patterns within the family as well as trends that track with false positive variants.

generation of variant test sets
the test family was analyzed for rare and de novo variants within the proband. proband variants were found by this screening method: > <dig> total read coverage depth, <3% minor allele frequency  in the  <dig> genomes, <2% maf in the esp <dig> exomes, and not present in the unaffected family members . in addition, since the  <dig> genomes and esp <dig> data set did not have insertions or deletions at the time of the study, variants that were found to be very common within several ngs datasets  were eliminated as being too common of a variant for a rare disorder.

additional proband variant test sets were generated to evaluate the varbin method. one variant set was enriched for true variants , by selection of only the proband's variants present between  <dig> and 20% maf in the  <dig> genomes data within chromosome  <dig>  the other variant set was enriched for false positive variants , by selection of only the novel and de novo proband variants  within chromosomes  <dig> through  <dig> 

sanger sequencing
big-dye terminator sanger sequencing was performed for ngs detected variant verification on a total of  <dig> variants to test the varbin method's accuracy. one dataset was randomly selected from the proband's de novo variants found in or near coding regions within chromosome  <dig> through  <dig> . another variant set was selected based on the proband's de novo variants. an additional  <dig> more bin  <dig> proband variants in other chromosomes were sequenced. eight sanger sequenced proband variants were found in bin  <dig> or  <dig> in a parent but was called wild type/non-variant in the parent's vcf file  and were also sanger sequenced. to expand the study to other families,  <dig> variants were sequenced in unrelated families that were in bin  <dig> and  <dig> that were previously thought to be true variants by manual visual verification of the read data in igv .

RESULTS
varbin method
whole genome sequencing data from the test family included in this study was comprised a male proband and his unaffected father, mother, and brother. in addition,  <dig> unrelated background samples sequenced with the same instrument, sequencing chemistry, and alignment methods were used for analysis. illumina errors tend to be consistent between samples using the same chemistry and instrument  <cit> , and the background data were used to help identify these errors. by a visual and manual cross comparison of ngs read data in the integrative genomics viewer   <cit> , it was possible to make predictions of likely true variants or false positive variants. this method was time consuming and difficult to analyze multiple background samples at once. to address this, the varbin method was developed to provide a more automated and discriminating procedure for classifying true variants versus false positive variants. varbin uses the likelihoods for the different possible genotypes  that are generated as part of the statistical framework of variant detection in gatk and samtools . the pl values for wild type, heterozygous and homozygous genotypes at a variant position are combined into a variant phred-scaled likelihood ratio  that is strongly affected by read coverage depth . to demonstrate the correlation of plr with depth, a set of proband variant calls enriched for true variants was created  and a data set enriched for false positive variants was created . these two data sets were used to plot plr versus depth for the proband variant calls as well as all plr values within background data sets corresponding to the same variant change and position as for the proband. variants are plotted to the left and right of zero on the plr × axis depending on their relative likelihood to be a false positive variant or a true variant, respectively. a linear distribution of plr versus coverage depth was observed for data points in figure 1a and 1b. plr was divided by corresponding coverage depth  to derive a more coverage independent parameter: plr by depth . minimal effect of coverage on plrd is demonstrated .

an important feature of the varbin method is that each variant is evaluated separately, since different positions can have different error rates/propensity due to sequence specific effects  <cit> . the proband's variant plrd value can be plotted as a histogram with all the background samples' plrd values for the same variant change and position. the plrd value spans from likely wild-type/non-variant  to likely true variant . as the plrd distribution broadens for the wild type/non-variants in the background samples, and as the proband plrd value drops, there is less distinction in the alignment data between the proband variant and the group of wild type/non-variants. this concept was quantified in an empirically derived varbin method where proband variants were scored as bin  <dig>  through bin  <dig>  based on the proband plrd and the wild type/non-variant plrd distribution median and interquartile distance . figure  <dig> shows example plrd histograms associated with two sanger sequence confirmed true variants from bins  <dig> and  <dig>  and four sanger confirmed false positive variants from the proband ngs data . samples with the variant passing the gatk hard filters are shown in blue, which can include true variants with the potential that some are miscalled, false positive variants. the samples that did not pass the hard filters at the tested variant position are in red, these are termed "wild type/non-variant" and can include samples that are truly wild type at the tested variant position with the potential that some were actually miscalled, false negative variants. variant plrd from the proband sample are shown in gold. variants that were called as homozygous were not considered to be as prone to be false positive variants due to their generally higher total number of variant containing reads and by default were excluded from analysis but were displayed with a plrd value of zero. these single site histograms in figure  <dig> show both typical bin  <dig> through  <dig> examples. in bin  <dig> and  <dig>  the plrd wild type/non-variant  distributions are broader and/or closer to the proband variant plrd for sites and are more likely to be a proband false positive.

comparison of varbin to gatk vqsr
the varbin method's bin values were compared to the gatk's vqsr score  using two proband derived variant sets, one set enriched for true variants and one set enriched for false positive variants . results for the enriched true variant set  show that of the approximately  <dig>  variant calls, bins  <dig> through  <dig> had 85% , 14%,  <dig> %, and  <dig> % variants, respectively. results for the enriched false positive variant set  show that of the approximately  <dig>  variant calls, bins  <dig> through  <dig> had 17%, 40%, 25%, and 18% variants, respectively. vqslod likelihood values for variants in the four separate bins for both data sets were spread into overlapping distributions with limited correlation between the varbin method's bin number and vqslod.

assessment of varbin predictions
sanger sequencing was performed on  <dig> variants in the proband, the proband family members, and in unrelated families as described in methods . these variants included single nucleotide variants, insertions, deletions, as well as homopolymer and repeat regions. of the  <dig> de novo variants detected in the proband that were sanger sequenced,  <dig> were false positive variants,  <dig> could not be accurately sanger sequenced ,  <dig> were true varaints. interestingly,  <dig> of the  <dig> proband's sanger confirmed variants that appeared de novo were actually present by sanger sequencing in the proband's family members but these variants were not called variants in their vcf files , indicating that the proband wasn't actually de novo for those variants and that the varbin method helped detect these false negative variants. an additional  <dig> variants  in family members or other unrelated individuals were sanger sequenced to confirm these false negatives and to expand the varbin study to other families. combining all sanger sequencing data for a total of  <dig> variants , 97%, 30%, 0%, and 0% of the bin  <dig>   <dig>   <dig>  and  <dig> variant calls, respectively, were true variants . the others were sanger confirmed as wild type sequence and are considered false positive variants. only one bin  <dig> variant was actually a false positive variant, while  <dig> of  <dig> bin  <dig> variants were true variants.

* <dig> variants were sequenced in the proband, the proband's family, or other families in the background data sets as stated in the methods. four of the  <dig> could not be sanger sequenced and were excluded from this table . snv, single nucleotide variant; indel, and insertion or deletion.

comparison of proband to background files
in addition to the varbin method, the individual background files and the proband's family members were used to track the variant frequency and other parameters . the total number of background samples and family members, variant zygosity in the background samples and family members, and which samples had the same variant called as the proband were tracked. this data highlighted how often a variant was called in the background data set, whether the same variant was in an unaffected family member, whether it was in families unaffected by the disease of the proband, and whether other unaffected samples had the same genotype . other tabulated data used for variant prioritization included low variant containing read depth, and low quality scores. these variant calling metrics were collected for all background individuals including proband family members. because low coverage depth or low quality positions may lead to a missed variant  in a family member which can conceal the true inheritance patterns present at these sites. using these data in the analysis of the proband's de novo variants indicated that approximately 25% were actually in a family member  but were missed by the variant calling procedure . by tracking these parameters in family members as well as use of the varbin method, many false negative variants were identified within this family.

discussion
variant prioritization of the thousands to millions of variants in a typical gene discovery study is critical to provide focus on the most likely causative variants. as a common step in the analytical process, variants from the affected individual are screened against those found in databases including the  <dig> genomes data and the nhlbi esp <dig> exomes data. variants are screened by a low minor allele frequency or alternatively all known variants are eliminated. the resulting set of rare or novel variants typically include a much higher fraction of false positive variants than are found in the initial list, since sequence specific error rates are known to be chemistry, instrument and method specific and false positive variants are not commonly expected in the public databases.

the presented varbin method as well as tracking family member's quality and bias data for the proband's variant facilitates variant prioritization by analyzing predictions of true variant versus false positive variants, the predicted inheritance pattern, and the potential false negative variants. these methods were tested using whole genome sequence data from an example family of four , as well as utilizing a  <dig> sample background data set.

a number of parameters within gatk or other analysis programs have been developed to evaluate illumina variants to identify false positive variants. these include quality by depth , raw coverage depth  and a set of alignment bias parameters, but the most common is the variant quality  that is derived from a statistical model which incorporates read mapping quality, base quality, base alignment quality, coverage, and variant read percentage  <cit> . the novel parameter in the varbin method is the variant-to-non-variant likelihood ratio , which is related to the variant quality  and is derived from the same statistical model. the plr is a ratio of genotype likelihood  values that are generated by variant detection algorithms found in gatk or samtools. the pl values compare the three possible genotypes, aa , ab , or bb  for a given site and change. unlike the related variant quality score, qual, the plr equation transitions smoothly from negative to positive as the variant in question moves from inferred false positive variant to inferred true variant. also, plr does not include the variant prior probabilities included in the calculation of qual.

there is a strong effect of read coverage depth on plr. as coverage drops, there is less confidence in calling a putative variant as true or false positive, and thus plr approaches zero. division of plr by coverage  minimizes the coverage depth dependence. at plrd equals zero, there is an inferred 50% chance of a true variant with an increasing probability of a true variant as the plrd value increases. .

plrd values were compared between two subsets of variants from the test family's proband sample: a set enriched for true variants and a set enriched for false positive variants. the enriched true variant set demonstrated fairly distinct plrd value groups for variants that did  or did not pass  the gatk best practices hard filters for variant calling. in contrast, the enriched false positive variant set demonstrated wild type/non-variants that did not pass filter overlapping into the pass filter variant range of plrd values . this indicates more variability, or noise, in the plrd for certain variant sites. this increased noise is the result sequencing and alignment errors, as well as error related changes in base and alignment quality scores in the aligned read data used to calculate plrd. in addition, this plrd variability was more common for the false positive variants as verified by sanger sequencing.

analyzing ngs read data  using the broad institute igv viewer allowed visual identification of several common features of false positive variants including: fewer variant containing reads compared to wild type reads , variant containing reads were all from one direction , the variant was in the same position in all reads , the preceding two bases were the same base as the variant change , and many background samples had some reads with the variant . in an effort to automate analysis of the information gained from the igv viewer comparisons  to differentiate true variants from the more likely false positive variants, the varbin method was developed. varbin analyzes heterozygous variant plrd distributions at each variant change and position, to compare the proband variant to the family and background data. the chosen plrd bin  <dig>  through bin  <dig>  heuristic was informed by visual interpretation of alignment data as an indicator of sequencing or alignment error and then verified by sanger sequencing data. median and interquarile distances were used to identify how much the proband's variant differed from the group of background samples plrd values that were wild type/non-variant.

a typical sanger confirmed proband variant position commonly had a tight distribution of plrd values for all the wild type/non-variant background samples, which clustered near - <dig> plrd. commonly, the proband's false positive variants  had lower proband plrd values  as well as an increasingly broad distributions of background sample's wild type/non-variant plrd values. the higher the proband plrd and the more separated from the distribution of the non-variant background plrd values, the more likely the proband variant was anticipated to be a true variant.

to estimate the percentage of variants in bins  <dig> through  <dig> that were true variants, sanger sequencing was performed on  <dig> of the proband's de novo heterozygous variants. sanger sequencing for four variants was inconclusive due to sanger sequencing or pcr issues, like polymerase slipping or difficulty amplifying one gene out of a homologous family of genes, indicating the difficulty of both calling these variants within ngs data and sanger confirming these variants. an additional  <dig> bin  <dig> and  <dig> variants were sequenced in the proband's family members or from the background samples. these variants included single nucleotide variants, insertions, deletions, and insertions or deletions at a homopolymer or repeat region. all but one of the bin  <dig> variants were sanger confirmed. the exception variant's plrd value was near the boundary between bin  <dig> and  <dig>  and this was the only bin  <dig> variant where multiple plrd values exceeded zero for the background files with no background variants passing filter. this indicates a position prone to false positive variants. but since the proband's variant had a high probability to be true, greater than  <dig> *iqd from the mean and > <dig> plrd, it was included in bin  <dig>  this example highlights that varbin allows for bin  <dig> variants even at sites prone to false positive variants  if the variant plrd value is adequately separated from the background non-variant plrd values. thus, varbin is an alternative to other methods that propose rejection of all variants in false positive prone regions or, reject variants at specific site/nucleotide change combinations  <cit> .

all bin  <dig> or  <dig> variants were found to be false positives variants by sanger sequencing, indicating that bin  <dig> and  <dig> may be combined into one bin. sanger sequencing also indicated that 30% of variants in bin  <dig> were true variants. the majority of the true bin  <dig> variants present in other family members were in bin  <dig> for the proband . these true variants were originally called "wildtype/non-variant", so they were false negative variants. the chosen gatk hard filters eliminated these variants, while the varbin method had put them in bin  <dig>  which would be prioritized for further analysis since ~30% of variants in bin  <dig> are true variants. this indicates the varbin method's potential for detection of false negatives within a family or potentially within one sample. the majority of false positive bin  <dig> variants and the only bin  <dig> false variant had a polymer motif leading up to the change . this motif is well known to lead to illumina sequence specific increased errors  <cit> , and may help further classify certain variants within bin  <dig> with these motifs as potentially false positive variants.

the varbin method differs significantly from other commonly used tools for false positive likelihood determination such as the gatk variant quality score recalibration   <cit> . vqsr uses a training set of variants across the genome in the sample of interest to train a gaussian mixture model for true variant detection based on several variant parameters of quality and bias. unlike vqsr, the presented varbin method does not depend on a model generalized over a broad range of many variants and variant contexts. instead this method evaluates each variant site separately and uses multiple, locally sequenced background samples to increase variant likelihood information about each specific variant change and position, even if the proband variant of interest was not called a variant within a background sample . results from the varbin method were compared to phred-scaled vqsr likelihood ratios of a true-to-false variant  results for a set of proband variants that were enriched for true variants or enriched for false positive variants. for the enriched for true variant data, the variants primarily scored as bin  <dig>  with only a small number scored as bin  <dig> or  <dig> . for the enriched false positive variant data set the majority of variants fell in bin  <dig> followed by  <dig> and  <dig>  each bin consisted of a relatively wide range of vqslod values, indicating limited correlation of varbin and vqsr methods for detection of false positive variants.

bin  <dig> variants are likely true variants due to the proband variant plrd score's larger separation from the distribution of background samples' wild type/non-variant plrd scores. in bin  <dig>  variants were separate enough from the non-variant background samples to have a probability of being true variants, but usually had one or more factor that could indicate a false positive variant, such as read strand bias, read position bias, low quality, and low count for variant containing reads. the median vqslod value for the bin  <dig> variants  corresponded to an expected 87% true variant estimate. the sanger sequencing for this data set indicates a 93% true variant result for bin  <dig>  but only 30% true variants in bin  <dig>  all bin  <dig> and  <dig> proband variants plrd values were near or within the range of background samples non-variants' plrd values, indicating that these are the most likely false positive variants. all variants in bins  <dig> and  <dig> were confirmed to be wild type by sanger sequence, and therefore false positive ngs detected variants. thus, bin  <dig> and bin  <dig> could possibly be merged into a single bin of false positive variants. the vqslod median value for bin  <dig> variants  corresponded to an expected 18% true variants. the plrd-based varbin method presented in this study appears to provide useful, improved segregation of false positive variants  and true variant  calls, with bin  <dig> being uncertain . this indicates that only bin  <dig> and a portion of bin  <dig> variants would be prioritized for further analysis in gene discovery studies.

CONCLUSIONS
varbin was created to classify false positive variants from true variants in illumina data sets. varbin was also created to automate the manual processes often used to analyze ngs data for visual indicators of false positive variants. the varbin method accurately binned variants into different levels of true variant likelihood, as confirmed by sanger sequencing, where bin  <dig> is most likely true, bin  <dig> and  <dig> were false positive variants, and bin  <dig> was uncertain . in addition, bin  <dig> variants were commonly true if the same variant was seen in bin  <dig> for a family member, highlighting the usefulness of family based data in false positive variant identification. of note, family data is not required for varbin and varbin can classify insertions, frame shifts and deletions, as well as single nucleotide variants. the plrd and variant filter parameter information for these "non-variants" is useful for false negative variant detection in family member samples used as background samples.

future work on the varbin method will focus on differentiating true variants from false positive variants within bin  <dig>  and converting the varbin result from a discrete bin to a continuous parameter. additional efforts will focus on using varbin to identify false negative variants  in bin  <dig> or  <dig>  the varbin method could also be incorporated into the gatk vqsr method for a potentially more accurate false positive variant detection. plrd values for background files can also be pre-calculated to speed analysis. also, we will explore using the varbin method for other ngs platforms and library preparation methods . in conclusion, varbin improves the accuracy of classifying true variants and false positives variants within illumina ngs data based on the comparison of the varbin method to vqsr and varbin predictions being verified by the sanger sequencing results.

competing interests
the authors declare that they have no competing interests.

authors' contributions
jd carried out bioinformatic analysis and jointly drafted the manuscript. rlm performed sequencing, sequencing data analysis, and jointly drafted the manuscript. emc participated in the sequencing and sequencing data analysis. kcm carried out sanger sequencing. kvv participated in the design and coordination of the study and helped to draft the manuscript.

declarations
funding for research and publication of this article came solely from the arup institute for clinical & experimental pathology®, salt lake city, utah.

this article has been published as part of bmc bioinformatics volume  <dig> supplement  <dig>  2013: selected articles from the 9th annual biotechnology and bioinformatics symposium . the full contents of the supplement are available online at http://www.biomedcentral.com/bmcbioinformatics/supplements/14/s13
