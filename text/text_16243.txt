BACKGROUND
pancreatic cancer is one of the most lethal types of cancer. in united states, there are ~ <dig>  new cases being diagnosed each year. the mortality rate of pancreatic cancer patients is approaching 100%. only 4% of the patients survive  <dig> years or more after being diagnosed. the grim statistics of pancreatic cancer necessitates the urgent development of methods to facilitate their early detection and prevention  <cit> . despite the advancement of our knowledge in recent years regarding the pathophysiology of pancreatic cancer  <cit> , we still lack an effective method to diagnose this cancer type early enough to impact the treatment outcomes.

recently, there has been substantial interests in applying proteomics technology to identify clinically useful biomarkers for early-stage pancreatic cancer  <cit> . in a more general sense, many investigators have applied proteomics technology and data mining methods to identify serum proteomic patterns that can distinguish normal from cancer samples. examples of these include ovarian cancer  <cit> , breast cancer  <cit> , prostate cancer  <cit> , lung cancer  <cit> , brain tumors  <cit> , and head and neck cancer  <cit> .

one of the major challenges for proteomic profiling is the analysis and mining of biologically useful information from the enormous dataset. due to the high dimensionality of proteomics dataset and their often small sample sizes, non-classical statistical methods for data analysis need to be employed. therefore, various machine learning classification algorithms have been applied to proteomics data analysis. these include the use of decision tree  <cit> , boosted decision tree  <cit> , random forest  <cit> , nearest centroid  <cit> , bayesian neural network  <cit> , self-organizing map  <cit> , support vector machine  <cit> , linear and quadratic discriminant analysis  <cit>  and meta-learners  <cit> . however, there are limitations regarding these studies  <cit> . these include the lack of efficient procedure for biomarker selection and the inability to cope with data noise. more importantly, most of these classification methods were constructed based on a single classifier derived from a single training process. they are not robust enough to handle the great variance inherent in the proteomics data. thus, a more general machine learning method is needed to overcome these challenges.

here, we present a computational method to analyze a proteomics dataset obtained from premalignant pancreatic cancer using decision tree based classifier ensembles coupled with three feature selection schemas and show that classifier ensembles always have better performances compared to a single decision tree and other models.

RESULTS
the premalignant pancreatic cancer mass spectrometry dataset used in this study include  <dig> samples. of the  <dig> samples,  <dig> are control serum samples and  <dig> are panin  samples. control samples are referred to as normal cases while panin samples as disease cases. the complete computational procedure used in this study is shown in figure.  <dig>  after preprocessing, we ran our processed data through a  <dig> fold cross-validation framework. in each round of the cross validation, 90% of the data were selected randomly as training set to build classifier. three feature selection methods were applied to select top features  from the training set only. classifiers were then tested on the rest of the 10% data using those selected features. the performances of various classifiers were also compared.

data preprocessing
to compensate for systematic differences due to sample loadings and instrument errors, raw proteomics data have to be preprocessed before any feature selection method and classification algorithm can be applied. three major preprocessing procedures were applied to our dataset: baseline adjustment, normalization and kernel smoothing. using one specific spectrogram as an example, the effects of these processing operations on the raw data are shown in figure.  <dig>  the original spectrograms consist of  <dig> different m/z ratios and they range from  <dig> to  <dig>  in their values . the spectrogram baselines were adjusted based on the group median . all data points were smoothed by substituting their values with the weighted average of  <dig> value points on each side using a gaussian kernel . using the area under each spectrogram curve , all spectrograms were normalized and rescaled such that their maximum values equal to  <dig> .

biomarker identification
in general, classifiers cannot successfully handle high dimensional dataset generated from proteomics experiments. to overcome this problem, we used three feature selection schemes  to reduce the dimensionality of the dataset to a manageable number. table.  <dig> lists all the top  <dig> features generated from each round of two-sample homoscedastic t test. these features are ranked based on their p-values that correspond to the probability of their observed differences in mean intensity between control and disease group being significant. interestingly, several features  such as  <dig>  and  <dig>  were repeatedly selected in our  <dig> rounds of cross validation analyses despite the fact that the training dataset is randomly selected from the whole dataset each time. regardless of how the data is partitioned, highly significant differences in peptides' m/z intensity between control and disease samples can and will likely be selected each time. thus, these m/z ratios are considered potentially good biomarkers for disease identification. the use of randomly selected training data provides greater confidence to our results.

rank is determined by the probability of the two means between disease and control groups in the training set being significantly different. m/z ratios with smaller probability ranks higher. most frequent features are determined by the frequency of each feature appears in the top  <dig> list in these ten runs and ranked by their frequency.

while t test assumes that the feature values from two different classes follow normal distributions. in reality, this is often not the case. therefore, we explored the possibility of using a nonparametric  test to select our top features. the top  <dig> features selected from wilcoxon nonparametric rank test are presented in table  <dig>  similar to t test, some of the m/z ratios such as  <dig>  and  <dig>  were also selected frequently. features that are repeatedly selected from independent runs suggest that those features play important roles in discriminating between normal and disease classes.

rank is determined by the probability of the two means between disease and control groups in the training set being significantly different.

to compare with filter feature selection method such as t test and wilcoxon rank test, we also explored the possible utility of a wrapper method, specifically the use of genetic algorithm coupled with linear discriminant analysis. in contrast to t test and wilcoxon rank test in which several features were repeatedly selected, genetic algorithm provided a very different result. as shown in table  <dig>  features selected from each round are quite different, with no feature being selected more than twice in  <dig> rounds of cross-validation. one possible reason for this result is that the initial population size used by the genetic algorithm was small and that it was randomly selected from the training set. due to its small population size , any particular feature is less likely to be selected repeatedly by random sampling.

classification results and comparisons
after data dimension reduction using methods mentioned above, we tested and compared the performances of a single decision tree algorithm c <dig> , six different decision tree-based classifier ensembles, and six different benchmark classification algorithms in a  <dig> fold cross validation framework. default parameters were used in all algorithms without any fine-tuning of individual classifier, thus, allowing us to compare the performance of each algorithm. because no particular classifier is preferred, potential misleading conclusion can be avoided.

tp rate: true positive rate, fp rate: false positive rate, tn rate: true negative rate, fn rate: false negative rate, rmse: root mean squared error. rbfnet: radio basis function network, svm: support vector machine.

besides accuracy, mean squared error of prediction  is another important measure of performance. mse is the expected value of the square of "error" and consists of two components â€“ prediction variance and the square of the prediction bias. in many contexts, variance and bias of a single classifier can be effectively reduced by constructing classifier ensemble such as bagging and adaboost  <cit> . our results support this observation. for example, rmse  of single decision tree c <dig>  is  <dig> , which is higher than those of random forest , bagging , logitboost  and adaboost , but interestingly smaller compared to those of stacked generalization  and multiboost  . most of the benchmark algorithms have higher rmse compared to either single decision tree or classifier ensembles.

similarly, using our top  <dig> features selected from the wilcoxon rank test , the prediction accuracy  of a single decision tree is lower than those of random forest, logitboost and multiboost, but similar to those from stacked generalization and bagging. the trade-off between prediction's sensitivity and specificity still exist for c <dig>  and other classifiers. this effect is even more obvious for stacked generalization. in general, the classification results from t test and wicoxon rank test have no significant difference, indicating that both feature selection methods work equally well in this context.

in contrast, features selected from the genetic algorithm show large variations compared to those features selected from t test and wilcoxon rank test. however, it is unclear whether the classification results using genetic algorithm also vary significantly. in our study, we observed a similar pattern in prediction accuracy and rmse value for genetic algorithm . classifier ensembles usually outperform a single decision tree. for example, a single decision tree has the lowest prediction accuracy  compared to other classifier ensembles. interestingly, the general performances of classifiers based on the feature selection method of genetic algorithm are considerably lower than those from t test and wilcoxon rank test, possibly because the heuristic nature of wrapper method can not guarantee that the best features will be selected.

recently, the area under roc  curve  has been widely used as a measure to compare the performance of different classifiers. theoretically, aug value equals the probability of correctly classified one pair of samples . therefore, one classifier is considered better if it has a larger area under the roc curve compared to a different classifier. thus, the aug value under the roc curve provides another measure of classifier performance. for example, the augs of classifiers using t test selected features are summarized in table  <dig>  single decision tree c <dig>  has the lowest aug value  while random forest has the largest aug value  among all classifier tested. these results strongly suggest the need to construct classifier ensembles to analyze proteomics data.

discussion
sensitive detection of clinically useful biomarkers and the building of a reliable predictor specific to pre-malignant pancreatic cancer will certainly aid the early detection of this deadly disease. here, we propose the use of a more accurate decision tree-based classifier ensembles combined with feature selection methods to address some of the challenges facing current cancer proteomics data analysis. we are able to build a low bias and a low variance predictor using model-averaging method: classifier ensembles. this method greatly improves the accuracy of classification. furthermore, the use of three feature selection methods have allowed us to select biomarkers that achieve the best classification performance and at the same time give us potential new insights into disease mechanism involved in cancer development.

biological data sets generated from proteomics studies typically have a very high number of features compared to their small sample sizes. many feature selection methods have been used in proteomic data analyses to reduce the high dimensionality of the dataset. these include methods such as information gain  <cit> , kolmogorov-smirnov test  <cit>  and random forest  <cit> . in our study, we used three different feature selection methods: t test, wilcoxon rank test and genetic algorithm. these methods are derived from the two major schemas in feature selection, namely the filter and wrapper method  <cit> . filter method is more efficient, reliable, and not subjected to any learning algorithm. however, this method considers each feature independently without regard to its relevance or the possibility that combination of features can improve classifier performance. in contrast, the wrapper method chooses a particular learning algorithm as its performance guide to consider how useful some feature combinations are to the predictor. in genetic algorithm, the initial size of the population sampled from the whole dataset significantly affects the output result. because of this, our repeated runs using genetic algorithm failed to yield similar results. the unreliability of genetic algorithm may limit its future utility in proteomics data analysis. using the three methods mentioned earlier, we observed a generally consistent performance of all classifiers. their accuracies range from 50% to 70%. thus, feature selection methods used here are sufficiently robust for classification purpose.

over the last two decades, intensive explorations of model-averaging methods for classification purposes produce a group of efficient decision tree-based classifier ensembles. in many different contexts, classifier ensembles outperform decision tree model and other single algorithms because of their superior ability to handle data variance. this is also demonstrated in our result. in all three feature selection method cases, classifier ensembles have better prediction accuracies. meanwhile, many attempts were made to compare classifier ensemble techniques, but most of them only focused on the two most popular methods: bagging and adaboost. although stacked generalization, multiboost and logitboost have been proposed earlier, only recently these methods gained greater popularity in machine learning and bioinformatics community  <cit> . until now, no direct comparisons of their performances were made. our study represents the first attempt in this direction by considering them in the context of pancreatic cancer proteomics analysis.

in general, the performances of classifiers tested on the premalignant pancreatic cancer dataset are lower than we had expected, with the best prediction accuracy of 70% in a single run. there are two possible reasons for this. first, this proteomics dataset comes from mice with histologically confirmed premalignant panin but no evidence of invasive or metastatic disease  <cit> . therefore, in the early developmental stage of pancreatic cancer, the levels of biomarkers may not exhibit significant differences between the normal and disease group. secondly, we used the default parameters for all our classifiers without performing any fine-tuning. the advantage of doing this is that it can prevent the problem of "over-fitting" because the parameters we used are not adapted to a specific dataset, thus our method can be generalized to more datasets. the disadvantage of using the default parameters is that our result may not represent the best possible results.

CONCLUSIONS
we presented a systematic machine learning method to analyze cancer proteomics data that utilized decision tree based classifier ensembles and three popular feature selection schemas in a cross validation framework. our method includes three steps: preprocessing, feature selection and classification. the proposed method is general enough that it can be adapted to other proteomics data analysis problems. our results show that classifier ensembles perform significantly better than single decision tree algorithm, highlighting the utility of classifier ensembles in future proteomics research. additionally, biomarkers selected in this process may shed new lights on processes and mechanisms underpinning cancer development. our study represents one of the first attempts to apply and compare decision tree based classifier ensembles in the context of cancer proteomics data analysis. results presented here will open up other possibilities for further research.

