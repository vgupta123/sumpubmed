BACKGROUND
the harnessing of dna recombination in vitro has transformed protein engineering by enabling engineers, like nature, to sample sequence space more broadly than is allowed by point mutagenesis at individual residues. recombination produces chimeras comprised of sequential fragments from parent genes, thereby bringing together sets of sequences that were previously active in the parental background, and are thus likely to be less disruptive than random ones. chimeragenesis typically produces combinatorial libraries, and those chimeras with beneficial properties can be identified by large-scale genetic screening and selection.

dna shuffling  <cit> , the progenitor of recombination-based protein engineering, works by randomly digesting the parent genes into fragments and reassembling the fragments into new chimeric genes . recombination occurs when fragments from different parents are sufficiently complementary to anneal and prime synthesis from the 3' end. dna shuffling has been called by its developer pim stemmer "the most dangerous thing you can do in biology"  <cit> , due to its power in generating novel proteins. indeed, it has been the basis both for commercial success  and the development of effective protein variants  <cit> .

dna shuffling is both homology-dependent , and stochastic . due to dependence on sequence similarity, dna shuffling may fail to generate desirable chimeras  for diverse parents, as they have only a few, small regions of dna similarity, insufficient to generate many cross-overs. homology-independent stochastic methods  mitigate the need for such parental sequence similarity, but at the cost of generating many more non-viable chimeras.

in contrast with stochastic methods, site-directed methods enable the engineer to explicitly choose break-point locations so as to optimize expected library quality . we have developed a site-directed method employing planned ligation of parental fragments by short overhangs  <cit> . we have coupled this approach to robotic implementation in order to generate specific chimeras in defined experimental vessels  <cit> . such highly-directed methods of chimera generation are most useful when screening represents a significant effort. in those situations where screening or genetic selection is readily available, then stochastic approaches, with less overall cost, might prove preferable.

we present here methods for extending stochastic experiments by optimizing dna shuffling , yielding an approach that is less dependent on parental dna sequence similarity  and more deterministic , and which is amenable to library optimization. our approach, which we call codns , employs efficient  dynamic programming algorithms to select a globally optimal set of codons for the parental amino acids, allowing for a fixed number of substitutions. while moore and maranas have also studied the problem of codon optimization for shuffling  <cit> , their ecodonopt method employs computationally-expensive integer programming to select codons. we present dynamic programming recurrences for the two crossover-maximization objective functions of ecodonopt: overall dna sequence identity and overall free energy of annealing as approximated by a nearest-neighbor potential. we then develop recurrences for two more powerful objectives that seek to maximize crossovers by promoting dna sequence identity within contiguous runs, optimizing either the overall number of runs or the diversity of the chimera library resulting from breakpoints in the contiguous runs.

we demonstrate the effectiveness of codns in several case studies. we first optimize the gar transformylases previously optimized by ecodonopt  <cit> . we then show that codns can optimize two dna polymerases  that are sufficiently diverse  to previously require the development and application of the scope method  <cit> , instead of direct application of dna shuffling. finally, we study the impact of parental sequence identity by considering pairs of beta-lactamase parents of differing diversity levels.

methods
we take as input the amino acid sequences of the parent proteins to be shuffled, aligned to a length of n  based on sequence and/or structure. for simplicity of exposition, we present our methods for the most common case of shuffling two parents, a <dig> and a <dig>  our methods readily extend to creating equivalent sites for recombination in multiple parents, and it remains interesting future work to allow for non-uniform shuffling .

to optimize the shuffling experiment, we select a codon for each amino acid for each parent, yielding dna sequences d <dig> and d <dig> of length 3n . to expand the pool of codons being considered at a particular position, we may choose to make an amino acid substitution. thus we take as additional input a specification of the allowed substitutions for each residue position for each parent, along with a number m of them to make. the allowed substitution specification may be derived from sequence and/or structural analysis of the parents, including general amino acid substitution matrices  <cit> , position-specific amino acid statistics from related proteins  <cit> , and ΔΔgfold∘ fold predictions for possible substitutions  <cit> . the results presented below determine allowed substitutions under the blosum <dig> substitution matrix, considering only "conservative" substitutions which score no more than  <dig> worse than wild-type  <cit> .

in describing the algorithms, we use possible codon sets representing the codons allowed at each position in the wild-type and under the allowed substitutions. for position i, set c <dig> contains the possible codons for a <dig>  pairing each with an indication of whether or not it requires a substitution, e.g., {, , } for an f that could potentially be mutated to w. set c <dig> is defined similarly for the second parent. we note that these may readily be used to restrict where to employ mutations , by allowing only wild-type codons  in some positions.

we consider four types of objective function, targeting common nucleotides , nearest-neighbor approximation to change in free energy of annealing , common nucleotide runs , or library diversity . we develop increasingly more complex dynamic programming algorithms to optimize these objectives.

common nucleotide optimization
in this most basic optimization for dna shuffling, the goal is to maximize the number of identical nucleotides at common positions:

  ont= ∑i=13ni{d1=d2} 

where i is the indicator function .

with no substitutions allowed, each residue position is independent of each other one. thus we simply select for each position a pair of codons  with a maximal number of common nucleotides. when substitutions are allowed, we need to allocate them for optimal impact. while several approaches are possible, we develop here one based on dynamic programming, to serve as the basis for the more complex objective functions we pursue in subsequent subsections.

in our dynamic programming matrix, one dimension represents an aligned residue position , and the other represents a number of substitutions . let n denote the number of common nucleotides within the first i residues, using exactly s substitutions. the value of n extends the value of n with the additional number of common nucleotides obtained by selecting a pair of codons for position i while making t <dig> + t <dig> additional substitutions . optimal substructure holds, since the optimal value of n depends on the optimal value of n. the recurrence is

  n <cit> = <dig> 

  n=-∞s> <dig> 

  n =max∈c <dig> ∈c2:t1+t2≤s ]+g) i> <dig>  s> <dig> 

where g gives the number  of common nucleotides for a pair of codons.

after filling in the dynamic programming table, we trace back from n to generate an optimal pair of dna sequences. the matrix is of size n * m and each cell takes constant time to compute.

Δgnn∘ optimization
while it is hard to directly model the process of dna shuffling  <cit> , it is driven by the change in free energy upon annealing of the different parental nucleotide strands . we want to minimize the free energy change, so that it is favorable to cross over. since the free energy change is very hard to compute, a common approach is to approximate it by decomposing the free energy into the sum of contributions from pairs of dinucleotides, the nearest-neighbor approximation  <cit> :

  onn= ∑i=13n-1Δgnn∘ 

where Δgnn∘ is the free energy change associated with annealing dinucleotide d1·d <dig> with dinucleotide d2·d <dig>  these values can be computed from enthalpic Δh  and entropic Δs  nearest-neighbor parameters compiled at 37°c and  =  <dig>  m  <cit> , including both pairs of complementary strands. to actually estimate the change in free energy, there are additional constant terms such as the average initiation energy contribution; we omit them as they do not affect the optimization. while the underlying Δgnn∘ parameters are defined on pairs of dinucleotides, we abuse notation a bit in our formulation below and use Δgnn∘ for 4-mers to mean the sum over the constituent dinucleotides.

we now develop a dynamic programming formulation to optimize this objective more efficiently  than the integer linear programming of ecodonopt  <cit> , while still ensuring global optimality. in order to compute the Δgnn∘ contributions from a selected codon, we must also know the final nucleotide of the previous codon, as it forms a dinucleotide with the first nucleotide of the current codon. thus we extend the common nucleotide dynamic programming table to keep track of this information. figure  <dig> illustrates the dependency; the recurrence is

  a= <dig> 

  a=∞s> <dig> 

  a =min∈c <dig> ∈c2:b1=c <dig> <cit> ,b2=c <dig> <cit> ,t1+t2≤s  minb′ <dig>  b′2 , b′ <dig>  b′2]+Δgnn°) i> <dig>  s> <dig> 

where b·c indicates the concatenation of base b onto codon c, and Δgnn∘ estimates the change in free energy, as described in the text. cell a holds the best score for the first i positions, using exactly s substitutions, with third nucleotides b <dig>  and b <dig>  for position i. as with common nucleotide optimization, if a codon pair makes t <dig> + t <dig> substitutions at position i, then a extends the solution to a cell for position i -  <dig> with s -  substitutions, considering any of the third nucleotides b1′ and b2′ at position i -  <dig> 

the table is of size n × m ×  <dig> for  <dig> parents, since there are only  <dig> combinations of single nucleotide pairs for two parents . each cell can be computed in constant time. in practice, we construct a 2d table , with each cell maintaining a list of scores for the  pairs that actually occur.

run optimization
moore and maranas argued that the nearest-neighbor approximation to change in annealing free energy is a better objective for shuffling optimization than the number of common nucleotides  <cit> . intuitively, since the nearest-neighbor approximation considers adjacent nucleotides together rather than treating them independently, it is more likely to yield sufficient complementarity between fragments and thereby promote recombination. here we go even further and explicitly optimize for contiguous complementary regions, since annealing is driven by sufficiently long  such regions.

we define a common nucleotide run as a maximal-length substring appearing at aligned positions in the dna sequences d <dig> and d <dig>  and use as our objective function:

  orun= ∑rf 

where f, which must be non-decreasing, indicates the value for dna shuffling of a run of length |r|, and the sum is taken over all runs. we have implemented and tested several different scoring functions; the results use the following two functions:

  f1=0r<θrr≥θ 

  f2=0r<69/4*5≤r<9rr≥ <dig> 

in f <dig>  we count the total number of nucleotides in a run, but only if the run exceeds a given length . this assumes that cross-overs are impossible for runs with fewer than θ common nucleotides, and become increasingly likely with additional nucleotides beyond θ. in f <dig>  we consider cross-overs impossible for fewer than  <dig> nucleotides and very likely for  <dig> nucleotides or more , and we ramp up from the impossible score of  <dig> at  <dig> nt to the likely score of  <dig> at  <dig> nt, thereby counting the partial benefit that may be provided by runs between  <dig> and  <dig> nucleotides.

we must extend our dynamic programming table with an additional dimension to keep track of the current run length. thus we have a table in which cell r holds the best score for the first i positions, using exactly s substitutions, such that the final nucleotide in the codons chosen for position i is the rth in a run . again, if we make t substitutions at position i, then r extends the solution to a cell for position i -  <dig> with s -  substitutions. now we must also account for the preceding run length; there are several cases : the codons chosen for the current amino acid position may continue a run from the previous position, may end that run, and may start a new run. in any case, the current r and possible codon pair determines the preceding r' at which to look, and optimal substructure still holds. the recurrence is thus

  r <cit> = <dig> 

  r=-∞s>0orr> <dig> 

  r=max∈c <dig> ∈c2:t1+t2≤s{r+f−fc1=c <dig>  r≥3maxr′, r′]  +f)−f+f) r=z<3−∞otherwisei> <dig> 

where a and z give the lengths of the longest common prefix and suffix, respectively, of a pair of codons. the first case handles a common codon, while the second case handles an unequal codon pair, which may end and/or begin a run. the score depends on that from the related cell, with an increment in f accounting for any extension in run length and initiation of a new run.  when there is a tie, we prefer the codon pair with the most common nucleotides, even if that has no impact on run score. this choice increases overall sequence identity, to promote better annealing of strands from different parents.

the matrix is of size n * m * , since the run length potentially ranges from  <dig> to the entire dna sequence length . however, in practical cases, most run lengths are not attainable. furthermore, for r <dig> < r <dig>  if r + f - f < r, then the r <dig> cell "dominates" the r <dig> one--the r <dig> one cannot be part of the optimal solution. thus we modify the usual dynamic programming algorithm slightly, to avoid filling in cells with unattainable or dominated run lengths. we perform the standard nested loop over i  and s . then for each i and s we determine which run lengths are attainable and undominated and fill in only those entries. rather than keeping a 3d table, we keep a 2d table in which each cell has a list of run lengths and their scores. note from the structure of eq.  <dig> that we can determine the run lengths for i, s from the possible codons at i and the run lengths that were attained and undominated for i -  <dig> and s, s -  <dig>  and s -  <dig> .

diversity optimization
we have previously developed methods for optimizing the diversity of libraries of chimeras produced by site-directed recombination  <cit> . we showed that the total number of mutations in a library is a constant determined only by the parents, but that by assessing the squared-differences in the numbers, we can optimize for a relatively uniform sampling of sequence space. in the case of two parents, we define the diversity variance over a library as:

  odiv=12λ*∑i=12λ−1∑j=i+12λ−m¯) <dig> 

where λ is the number of fragments, m is the mutation level  between a pair of chimeras hi and hj, and m¯ is the average of m over the library.  to mitigate the effect of neutral mutations, rather than using literal equality we measure m using one of the standard sets of amino acid classes. the goal is to minimize the variance, seeking to sample sequence space as uniformly as possible.

the objective function is defined in terms of the chimeras in the library. in the context of dna shuffling, we assume that a sufficiently large run of common nucleotides  results in a breakpoint, and thus that the  chimeras are well-defined as all combinations of fragments between the breakpoints. breakpoints resulting from smaller runs only add to the diversity of the resulting library.

for an efficient algorithm, we must be able to compute the objective function during the optimization, without enumerating the exponential number of chimeras. in our previous site-directed work  <cit> , we developed a recursive formulation relating the diversity variance for a library to that of a sub-library with one fewer breakpoint. that formulation took as given the total number of breakpoints, which isn't available in the dna shuffling context. however, similar algebraic manipulations  yield a related formula without requiring pre-knowledge of the number of breakpoints.

claim  <dig> the diversity variance d of a library from parent sequences pa and pb with kth breakpoint is at residue l can be computed from the diversity variance d for a library with  st breakpoint at residue l' < l by the following formula:

  d=2k-22k-1*d+e 

where

 e=222k∗m   +m2)+2k−22k−1*2∗m2∗22k−62−2∗m2∗22k− <dig> 

and we use notation p to indicate the substring from position i to j, inclusive.

based on eq.  <dig>  we further extend our run-length optimization dynamic programming recurrence to optimize for diversity:

  d <cit> = <dig> 

  d=0s>0orr>0orl>0ork> <dig> 

  d=min∈c <dig> ∈c2:t1+t2≤s{d  −e+eminr′+a≥θ,l′<i−12−22−1d  +eminr′+a<θd   −e+e∞  c1=c <dig>  r≥3r=z< <dig>  l=i−1r=z< <dig>  l<i−1otherwisei> <dig> 

we add two more dimensions, to keep track of k, how many runs of length θ we have seen , and l, where the last one was, as in the claim. intuitively these two additional dimensions are necessary since the number of breakpoints affects the size of the library and thus the diversity variance, and since the additional diversity induced by a run depends on the nucleotides between the previous breakpoint and the new one. note that in eq.  <dig>  k is the number of breakpoints, with the last breakpoint always at the end of the current position l; however, in eq.  <dig>  k is the number of previous runs, or k +  <dig> when substituted into eq.  <dig>  as with run optimization, our implementation avoids filling in the table for run lengths that are unattainable .

codon usage
in order to promote better protein expression, we follow the genedesigner protocol  <cit>  in employing organism-specific codon usage tables. a codon usage table for an organism  <cit>  encodes the frequency with which each codon has been observed in a sequence database; different organisms display different "preferences"  <cit> . in a preprocessing step, we disallow rare codons that make up less than 10% of the occurrences for their amino acid. then when computing one of the recurrences, we use the codon usage table to resolve cases where multiple possible codons give the same score . in such cases, we selecting among the possible codons with probability according to their usage frequency.

RESULTS
we use three case studies to demonstrate the effectiveness of codns in optimizing dna shuffling experiments. the first two case studies are a pair of glycinamide ribonucleotide  transformylases  and a pair of distantly related dna polymerases . we optimize shuffling plans using from  <dig> to  <dig> mutations under each of the objective functions, abbreviated in the figures as cn , Δg , f <dig> , f <dig> , and dv . we examine particular plans optimized under different objectives, in order to see how they differ in allocating mutations and producing homologous runs suitable for cross-overs. we then study the overall trends in optimizing the objectives and in producing runs. we also consider the diversity of the chimeras that would result by recombination under different run-optimal plans. comparisons with what would result ecodonopt  <cit>  can be made by noting that it optimizes cn and Δg . in a third case study, we evaluate the effects of wild-type sequence identity on the optimization, using different pairs of beta-lactamases.

gar transformylases
the parents for our first case study are a gar transformylase from e. coli and one from humans. previous work showed that dna shuffling crossovers are extremely rare without codon optimization  <cit> . we obtained the  alignment from the supplementary material of  <cit> , and transcribed it to  <dig> amino acids with  <dig>  in common. the wild-type dna sequences had 47% nucleotides in common  <cit> , with only two runs of length  <dig> and no runs longer than  <dig> nt.

we next analyzed the overall ability of codns to select codons and allocate mutations to meet the different optimization goals. figure  <dig> illustrates the objective score trends with increasing numbers of mutations. all of the plots are quite linear , demonstrating that there is sufficient freedom within these two parents to enable effective optimization for the objectives, and that the algorithms are successfully exploiting the available freedom. since the f <dig> metric gives "partial credit" for run lengths of  <dig>   <dig>  and  <dig>  we break out those contributions to its score. we see most of the optimization still focuses on full  <dig> nt and larger runs, which is natural given the reduced score contribution for shorter runs . the trends for diversity optimization are not shown here since scores are not directly comparable for libraries of different sizes .

we introduced novel run-based objective functions in order to more directly target the sufficient stretches of parental homology required for annealing, only indirectly optimized by the objectives of common nucleotides and Δgnn∘ employed by ecodonopt. to assess the impact of this more direct objective functions, we determined the number of runs produced by plans under the different objectives. we varied the threshold to consider a homologous region as a "run" from  <dig>  to  <dig> . as discussed above, among the plans tied for optimal for a particular objective, we sought the one with the best run score. we evaluated both the number of runs and the number of nucleotides in those runs. for the sake of space, figure  <dig> presents only the results for a threshold of 9; the trends at the other thresholds are very similar. we see that, as mutations are introduced, optimizing directly for runs is indeed much more effective at producing runs than either of the "proxies" of common nucleotides or Δgnn∘. we do not show trends for f <dig>  as it also optimizes for "partial credit" runs .

the final question regards diversity--how much control we can exert over the level of diversity we introduce . here we deem a  <dig> nt run as sufficient for a breakpoint, and evaluate the ability of codns to minimize our library diversity variance objective  while maximizing the number of runs. figure  <dig> illustrates some plans with the same  number of runs but different library diversity scores. as discussed above, mutations in diversity-optimal plans are optimally allocated so as to create runs more evenly distributed throughout the entire sequence . however, plans with larger diversity variance scores place runs closer together and leave the c-terminal portion without any runs, thereby generating no diversity there .

dna polymerases
our second case study involves two distantly-related members from the x-family of dna polymerases: african swine fever virus dna polymerase x  and rattus norvegicus dna polymerase beta . while these two proteins share a similar fold, they have very low sequence identity. the site-directed scope method  <cit>  was developed due to the difficulty in producing viable pol x -- pol β chimeras by other methods. we obtained the published structure-based sequence alignment of the two parents, in which the full pol x and the palm and finger domains of pol β were aligned to a length of  <dig> residues and gaps, with only  <dig> residues  in common. the wild-type dna sequences had only 158/ <dig>  nucleotides in common, with no common nucleotide runs of length greater than  <dig>  thus standard dna shuffling techniques are unlikely to produce any cross-overs.

we optimized these parents under each of our objective functions, using from  <dig> to  <dig> mutations. figure  <dig> illustrates an optimal plan for each objective with  <dig>   <dig>  or  <dig> mutations, showing runs of length ≥  <dig>  these particular parents are so diverse that only a few such runs can be produced by codon selection alone . we do see, however, that the run-optimization methods form one more run  than do the common nucleotide and Δgnn∘ methods, and f <dig> forms some potentially productive shorter runs. the difference increases with more mutations, as run optimization directly allocates them so as to produce more runs, while, due to the parental diversity, the indirect choices made to optimize common nucleotides and Δgnn∘ are unlikely to lead to runs. with less freedom, it is harder to optimize diversity. we do see that while the f <dig> plan is diversity-optimal for  <dig> and  <dig> mutations, it is not for  <dig> mutations, and the diversity-optimal plan spreads mutations out more. we also observe that the n-terminal region is so diverse that no run is produced there even with  <dig> mutations. diversity optimization thus tends to create runs that are more evenly distributed in the large c-terminal region.

even with such diverse parents, there is sufficient freedom in the codon and mutation choices that different run-optimal plans yield different levels of chimera diversity. figure  <dig> illustrates some such plans, at two mutation levels. the three plans at the same mutation level have the same number of runs but increasing diversity  from top to bottom.

beta-lactamases
our third case study examines the effect of wild-type sequence identity. beta-lactamases, which hydrolyze the beta-lactam found in certain antibiotics , have been the object of much chimeragenesis work, including dna shuffling  <cit>  and site-directed methods  <cit> . we previously developed a multiple sequence alignment  of diverse beta-lactamases  <cit> . for the present study, we considered  the common beta-lactamase targets tem- <dig>  and pse- <dig>  ;  the even more diverse pair from p. aeruginosa and bacillus licheniformis ;  the more similar pair from e. coli and proteus mirabilis .

optimizing the wild-type amino acid sequences for common nucleotides yields dna identity of  70%,  61%, and  73%. these numbers are somewhat borderline for standard dna shuffling. they do result in some runs, though generally fewer than when directly optimizing for runs, a trend that widens with more mutations. optimizing for runs yields the same behavior as observed for the previous two cases; due to lack of space, we only present the free energy score and the number of nucleotides in runs under the f <dig> metric . we again see the linear tread for both objectives with increasing mutations from  <dig> to  <dig>  the actual energy score and run score both depend on parental sequence identity, with the same ranking on both metrics.

CONCLUSIONS
dna shuffling is a staple of protein engineering, and we have demonstrated that our new algorithms can substantially improve the expected productivity of an experiment. even without performing any mutations, we are able to allocate codons to better form runs. by performing a small number of conservative substitutions, not expected to significantly affect stability or activity, we generally are able to increase the number of runs and the number of nucleotides in runs, linearly with the number of substitutions. finally, since we are establishing runs whose lengths are sufficient to promote regular recombination, we can enhance our optimization to account for properties of the resulting chimeric library. future directions include extending run optimization to incorporate the type of potential underlying Δgnn∘ , to optimize multiple parents simultaneously, and to integrate codns within our pareto-optimization framework  <cit>  in order to optimize productivity of shuffling in concert with other properties. while both extensions will increase the computational expense, the resulting gain in experimental efficiency could be well worth it. in summary, our methods yield a new approach to dna shuffling that supports substantially more diverse parents, is more deterministic, and generates more predictable and more diverse chimeric libraries.

competing interests
the authors declare that they have no competing interests.

authors' contributions
lh, amf, and cbk developed the approach; lh, and cbk designed the algorithms, lh implemented the algorithms and collected the results; lh, amf, and cbk analyzed the results and wrote the paper. all authors read and approved the final manuscript.

