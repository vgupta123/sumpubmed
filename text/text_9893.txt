BACKGROUND
recent advances in proteomic technologies allow comprehensive investigations of protein-protein interactions on a genomic scale. interacting proteins provide detailed information on basic biomolecular mechanisms and are a valuable tool in the exploration of cellular life. protein complexes are physical entities that are formed by stable associations of several proteins to perform a common, often complex function; in fact most of the basic cellular processes such as transcription, translation or cell cycle control are carried out by protein complexes. the goal of our work is to identify protein complexes directly from experimental results obtained from co-immunoprecipitation techniques, in particular the important tandem affinity purification approach   <cit> . tap employs a fusion protein carrying an affinity tag that is used to bind the protein to a matrix; subsequent washing and cleavage of the tag allows for obtaining the complexes under almost native conditions. the identification of the mixture of different proteins is usually carried out by mass spectrometry. genome wide screens using tap are available for the yeast saccharomyces cerevisiae  <cit> .

in prior approaches for predicting protein complexes, the experimental observations had to be condensed into a protein interaction graph. a protein-protein interaction graph is an undirected graph g =  where v is a set of nodes representing proteins and e is a set of edges. an edge indicates, depending on the particular model, either a physical interaction or protein complex co-membership of two proteins and may be weighted to designate interaction probability. all approaches that use an unweighted  interaction graph as an intermediate step suffer from the problem that the uncertainty contained in the observation is no longer represented in the interaction graph, and cannot be properly accounted for when computing the clustering.

moreover, most existing techniques for predicting protein complexes rely on heuristics for further analysis of the protein interaction graph. often several parameters have to be chosen, usually with very little guidance from theory. instead, parameters are optimized on benchmark data sets  <cit>  and thus depend on the existence of such data sets for successful prediction. other, more stringent algorithms suffer from the requirement of having an absolute measure of an interaction as input  <cit> .

in contrast to previous methods that rely on constructing an intermediate interaction graph, our model-based approach uses the experimental measurements directly, which should provide a more rigorous framework for protein-protein interaction analysis. our probabilistic model explicitly and quantitatively states the assumptions about how protein interactions are exposed by the experimental technique. a suitable algorithm then uses this model to subsequently compute a clustering.

for this work, we focus on partitioning proteins into complexes. furthermore, any pair of proteins is assumed to either interact or not, independent of the context of other proteins in which it appears. as a consequence, clusters never overlap and each protein is assigned only to a single cluster. several proteins are known to be part of more than one protein complex. while the problem is biologically relevant, only few proteins are bona fide members of many complexes  <cit>  and even more complex methods such as used by gavin et al. identify largely non-overlapping solutions  as basic, reliable elements  <cit> .

our work is inspired by an approach for evaluating protein-protein interaction from tap data by gilchrist et al.  <cit>  that calculated maximum-likelihood estimates of false negative error rate, false positive error rate and prior probability of interaction, but which cannot compute protein complexes. our model uses their observation model, but we also compute likely protein complexes along with maximum-likelihood estimates of error rates.

there are two extreme cases in the interpretation of purification experiments. one is the minimally connected spoke model, which converts the purification results into pairwise interactions between bait and preys only. the other is the maximally connected matrix model, which assumes all proteins to be connected to all others in a given purification  <cit> . while the real topology of the set of proteins must lie between these two extremes, most previous works focused on the spoke model of interaction  <cit> . from a sampling perspective, each purification given a certain bait protein and its preys can be seen as a trial to gather information on which of these proteins interact. for illustration, we use the example given in  <cit>  for a scenario involving four proteins v, w, x, y . assuming the spoke model and choosing v as a bait protein, we can view this experiment as a trial to observe three interactions between v and the proteins w, x, y. in repeating this experiment, we would have a second trial to observe these three interactions. a third experiment, now using protein w as a bait, provides a third trial to observe an interaction between v and w, as well as the first trial to observe an interaction between w and proteins x or y. combining these three experiments, we have three trials for observing an interaction between v and w, two trials for observing an interaction between v and x and no trials for observing an interaction between x and y . we define t as the number of trials in which we might observe an interaction between two proteins. for example, from these three experiments and assuming the spoke model, t is equal to  <dig>   <dig>   <dig> and  <dig> for the protein pairs , ,  and , respectively. assuming the matrix model, t is equal to  <dig> for all protein pairs. notice that in the matrix model the pair  is tested  <dig> times while in the spoke model this pair is not tested at all .

however, in each trial we may or may not observe an interaction. consequently, we define s  as the number of experiments in which we observe two proteins to interact . in figure  <dig>  using the spoke and matrix model respectively, we illustrate how the experimental results from the three experiments can be summarized as a set of observation  values for each possible pair of proteins, which form the basis of our observation. after the transformation, an interaction probability can be calculated using a statistical model of interaction  <cit> . in this work, we will directly use these counts to build a markov random field  model of protein complexes and estimate the number of clusters as well as false negative and false positive rates.

markov random fields have been successfully applied as a probabilistic model in many research areas, e.g. as a model for image segmentation in image processing  <cit> . in biological network analysis, mrf were used to model protein-protein interaction networks to predict protein functions of unknown proteins from proteins with known functions  <cit> . they were also used to discover molecular pathways, for example by combining an mrf model of the protein-interaction graph with gene expression data  <cit> . our model differs from these previous works in that we use mrfs to model protein complexes without an intermediate interaction graph and model the observational error directly. we incorporate the observation error into the formulation of the model and apply mean field annealing to estimate the assignment of proteins to complexes.

for estimating protein-protein interaction graphs, several protein-protein interaction databases are available, in particular for the yeast proteome. they mostly rely on data from the yeast two-hybrid system  <cit>  and the tandem affinity purification-mass spectrometry analysis of protein complexes  <cit>  and individual studies that focus on particular aspects  <cit> . creating a protein interaction network from high-throughput experiments is difficult due to high error rates. therefore, with present techniques, the resulting networks are often not accurate  <cit> . current approaches merge the results of different types of experiments such as two-hybrid systems, mrna co-expression and co-immunoprecipitation such as tap-ms. in that, much information on experimental details is lost, which we would like to exploit. we therefore focus on tap-ms results as experimental data source, which outperforms other techniques in accuracy and coverage in yeast  <cit> .

in the following, we introduce two computational methods previously described that predict protein complexes given pairwise protein-protein interactions, which are most comparable and relevant to our approach  <cit> . molecular complex detection   <cit>  detects densely connected regions in a protein-interaction graph. first it assigns a weight to each vertex computed by its local neighborhood density, a measure related to a clustering coefficient of a vertex. then, starting from a vertex with the highest density, it recursively expands a cluster by including neighboring vertices whose vertex weights are above a given threshold. vertices with weights lower than the threshold are not considered by mcode. the method can retrieve overlapping complexes, but in practice many proteins are left unassigned by mcode.

another popular approach applies the markov clustering algorithm   <cit>  to predict protein complexes, usually after low quality interactions are removed from the data set. in the application of mcl used by krogan et al.  <cit> , first several machine learning techniques are combined to model interaction probability from mass spectrometry results. in the next step, an intermediate interaction graph is generated by removing interactions with probability lower than a given threshold. mcl is then applied on the resulting graph to predict complexes. mcl simulates a flow on the graph by calculating powers of the transition matrix associated with the interaction graph. its two parameters are the expansion and inflation values, the latter influencing the number of clusters. mcl produces non-overlapping clusters.

following the statistical approach to model protein interaction  <cit> , we consider each purification experiment to be an independent set of observations of the interaction or non-interaction of proteins. we model the assignment of proteins to complexes as a markov random field . the model incorporates the observational error as false positive and false negative error rates, which are assumed to be identical for all purifications. the cluster assignment is computed using mean field annealing , which requires two input parameters, the number of clusters k and the log-ratio of error rates ψ. we systematically estimate both the cluster assignment of proteins and the false positive and false negative error rates using maximum likelihood. we explore both spoke and matrix model and compare the solutions to other published solution of protein complexes. data sets and the detailed description of methods can be found in the methods section.

RESULTS
performance on simulated data
to test convergence of our algorithm irrespective of the starting point, we first ran it on simulated data. we created the data from a set of n nodes, which we randomly assigned to k clusters. the number of trials t was the same for each pair of nodes, with the number of successes s reflecting the specified values of the false negative rate ν and the false positive rate φ. we ran the algorithm multiple times with different random starting points and initial values for ψ. we tested the algorithm on two problem sizes:  a small size n =  <dig>  k =  <dig> and  a large size n =  <dig>  k =  <dig>  we set φ to be  <dig> , which is similar to the mips data  and tested two values of ν:  <dig>  and  <dig>   <cit> . we computed the average minimum cost at a given number of clusters, as shown in figures  <dig> and  <dig>  figures  <dig> and  <dig> depict the quality of our solution as the geometric average of sensitivity  and specificity .

for the small problem size, figures  <dig> and  <dig> show that the algorithm converges to the correct solution, with correct cluster assignments as well as correct estimates of the model parameters, ν and φ. with the high false negative rate of  <dig> , the algorithm needs more clusters, some of which remain empty, to arrive at the correct solution. for the larger problem size of k =  <dig>  we searched all k from  <dig> to  <dig> in steps of  <dig>  the estimate of the error rate is approximately correct and the likelihood takes a minimum around k =  <dig> ), but we only come close to the correct cluster assignment, with about 85% of all pairs correctly identified.

ideally, we can estimate the number of clusters k from the likelihood of the solution for each k. when increasing k, the likelihood of the computed solution is increasing as long as the added clusters are used for a better cluster assignment of proteins. the likelihood is going to reach its maximum if all proteins are correctly assigned. any additional clusters will remain empty, and the likelihood will increase no further ). in reality, with large problem sizes, the solution does not converge to the optimum cluster assignment, in particular when noise is present. the flattening of the likelihood however indicates that the correct number of clusters has been reached ).

clustering of data sets obtained in high-throughput experiments
for clustering proteins, we compute clusters for two types of observation models: the spoke model and the matrix model of protein interactions. to find a maximum likelihood solution, we first use a large number of clusters to search for a ψ maximizing the likelihood. for that ψ, we then run the optimization for different cluster sizes. we do three runs per cluster size to control for influences of the optimization starting point, and use the one with the highest likelihood. the maximum likelihood solutions are shown in table  <dig>  the estimated false positive rate φ* of our clustering solution is on the order of 10- <dig> agrees with previously published results  <cit> . note that by our definition, the false positive rate is the fraction of interactions observed between distinct complexes of the model divided by the number of all tested interactions between distinct complexes, which are present in the observation. for example, given our cluster solution for the spoke model, there are approximately  <dig> million trials between distinct complexes  and among them, we observe about  <dig> false positives. the number of trials within complexes is much smaller, about  <dig> trials in total, but only about half of them are observed, resulting in a false negative rate of approximately  <dig> . based on the experimentally observed interactions, about 70% are false positive. however, this is not the definition of the error rates used by our model.

we have also calculated the error rates based on the mips data  <cit> . the false negative rate is very close to the one we estimated for our solution. the false positive rate is still of the same magnitude, but  <dig> to  <dig> times larger than the false positive rate computed for our solution. the decisions underlying the manually curated mips dataset were similarly conservative in assigning proteins to the same cluster as our algorithm. we discuss a method to distinguish reliable from less reliable clusters in our solution later. false positive rates in tap-ms experiments are much lower than for other experimental techniques as has been reported earlier  <cit> .

the approach presented here does not rely on a benchmark set. however, to evaluate the performance of the algorithm to extract relevant information from high-throughput data sets we compared it to the results of other algorithms  and the protein complexes accompanying publications of the data sets. we use two data sets, gavin <dig> and gavin <dig>  <cit> , to compare the results to earlier studies. the first data set was used in previous works to benchmark the predictions  <cit>  and is basically a subset of the second. see table  <dig> and the methods section for the description of the data sets.

because mcl and mcode require an interaction graph as input we construct one using a spoke model for each data sets. mcl accepts both weighted and unweighted graphs as an input. for the weighted interaction graph, we compute the interaction probability using the statistical model in  <cit>  without a threshold.

to set the inflation parameter for mcl, we find that the optimal setting as published in  <cit>  is suitable for the smaller data set , but yields a biologically implausible small number of clusters for the larger gavin <dig> data set. therefore, we have explored several inflation parameters from the recommended range of  <dig>  to  <dig> . we found the inflation parameter of  <dig>  to result in a number of clusters containing more than  <dig> proteins, which is close to the published number of  <dig> complexes  <cit> . the trade-off in sensitivity and specificity from exploring the inflation parameters is shown in figure  <dig>  we summarize the parameter setting for all three algorithms in table  <dig>  for comparison of the clustering algorithms, we compare the performance measures to evaluate the clustering solutions for the mips and reguly data sets  <cit> . we compare these measures for clustering and random complexes and observe good separation. for the evaluation, we do not consider singletons as valid clusters and exclude them from the distribution of cluster sizes, see table  <dig> and table  <dig>  we summarize the measurements in table  <dig> for the gavin <dig> data set and the gavin <dig> data set.

for each data set, we use the set of annotated and clustered proteins for the evaluation. note that this can lower sensitivity and complex-coverage in the results of algorithms such as mcode that leave proteins unassigned. the results are shown in table  <dig> and the roc curves in figure  <dig>  as expected, we find clustering solutions of mcode to have low sensitivity  and high specificity because it assigns only few proteins and ignores the majority of proteins present in the experiment. we set the parameters of mcode as described by brohée and van helden  <cit> . when we changed the setting of mcode to include more clusters and assign more proteins, we significantly lose accuracy in all measures.

testing
to extract relevant information from our clusters, we compare the results to the mips and reguly data sets. we apply two evaluation procedures: one based on a set of benchmark procedures recently introduced by brohée and van helden  <cit>  and the other based on the pair-wise comparisons of proteins.

comparing a clustering result with annotated complexes using the evaluation procedure of brohée and van helden  <cit>  starts with building a contingency table. with n complexes and m clusters, the contingency table t is an n × m matrix whose entry tij is the number of proteins in common to the ith complex and the jth cluster. given a contingency table t, overall accuracy and separation value can be computed to measure the correspondence between clustering result and the annotated complexes  <cit> . the separation measure yields undesirable effects when the reference data set contains overlapping complexes because according to its definition  <cit> , a good match of a cluster to more than one complex will result in a low separation value. this situation arises for the mips and reguly benchmark, which are overlapping, while the computed results of mcl and mrf are not. furthermore, when matching the reference data set to itself, we found that its separation value can be less than that of some clustering solutions. for these reasons, we do not apply the separation measure. the definitions related to benchmarks are summarized in the methods section.

quality of clusters
in any given solution, some clusters will have more support from the observation than other clusters. support for a cluster is high if proteins in this clusters are less likely to be part of false positive or false negative observations. so we can compute a cluster quality metric as the difference between the actual number of false positives and false negatives and their expected number, based on the number of trials involving proteins of this cluster. let qi be the cluster assignment for protein i, ν * the estimated false negative rate and φ * the estimated false positive rate. then the difference between actual and expected errors e for each cluster k is

  

where efn=ν∗∑:qi=qj=ktij
 mathtype@mtef@5@5@+=feaagaart1ev2aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaacpc6xni=xh8vivgi8gi=heeeu0xxdbba9frfj0xb9qqpg0dxdb9aspei8k8fii+fsy=rqgqvepae9pg0db9vqaivgfr0xfr=xfr=xc9adbaqaaegacagaaiaabeqaaeqabiwaaagcbagaemyrau0aasbaasqaaiabdagamjabd6gaubqabagccqggoaakcqwgrbwacqggpaqkcqgh9aqpiigacqwf9ogbdaahaawcbeqaaiabgehiqaaakmaaqafabagaemidaq3aasbaasqaaiabdmgapjabdqgaqbqabaaabagaeiikagiaemyaakmaeiilawiaemoaaomaeiykakiaeiooaojaemyuae1aasbaawqaaiabdmgapbqabawccqgh9aqpcqwgrbqudawgaaadbagaemoaaogabeaaliabg2da9iabdugarbqab0gaeyyeiuoaaaa@4c6e@ and efp=ϕ∗∑:qi≠qj=ktij
 mathtype@mtef@5@5@+=feaagaart1ev2aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaacpc6xni=xh8vivgi8gi=heeeu0xxdbba9frfj0xb9qqpg0dxdb9aspei8k8fii+fsy=rqgqvepae9pg0db9vqaivgfr0xfr=xfr=xc9adbaqaaegacagaaiaabeqaaeqabiwaaagcbagaemyrau0aasbaasqaaiabdagamjabdchawbqabagccqggoaakcqwgrbwacqggpaqkcqgh9aqpiigacqwfvpgzdaahaawcbeqaaiabgehiqaaakmaaqafabagaemidaq3aasbaasqaaiabdmgapjabdqgaqbqabaaabagaeiikagiaemyaakmaeiilawiaemoaaomaeiykakiaeiooaojaemyuae1aasbaawqaaiabdmgapbqabawccqghgjsucqwgrbqudawgaaadbagaemoaaogabeaaliabg2da9iabdugarbqab0gaeyyeiuoaaaa@4d43@.

complex-size distribution
principle properties and potential artifacts are visible in a simple plot of the population of proteins by cluster size . in figure  <dig>  we only consider proteins with mips complexes assigned from the gavin <dig> data set, ignoring singletons; this results in  <dig> proteins. for each clustering solution, we compute the cluster size distribution of mips proteins which have cluster assignments. it is worth to note that there is an absence of mips complexes in the range from  <dig> to  <dig>  obviously, the proteins in the largest complex of size  <dig> all correspond to a single complex , whereas the  <dig> proteins in clusters of size  <dig> correspond to  <dig> different clusters. in figure  <dig>  when considering all proteins, all clustering solutions substantially deviate from the mips size distribution. mcl has a large cluster containing  <dig> proteins, likely an artifact. the gavin core set is only a subset and contains a substantial number of small elements and fewer complexes than the mips solution, prominently the mitochondrial ribosome and mediator complex. the larger, complete solution ) contains few small clusters; although this solution contains larger clusters , they do not accurately map to larger complexes. in figure  <dig>  our mrf solution for the spoke model contains more clusters of size  <dig> than the matrix model, but otherwise both have similar size distribution with more small clusters than large ones.

cluster visualization
for each clustering solution, we can visualize matches to the mips complexes by generating a contingency table whose rows are complexes and columns are clusters. for each cell in the table, we calculate the simpson coefficient  <cit>  and order the diagonal of the table by increasing matching sizes. clusters without any matches to annotated complexes are not part of the table, neither are complexes without a match to any cluster. in figure  <dig>  we summarize the mapping of mrf , mcl and the core gavin <dig> solutions. for more visualization of other clustering solutions and mapping to the reguly benchmark, refer to the supplementary material. we also visualize how well each solution maps to the complex-size distribution. for each clustering solution, we plot the histogram of cluster size distribution on the log-scale.

examples
a positive evaluation of a clustering procedure by internal and by clustering indices does not necessarily mean that the results are useful and match a user's expectation. above, we compared the results on a large scale, here we inspect the solutions in detail. when selecting biological examples, the mrf solution under the spoke model seems to produce better results for smaller complexes. note for example the underrepresentation of size  <dig> complexes under the matrix model in figure  <dig>  . the high false negative rate of the matrix model could imply that it is less capable than the spoke model. nonetheless, it recovers meaningful clusters, showing that it is robust against such high error rate as can be seen in the benchmark in figure  <dig> 

our mrf solution for the spoke model contains two largest complexes of size >  <dig> of presumably high quality. contradicting the observation that the spoke model appears to produce better results for larger complexes , manual inspection suggests that these structures are not similar to complexes like the ribosome or the proteasome but a rather spurious collection of proteins that interact. the two largest clusters in the spoke model do not constitute known complexes and highlight a peculiar property of the tap-ms data set. apparently, high-quality results are sporadically obtained for rather well characterized proteins that seem to link very different pathways and cellular localizations. although the two clusters have high quality with respect to the model, we find that there are not enough repetitions for these proteins and in practice we must interpret their interactions as of medium confidence only.

there is no general agreement in the field how a protein complex should be defined biochemically. many factors – binding constants, protein concentration and localization, different purification protocols – lead to different associations of proteins into aggregates that we consider complexes. moreover, paralogous proteins that lead to variant complexes complicate the distinction of similar complexes. disagreeing solutions for protein complexes offered by different methods do not necessarily indicate that either solution is wrong. for some complexes, all methods compared in this context lead to the identical solutions, such as the arp2/ <dig> complex  or the origin of replication complex . these complexes that are similarly found by all methods generally receive good  quality scores e in our model, indicating that all methods work for simple cases.

for larger complexes that can be well studied such as the proteasome, the results appear fairly consistent across the different solutions. the best mcl solution according to our benchmark only splits pre <dig>  an element of the 20s subunit, into a separate complex and assigns several components of the 19s subunit to a giant cluster together with many unrelated proteins. the mrf solution appears slightly superior to the predicted cores in gavin et al.  <cit>  in that no components of the 19s subunit are assigned to other elements. a complex that appears not represented well in our set are the rna polymerases, three complexes of 12– <dig> proteins that share  <dig> proteins. an ideal solution would either place all elements of the complexes into one or into three clusters. while the gavin solution neatly separates the complexes, the mrf solution only places several elements of the rna polymerases into clusters of low quality. the high quality cluster containing most elements of rnapii, the best characterized complex of the three by experimental data, is "contaminated" with specific members of the other two complexes. the mcl solution displays similar problems.

one solution to the clustering that we find superior in our results is complex  <dig> from the spoke model, consisting of sol <dig>  ade <dig>  ade <dig>  ste <dig>  sol <dig>  rtt <dig>  and yol063c. sol <dig> and sol <dig> are not part of the same complex in the gavin set of complexes or the mcl solution, and do not interact observably, but are homologues. the isoenzymes ade <dig> and ade <dig> are not part of the same complex in the solution in gavin et al.  <cit>  but can be assumed to have the same binding partners.

discussion
before we discuss the details of the results, we would like to point out that mrf is essentially a parameter-free method. although mfa requires two inputs, ψ and the number of clusters k, we provide a systematic way to estimate them using maximum likelihood. methods such as mcode require more parameters without a systematic way to select them other than trying out several values and comparing the results to benchmark data. if there is no such data set available, these methods cannot asses the quality of their solution, while the value of the likelihood function can be used for our mrf approach. mcl suffers from the same problem of parameter selection and essentially has three parameters, the expansion and inflation values and the number of clusters. so to choose a solution from mcl we must not only compare with the benchmark, but also decide if the number of clusters is biologically plausible. with regard to the number of predicted clusters, it is not surprising that mrf estimates higher number of clusters because it does not eliminate proteins prior to clustering, unlike other solutions  <cit> .

although we recommend the spoke model over the matrix model due to lower false negative rate, it is noteworthy that the solution of the matrix model is also biological meaningful when compared to the mips data set, although with slightly lower specificity than the spoke model . in reality, the model of interaction likely lies in between the two extremes. with regard to the quality of the clusters, we observe that almost all predicted clusters fit the model except some outliers that should not be regarded as complexes due to extremely high observed errors  and 4). closer inspection reveals that they are clusters consisting mostly of proteins that are systematic contaminants; one would not assign them to any complex manually. by giving these "junk" clusters the worst quality score, mrf can separate them from the rest of other complexes. for mcl, there is no such indicator.

the performance of mcl and mrf on the gavin <dig> data set is comparable as both achieve high accuracy. this is the result of the lower level of noise in the gavin <dig> data, which was filtered for abundant proteins. error modeling does not necessarily yield more accuracy. note also the similar distribution of cluster sizes .

the performance gain from error modeling is more noticeable in the larger gavin <dig> data set which is not filtered and likely contains more errors. the accuracy acc is the average of the agreement of a cluster to a complex. it penalizes complexes that are split more than complexes that are merged. to see if complexes are merged, we have to consider at the all pairs comparison for high sensitivity with low specificity. due to complexes merged in a giant component, mcl performs quite well on gavin <dig> measured by the accuracy value, but not when we consider the all-pairs sensitivity  and specificity  and comparing to the mips data set. to avoid the giant component, the inflation parameter of mcl must be set to the maximum level recommended  which reduces sensitivity . mrf in contrast can maintain high specificity without sacrificing sensitivity nor does it produce giant components. when comparing to highly specific solutions such as mcode or gavin <dig>  which assign fewer proteins, mrf loses only a few percent  in specificity, but gains about 30% in sensitivity and while clustering more proteins .

in general, both mcl and mrf perform better when compared to the mips benchmark than to the reguly data, with mrf performing better than mcl at matching both benchmark sets on the gavin <dig> data set. many complexes in the reguly set are redundant and overlap, some even completely which no method possibly could recover from data. hence, mcl and mrf will never be able to fully reconstruct the reguly data set as they assume no overlap between protein complexes. on the mips complexes and based on all-pair comparison, mrf outperforms mcl. this indicates that in general the assumption of complex formation based on only pairwise interaction is a reasonable one producing few false positive errors. we can observe the giant component of the mcl solution in figure z as the first column including several complexes. a perfect mapping would be displayed as a diagonal line with no off-diagonal entries. the results show that no solution provides the best mapping. although the core solution of gavin <dig> appears to have the cleanest mapping with few off-diagonal entries, it only contains  <dig> proteins, while our solution includes all  <dig> proteins. when comparing all solutions to the mips-size distribution in figure f, we clearly see that mcl is particularly far off due to the giant component which assigns about  <dig> proteins from different mips complexes into the same cluster. the solution from mrf appears to be the closest match in this regard, although it still cannot reconstruct mips-complexes larger than  <dig>  other solutions also have the same problem; the gavin <dig>  solution only maps to small complexes . mrf replaces large complexes by producing more smaller clusters than mips .

in summary, if the data has already been filtered as in the gavin <dig> data set, mrf does not have an advantage over mcl and is computationally more expensive. when clustering large and noisy data set, the evaluation demonstrates that mrf is a more suitable method, due to its rigorous framework allowing parameter selection using maximum likelihood.

CONCLUSIONS
we introduce a probabilistic model based on markov random fields to identify protein complexes from data produced by large-scale purification experiments using tandem affinity purification and mass spectrometric identification. unlike previous work, our model incorporates observational errors, which enables us to directly use the experimental data without requiring an intermediate interaction graph and without prior elimination of proteins from the sets. the assignment to clusters corresponding to protein complexes are computed with the mean field annealing algorithm. because there are proteins which cannot be well clustered, we also provide a model-based quality score for each predicted complex. our method does not rely on heuristics, which is particular important for applications on protein complex studies in organisms that do not have an established reference frame. the model has two parameters, which are estimated from the experimental data using maximum likelihood, providing an elegant solution to the problem. our results compare favorably on reference data sets, notably for the larger unfiltered data sets.

for future work, the hard assignments imposed by our model can be relaxed to capture overlapping complexes, but the model and minimization algorithm must be changed.

it would also be useful to have a quantitative estimate of the number of clusters k. one would need to trade off the increase in likelihood against the increase in the number of clusters, in effect finding the smallest number of clusters with almost maximal likelihood. one approach would be the minimum description length  criterion  <cit> , a rigorous technique to assign costs to both observation likelihood as well as the number of clusters.

