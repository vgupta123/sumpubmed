BACKGROUND
although the semantic similarity between two go terms has been extensively investigated  <cit> , how to define similarity between two gene products based on go annotations for a specific application remains unclear  <cit> . to date annotation similarity has been computed by four general approaches: the set-based approach; the graph-based approach; the vector-based approach; and the term-based approach. in the set-based approach an annotation is viewed as a 'bag of words'. two annotations are similar if there is a large overlap between their sets of terms. a graph-based approach views similarity as a graph-matching procedure. vector-based methods embed annotations in a vector space where each possible term in the ontology forms a dimension. term-based approaches compute similarity between individual terms and then combine these similarities to produce a measure of annotation similarity.

all the above approaches do not consider the semantics of relationships between terms. how terms are related can significantly alter how an annotation, which is a set of terms, is interpreted. in the go there are two main types of relations: is_a and part_of. the is_a relation represents a taxonomic relationship between terms that can be modeled using the improper subset relation, which is a partial ordering of terms. the part_of relation represents a partonomic relationship between terms that can also be modeled in terms of a partial order. though the partial orders represented by taxonomies and partonomies are well understood there has been little attention given as to how these two partial orderings combine. using the various cases identified by combining taxonomies and partonomies we construct an algorithm called ssa  that identifies the terms that can be associated with an annotation and terms that relate to both annotations. instances associated with these terms are then used to construct a resnik-like measure of annotation similarity thus extending the underlying intuitions behind this term-based measure to the annotation level.

a measure of term or annotation similarity should be based on a set of principles that form the basis for what is considered similar. the nature of similarity has been the focus of intense research in the areas of aesthetics  <cit>  and psychology  <cit> . in mathematics properties such as identity, symmetry and the triangle inequality have been used to form the basis of measures of similarity of mathematical objects. principles of term and annotation similarity have been suggested by various authors. this work intends to build on these principles and introduce additional principles that a measure of similarity should seek to satisfy. 

similarity between objects is normally expressed as a number that ranges along an interval on the real numbers ℝ. however the main purpose of similarity is usually to determine whether two or more objects are similar to a reference object. for this reason a measure of similarity can be viewed as a partial order on a set of objects, the actual numbers play only a secondary purpose. for example, we may say that an object x is more similar to z than another object y. formally this is expressed as sim > sim. 

in the study of ontological similarity lin  <cit>  develops the principles of commonality and difference when constructing a measure of term similarity. the greater the commonality between objects the greater the similarity. likewise, the greater the difference between objects the greater the dissimilarity. the source of both the commonality and difference between terms depends on the method chosen to measure the descriptiveness of terms. different sources of descriptiveness may result in different orderings of similarity between terms or annotations.

popescu et al.  <cit>  recognize that an important property of term similarity is that two different terms should have a non-zero similarity value if the terms are related. they also recognize that an important property of annotation similarity is that the descriptiveness of annotations should be greater than or equal to the descriptiveness of its constituent terms. in this paper this property is called the monotonicity property.

in defining a measure of similarity a set of relevant properties that objects can be compared along are identified. in ontological similarity, whether of terms or annotations, there are two main sources of similarity: the conceptual or structural level; and the instance level. at the structural level we may consider such properties as graph distance, graph similarity, relation types, common ancestors, etc. at the instance level we consider the set of instances associated with a term or annotation. our measure of ontological similarity combines aspects from both levels. here we survey how various measures of annotation similarity combine these properties in various ways to form the basis for a measure of descriptiveness of a term or annotation.

set-based approaches
set based methods for measuring the similarity of annotations are based on the tversky ratio model of similarity  <cit>  which is a general model of distance between sets of terms. it is represented by the formula

 ff+α∗f+β∗f 

where g <dig> and g <dig> are sets of terms or annotations from the same ontology and f is an additive function on sets . for α = β =  <dig> we get the jaccard distance between sets:

 sjaccard=ff 

and for α = β =  <dig> we get the dice distance between sets  <cit> :

 sdice=2∗ff+f 

in this situation the source of descriptiveness of an annotation is its set of terms. each term and its set of associated instances is considered independent of other terms. the commonality and difference between annotations is modeled as set intersection and difference of sets of terms respectively. set-based approaches return a similarity of zero if they do not share common terms ignoring the fact that terms may be closely related. because of the atomic nature of terms in the set-based approach the monotonicity property does not apply.

vector-based approaches
vector-based methods embed ontological terms in a vector space by associating each term with a dimension. usually a vector is binary consisting of 0's and 1's where  <dig> denotes the absence  of a term  in an annotation. this has the advantage that standard clustering techniques on vector spaces such as k-means can be applied to group similar terms. what is required is a means of measuring the size of vectors. this can be achieved by embedding terms in a metric space . the most common method of measuring similarity between vectors of terms is the cosine similarity

 sv=v1·v2|v1||v2| 

where vi represents a vector of terms constructed from an annotation  gi. |·| corresponds to the size of the vector and • corresponds to the dot product between two vectors. the source of descriptiveness, commonality and difference is the same as the situation for set-based approaches.

graph-based approaches
an ontology is a directed, acyclic graph  whose edges correspond to relationships between terms. thus it is natural to compare terms using methods for graph matching and graph similarity. we may consider the similarity between annotations in terms of the sub-graph that connects terms within each annotation. annotation similarity is then measured in terms of similarity between two graphs. graph matching has only a weak correlation with similarity between terms. it is also computationally expensive to compute, graph matching being an np-complete problem on general graphs  <cit> .

the descriptiveness of an annotation is modeled by the set of nodes and edges associated with a subgraph. commonality between annotations is based on the set intersection while difference is modeled by the set difference where each set consists of the nodes and edges associated with each subgraph. alternatively, the set of edges may be ignored and only common terms of both graphs are considered  <cit> .

improving similarity measures by weighting terms
set, vector and graph-based methods for measuring similarity between annotations can be improved by introducing a weighting function into the similarity measure. for example, the weighted jaccard distance can be formulated as:

 sweightedjaccard=∑{ti∈g1∩g2}m∑{tj∈g1∪g2}m 

where, as before, g <dig> and g <dig> are annotations or sets of terms describing data , tx is the xth term from a set of terms and m denotes the weight of tx. this weighting function can be used to represent various properties of a term or annotation such as a measure of vagueness, uncertainty, sense of preference or a combination of the above. the vector-based approach may be extended so that values along a particular dimension can lie on the interval  <cit>  or [ <dig>  ∞). the graph-based approach can be extended by weighting the edges between terms in the graph.

assigning a weight to each term in an annotation allows for the possibility of introducing the monotonicity property into a similarity measure. using the monotonicity property, the weight associated with an annotation should be greater than or equal to the weight associated with any of its constituent terms. weights can form an additional basis on which to measure the descriptiveness of a term or annotation.

instance-based weights
one approach to assigning weight to an ontological term is to measure how informative a term is in describing data. a method of measuring information is to analyze a term's use in a corpus against the general use of ontological terms in the same corpus. information is measured using the surprisal function:

  iccorpus = -log) 

where p corresponds to the probability of a term ti or its taxonomic descendants occurring in a corpus. for example, consider the case where there are  <dig> distinct instances in a corpus and  <dig>   <dig> and  <dig> of these instances are annotated by the terms ti, tj and tk respectively. if tj and tk are sub-types or children of ti and do not have child terms themselves then iccorpus=−log⁡≈ <dig> .

other weighting approaches
other measures of information can be used not necessarily relying on corpus data. one measure  <cit>  relies on the assumption that how the ontology is constructed is semantically meaningful:

 icont=1−log⁡+1)log⁡ 

where desc returns the number of descendants of term ti and numterms refers to the total number of terms in the ontology.

term-based approaches
in term-based approaches similarity between pairs of terms from each annotation are computed. these weightings are then combined in order to characterize the similarity between annotations as a whole. there are several ways to combine similarities of pairs of terms such as the min, max or average operations. term-based approaches depend on a function s where ti and tj are terms from two annotations g <dig> and g <dig> respectively. s provides a measure of distance/similarity between these two terms. once distances has been measured between all possible pairs of terms they are then aggregated using an operation such as max or the average of all distances. for example:

 savg=∑i=1n∑j=1msm∗n 

more sophisticated term based approaches combine multiple measures of term similarity and aggregate similarity values using more complex functions, for example  <cit> .

graphical measures of term similarity
the simplest approach to measuring similarity between ontological terms using the graph structure is to measure the shortest path distance between terms in the graph  <cit> . referring to figure  <dig>  in terms of graph distance, we may consider the terms 'muscle cell proliferation' and 'fibroblast cell proliferation'  as being more similar than the former term with 'fibroblast regulation' . however the graph distance has only a weak correlation with similarity of terms. the semantic similarity between 'positive fibroblast regulation' and 'negative fibroblast regulation' is far greater than the similarity between 'muscle cell proliferation' and 'fibroblast cell proliferation' even though both examples have a graph distance of two. a simple graph distance-based measure of similarity does not model in a consistent way any notion of commonality or difference between terms.

a more refined use of graph distance as a basis for a measure of term similarity is found in the wu-palmer measure of similarity  <cit> . it uses the idea that the distance from the root to the lowest common taxonomic ancestor  measures the commonality between two terms while the sum of the distance between the lcta and each term measures the difference between two terms. combining these aspects results in the formula:

 swu−palmer=2∗distdist+dist+2∗dist 

where t <dig> and t <dig> are the two terms being compared, tlcta is the term that corresponds to the lowest common taxonomic ancestor between t <dig> and t <dig>  troot denotes to root node of the ontology . dist denotes the graph distance between terms ti and tj. the  <dig> * dist component of the denominator serves to normalize the measure.

instance-based measures of term similarity
similarity may be measured using an instance based measure of semantic similarity as computed by either resnik  or lin . resnik  <cit>  exploits the informativeness of the lowest common ancestor between terms as a measure of semantic similarity:

  sresnik = iccorpus 

where tlcta denotes the lowest common taxonomic ancestor between ontological terms ti and tj. this measure only accounts for the commonality between terms.

another method of measuring similarity derived by lin  <cit>  is:

  slin=2∗iccorpusiccorpus+iccorpus 

which has the advantage that it maps onto values on the interval  <cit>  unlike resnik's measure which maps onto the interval [ <dig>  ∞). lin's measure also accounts for both the commonality and difference between terms. resnik's measure does have the desirable property that terms close to the root of the ontology have a low similarity however. this is not the case for lin's measure.

the only structural property that both resnik and lin exploit is the lowest common taxonomic ancestor. to overcome this weakness jiang and conrath  <cit>  integrate graph distance based measures of similarity into information based approaches. they construct a generalized weighting measure between a child and its immediate parent that accounts for the number of out edges and depth of terms along the shortest path between the compared terms in the ontology. while they acknowledge that other relation types might be relevant to measuring similarity their measure is based solely on the taxonomic or is_a relations in the ontology.

new approaches to annotation similarity
beyond the set, vector, graph and term-based approaches to measuring similarity of annotations exist other methods that introduce the additional properties discussed above such as monotonicity and taking into account the semantics of ontological relations.

similarity based on fuzzy measures
the monotonicity property leads naturally to the use of fuzzy measures as a basis for measuring the descriptiveness of an annotation. using the information content measure of terms described in eqn.  <dig> as the basis for measuring similarity a fuzzy measure is constructed. a fuzzy measure is a weighting on sets of terms such that the weight associated with a set of terms is greater than or equal to the weight associated with any of its subsets.

popescu et al.  <cit>  use fuzzy measures to induce a weighting m for an annotation from its constituent terms. this weight is extrapolated from the weights of individual terms by using the formula for constructing a sugeno λ-fuzzy measure: for a set of terms ga, gb and gc where gc = ga ∪ gb and ga ∩ gb = ∅ a λ-fuzzy measure for gc is

 mλ = mλ + mλ + λ * mλ * mλ 

where λ is a value that ensures that m ≥ m and m ≥ m. given that the weights  m for individual terms ti in an annotation are known then λ can be determined by solving the following equation:

 1+λ=∏ti) 

in  <cit>  the weight for each term is based on the iccorpus measure . the similarity of two annotations, represented by a set of terms g <dig> and g <dig> from the same ontology, are compared using the similarity function:

 sfms=mg1+mg <dig> 

where mg <dig> and mg <dig> are the λ-fuzzy measure functions that characterize g <dig> and g <dig> respectively. the relatedness of terms is accounted for by augmenting each annotation with the lowest common ancestors for each pair of terms from each annotation. this ensures a non-zero similarity between annotations containing related terms.

however, an ontology models other aspects of relatedness that should be taken into account. relations between terms in an annotation can be used to identify redundant terms whose relevance to the descriptiveness of an annotation is already accounted for by other terms. for example, if two terms in an annotation are taxonomically related the existence of the parent term is implied by the existence of the child term.

if redundancy of terms is not taken into account it may lead to too many or too few instances being associated with the term. this is especially true when a term is part_of another term. the instances associated with the annotation consist of the parts and not what the instances are part of.

exploiting semantics of ontological relations
wang et al.  <cit>  account for the different contributions that terms related by is_a and part_of relations make to the descriptiveness of a term. the semantic contribution that ancestor terms make to a child term is calculated by:

 sv=∑tj∈tanc,isti 

where tanc, i denotes the ancestors of term ti and sti is calculated as

 {sti=1sti=max⁡{we∗sti|tk∈childrenof} if tj≠ti 

where we ∈  <cit>  is a number that corresponds to the semantic contribution factor for edge e. childrenof is a function that returns the immediate children of tx that are ancestor terms of ti. in this paper wis_a =  <dig>  and wpart_of =  <dig> . the similarity of two terms is computed by the formula

 s=∑tk∈tanc,i∩tanc,j+stj)sv+sv 

a term-based approach is taken to measuring the similarity between annotations g <dig> and g <dig>  the similarities of the most similar pairs of terms from each annotation are averaged over to calculate the similarity between annotations:

 swang=∑ti∈g1s+∑tj∈g2s|g1|+|g2| 

where s=max⁡ty∈gy) and |gy| denotes the number of terms in annotation gy.

wang et al. make the observation that the instance based measures of term similarity will produce varying results based on the corpus chosen. they keep a fixed value for the contribution each relation type makes to the descriptiveness of a term. this does not account for the varying influence of terms on each other throughout the ontology even if the graph distance is the same. exploiting the corpus statistics, if used appropriately, may account for this drawback. as with all term-based methods, where terms from each annotation are compared in a pairwise fashion, it is difficult to see how the monotonicity property is ensured when measuring the similarities between two annotations.

methods
the gene ontology relates terms using is_a and part_of relations. we develop a measure of informativeness that provides a description of an annotation that takes into consideration the relations between terms. we use the informativeness measure of a term  as the basis for providing a description of an annotation. we define an algorithm called ssa that combines the instances of terms while taking into account how these sets of instances are related by how their associated terms are related in the ontology. this results in a set of instances that can be said to be associated with an annotation and not just a term. we can then extend the concept of instance based semantic similarity of terms, such as resnik's measure, to annotations.

interpreting annotations from taxonomies
a taxonomy induces a partial ordering on a set of terms by the improper subset relation ⊆. if ti is_a tk and tj is_a tk then the set of instances associated with both ti and tj are subsets of tk. assuming that we know of all possible instances that can be associated with a term, whatever properties that instances of both ti and tj share can be associated with any of the instances that can be associated with tk. this forms the basis for measuring the commonality between terms used in instance-based measures of similarity between terms.

the difference between terms ti and tj is modeled by the difference between the set of instances associated with each term. if we have two or more terms from a taxonomy in an annotation then it is reasonable to argue that the set of instances associated with an annotation should be the intersection of the set of instances associated with each term. the informativeness of the annotation is then based on the set of instances resulting from this intersection.

interpreting annotations from partonomies
the part_of relation between terms denotes the concept that one term is 'part of ' another. it provides an alternative notion of relatedness between terms. an ontology consisting only of part_of relations is known as a partonomy. an example of a simple partonomy is wheel part_of car. it would not make sense to say that a wheel is_a car. the study of partness is complicated by the fact that there are many kinds of part_of relations. yet the study of partness, known as mereology  <cit> , has shown that there are also common aspects to all types of part_of relations, namely that part_of relations form a partial ordering on the sets of instances associated with each term.

according to the go consortium's usage guidelines since  <dig>  <cit>  the part_of relation should be interpreted as 'necessarily part of' where ti part_of tj means that all instances of ti are part of one or more instances of tj. the converse is not necessarily true. for example, all nuclei are part of cells but not all cells contain a nucleus. bittner  <cit>  models such a part_of relation using an improper partial order i.e. for term ti with descendant terms tj.

  tj ≤part_of ti ∀tj part_of ti 

annotations consisting of terms such that one term is part_of another should view the child term as being relevant to the annotation while the parent term provides redundant, contextual information. for example, consider an annotation consisting of two terms ti and tj from a partonomy. if tj part_of ti then the annotation should be interpreted as the set of instances of tj. all we can say is that the number of instances of ti associated with the annotation can be no more than the number of instances of tj. in general, an annotation consisting of terms belonging to a partonomy consists of terms that provide the set of instances that can be associated with the annotation while other terms provide the context in which these instances are embedded.

partial order constraints for go annotations
the go consists of many examples similar to the one described above. in general, the go can be viewed as a taxonomy interspersed with part_of relations. two terms are said to be directly related if there exists a series of relations on a single path between them. terms that are not directly related along a path in the graph are indirectly related via a common ancestor. for example there may be other terms that are part_of 'mitochondrial nucleoid' in which case the term 'mitochondrial chromosome' is only related to the other parts by an indirect path of part_of relations. though not shown, the terms 'mitochondrial nucleoid' and 'chromosome' are only indirectly related via a common ancestor through a number of is_a relations. when interpreting an annotation it is necessary to account for such situations.

in general, as described in table  <dig>  there are nine cases to handle when trying to account for how terms are related. terms or their taxonomic descendants may be directly related to each other in the ontology via a single path. alternatively they may be indirectly related to each other via a common ancestor in which case we consider the two paths from the common ancestor to each term. a path may be homogeneous in that it consists of relations of only one type i.e. all relations are either only is_a or only part_of. such paths are denoted by is and part respectively. a path that is inhomogeneous, consisting of both is_a and part_of relations, is denoted by mixed.

overview of general forms of relation based ordering for directly and indirectly related terms. terms are indirectly related via a common ancestor term tlca. instances of terms ti and tj may be part of the common ancestor tlca via terms tk and tm respectively. ρ denotes a function that measures the number of instances  of terms. these orderings assume complete knowledge of all instances associated with a term.

directly related cases
there are three cases to handle when there exists a single path between terms in the ontology: is, part and mixed paths. the first case is the generalized case of taxonomic relations where ti is tj. for two terms ti and tj, where tj is the parent term and ti is a descendant, and a set of n intermediate terms {tn} such that:

 ti⊆t1n⊆t2n…⊆tn−1n⊆tnn⊆tj 

it can be inferred that ti ⊆ tj. where terms are related by a part path a similar argument can be inferred for how two terms are ordered.

for the mixed case there exists a mixture of is_a and part_of relations. the nature of the mixed relationship is ultimately determined by the part_of relations. for example, if ti mixed tj then this can be interpreted as ti part_of tj. there may be several is_a relations traversed along a mixed path from tj to ti before a part_of relation is encountered. this means that ti can only be part_of a subset of the instances of tj. this subset is identified by the set of instances associated with the term  which is the parent term of the first part_of relation encountered along a mixed path from tj to ti. this results in the partial order:

 ti ≤ tk ≤ tj 

where ti is the descendant of tj, ti is the parent and tk denotes the first term before a part_of relation is encountered while traversing the mixed path in the ontology from tj to ti. this form of reasoning can be further extended along the rest of the mixed path to produce a more detailed partial order. however if the ultimate goal is to only determine the partial order between ti and tj then such induction of this reasoning is unnecessary.

indirectly related homogeneous cases
there are three cases to handle where both the paths to the common ancestor between terms are homogeneous: is – is, part – part and is – part . in the first case, where ti is tlca and tj is tlca, since both terms ti and tj are taxonomic descendants of a lowest common ancestor tlca then it should be expected that the number of instances associated with ti and tj are less than the number of instances associated with tlca. this results in the partial order

 ti, tj ≤ tlca 

an annotation consisting of two such related terms can be interpreted as the set of instances that are associated with both ti and tj. a similar form of reasoning can be applied to the part – part case. the partial order for the final case is – part  can be derived in a similar fashion to the inhomogeneous direct mixed case. if ti is tlca and tj part tlca then it can be inferred that tj part ti. if an annotation consists of two such terms then it should be interpreted as the set of instances of tj. as a partial order constraint this can be modeled as

 tj ≤ ti ≤ tlca 

indirectly related inhomogeneous cases
indirectly related inhomogeneous cases occur when terms are related by a common ancestor in the ontology and one or both of the paths connecting the common ancestor with each term consists of an inhomogeneous set of relation types. there are three such cases to account for: is – mixed , part – mixed  and mixed – mixed.

the partial order for the first case is – mixed  can be handled by considering each path separately. the partial order for the ti is tlca path is ti ≤ tlca. the partial order for the mixed path is tj ≤ tk ≤ tlca which is derived in the same way as the directly related mixed case. combining the two partial orders results in

 , ti ≤ tlca 

if an annotation consists of two such terms then it should be interpreted as the set of instances of tj that are part of instances that are of type ti and tk.

the part – mixed  case requires slightly more reasoning about to construct its associated partial order. if ti part tlca and tj mixed tlca then it can be inferred that both ti and tj are part of tlca. because tj is only part of a subset of the instances associated with tlca, the instances associated with tk, then ti can only be part of the set of instances associated with tk also. this results in the partial order

 tj, ti ≤ tk ≤ tlca 

an annotation consisting of two such related terms should be interpreted as the set of instances of ti and tj that are part of the same instances of tk.

the final case mixed – mixed occurs when paths from both terms to the common ancestor consist of a mixture of relation types. the partial order for such a case can be constructed by looking at each path separately. if ti mixed tlca then the partial ordering is ti ≤ tk ≤ tlca. similarly for tj mixed tlca we get tj ≤ tm ≤ tlca. combining the two partial orders results in

 ,  ≤ tlca 

if an annotation consists of two such terms then it should be interpreted as the set of instances of tiand tjthat are part of the same instances of tkand tm.

the ssa algorithm
the ssa algorithm is based on the nine cases of term relatedness described above. the ssa algorithm derives the set of instances that can be associated with an annotation from the set of instances associated with that annotation's constituent terms. there are two aspects to the algorithm: identifying which terms are the contextual, redundant instances and which terms' instances can be associated with the annotation. for example, a contextual instance may be 'mitochondrial nucleoid' that provides the context for the set of instances of 'chromosome'. throughout we denote the set of contextual terms by exclterms and the set of terms whose instances can be associated with the annotation as inclterms. numinst denotes the number of instances associated with ti.

the above partial order constraints were constructed under the ideal assumptions assumed by the partial orderings in taxonomies and partonomies. in reality there only ever exists an incomplete set of instances associated with terms and some adjustment of the number of instances is required if the partial order constraints are to be satisfied. terms that are taxonomically related are guaranteed to satisfy the taxonomic constraints. however, terms that are partonomically related may not satisfy their associated partial order constraints. in these cases some adjustment of the number of instances associated with a term is necessary. for example, if ti part tj and there are no instances associated with tj in the corpus while there are a number of instances associated with ti then in order to satisfy the part constraint the number of instances of tj is set equal to the number of instances associated with ti.

the algorithm consists of the following steps:

• for each distinct ordered pair  of terms in annotations g <dig> and g <dig> respectively

- identify the case that corresponds to how ti is related to tj

* terms are assigned to inclterms or exclterms depending on case

* the number of instances associated with a term may be adjusted if the case allows

• remove any terms from inclterms also found in exclterms

• return the sets inclterms and exclterms

where an ordered pair of terms  means that  ≠ . in the following sections we identify how each case assigns terms to inclterms and exclterms and adjusts the number of instances associated with each term used to compare annotations.

direct cases
the is constraint where one term in an annotation is a special case of another term can be implemented as follows:

 <dig> if 

inclterms ← inclterms ∪ ti

exclterms ← exclterms ∪ tj

in this situation the term tj is viewed as being the common taxonomic ancestor of both terms.

the part constraint where one term is a part of another term can be implemented as:

 <dig> if 

inclterms ← inclterms ∪ ti

exclterms ← exclterms ∪ tj

if  < numinst)

numinst = numinst

in this situation the term tj is viewed as providing the context that instances of ti are part of.

the case is similar for ti mixed tj. in these cases we are relating terms that belong to two different lines of taxonomic inheritance where terms have a possibly incomplete set of associated instances. in order to ensure that the partial order constraint associated with this case is implemented correctly if tj has fewer instances associated with it than ti then we adjust the number of instances associated with tj to be equal to the number of instances associated with ti.

the mixed constraint where ti is a part of another term tj via an intermediate term tk can be implemented similarly to the part case:

 <dig> if 

inclterms ← inclterms ∪ ti

exclterms ← exclterms ∪ tj

exclterms ← exclterms ∪ tk

if  < numinst)

numinst = numinst

if  < numinst)

numinst = numinst

in this situation the term tk is viewed as providing the context that instances of ti are part of.

indirect homogeneous cases
in the indirect homogeneous cases compared terms ti and tj are indirectly related via a common ancestor tlca along homogeneous paths. the first such case is where ti is tlca and tj is tlca. in this situation the number of instances associated with tlca provides a measure of similarity between ti and tj:

 <dig> if 

numinst, numinst ← min, numinst)

inclterms ← inclterms ∪ tj ∪ ti

exclterms ← exclterms ∪ tlca

in the case where ti part tlca and tj part tlcatlca provides the context in which instances of ti and tj are embedded.

 <dig> if 

numinst, numinst ← min ∩ numinst)

inclterms ← inclterms ∪ tj ∪ ti

exclterms ← exclterms ∪ tlca

if  < numinst)

numinst = numinst

since terms from two different lines of taxonomic inheritance are being compared and the set of instances associated with each term is incomplete an adjustment of the number of instances associated with each term is necessary.

the final homogeneous indirect case occurs when ti part tlca and tj is tlca. this is equivalent to ti part tj since if ti is a part of tlca and tj is a kind of tlca then ti is a part of tj.

 <dig> else if 

inclterms ← inclterms ∪ ti

exclterms ← exclterms ∪ tj

exclterms ← exclterms ∪ tlca

if  < numinst)

numinst = numinst

if  < numinst)

numinst = numinst

as with other cases the number of instances associated with each term are adjusted to ensure that the partial order constraint associated with the case is satisfied.

indirect inhomogeneous cases
in these cases one or both paths from tlca to terms ti and tj contain inhomogeneous types of relations. throughout this section the term tk is a term in the ontology such that tm mixed tk and tk is tn if tn is an ancestor of tm in the ontology.

the first such case occurs where for two indirectly related terms being compared, ti and tj, there exists an mixed path from ti to tlca via tk and an is path from tj to tlca.

 <dig> if 

inclterms ← inclterms ∪ ti

exclterms ← exclterms ∪ tlca

if  < numinst)

numinst = numinst

if  < numinst)

numinst = numinst

since the relationship between ti and tj cannot be refined further than their relationship via tlca only tlca is assigned to exclterms.

the second case occurs when ti mixed tlca via tk and tj part tlca. since tj is part of tlca and ti is part of tk which is a kind of tlca then tj is a part of tk.

 <dig> if 

inclterms ← inclterms ∪ ti

inclterms ← inclterms ∪ tj

exclterms ← exclterms ∪ tk

exclterms ← exclterms ∪ tlca

if  < numinst)

numinst = numinst

if  < numinst)

numinst = numinst

if  < numinst)

numinst = numinst

the final case occurs when both terms ti and tj are mixed related to tlca via tk and tm respectively. what is common between both terms ti and tj is that they are both part of tlca. the number of instances associated with each term is adjusted to satisfy the partial order constraints associated with this case.

 <dig> if 

inclterms ← inclterms ∪ ti

inclterms ← inclterms ∪ tj

exclterms ← exclterms ∪ tlca

if  < numinst)

numinst = numinst

if  < numinst)

numinst = numinst

if  < numinst)

numinst = numinst

if  < numinst)

numinst = numinst

after all terms have been compared with each other it is necessary to remove any terms from inclterms that are found in exclterms. this can occur when one comparison assigns a term to inclterms while another comparison identifies the term as belonging to the excluded set. after all terms are compared each term in inclterms should have the same number of instances associated with it. the number of instances that are associated with an annotation g is equal to the minimum number of instances that can be associated with any of the terms in inclterms ∩ g.

finding the nearest common annotation
just as in semantic similarity of terms, where there is a common ancestor between two terms, there exists a nearest common annotation between two annotations. the concept of a nearest common annotation allows the extension of information based semantic similarity measures of terms, such as resnik's and lin's measures, to information based measures of semantic similarity of annotations.

we define the nearest common annotation  between two annotations g <dig> and g <dig> to be the annotation containing terms related to both annotations. the nca should have the minimum possible number of instances associated with it such that either g <dig> or g <dig> can be derived from it. the set of terms exclterms which results from applying ssa to two annotations g <dig> and g <dig> will return the set of terms associated with the nca.

measuring similarity
by introducing the notion of nearest common annotation we can naturally extend resnik's measure to measuring similarity of annotation. the lca between two terms is replaced with the nca of two annotations g <dig> and g <dig>  likewise, instead of applying iccorpus  to instances associated with a term we apply iccorpus to instances of an annotation. thus the extension of resnik's measure from terms to annotations g <dig> and g <dig>  ssaresnik, becomes:

 exclterms←ssassaresnik=−log⁡max⁡numinst) 

where maxnuminst is the number of distinct instances in the corpus.

lin's measure may be extended as follows:

 inclterms1←ssainclterms2←ssaicg1←−log⁡maxnuminst)icg2←−log⁡maxnuminst)ssalin=2∗ssaresnikicg1+icg <dig> 

in this case the ssa algorithm is used to find the non redundant terms that can be associated with an annotation.

example
we compare the similarity of two gene product's annotations that returns a high measure of similarity when compared using our measure ssaresnik. two gene products, aah <dig> and fur <dig> whose annotations  were taken from the sgd database  <cit>  were compared producing a similarity value of  <dig> . the number of instances associated with each term were obtained from the goa  <cit> s. cerevisiae table of go assignments.

fur1's annotation consisted of six terms: {go: <dig>  go: <dig>  go: <dig>  go: <dig>  go: <dig>  go:0016757}. each term's description is found in table  <dig>  likewise, aah1's annotation consists of twelve terms: {go: <dig>  go: <dig>  go: <dig>  go: <dig>  go: <dig>  go: <dig>  go: <dig>  go: <dig>  go: <dig>  go: <dig>  go: <dig>  go:0043103}. the nca is constructed by applying the ssa algorithm to identify the set of contextual terms common to both annotations. terms such as the root term 'all' are immediately added to exclterms. the term 'cellular component'  is added to exclterms since another term 'cell part' is is_a related to it. the term 'nucleobase metabolic process'  is a more specific type of 'nucloebase, nucleoside and nucleotide process'  and the terms are added to inclterms and exclterms respectively. similar assignments occur for 'nucleobase metabolic process' /'cellular metabolic process' , 'nucleobase metabolic process' /'cellular process'  as well as other terms.

the ssa algorithm return nine contextual terms, {'all' , 'cellular process' , 'cellular metabolic process' , 'nucleobase metabolic process' , 'nucleobase, nucleoside, nucleotide and nucleic acid metabolic process' , 'nucleobase, nucleoside and nucleotide metabolic process' , 'cell part' , 'intracellular' , 'catalytic activity' , 'metabolic compound salvage' }. the resulting annotation contains terms from all three ontologies in the go. there are  <dig> instances associated with the annotation. the number of instances is determined by the most specific term: 'metabolic compound salvage' . the total number of instances in the corpus is  <dig>  ssaresnick=−log⁡≈ <dig> . since the highest value that ssaresnik could return for the chosen corpus is ~ <dig> , taking the natural log of  <dig>   <dig>  corresponds to high degree of similarity.

RESULTS
to validate our approach the discriminatory power of our method to identify clusters of related gene products was compared against wang's measure of annotation similarity that also exploits the differences between types of relations. the average similarity of gene products found in the same biochemical pathway in the sgd database was compared against the average similarity of the same gene products compared with gene products found in other pathways. a large difference between these two values indicates the effectiveness of a similarity measure in discovering new pathways in a set of gene products. average similarity of annotations inside and outside pathways was measured under four conditions: all terms; cellular component terms only; biological process terms only; and molecular function terms only.

a better test would be to take the average similarity of a set of gene products found in the same pathway and find the average or max of the average similarities of all other similarly sized sets of gene products. of course this is intractable since the computational complexity of such a test is o since there are  ways of creating a set of size n from a set of n elements.

as shown in figures  <dig>   <dig>   <dig>  when only terms from the cellular component sub-ontology are used the difference between ssaresnik and maxresnik becomes clear. maxresnik returns a very high average similarity value between terms inside and outside a pathway. this may be an artifact of the low number of instances associated with cellular component terms. however when ssa is applied the average similarity values between annotations inside and outside pathways remains consistently low. ssaresnik returns a comparatively high average similarity value for annotations inside pathways for approximately half the cases to which it can reasonably be applied. wang's method behaves similarly to maxresnik in this situation.

as shown in figures  <dig>   <dig>   <dig>  if only biological process terms are used further dissimilarity between maxresnik and ssaresnik can be observed. the average similarity values of annotations inside a pathway with annotations outside a pathway is much higher for maxresnik than for ssaresnik. wang's method and ssaresnik behave similarly. similarity values of annotations inside a pathway remain consistently higher than when the same annotations are compared with annotations outside the pathway for all methods.

the source of the similarity between ssaresnik and maxresnik can be identified when only molecular function terms are used, as shown in figures  <dig> and  <dig>  in this case both methods behave exactly the same since there are no part of relations to exploit when comparing terms. wang's method, shown in figure  <dig>  returns a consistently high average similarity value for annotations inside a pathway compared with annotations outside a pathway.

further discriminatory power can be achieved by considering the standard deviation of similarity values inside and outside a pathway. a set of gene products paired with other gene products in a pathway tend to have a high standard deviation of similarity values over all pairs mainly due to the small number of pairs being compared. conversely, pairing gene products inside a pathway with those found outside the pathway should produce a set of similarity values with a lower standard deviation since annotations are expected to be dissimilar and values come from a larger set.

figures  <dig>   <dig>   <dig> shows the standard deviation of similarity values of annotations consisting of cellular component terms inside pathways. maxresnik returns a low internal standard deviation while reporting a consistently high standard deviation of similarity values when annotations inside a pathway are compared with annotations outside a pathway. the standard deviation of annotation similarity values between different pathways returned by both ssaresnik and wang's method are both consistently low. the standard deviation of all methods behave similarly as average similarity of annotations, consisting only of biological process terms, within pathways increase, as shown in figures  <dig>   <dig>   <dig>  the same is also true of annotations consisting of molecular function terms, as shown in figures  <dig>   <dig>   <dig> 

discussion and 
CONCLUSIONS
the ssa algorithm provides the basis of a framework for extending instance based measures of term similarity to annotations. the algorithm's construction is based on the set of cases for how terms are related to each other when the ontology consists only of is_a and part_of relations. due to the incomplete nature of the set of instances associated with a term it is necessary to adjust the number of instances associated with a term in order to satisfy the partial order constraints of each case fully. as the number of annotations of gene products increase and ontological terms are applied more consistently it may be possible to satisfy the constraints without such adjustment. alternatively, the partial order constraints can be used to develop a similarity method which is less dependent on the set of instances associated with terms.

when terms from all three sub-ontologies  are used similarity of annotations between maxresnik and ssaresnik are equivalent on proteins found in the sgd database. this is due to the high degree of specificity of molecular function terms, which are not related partonomically, which causes the two measures to return the same values. when only cellular component and biological process terms are used, based on the experimental evidence, ssaresnik becomes a better identifier of proteins belonging to pathways. ssaresnik may identify new gene products that belong to pathways but have a different molecular function to those proteins already identified as belonging to the pathway. molecular function terms only play a small role in identifying new pathway proteins since proteins tend to have different molecular functions inside pathways.

by finding the set of instances that can be associated with an annotation it is possible to preserve, at the annotation level, the properties of instance based methods used to measure the similarity of terms. for two given annotations, the nearest common annotation  is a minimal set of terms such that either annotation could be derived from it. the ssa algorithm provides a method for finding the set of terms associated with the nca.

by combining the ssa algorithm with resnik's measure and the concept of nearest common annotation we have developed a measure that provides good discriminatory power to identify possible pathways and other functional groups from gene product annotations. more generally, the set of cases and their associated constraints further extend the set of principles that a reasonable measure of annotation similarity should be built on.

competing interests
the authors declare that they have no competing interests.

authors' contributions
bs proposed, designed and implemented the algorithm and table of constraints. bs wrote the manuscript. aq and bg supervised and approved the production of this paper. sd contributed helpful suggestions for the final manuscript.

supplementary material
additional file 1
averages and standard deviations of similarity values. averages and standard deviations of similarity values of maxresnik, ssaresnik and wang's method for each pathway in sgd.

click here for file

 acknowledgements
this work has been supported by microsoft research cambridge and the irish research council for science, engineering and technology.
