BACKGROUND
the recent advent of genotyping chips, which can analyze up to  <dig>  single nucleotide polymorphisms  per individual, offers a powerful tool for large scale association studies in human diseases. the most common approach to find genes possibly implicated in a disease relies on the comparison, in patients and controls, of the distributions of snp markers. an approach to increase the power of such studies is to focus on more complex markers which capture implicitly the linkage disequilibrium  between snps: the combination of snp alleles on the same chromosome called haplotypes. haplotypes are of great interest to study complex diseases since they are generally derived from chromosomal fragments which are transmitted from one generation to the next or which may have a biological meaning such as the promoter or the exons of a gene  <cit> . beyond the biomedical applications, the comparison of haplotype distributions between populations also provides new insights in the diversity, the history and the migrations of human populations. for instance, several studies  <cit>  have recently highlighted that genetic diversity of the human genome is organized in regions called haplotype blocks in which snps exhibit a high degree of ld and few common haplotypes. these haplotype blocks are delimited by recombination hotspots and chromosomes can thus be viewed as mosaics of common haplotypes. the recently developed hapmap project, dedicated to establish a dense map of snps and ld in various human populations  <cit> , has emphasized the interest of haplotypes to study human diversity.

regular genotyping  provides the genotype for each snp but does not allow the determination of the haplotypes , and current experimental solutions to this problem are still expensive and time-consuming  <cit> . clark was first to introduce a computational alternative  <cit> : the determination of haplotypes via a parsimony criterion which leads to a minimal set of haplotypes sufficient to explain the entire population. since then, efficient statistical algorithms have been developed under the random mating assumption where the observed genotypes are formed by sampling independently two unknown haplotypes. this assumption, coupled with a probabilistic model for the haplotypes, permits to define the likelihood of the observed genotypes as a function of the model parameters. thus, in order to infer haplotypes, the most likely parameter values are estimated via an expectation maximization algorithm  or a gibbs sampler algorithm  on the observed genotypes.

the first em-based model estimated the most likely haplotypes frequencies for observed genotypes without making any assumption on the mutation and recombination history of haplotypes  <cit> . many software were built on this simple model and the best-known is certainly plem  <cit> . later on, two new models were developed based on the idea that the haplotypes were arising through mutation and recombination events from few founder haplotypes. in gerbil  <cit> , haplotype blocks are strictly defined by dynamic programming and in each block, the haplotypes are derived through mutations from founder haplotypes. on the other hand, in fastphase  <cit> , in hit  <cit> , and in hint  <cit> , both mutation and recombination events on founder haplotypes are simultaneously modeled through a hidden markov model . all these methods estimate founder haplotypes from observed genotypes via em algorithms.

for the gs-based algorithms, the general case relies on sampling haplotypes for a genotype in function of all the haplotypes currently assigned to the other genotypes. the model of haplotyper  <cit>  simply favors haplotypes which have been already assigned to many genotypes. in phase v <dig>   <cit> , the idea was to favor the sampling of haplotypes which likely coalesce with the already assigned ones. at last, in phase v <dig>   <cit> , the sampled haplotypes are mosaics of the previously sampled ones modeled in a hmm.

recently, an alternative approach to the statistical algorithms was proposed in 2snp  <cit>  which computes ld measures for all pairs of snps and then resolves genotypes by finding the maximum spanning trees.

several studies have suggested that the hmm-based methods were the most accurate to infer the haplotypes  <cit> , certainly because of the flexible definition of the haplotype blocks which depends generally on the physical distance between snps  <cit> . among the hmm-based methods, phase v <dig>  is often considered as the most accurate developed so far  <cit>  which explains why it is widely used in genetic association studies  <cit>  and why it was used to phase the genotype data of the hapmap project  <cit> . the strength of phase v <dig>  probably comes from two particularities. first, the hmm is built during the gs iterations with a number of haplotypes proportional to the number of genotypes in opposition to other hmm-based methods which define a fixed number of founder haplotypes. second, the haplotypes are inferred by summing over all the possible hidden state sequences of the hmm  whereas many other hmm-based methods infer haplotypes by sampling only the most probable hidden sequence in the hmm .

however, the required running time increases dramatically with the number of snps since the search space grows exponentially. this prevents the easy use of phase v <dig>  in the current high-throughput chips. this fact has previously motivated us to develop ishape  <cit>  which matches phase v <dig>  accuracy while maintaining feasible running times. for that, we have used a two-step strategy:  <dig>  we defined a limited space of possible haplotypes with a rapid pre-processing algorithm based on bootstrapped em haplotypes estimations  <dig>  on this limited set of haplotypes, we then used an accurate phase-like algorithm. the rapidity of the first step is made possible thanks to an iterative implementation of the em algorithm which avoids any exponential growth of the space of possible haplotypes and includes the snps one after the other during the computations. in practice, ishape runs up to  <dig> times faster than phase  <dig>   with a similar accuracy in populations with high ld, such as caucasian genomes.

in this work, we present major improvements which greatly reduce the computational time of phase v <dig> . these improvements have been implemented in the software package shape-it and compared to the widely used competitor software.

algorithm
notations 
let's assume we have a sample of n genotypes g = {g <dig> ..., gn} describing the allelic content of n diploid individuals over s snps. a genotype is split into a haplotype pair by setting the phases between the z heterozygous snps . the number of distinct haplotype pairs consistent with a genotype is then  <dig>  let s = {s <dig> ..., sn} denotes the total haplotype space where si is the space of possible haplotype pairs associated with the ith genotype. moreover, let's assume we have the recombination parameters ρ = {ρ <dig> ..., ρs-1} in the s- <dig> intervals between the s snps of the sample as described by stephens et al  <cit> .

gibbs sampler algorithm
the gs algorithm considers the haplotype reconstructions of n individuals as a set of n random variables h = {h <dig> ..., hn} with sampling spaces in s and it estimates the conditional joint distribution of h given g and some recombination parameters ρ: pr. in simple words, it computes a conditional probability for each haplotype pair of s in light of the observed genotypes g and the recombination pattern between the snps. given these probabilities, the haplotype frequencies and the most likely haplotype pair for each genotype are straightforward to obtain. in practice, pr is estimated by sampling from the stationary distribution of a gibbs sampler  h,..., h,... where a state h is a particular realization of the random variables of h: n haplotype pairs from s which resolves the n genotypes of g. the gs starts with a random haplotype realization h, and goes from h to h by updating the haplotype pair of an individual i in light of the 2n- <dig> other haplotypes found in h, that we call h−i. this "haplotypes update" step is done by sampling a new haplotype pair from the conditional distribution pr, ρ) proposed by fearnhead and donnelly  <cit>  and li and stephens  <cit> . this conditional distribution, called fdls distribution in the following, is computed thanks to a hidden markov model for haplotypes described in the next section. the important fact here is that computation of pr, ρ) constitutes the most time-consuming part of the gs since it has to be done on a space of possible haplotype pairs which grows exponentially with the number of heterozygous snps.

an iteration of the gs algorithm corresponds to update successively the haplotypes of the n individuals of g given a randomly initialized order of treatment. between iterations, according to the metropolis hasting acceptance rates described by stephens et al  <cit> , we accept or reject  new values for the recombination parameters ρ = {ρ <dig> ..., ρs-1} in the s- <dig> intervals between snps and  new treatment order of genotypes in the gs. to finally obtain pr, we discard the first iterations of the gs as burn-in iterations  and for the n genotypes gi, we average the distribution pr, ρ) on several main iterations .

computation of a haplotype pair probability in a hmm 
first of all, we assume that genotypes are produced by sampling independently two haplotypes according to their respective probabilities, which yields:

  pr⁡|h−i,ρ)=ππ 

where δh,h' =  <dig> if h ≠ h' and δh,h' =  <dig> if h = h'. the conditional probability π of haplotype h reflects how likely h corresponds to an "imperfect mosaic" of the other haplotypes {h <dig>  ..., h2n-2}  <cit> . the underlying idea is that haplotype h has been probably created through the generations as a recombined sequence of haplotypes from the pool {h <dig>  ..., h2n-2}, possibly altered by some mutations. one models this by computing the probability of observing the sequence h = {o <dig>  ..., os} in a hidden markov model λ designed to represent all possible mosaics of {h <dig>  ..., h2n-2}: π = pr. such hmm λ can be viewed as a trellis of s ×  hidden states qj  with  <dig> ≤ j ≤ s and  <dig> ≤ k ≤ 2n- <dig>  a hidden state qj of λ corresponds to the allele of haplotype hk at snp j and it is linked to all the hidden states qj+ <dig>  at snp j+ <dig> in order to model all the possible recombination jumps of haplotypes between snps j and j+ <dig> . then, a sequence of s hidden states in λ through the s snps corresponds to a particular mosaic of {h <dig>  ..., h2n-2}. the probability of observing h = {o <dig>  ..., os} in λ is computed thanks to transition probabilities between hidden states which mimic recombination and thanks to emission probabilities from hidden alleles to observed alleles which mimic mutation. similar hidden markov models have been proposed, but they generally rely on a limited number of founder haplotypes where the most likely transition and emission probabilities are estimated from observed genotype data via an em algorithm  <cit> . here, the emission and transition probabilities are defined with prior distributions depending respectively on a constant mutation parameter and on the variable recombination parameters ρ . the objective of this section is not to fully describe the probabilistic model of transitions and emissions since this has already been done by stephens and scheet  <cit> . instead, we focus on how the haplotype probability is computed in such a hmm λ from transition and emission probabilities. we thus assume that the following quantities are known as set up by stephens and scheet:

• the transition probability aj  from the state qj of haplotype hl for snp j to the state qj+ <dig> of haplotype hk for snp j+ <dig>  if l ≠ k then aj  is the probability for hl to be recombined with hk between snp j and snp j+ <dig> . and conversely, if l = k then aj  is the probability for hl to be not recombined between the two snps .

• the emission probability bj of the hidden allele of qj in the observed allele oj of h . if the hidden allele is different from the observed one, then bj corresponds to the probability that the hidden allele qj has been altered in oj by a mutation event. else, bj corresponds to the probability that no mutation has occurred.

in the hmm λ, the probability of a hidden states' sequence is given by the product of the corresponding transition probabilities. and the probability to observe h = {o <dig>  ..., os} given a particular hidden states' sequence is obtained by the product of the probabilities for the hidden alleles to be emitted in the observed ones. finally, to compute the probability pr, one must sum up the probabilities of observing h over all s possible sequences of s hidden states. an alternative to this expensive computational approach is to define a forward probability αj as the probability for the incomplete observed sequence {o <dig>  ..., oj} to be emitted by all the possible hidden sequences that end at state qj. then, the partial posterior probability πj until snp j of h can be written as follows:

  πj=∑k=12n−2αj 

and the total probability of h over the s snps becomes:

  π = πs 

the computations of αj for k =  <dig> ..., 2n- <dig> and j =  <dig> ..., s are efficiently done by a recursive algorithm for hmm called forward algorithm  <cit> . it starts from initial values:

  α <dig> = b1/ 

and recursively computes the αj+ <dig> values from the αj values as follows:

  αj+1=bj+1×∑l=12n− <dig> 

computing all the α values for a haplotype requires now running time in o instead of o.

computation of the fdls distribution from a haplotype list by phase v <dig>  
the phase v <dig>  algorithm considers the haplotype space si as a list of 2zi haplotypes compatibles with the genotype gi where zi is the number of heterozygous snps. and it computes the fdls distribution over this list with equations  and  on the hmm λ. this approach is computationally intensive for two reasons. first, it performs many times the same computations of α values with the forward algorithm since the haplotypes of si are derived from the same genotype and share thus identical allelic segments. for instance, as shown in figure 3a, several haplotypes of si differ only in the last snps while the computation of forward values α starts each time from the first snp. second, the list of haplotypes grows exponentially with the number of heterozygous snps which prevents any application with a high number of snps. to partially overcome this problem, a "divide for conquer" solution called "partition-ligation"  was first proposed by niu et al  <cit> . it has been included in the phase v <dig>  algorithm as follows: it first divides the genotypes into segments of limited size , determines the most probable haplotypes on each segment with complete runs of the gs, and then progressively ligates haplotypes of the adjacent segments in several runs until completion. when two adjacent segments are ligated, the space s of candidate haplotype pairs is initialized from all combinations of the most probable haplotypes previously found in each segment. however, the pl procedure remains computationally expensive because it implies 2s/p -  <dig>  complete runs of the algorithm, each time on a quadratic number of combinations of adjacent plausible haplotypes.

computation of the fdls distribution from a complete binary tree by shape-it 
to compute the fdls distribution while avoiding any redundant calculations of α values, our algorithm uses a complete binary tree  instead of an exhaustive list to represent the haplotype pairs space si. it can be viewed as an extension of the forward algorithm which computes the probabilities of observing in the hmm λ several pairs of sequences classified into a binary tree rather than observing a unique sequence.

such a haplotype tree is easily derived from a partition of genotype gi into m unambiguous segments gi={,...,} : each one starts from a heterozygous snp, includes all the following homozygous snps, and ends before the next heterozygous snp. a node of the haplotype tree corresponds to a genotype segment , and the two children nodes, to the two possible switch orientations with the following segment  and . then, a single path from the root to a leaf corresponds to a single possible haplotype pair of si .

to compute efficiently the fdls distribution, shape-it explores the haplotype tree with a single recursive algorithm which combines the reconstruction of the haplotypes and the calculation of associated α forward values. in practice, it iterates the nodes by level-order  to avoid any previous construction in memory of the haplotype tree. when visiting a node with the associated genotype segment , the algorithm makes recursively a quadruplet q = {h, α, h', α'} where h and h' are the two haplotypes with respective forward values α and α' corresponding to the current explored path in the haplotype tree. once all the nodes visited, the haplotype pairs of si and the fdls distribution are given respectively by the haplotypes and the forward values of the quadruplets associated to the leaf nodes. this approach is implemented in the algorithm  <dig> .

this algorithm avoids all the unnecessary forward value computations made when using the representation by haplotype lists. however, the haplotype tree to be explored still grows exponentially with an increasing number of heterozygous snps. it results in a list l whose size is multiplied by two at each level explored . as with the classical haplotype list approach, this algorithm can be simply implemented in a pl strategy: first, a haplotype tree is derived for each segment of genotype, and then the most probable adjacent subtrees are determined and combined until completion. we have used an alternative strategy described in the next paragraph.

computation of the fdls distribution from an incomplete binary tree by shape-it 
in practice, the number of haplotype pairs sufficiently probable to be sampled in the fdls distribution is roughly linear with the number of snps instead of being exponential. as an alternative to the classical and expensive pl strategy, we have thus modified our recursive algorithm to explore only the paths in the haplotype tree which correspond to the most plausible haplotype pairs. in other words, our algorithm aims at identifying an incomplete binary tree of limited size which captures at best the informative part of fdls distribution . for that, recursions are made only on nodes exhibiting a probability, as given by expressions  and , greater than a threshold f initially defined. in practice, it results in maintaining a list l of quadruplets of limited size for each level of the tree explored, which no longer grows exponentially with the number of heterozygous snps. the corresponding modifications made in algorithm  <dig> are implemented in algorithm  <dig> . obviously the value of the threshold f affects the number of quadruplets kept at each level of the haplotype tree and thus, the number of haplotype pairs on which the fdls distribution is computed. it is clear that the value of threshold f influences the diversity of haplotypes to be captured and so, the computational effort needed. however, the strength of our algorithm clearly lies in the greatly reduced complexity with the number of snps of the fdls computation step. moreover, compared to the 2s/p -  <dig> complete runs of the gs required by the pl strategy, it treats all the snps in a single run.

methods
we have implemented our algorithm in the software package shape-it publicly available at . we have extensively compared shape-it with the widely used haplotype inference software 2snp  <cit> , gerbil  <cit> , fastphase  <cit> , pl-em  <cit> , ishape  <cit>  and phase v <dig>   <cit>  on  <dig> kinds of datasets described hereafter. all the software were run with default parameters on a standard  <dig> ghz computer with  <dig> go of ram.

in the comparisons, we have tried to work as close as possible to real conditions: on the one hand, we have used tightly linked snps such as those used in a single gene fine mapping and on the other hand, we have used tagsnps with a low level of ld which correspond to the worst conditions to infer haplotypes. at last, we have also made estimations of the running times required by the most accurate software to infer the haplotypes of a  <dig> k illumina chips.

single gene datasets
first, we have used genotypes for which the haplotypes have been completely determined experimentally: the gh <dig>  <cit>  and apoe  <cit>  genes. the gh <dig> dataset contains  <dig> snps for  <dig> caucasian individuals and the apoe dataset contains  <dig> snps for  <dig> individuals of mixed ethnic origins. for each gene, we have additionally generated  <dig> replicates by randomly masking 5% of the alleles in order to simulate real experimental conditions . on these datasets, we have measured the ier  and the mer  which corresponds respectively to the percentage of individuals incorrectly inferred and to the percentage of missing data incorrectly inferred. although of limited size, these two genes are very useful to compare precisely the haplotype frequency estimations made by the algorithms via the if coefficient  <cit> , since haplotype frequencies are commonly used by the geneticists in genetic association studies.

hapmap trio datasets
second, we have worked on trios' genotypes  derived from the hapmap project  <cit> . we have collected five regions of  <dig> mb on chromosomes  <dig>   <dig>   <dig>   <dig> and  <dig> in african  or european  populations. the  <dig> resulting chromosomal regions have been preprocessed by the haploview software  <cit>  to remove snps with mendelian inconsistency or with insufficient minor allele frequency . from these chromosomal regions, we have generated several hapmap datasets according to the choices of markers described in table  <dig> <cit> . on all these trios' genotypes, the parent haplotypes can be partially obtained , and we have measured the running times of the various algorithms and the ser  of haplotypes inferred by the various software. the ser corresponds to the percentage of known phases between adjacent heterozygous snps  incorrectly inferred  <cit> , which is more adapted than the ier on large numbers of snps because the ier does not differentiate between one or several heterozygous snps incorrectly inferred.

description of the benchmarks derived from the hapmap trios datasets that we used to compare accuracy and runtimes of the various algorithms in table  <dig>  for each parameter   <dig> samples were chosen in each of the chromosomes  <dig> to  <dig>  i.e. a total of  <dig> tests per parameter.

to investigate on the impact of low ld in haplotype inference, we have also used a set of  <dig>  adjacent tag snps picked up from the large arm of chromosome  <dig> and found in the  <dig> k illumina chips.

griv cohort datasets
third, we have generated large snp datasets from subjects of the griv  cohort genotyped with the  <dig> k illumina chip. the griv cohort comprehends about  <dig> caucasian subjects collected for genomic studies in aids  <cit> . these datasets were used to estimate the running times required by the most accurate software to infer the haplotypes of a  <dig> k illumina chips. for that, we have generated  <dig> datasets from the griv cohort data for various numbers of markers  and for various numbers of individuals . then the average running time over the  <dig> datasets of each combination of snp number and genotype number was used to extrapolate the running time required to infer the haplotypes over the  <dig>  snps.

RESULTS
empirical determination of the threshold f 
as discussed in the section algorithm, shape-it relies on a threshold f to discard some branches of the haplotype binary trees. so, we have tested several values for f: the accuracy is clearly stable for values below  <dig> . since the running time was optimal for f =  <dig> , we have used this value as default in all the following comparisons.

comparisons on the single gene datasets 
for the various software tested, we measured the percentage of individuals incorrectly reconstructed , the percentage of missing data incorrectly inferred , and the distance between real and inferred haplotype frequencies  on the apoe with complete genotypes and 5% random missing genotypes.

for the various software tested, we measured the percentage of individuals incorrectly reconstructed , the percentage of missing data incorrectly inferred , and the distance between real and inferred haplotype frequencies  on the gh <dig> with complete genotypes and 5% random missing genotypes.

on these datasets, shape-it, ishape and phase v <dig>  give clearly the better haplotype reconstructions and frequency estimations compared to the other software. one can notice that ishape seems to be slightly more accurate than shape-it and phase v <dig> . for the completion of missing data, all the methods  are closely related.

comparisons on the hapmap trio datasets 
n/a: software was unable to handle some of these datasets . results of the various tested software on the hapmap trios datasets described in table  <dig>  for each software tested, the mean percentage of heterozygous markers incorrectly inferred  is shown in the upper-left corner, and the mean running time in seconds is shown in the lower-right corner.

as a matter of accuracy, shape-it and phase v <dig>  outperform all the other methods. ishape comes second but plunges when dealing with larger number of tag snps. fastphase comes third but it seems to work relatively better when the datasets get bigger. 2snp, gerbil, and plem do not match the accuracy of the other software. all the software get higher error rates when the number of tag snps increases which is probably the consequence of the increasing complexity of the ld pattern when dealing with limited numbers of individuals.

as a matter of speed, the fastest software is clearly 2snp. for relatively small numbers of snps, plem and gerbil are also very fast, but become very slow when the number of snps increases or when the ld pattern gets more complex to capture. among the  <dig> most accurate software , phase v <dig>  is the slowest, shape-it is the fastest for small and medium-sized snp samples , and fastphase becomes faster for larger numbers of snps .

running time on the griv cohort datasets 
estimations of the running times in days of the  <dig> most accurate software  to infer the haplotypes for  <dig>   <dig>  or  <dig> genotypes derived from illumina  <dig> k chips partitioned into segments of either  <dig> snps, or  <dig> snps, or  <dig> snps. for each combination #snps #genotypes, the running time estimations were extrapolated from the measures performed on  <dig> datasets extracted from the griv cohort  <dig> k illumina chip genomic data.

on these datasets, shape-it runs between  <dig> to  <dig> times faster that phase v <dig> , depending on the segmentation strategy used  and the number of genotypes in the population . fastphase remains the fastest software but closely followed by shape-it. the increase of snp and genotype numbers strongly cripples phase v <dig>  and ishape, while it is better handled by shape-it and fastphase.

discussion and 
CONCLUSIONS
we have developed a new algorithm derived from the phase v <dig>  gibbs sampler scheme. we have improved the most time-consuming steps by using binary tree representations and by avoiding the pl procedure thanks to an incomplete exploration of binary trees. the resulting software, shape-it, is extremely accurate like phase v <dig> , but may run up to  <dig> times faster as shown in our tests. these results have an impact for the computation of haplotypes in genome scans as shown in table  <dig>  as an example, for the  <dig>  snps of an illumina genotyping chip, inferring haplotypes on  <dig>  segments of  <dig> snps with a regular  <dig> ghz computer would take for shape-it about  <dig> days for  <dig> individuals,  <dig> days for  <dig> individuals,  <dig> days for  <dig> individuals while it would take for phase v <dig>   <dig> days for  <dig> individuals ,  <dig> days for  <dig> individuals  and  <dig> days for  <dig> individuals . the gain of time using shape-it is thus considerable and practically very useful to exploit datasets derived from large-scale genotyping chips.

an important aspect of this work is that other haplotype inference software relying on hmm may gain to implement this new binary tree representation of the observed genotypes. moreover, we have not found in the literature the description of this algorithm whereas it might be useful for other fields using hmm.

availability and requirements
project name: shape-it v <dig> 

project home page: 

operating systems: macos, windows, linux32bits and linux64bits.

programming language: c++

do not forget to read the manual file, manual_shapeitv <dig> .pdf, to get the detailed information. the software remains confidential until publication of the work. it will be freely available to academics, and a licence will be needed for non-academics .

authors' contributions
od and cc worked on developing the methods and programs used in this study under the direct supervision of jfz who conceived the study. all the authors have read and approved the final manuscript.

supplementary material
additional file 1
detailed trio datasets results. detailed results of the various software tested on the hapmap trios datasets described in table  <dig>  for each software tested, the mean percentage of heterozygous markers incorrectly inferred  and the average running time in seconds are shown.

click here for file

 acknowledgements
od has a fellowship from the french ministry of education, research and technology, and cc has a fellowship from conservatoire national des arts et métiers. this work was supported by acv development foundation, by vaxconsulting, and by the innovation  <dig> program of conservatoire national des arts et métiers. the authors thank dr adkins and dr orzack for providing respectively the gh <dig> and apoe gene datasets.
