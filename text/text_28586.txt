BACKGROUND
survival prediction and prognostic factor identification play a very important role in medical research. survival data normally include the censoring variable that indicates whether some outcome under observation  has occurred within some specific follow-up time. the modeling procedures must take into account such censoring. it is even more difficult to develop a proper statistical learning method for survival prediction.

several models for survival predictions have been proposed in statistical literature. the most popular one is the cox proportional hazards model  <cit> , in which model parameters are estimated with partial log likelihood maximization. another one is the accelerate failure time  model  <cit> . aft is linear regression model in which the response variable is the logarithm or a known monotone transformation of a failure  time. there are mainly two approaches in literature for fitting a aft model. one is the the buckley-james estimator which adjusts censored observations using the kaplan meier estimator  <cit> , and the other is a semiparametric estimation of aft model with an unspecific error distribution  <cit> . however, the semi-parametric bayesian approach based on complex mcmc procedures is computationally intensive and tends to have inaccurate results, and the stute's weighted least squares  estimator only implicitly accounts for the censored time. the model has not been widely used in practice due to the difficulties in computing the model parameters  <cit> , and there is no nonlinear aft model in the literature.

kernel based methods such as support vector machines  have been extensively studied recently in the framework of classification and regression  <cit>  in the area of pattern recognition and statistical learning. the concept of kernel formulated as an inner product in the feature space allows us to build nonlinear extensions of many linear models  <cit> . it would have been a potential alternative if it were not for the complexity of censoring. moreover, lasso type penalty and its generalized versions have been proposed for gene  selection with high dimensional genomic profiles with censored survival outcomes  <cit> . however, since the sample size n ≪ m , methods based the primary formulation with a huge m  are not efficient. consequently, in current microarray analysis, what people really do is select a couple of thousands  of genes using filter-based methods  and then apply the lasso-type penalty to further reduce the number of disease associated genes. this two-step procedure will lead to missing biologically important genes and introducing bias. the dual solution with kernel proposed in this article attempts to resolve these inadequacies by solving a much smaller n × n matrix.

in this paper, we propose a nonlinear kernel ridge regression for censored survival outcome prediction under the framework of aft model. we also develop an efficient dual solution with adaptive kernel ridge regression for ultra-high dimensional genomic data analysis.

unlike the weighted least square method, our model explicitly accounts for censoring. the proposed models are evaluated with simulation and real data and the prediction error of the test data.

RESULTS
simulation data
simulation studies are conducted to evaluate the performance of the proposed methods under different assumptions. the following describes a method to generate input data with censored survival outcomes that emulates the mechanisms presented by the actual data.

 <dig>  sample  <dig> -dimensional input data x with  <dig> training and test samples respectively from a multivariate normal distribution with mean zero and variance-covariance matrix Σ. the pairwise correlation between the ith and the jth input variables in Σ is r|i-j| and different correlations  will be chosen to assess the performance of the proposed method.

 <dig>  choose the model parameters w =  <cit> t, and generate the event time from log t = wt xk + ε, where ε ~ n and σ is determined by the signal to noise ratio . for instance, with the mean log survival time of  <dig>  and snr =  <dig> :  <dig>  we have σ =  <dig>  snr =  <dig> :  <dig> is used in all of our simulations. finally, k indicates the kth power of input variables, so the log survival time is associated with the input variables nonlinearly.

 <dig>  the censoring variables are generated as uniformly distributed and independent of the events. letting di = ti, the censoring status will be δi = ti <di. different cs give a different portion of censored data. roughly 40% - 60% censored data are produced in our simulations.

we analyze the simulation data with the proposed dkrr algorithm and build the model with training data, evaluate the performance of the model with the test data. the performance of the dkrr algorithm with different kernels and different correlation structures are shown in figure  <dig>  as shown in the upper panels of figure  <dig>  when the the survival data are simulated with k =  <dig> and the true model is linear, the linear model has the best performance with the the average relative root mean squared error  around  <dig> . models with the radial basis function  kernel have the second best performance with different correlation structures . models with the third order polynomial have the worst performance with the mean rrmse around  <dig> . on the other hand, when the survival data are generated with a quadratic model with k =  <dig> as shown in the lower panels of figure  <dig>  model with second order polynomial kernel and rbf kernel are the two top performers with the average test rrmse around  <dig> , and the linear model performs the worst with the largest average test rrmse around  <dig> . these results indicate that model specification is very important. a misspecified model may lead to inaccurate predictions. finally, there are no statistical significant differences for input variables with different correlations .

to evaluate the performance of akrr method, the survival data are generated from linear model with r =  <dig> , and different ws. the generated input data have the dimensions of  <dig>   <dig>   <dig>   <dig>  and  <dig>  but only  <dig> variables at the positions of  <dig>   <dig>   <dig>   <dig>  ...,  <dig>   <dig> are nonzero with the values of t =  <cit> t , t, or t respectively. the rest coefficients are set to  <dig>  the random noise and rest of the variables are generated from the distribution of n, and σ is determined by the mean survival time and the signal to noise ratio . the test rrmses with different input dimensions are shown in figure  <dig>  figure  <dig> shows that the test rrmses have not changed significantly when the input dimension increases from  <dig> to  <dig>  which indicates that akrr method performs well even with a huge number of variables. the frequencies of first  <dig> component variables being selected out of  <dig> random simulations with different w are given in table  <dig>  table  <dig> shows that akrr can correctly identify the survival associated variables with high accuracy. akrr identifies all  <dig> variables with over 88% ratios and identifies  <dig> out of  <dig> variables with over 96% ratios when |wi| =  <dig>  moreover, the performances are still very impressive when the associations between survival time and covariates are weak. akrr identifies  <dig> out of  <dig> variables with over 95% and 94% ratios when |wi| =  <dig>  and |wi| =  <dig>  respectively. table  <dig> gives more details about the average number of variables being selected and the ratios of correctly-detected, over-fitting, and under-fitting. the optimal parameters in the parenthesis are decided by 10-fold cross-validation with the training data only. p* is chosen from the values of  <dig> ,  <dig> ,  <dig> ,  <dig> ,  <dig>  since our computational experiments show that akrr seems to converge to the same solution when p ≥  <dig>  with different initializations for the same data set. λ* is chosen from 0: <dig> : <dig>  the average number of selected variables varies from  <dig> - <dig>  around the true number  <dig>  akrr identifies exactly the same  <dig> variables with the ratios of 75%, 54%, and 52% for |wi| =  <dig>   <dig> , and  <dig>  respectively. in all three cases, akrr chooses the number of variables in the range of 11- <dig> with over 90% ratio.

for comparison purposes, we also implement the primal version of lasso for aft model with gauss-seidel method to optimize w directly. the computational time for different input dimensions is listed in table  <dig>  table  <dig> shows that akrr is so computational efficient that it only takes  <dig>  seconds for one run to identify variables from  <dig>  candidate variables, while lasso might take days. with  <dig> variables, akrr only needs  <dig>  seconds on average to converge, while lasso fails to converge after  <dig> hours. when the input dimension is large, akrr is much more efficient. this is reasonable since the computational time of akrr is mainly associated with the sample size and dual variables. this method will be fast even with ultra-high dimensional input as long as the sample size is small, which is common in genomic data analysis.

diffuse large b-cell lymphoma data
we now consider one diffuse large b-cell lymphoma  data  <cit>  evaluating gene expression profiles associated with the patient's survival. in this study, tumor-biopsy specimens and clinical data were obtained retrospectively from  <dig> patients with untreated diffuse large-b-cell lymphoma who had no previous history of lymphoma, according to a protocol approved by the national cancer institute institutional review board. the median follow-up time was  <dig>  years overall , and  <dig> percent of patients died during this period. the median age of the patients was  <dig> years, and  <dig> percent were men. cdna microarray data with  <dig>  probes were collected. we divide the data into two equal parts with  <dig> training data and  <dig> test data. we utilize the two-fold cross validation scheme to choose the optimal λ and evaluate our method. we randomly split the data into two roughly equal-sized subsets and build the model with one subset and test it with the other. to avoid the bias arising from a particular partition, the procedure is repeated  <dig> times, each time we split the data randomly into two folds and do cross validation. the relevance count is utilized to count how many times a gene is selected in the cross validation. clearly the maximum relevance count for a gene is  <dig> with the two-fold cross validation and  <dig> repeating. the optimal λ* is in the range of  <dig> - <dig> , and the optimal p* is set to  <dig>  in all the experiments. the test rrmse is  <dig>  on average, which is better than the average test rrmse  with lasso based primal model. this is reasonable, since akrr has one additional parameter p. genes associated with survival time are shown in table  <dig>  we identify  <dig> probes with over  <dig> relevant counts. those  <dig> probes are corresponding to  <dig> known genes. all of the selected genes play important roles in apoptotic processes and/or the development and progress of various cancers.  <dig> out of  <dig> genes are associated with different lymphoma according to pubmed. for example, bmp <dig> is the top gene in other category associated with poor outcome and hla-c gene is from the major histocompatibility class  ii family, both genes were also identified by rosenwald et al.  <dig>  moreover, cd <dig>  cd79a, and cd <dig> are well known antigens and mhc ii signatures associated with favorable survival outcomes. we then perform pathway analysis using david  and identify  <dig> lymphoma associated pathways: nod-like receptor signaling pathway, pathways in cancer, allograft rejection, focal adhesion, and graft-versus-host disease. four out  <dig> pathways  are known to be associated with dlbcl from pubmed.

follicular lymphoma  data
follicular lymphoma is a common type of non-hodgkin lymphoma . it is a slow growing lymphoma that arises from b-cells, a type of white blood cell. it is also called an "indolent" or "low-grade" lymphoma for its slow nature, both in terms of its behavior and how it looks under the microscope. a study was conducted to predict the survival probability of patients with gene expression profiles of tumors at diagnosis  <cit> . fresh-frozen tumor biopsy specimens and clinical data were obtained from  <dig> untreated patients who had received a diagnosis of follicular lymphoma between  <dig> and  <dig>  the median age of patients at diagnosis was  <dig> years  and the median follow up time was  <dig>  years . the median follow up time among patients alive was  <dig>  years. four records with missing survival information were excluded from the analysis. affymetrix u133a abd u133b microarray genechips were used to measure gene expression levels from rna samples. a log  <dig> transformation was applied to the affymetrix measurement. detailed experimental protocol can be found from the original paper. there are total of  <dig> probes. it is time consuming to directly apply standard lasso methods to this problem without an initial reduction of dimensions. our method takes less than  <dig> seconds for one run. similar two-fold cross validation scheme with  <dig> random partitions is utilized to this data. the optimal λ* is in the range of  <dig>  -  <dig>  with the optimal p* =  <dig> . the test rrmse is  <dig> . the final results are shown in table  <dig> 

thirteen probes with over  <dig> relevance counts are identified. those  <dig> probes are corresponding to  <dig> known genes associated with lymphoma and related diseases. for instance, gene c4a localizes to the major histocompatibility complex  class iii region on chromosome  <dig>  it plays a central role in the activation of the classical pathway of the complement system. c4a anaphylatoxin is a mediator of local inflammatory process. it induces the contraction of smooth muscle, increases vascular permeability, and causes histamine release from mast cells and basophilic leukocytes. c4a is on the pathway of systemic lupus erythematosus . patients with sle can increase the risk of certain cancers, including non-hodgkin's lymphoma. we find that c4a is negatively associated with survival time according the estimated coefficient of c4a. aldh <dig> is another well studied gene which is significantly associated with acetaldehyde-induced micronuclei and alcohol-induced facial flushing. defects in aldh <dig> are a cause of acute alcohol sensitivity and alcohol induced cancers. there are accumulating evidences that aldh2-deficient individuals are at much higher risk of esophageal cancer and malignant lymphoma. our study indicates that the up-regulated aldh <dig> is positively associated with patient survival outcomes. six other genes are also associated with different cancers including follicular lymphoma.

CONCLUSIONS
we proposed kernel based methods for nonlinear aft model and variable selection for ultra-high dimensional data. our evaluations with simulation and real data illustrate that the proposed methods can effectively reduce the dimension of the covariates with sound prediction accuracy. in many studies, both clinical and genomic data are available. due to the ultra-high dimension in genomic data, directly applying lasso based methods to genomic data is usually not feasible. our proposed method provides an efficient solution for it. kernel based nonparametric methods have been well studied in statistical learning, but there are not many studies for survival analysis. in this paper, we provide a basis for further explorations in this field.

