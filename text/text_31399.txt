BACKGROUND
population and quantitative geneticists interested in a wide variety of evolutionary questions are increasingly bypassing conventional genotyping strategies in favor of high-throughput re-sequencing. tradeoffs between sample size and marker density can largely be overcome by these methods, making it possible to acquire dense genomic coverage in relatively large populations at a reasonable cost. a significant advantage of this approach is that it bypasses the conventional snp discovery phase, ameliorating the problem of ascertainment bias and allowing for the scoring of snps without regard to a priori selection based on minor allele frequency. several options exist for data acquisition in what can be generally called ‘genotyping-by-sequencing’ . while theoretically desirable, whole-genome re-sequencing may be too costly for species with large, complex genomes such as many plants, and may result in an unwieldy dataset in terms of the computational effort required for assembly and annotation. genome complexity reduction provides an alternative, with the goal of reducing the genomic space that is sequenced  <cit> . transcriptome sequencing  is one option that has been available since the beginning of next-generation sequencing, and takes advantage of the natural ‘genome complexity reduction’ of the cellular transcriptional machinery  <cit> . rna-seq has some advantages, most notably the ability to re-sequence much of the gene space, which is presumed to harbor a substantial fraction of the functional variation present in the genome. however, upstream regulatory regions are expected to harbor functional variants due to the potential for relatively minor changes to have profound effects on gene expression affecting fitness  <cit> , and copy number polymorphisms with functional consequences cannot be scored from transcriptome data  <cit> . on the other hand, studies of neutral evolutionary processes  must avoid  areas of the genome that may have been the targets of natural selection, and the ability to also score polymorphisms well outside of genes is therefore advantageous in such studies.

with these constraints in mind, two primary methods for genome complexity reduction have come to the fore in recent years: restriction enzyme-based approaches that recover a subset of the genome in a random but  repeatable manner, and sequence capture, in which specific genomic intervals are retrieved through hybridization of fragmented genomic dna with labeled baits. the former class of methods have many variations, but all involve the use of one or more restriction enzymes to digest genomic dna followed by size selection and sequencing  <cit> . the number of fragments isolated in this way depends on the choice of enzyme, and it is possible to enrich for regions that include transcribed genes by using an enzyme sensitive to methylation status. due to the large size and repetitive content of many plant genomes, filtering out methylated heterochromatin prior to sequencing has been a popular way of enriching genomic libraries for gene-rich regions. this approach was initially applied sanger-based est sequencing  <cit> , and subsequently to next-generation libraries  <cit> . contemporary restriction-enzyme-based gbs is relatively inexpensive, avoids repetitive regions, and is amenable to situations where a limited number of haplotypes or extended linkage disequilibrium  are expected, for example, in domesticated species or advanced pedigrees. that is, the goal of restriction-enzyme approaches is not necessarily to capture functional variants, but rather to saturate the ’haplotype space’ of the genome. this is similar in principal to conventional qtl mapping, but allows denser sampling of the genome and hence finer mapping of qtl in populations with lower ld than conventional backcross qtl-mapping pedigrees, but more ld than exists in wild populations.

sequence capture involves designing long oligonucleotide ‘baits’ specific to regions of interest in the genome. in the original formulation, these baits were immobilized on a solid support, but solution-based capture using biotinylated-baits is more common at present  <cit> . the latter is more cost-effective and scalable for custom projects. while significantly more expensive than restriction-enzyme-based methods, sequence capture has a number of advantages for studies of genetic variation relevant to adaptation in large, unstructured, natural populations. these include more consistent and complete recovery and sequencing of the gene/exon space than restriction enzyme-based approaches. at the same time, sequence capture allows recovery of selectively neutral intergenic regions that can be used to estimate the effects of demographic processes such as migration history and population structure, a step that is usually required in association and landscape genomics studies. another significant advantage of sequence capture is the ability to target long stretches of dna such as entire exons or genes. re-sequencing of longer fragments allows estimation of the site frequency spectrum and identification of cases of genetic hitchhiking – a hallmark of natural selection  <cit> . in general, for association mapping in trees, the haplotype-tagging approach relied on in human genetics may not be successful due to low ld in natural populations, and identifying functional variants requires denser genotyping  <cit> . however, while most long-lived tree species have very low ld, recent data from black cottonwood  suggest somewhat slower ld decay, on the order of a few kilobases, which may facilitate haplotype-tagging  <cit> . in balsam poplar , a close relative to p. trichocarapa, little average decay in ld was observed within genes  <cit> .

sequence capture was first used for targeted re-sequencing of the human genome  <cit> , and is of particular current interest to studies of human disease, as it enables cost-effective genotyping of snps in large populations without a priori selection of snps based on minor allele frequency. while few reports exist at present, there is also considerable interest in the sequence capture approach for studies of complex traits in other taxa  <cit> . with large and complex genomes that harbor extensive repetitive elements, this technology is particularly useful in plants. fu et al.  <cit>  reported the application of a two-stage solid-state approach to the large and complex maize  genome, in which libraries were first de-enriched of repetitive sequence, and then enriched for a  <dig> mb target region. others have used both solution-based  <cit>  and array-based  <cit>  capture to successfully re-sequence target genes in big sagebrush  and soybean , respectively. here we report the application of solution-based sequence capture to black cottonwood . we targeted most of the poplar exome, as well as regions immediately upstream of genes  and random genomic control intervals, and sequenced these in a preliminary panel of  <dig> individuals from across the natural range of the species . the success of this approach as well as design considerations for future sequence capture studies are discussed.

RESULTS
data preprocessing and alignment
we designed baits and completed hybrid capture of  <dig> mb of the p. trichocarpa exome, which included at least one exon from each predicted gene, as well as  <dig> randomly selected intergenic control regions. the  <dig> samples were pooled post-capture and sequenced in four lanes in a 2x <dig> paired-end format on an illumina hiseq instrument . for each clone we obtained an average of  <dig>  million, 100bp reads, with a range of  <dig>  to  <dig>  million. an average of  <dig> %  of the total raw reads passed our quality filters , and an average of  <dig> %  of the raw reads remained in pairs after the preprocessing procedure . read pairs for each clone were aligned to the unmasked poplar genome using the bwa alignment tool, and  <dig>  ~  <dig> % of the quality-filtered reads were mapped onto the poplar genome. the vast majority of the reads  were uniquely mapped , and those that did not were excluded from further analysis. one particular clone, sv <dig>  had a much lower percentage of uniquely mapped reads, gapless alignments, and perfect alignments, and we therefore excluded this clone from further analysis.

efficiency of on-target enrichment
alignment of the reads to the poplar genome showed a high level of on-target enrichment efficiency . the 173k designed baits correspond to a total of  <dig> mb of genomic regions, which account for ~5% of the poplar genome. the number of baits per million base-pairs ranged from  <dig> to  <dig>  with an average of  <dig>  on average,  <dig> % of base pairs in the bait regions were covered by uniquely mapped reads at ≥ 10x depth, and only  <dig> % of the target regions were not covered. due to the variable length of sheared dna fragments in the prepped library, and because the median length of the sheared fragments  was greater than the length of the baits, we acquired additional coverage in regions adjacent to baits. for analysis purposes, we defined these regions as up to  <dig> base pairs flanking both sides of the bait. on average,  <dig> % of the adjacent area were covered at a depth ≥ 10x . in contrast, little coverage was found in the off-target genomic regions, defined as those >  <dig> bp from any bait . with a stringent cutoff of ≥ 10x coverage in all clones, we acquired data on  <dig> mb of the genome, whereas  <dig> mb of the genome was covered at ≥ 10x in at least one clone.

sequencing coverage in bait regions
coverage among the  <dig> poplar clones was highly consistent and uniform in both target regions and their adjacent regions . in target regions, the  <dig> clones  had a narrow mean coverage range between 33x and 51x, with a mode ranging from 20-32x, and a median from 30-45x. of the targeted bases,  <dig> % were unanimously covered at least 10x, in addition,  <dig> % of the base pairs within 250bp of either side of a given bait are also unanimously covered 10x or greater. to illustrate the depth of coverage within and adjacent to baits arrayed across the gene regions, we extracted coverage data for the gene model poptr_0006s <dig> as an example . coverage depth for this gene, which was targeted by  <dig> baits, showed a consistent relationship between coverage depth and the positions of baits, and coverage was relatively uniform among clones.

coverage decay in regions adjacent to baits
to investigate the decay in coverage moving away from the baits, we retrieved genomic regions adjacent to baits for which there was no neighboring bait within 1000bp. sequencing depth in these ‘bait wings’ showed a consistent decay with distance from the bait , with similar decay patterns between the left and the right wings. on average, approximately  <dig> base pairs nearest the bait were sequenced at a depth of 10x or more. we also extracted genomic regions that were covered by pairs of baits immediately adjacent to one another, and for which there was not another bait within 1000bp on either side. interestingly, coverage analysis of these double-baits  indicated a diminished effect on coverage in adjacent regions. on average, double-baits had a total of  <dig> bp  that were covered at ≥10x, while single baits had 292bp .

parameters affecting capture efficiency
although coverage depth for a given region was fairly uniform among clones , there was wide variation in coverage among target regions. as the algorithm agilent technologies uses to design baits is proprietary, we assessed the role that two variables played in capture efficiency: gc content and gene duplication. a clear relationship between gc content and coverage was apparent, with decreased coverage for target regions with both low and high gc content . to assess this relationship, we linearized the data by taking the absolute values of mean-subtracted gc content and found a highly significant but weak relationship with coverage depth . another parameter that may also affect the recovery of target regions is the level of gene duplication. to determine if mean coverage depth and variance was affected by the presence of paralogs, we separated the data for target genes into two categories: single-copy and those with retained duplicates from the salicoid whole-genome duplication. coverage depth was slightly higher for the duplicate class, while variance in depth of coverage was similar between these two categories .

snp calling and diversity statistics
our pipeline called a total of  <dig> , <dig> snps  that passed through the initial filter  for a particular clone. after applying additional filters , this snp set was refined down to a total of approximately 495k candidate snps . of these, 240k candidate snps were from the targeted bait regions and 225k were from adjacent regions , which combined accounted for  <dig> % of the total. in terms of distribution of candidate snps in genomic features, 240k were from coding regions, 64k from promoter regions, and  <dig> from the intergenic regions, with the rest distributed in introns and untranslated regions .

1inclues snps from both targeted intergenic control regions as well as off-target regions.

we used manva software  to calculate multi-locus nucleotide diversity and tajima’s d, a summary statistics of the folded site frequency spectrum, for the  <dig> intergenic regions, as well as  <dig>  gene regions. for both of these, flanking regions were incorporated where coverage was sufficient. gene regions included upstream and downstream flanking sequence, as well as introns and utrs. we merged gene regions in cases where two or more genes were adjacent in the genome and depth of coverage between them was sufficient. per site nucleotide diversity, estimated using watterson’s θ and tajima’s π, was higher in intergenic regions –  <dig>  and  <dig> , respectively, compared with  <dig>  and  <dig> , respectively, for the genic regions . the difference between these two estimators of nucleotide diversity yielded a mean negative tajima’s d, which was more negative in genic regions  compared with intergenic regions . as genes with retained duplicates from the salicoid whole-genome duplication may be difficult to accurately align, which could lead to higher levels of false-positive snps, we assessed diversity in single-copy genes vs those with retained duplicates. diversity was similar between these two groups, though slightly higher for single-copy genes .

abbreviations: s, segregating sites; θ, watterson’s theta; π, tajima’s pi; d, tajima’s d.

discussion
while contemporary high-throughput sequencing technologies make genome-wide studies feasible in both model and non-model species, whole-genome re-sequencing is usually still cost prohibitive. even where funds are available, studies of natural variation and its relationship to adaptation may be better served by increasing sample sizes, rather than genomic coverage beyond a certain point. our data suggest that sequence capture results in a dataset that is a reasonable tradeoff between cost and genotyping coverage in regions most likely to contribute to adaptation – that is, the gene and regulatory space.

capture efficiency and specificity
our results suggest that sequence capture is a reliable approach to score snps in both the gene space and non-repetitive intergenic regions. although the depth of coverage varied among target regions, it was consistent among clones for a given bait. only about 3% of the sequence data did not map to a target region, suggesting that baits did not frequently hybridize with off-target fragments. the only exception to this was for a single clone collected from north central california, usa , which had a much lower percentage of mapped reads. preliminary population structure analysis suggests that this clone clusters separately from all of our other samples, and is likely either another species – p. fremontii or a p. trichocarpa x fremontii hybrid .

it should be noted that the level of off-target capture in our study may be low in part because we designed baits for most of the poplar gene space. hence, off-target hybridization of one of our baits would require a level of complementarity with the off-target region that is probably rare given the 120bp length of the baits. by contrast, more focused studies may observe inflated off-target capture in cases where the goal is to retrieve, for example, specific members of gene families. in such cases, recovery of untargeted paralogous genes may be expected. this is a particular issue in populus, which has experienced a relatively recent whole genome duplication  <cit> . as sequence capture baits have some tolerance for mismatches, it is likely that a bait designed for a given gene will capture paralagous genes in cases where sequence divergence is not high. while this is not a problem in the context of whole exome capture, it may present a problem for accurate assembly of the resulting short-read sequence data. to evaluate this, we separated genes into two categories – those with retained paralogs from the salicoid whole-genome duplication event, and those without paralogs . if reads from a given gene were assembling to their cognate paralog, and vice-versa, we would expect a higher rate of putative snps in the ‘duplicate’ category of genes. this was not the case in our data – both the single-copy and duplicate categories had similar rates of snp discovery – which suggests that our assembly pipeline handled reads from duplicate genes reasonably well.

nucleotide diversity
our snp discovery pipeline called approximately  <dig>  snps, although many more possible polymorphisms were detected before we applied rigorous thresholds for accepting a polymorphism. as we recovered  <dig>  mb of sequence data including both target and adjacent regions, this corresponds to about one snp per 52bp. this value is higher than that found in recent black cottonwood and balsam poplar studies  <cit> , but similar to trembling aspen   <cit>  and european aspen   <cit> . slavov et al.  <cit>  recently reported genome-wide resequencing of the poplar genome for  <dig> individuals originating from diverse locations across the range. for this panel, one snp per 313bp were detected  filtering methods to those that we employed). geraldes et al.  <cit>  reported a higher snp rate – approximately one per 142bp – based on transcriptome re-sequencing of a panel of p. trichocarpa individuals that was similar to that of slavov et al. in terms of geographic diversity . that the snp rate obtained by geraldes et al. is substantially lower than our own may reflect that fact that they studied only expressed sequences, which are more likely to be constrained by natural selection. probably more important, our population was about 2x larger and included individuals from relatively isolated populations at the northern range limit on the south coast of alaska.

as snp discovery rates per base-pair depend on the size and diversity of the re-sequenced panel of individuals, we calculated per site nucleotide diversity – estimated by watterson’s θ and tajima’s π – to allow us to compare the variation in our data more directly with studies of other populus species. tajima’s π for gene regions was very similar to values obtained from a large sanger-based re-sequencing study of p. balsamifera <cit> , a close relative of p. trichocarpa, and ~30% lower than for european aspen   <cit> . intergenic regions carried about two-fold higher diversity than the gene regions, and data from the poplar genome sequence  <cit>  support this result – the number of snps in the intergenic space in the sequenced nisqually- <dig> clone was about double that of exons. that nucleotide diversity in our data was higher for non-coding regions far from genes suggests a relaxation of purifying/background selection compared with gene regions. the difference between our estimates of θ and π resulted in a slightly negative average tajima’s d, which was more pronounced in genes compared with intergenic regions, suggesting that selection is relaxed in the intergenic space. deviations from the neutral expectation for summary statistics of the site frequency spectrum  are common among forest trees  <cit> . simulations have shown that such results are consistent with changes in population size during pleistocene range expansion and contraction, and our data suggest that similar demographic processes may have affected the genome-wide frequency distribution of mutations in p. trichocarpa <cit> . future studies of the genetic targets of natural selection in this species will therefore need to account for this genome-wide deviation from the neutral expectation for the site frequency spectrum.

capture and alignment for duplicated genes
paralagous genes in the poplar genome that arose from the salicoid whole-genome duplication event, as well as tandem gene duplication, may create problems both for the physical process of capturing fragments of genomic dna, as well as correctly aligning the resulting sequence data. because the solution hybridization process tolerates some mismatch, baits designed for one gene may capture close paralogs. this is not a problem for whole-exome sequencing so long as the resulting data can be aligned correctly to the genome. however, in cases where baits are designed against two paralagous genes, it is possible that hybridization and capture could be skewed to one or the other gene. such a skew should increase mean coverage depth in duplicated vs. single-copy genes – though fewer genes will be captured, those that are will be captured in greater abundance and hence sequenced to a greater depth. at the same time, capture bias should result in a greater variance in the duplicated vs. single-copy genes – because capture bias is unlikely to be complete, some genes will be ‘over-captured’ and hence sequenced to great depth, whereas others will be ‘under-captured’ and sequenced only lightly. we did not observe either of these effects – both mean depth of coverage and variance were similar between single-copy and duplicate gene pairs – and we therefore conclude that capture efficiency in our study was not substantially impacted by the presence of paralagous genes. with respect to the second issue noted above – the impact of paralogs on the ability to correctly align sequence data – we used estimates of nucleotide variability in these two classes of genes to determine if there was a significant problem with misalignment of genes to their respective paralogs in the genome. such misalignment should increase the level of snps in the duplicate category, as fixed differences between duplicates would be incorrectly called as snps. our estimates of nucleotide diversity for single-copy vs duplicates were very similar, which suggests that misalignment was not a problem. interestingly, diversity was slightly higher in the single-copy class of genes , and tajima’s d was somewhat less negative . this result suggests that genes with duplicates are slightly more constrained by selection than single-copy genes, which is counterintuitive. while this may simply be a stochastic effect, more detailed analyses of these data are warranted to elucidate what, if any, evolutionary mechanism may be at work here.

possible improvement to future bait design
particularly for whole exome sequencing in non-model organisms – i.e., custom bait designs – the cost of the bait pools may limit the size of targeted regions to something less than the cumulative length of the exome, as was the case in the current study. one possible way to circumvent this issue is to ligate index adapters and pool samples before capture, thereby allowing for the capture of a larger number of samples than a given kit was designed for. kirst et al.  <cit>  reported success with this approach, although a greater proportion of off-target capture may be expected. pre-capture pooling is now supported by both agilent technologies and roche nimblegen , and this approach both reduces liquid handling as well as reagent costs.

our results suggest improvements that can be made in bait design to recover the largest fraction of the gene space given a particular capture size . specifically, we found that on average approximately 80bp on either side of a given 120bp target region returned sequence of acceptable depth to call snps. this is not a surprising result given that we sheared our genomic dna preparations to an average length of ~200bp. as a result, hybridized genomic dna fragments were longer than the baits that retrieved them. future studies that employ sequence capture would therefore benefit from the following changes to bait design when the goal is to maximize the length of captured regions while minimizing the expense of the bait pools:  for target regions less than ~300bp, a single bait should be centered on the target – most or all of the flanking regions will be recovered;  for target regions >300bp, gaps of ~150bp should be arrayed between the targeted regions; and  when two target regions are separated by <150bp, they can be treated as one, with gaps as in  allowed to fall at whatever location the target sequence dictates .

with respect to depth of coverage, we acquired an average of ~40x with  <dig> indexed samples in each lane, sequenced in a 2x100bp format on an illumina hiseq instrument. it may be possible to multiplex more samples within a single lane depending on the goals of the study and the analytical methods used. with the relatively high ld recently reported in populus <cit> , imputation of missing data may be a reasonable strategy. however, as our results show, coverage depth from captured libraries is both heterogeneous among regions and uniform across samples for a particular region. while we show that gc content plays a role in coverage depth for a given target, other unknown factors are more important. it is therefore difficult to assess a priori which targets will exhibit poor capture and hence lower coverage depth. with lighter coverage, a greater proportion of regions will have low or no coverage. this missing data will likely be missing in all samples for a given target region, thus making it impossible to impute missing data for such targets. depending on the purpose  and level of ld in the focal species, this may be acceptable. it should be noted that the strategy for bait design must be considered when calculating the approximate mean coverage depth expected from a given multiplex sequencing scenario. the strategy outlined above is designed to maximize the cumulative length of captured regions, and the amount of captured sequence may be double the size of the bait design.

CONCLUSIONS
the goal of this study was to test solution sequence capture as a means to genotype the exome of the highly heterozygous model tree p. trichocarpa. we targeted nearly 21mb of the genome, and with  <dig> samples in a single lane of an illumina hiseq instrument, approximately 85% of our target regions returned quality data of acceptable depth to call snps. in addition to the target region, we recovered ~80bp of flanking sequence on either side of baits. our results show that solution sequence capture is a reliable method to enrich the gene space in complex plant genomes. a relatively small proportion of off target capture was observed, and inter-sample variability in depth of coverage for a given locus was small. with careful attention to bait design, it should be possible to recover approximately double the amount of sequence targeted due to the recovery of flanking regions, though it is important to account for this additional sequence when determining multiplex level for sequencing.

