BACKGROUND
deciphering the structure of the gene regulatory networks   <cit>  is crucial for bioinformatics, as it provide insight on the development, functioning and pathology of biological organisms. with the advent of high-throughput technologies such as next-generation sequencing, it has become relatively easy to measure chromatin state and gene expression genome-wide. gene expression data obtained from high-throughput technologies correspond to the expression profiles of thousands of genes, which reflect gene expression levels for different replicates or experimental conditions . as a consequence, many methods have been proposed to solve the grn reverse engineering problem by using gene expression data .

however, inferring the grn from gene expression data remains a daunting task due to the large number of potential interactions, the small number of available measurements and the high dimensional, noisy data. methods based on the statistical analysis of dependencies have been applied to the inference of grns, such as the method proposed in  <cit> , which uses correlation coefficients to define the gene similarity metric for inferring the grns. one weakness of this method is that correlation coefficients fail to identify more complex statistical dependencies  between genes. thus, information theoretic measures have been proposed to capture more complex dependencies. in particular, these methods use mutual information  between a pair of genes as a measure to infer networks  <cit> . as the existence of indirect interactions in relevance network, some refinements have been proposed to correct the predictions. for example, the clr method  <cit>  eliminates indirect influences based on the empirical distribution of all mutual information scores. the aracne method  <cit>  was also designed to filter out indirect interactions by using the data processing inequality. c3net  <cit>  and its extension bc3net  <cit>  correct the predictions based on estimates of mutual information values in conjunction with a maximization step. the anoverence method  <cit>  includes meta-information of the microarray chips to guide the network inference process and uses η
 <dig> score as an alternative measure to evaluate dependencies between genes, where η
 <dig> score is a correlation coefficient derived using anova.

the methods  based on probabilistic graphical models  have been widely used to infer grns. however, bayesian networks do not allow the presence of feedback loops. dynamic bayesian networks  <cit>  are able to overcome the limitation while they can only handle time-series expression data. moreover, learning the structure of a bayesian network is a daunting task both from a computational and theoretical point of view  <cit> . comparisons of existing grn inference methods and detailed reviews can be referred in  <cit> .

recently, some ensemble methods  formalized the grn inference problem as a feature selection problem and show interesting performance. the genie <dig> method  <cit> , which is based on feature selection with ensembles of random forests, is recognized as state-of-the-art on some benchmarks  <cit> . as using random forests for feature selection is not well understood theoretically, the tigress method  <cit>  uses least angle regression  with stability selection combined to solve the grn inference problem. the ennet method  <cit>  aggregates the features selected by an algorithm based on gradient boosting machine. however, the ennet method has high computational cost when it is applied on the high-dimensional data . the nimefi method  <cit>  explores the potential of several ensemble methods, such as genie <dig>  ensemble support vector regression  and ensemble elastic net  <cit>  , and combines the predictions of these methods under a general framework. however, nimefi has more adjustable parameters than other ensemble grn inference methods, which increases the uncertainties of the model.

in this paper, we propose a new ensemble grn inference method based on partial least squares . the method casts pls-based feature selection algorithm into an ensemble setting by taking random potential regulatory genes. then, we use a statistical technique to refine the predictions in our method by taking into account the impact of hub regulatory gene . various evaluations of techniques have been performed in the context of dream  challenges  <cit> , which aims to provide researchers with benchmark datasets to validate their work. hence, we compare the performance of our method to several state-of-the-art methods in dream <dig>  <cit>  and dream <dig>  <cit>  gene reconstruction challenge, and the results show our method performs competitively.

methods
problem definition
we focus on inferring the directed topology of grns using gene expression data in this paper. as input data, we consider gene expression measurements for p genes in n experimental conditions. the same as many ensemble methods , we use a general framework for grns inference problem, which does not take the information of different experimental conditions  into account. the gene expression data d is defined as following:  <dig> d=x1…xp∈rn×p where x
i is a column vector of expression values of i-th gene in n experimental conditions.

grn inference methods aim to make a prediction of the regulatory links between genes from gene expression data d. most methods provide a ranking list of the potential regulatory links from the most to the less confident. then, a network is automatically obtained by selecting a threshold value on this ranking. as it is beneficial to the end-user to explore the network at all sorts of threshold levels  <cit> , we focus only the ranking task in this paper. it should be noted that the ranking is the standard prediction format of the dream challenges, where the challenges have been widely used to evaluate various grn inference methods.

in order to infer the regulatory network from the expression data d, we compute a score w
ij for a potential edge directed from gene i to gene j, where the edge indicates that gene i regulates gene j on expression level and the score w
ij represents the strength that gene i associates  gene j.

network inference with feature selection methods
motivated by the success of ensemble methods based on feature selection , we decomposed the grn inference problem with p genes into p subproblems, where each of these subproblems can be viewed as a problem of feature selection in statistics  <cit> . more specifically, for each target gene, we wish to determine the subset of genes which directly influence the target gene from the expression level. let d is the gene expression data defined in , the i-th gene is the target gene, and we define candidate regulators containing expression values in n experimental conditions as:  <dig> x−i=x1…xi−1xi+1…xp and the feature selection problem can be defined as:  <dig> xi=fx−i+ε,,∀i∈12…p where f is a regression function exploits the expression in x
− i of genes that are directly connected to gene i, and ε is some noise. usually, f can be defined as:  <dig> fx−i=Σjwjixj,∀j∈ <dig> …,i− <dig> i+ <dig> …,p where w
ji ≥  <dig> represents the strength that gene i associates  gene j. the rankings of the regulatory links of gene i is obtained by computing the w
ji. by aggregating the p individual gene rankings, we can get a global ranking of all regulatory links.

grn inference with pls-based ensemble methods
recently, as pls  has been exploited by several authors to address the problem of feature selection for classification and showed interesting performance, such as totalpls  <cit>  and kernelpls  <cit> , in this paper, we also use the pls based method to solve the problem defined in . one difficulties of grn inference problem is that we do not know how many candidate regulatory genes are sufficient to provide a good model for a target gene. for the purpose, we use pls-based ensemble method. the basic idea is that the w
ji for gene i is computed by running pls-based feature selection method many times, resampling the samples and selecting random k candidate regulatory genes at each run. we discuss and explore the effect of k values on the method performance in the results section.

feature selection with pls-based method
let x = [x
 <dig>  …, x
p] ∈ r
n × p be a matrix that has been normalized to have a mean of zero and y = [y
 <dig>  …, y
n]t ∈ r
n ×  <dig> be a column vector that has been normalized to have a mean of zero. pls aims to find a pair of projection directions w and u such that the projections p = xv  and q = yu can carry as much information on variation as possible in x and y  <cit> . the projections p and q can be obtained by solving the criterion function as:  <dig> maxjv,u=vtΣxyu2vtv⋅utus.t.vtv=utu= <dig>  where Σ
xy = cov
 <dig> is the covariance matrix for the vectors of x and y.

the common solutions to pls-based model include non-linear iterative pls   <cit>  and statistically inspired modification of pls   <cit> . as simpls is slightly superior to nipals and is computationally efficient, our analysis and calculation is based on simpls in this paper. pls components p are constructed to maximize the objective function based on the sample covariance between y and p = xv. let m be the number of components, simpls is able to calculate v
 <dig>  v
 <dig>  …, v
m by solving the objective function as follow:  <dig> maxjv=cov2xvi,ys.t.∥vi∥=1;vitxtxvj=0;j= <dig> …,i− <dig>  


the component p
i = xv
i, which extracts from the simpls calculation, represents as much variation information of x as possible. to explain the information of y, the component should be associated with y as much as possible. in order to analyze the explanation of variation of x to y, the variable importance in projection   <cit>  is introduced to quantitatively denote the impact of i-th feature to y.


definition vip: let r be the correlation coefficient between two variables. the vip is defined as:  <dig> vipxj=p∑i=1mψytivji2∑i=1mψyti where ψ = r
 <dig> is the explanation of variation of component p
i to y, p is the number of features and v
ji is the weight of the j-th feature for the i-th component. the larger value of vip is, the more explanatory power of x
j to y.

the pseudo code of pls-based feature selection is presented in method  <dig> 


refining the inferred regulatory network
in our method, we use a statistical technique to refine the inferred regulatory network in our method. the final result is improved under the assumption that if a regulatory gene regulates many target genes , it is an important regulatory gene. once the solution of the gene regulatory network inference is calculated, we can obtain an adjacency matrix w, where w
ij represents the strength that gene i associates  gene j. regulatory genes are scored based on their impacts on multiple target genes. an updated adjacency matrix w is given as:  <dig> wi:=wi:*σi <dig> ∀i∈12…p where w is the i-th row of w, and σ
i <dig> is a variance in the i-th row of w. it should be noted that each row of w is calculated in a subproblem of our method. each row of w contains relative scores with respect to a different target gene. therefore, if a regulatory gene regulates many target genes, the variance in a row of w corresponding to that regulatory gene is elevated.

the pseudo code of pls-based ensemble method  is presented in method  <dig> 


parameter settings
the main parameters of plsnet are the number of components m and the number of candidate regulatory genes k. parameter selection  for the pls model is a difficult task due to the fact that if m is too large, there will be over-fitting in the model and if m is too small, there will be under-fitting in the model. there are two widely used methods for pls parameter tuning, specification and cross validation . the drawback to cv is that it significantly increases the computation cost and the problem to a certain extent becomes even more difficult to handle. the specification method usually fixes the value of m, typically, the value is not larger than  <dig>  since we do not know how many candidate regulatory genes are sufficient to provide a good model for a target gene, the choice of k may not be trivial.

in this paper, we evaluated our method plsnet on two popular benchmarks: dream <dig> multifactorial datasets and dream <dig> datasets. for dream <dig> multifactorial datasets, we use cv to set two main parameters of plsnet, where m is chosen from { <dig>   <dig>  ⋯, 5} and k is chosen from { <dig>   <dig>  ⋯, 100}. and we choose the parameter setting  as default values. as the size of dream <dig> datasets is much larger than that of dream <dig> multifactorial datasets, it is difficult to utilize cv to choose the parameters due to the fact that it would significantly increase the computation cost. instead, we utilize the specification method to set m =  <dig>  and following the suggestion of genie <dig>  <cit> , we set k=p as default value for dream <dig> datasets.

computational complexity
as shown in method  <dig>  there are two main parts in plsnet, including calculating the score of each edge and refining the inferred network. consider n × p matrix x and n × 1 matrix y, simpls is o complex. here, m is the number of components, n is number of samples and p is the number of genes. another part of plsfs  is also o complex. hence, the computational complexity of plsfs is o and we calculate the score of each edge in an o time, where k is the number of candidate regulatory genes and t is the number of iterations. plsnet’s complex is thus on the order of o. in practice, the dominating part of the sum is mtknp and the value of m is not larger than  <dig>  we therefore report a final computational complexity of plsnet as o. we compare our method with other inference methods in table  <dig>  it should be noted that the calculation of the mutual information matrix is not included for information-theoretic methods .table  <dig> the computational complexity of different grn inference methods

otkpnlogn,t= <dig> k=p.
otkpnlogn,t= <dig> k=p
otkpn,t= <dig> k=p.
the computational complexity of plsnet and other grn inference methods with respect to the number of genes p, the number of iterations t and the number of samples n





RESULTS
in recent years, the problem of evaluating performance of the inference methods on adequate benchmarks has been widely investigated  <cit> . the most popular benchmarks, such as s. cerevisiae  <cit> , e. coli  <cit>  and artificially simulated in silico networks , are derived from well-studied in vivo networks of model organisms. one weakness of in vivo benchmark networks is that no matter how well the model organism is studied, experimentally confirmed pathways can never be assumed complete  <cit> . as such networks are assembled from known transcriptional interactions with strong experimental support, the gold standard networks are expected to have few false positives. given a gene expression data matrix, a grn inference method outputs a ranked list of putative regulatory interactions. taking the top l predictions in this list, we can compare them to known regulations  to evaluate the performance of the grn inference method.

in this paper, we used several popular benchmark grns to evaluate the accuracy of our proposed method and compare it with the other inference methods. the datasets we used in our experiments are from dream challenges and the details of the datasets are summarized in table  <dig>  the first three networks come from the dream <dig> challenge. network  <dig>  is a simulated network with simulated expression data, while the other two expression datasets are real expression data collected for e. coli  and s. cerevisiae . it should be noted that we do not use network  <dig> of dream <dig> in our experiments for the reason that there is no verified interaction provided for this dataset. in order to assess the ability of our method to predict directionality, we used the five dream <dig> size  <dig> multifactorial networks in our experiments, where the regulatory genes are not known in advance for these networks.table  <dig> datasets




in fact, dream <dig> and dream <dig> datasets have been widely used for several grns inference methods to evaluate the performance recently. for example, the authors of tigress  <cit>  compared the performance of some grns inference methods on dream <dig> multifactorial networks and dream  <dig> networks in  <dig>  in the same year, the authors of anoverence  <cit>  presented the results of several grns inference methods performed on dream <dig> networks. in  <dig>  the performance comparisons of many grns inference methods on dream <dig> multifactorial networks and dream  <dig> networks were shown in nimefi  <cit> .

we evaluated the accuracy of the methods using the overall score metric proposed by the authors of dream challenges  <cit> , as shown in the following:  <dig> overallscore=−12log10p_aupr⋅p_auroc where p_aupr and p_auroc are respectively the geometric means of p-values taken over the networks from dream challenges, relating to an area under the precision-recall curve  and an area under the receiver operating characteristic curve . the probability densities of dream network data which are used to calculate the p-values and the respective gold standard networks are provided on dream web site.

performance evaluation
we compare the performance of our method plsnet with five of the most prominent grn inference methods, genie <dig>  <cit> , tigress  <cit> , clr  <cit> , aracne  <cit>  and nimefi  <cit> , that are widely used in the literature. moreover, the top three performers in each of dream challenges as listed on the dream web site are also selected for comparison. we use the matlab implementations of genie <dig> and tigress, while aracne and clr are run in the minet r package  <cit> . nimefi is implemented using the r package available for download at http://bioinformatics.intec.ugent.be/. the matlab code of plsnet is included in additional file  <dig>  we keep default parameter values for each of these methods and set the number of iterations t =  <dig> for ensemble methods .

performance on the dream <dig> multifactorial datasets
the goal of the in silico size  <dig> multifactorial challenge of dream <dig> was to infer five networks from multifactorial perturbation data, where each of them contained  <dig> genes and  <dig> samples. multifactorial perturbation data are defined as gene expression profiles resulting from slight perturbations of all genes simultaneously. the topology of these benchmark networks were derived from the transcriptional regulatory system of s. cerevisiae and e. coli.

each dream <dig> multifactorial network data is a 100 ×  <dig> matrix, where each column represents a gene and each row represents a different experimental condition . the values in the matrix are the expression values of the genes on the respectively experimental conditions. in our experiments, all compared grns inference methods used these matrices as the input data and the results are shown in table  <dig> table  <dig> performance comparisons of different grn inference methods on the dream <dig> networks, challenge size  <dig> multifactorial

 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
the best results for each column are in bold. numbers in the “winner of competition” part of the table correspond to the best methods participating in the challenge as listed on the dream web site




table  <dig> lists the results of plsnet with default parameter setting  compared with those of other grn inference methods on the dream <dig> multifactorial datasets. without further optimization of the parameters on these networks, plsnet achieves the best overall score. and plsnet shows particularly strong performance on network <dig> and network <dig>  improving over other grn inference methods in terms of aupr and auroc.

influence of parameters
in this section, we provide more details about the influence of the parameters of compared methods on performance, taking five dream <dig> multifactorial networks as benchmark datasets.

figure  <dig> summarizes the overall score of three compared methods  for different number of candidate regulatory genes k on the dream <dig> multifactorial datasets. as seen in fig.  <dig>  the range of k values leading to the best performance is narrow with our proposed method, and therefore it is difficult to find an appropriate value of k as default value in advance.fig.  <dig> boxplots of overall score on dream <dig> multifactorial networks with respect to the number of candidate regulatory genes




figure  <dig> shows the overall score of our method for different number of components m with k =  <dig> on the dream <dig> multifactorial datasets. we observe in fig.  <dig> that the overall score is not very sensitive to the choice of the number of components, and therefore one may practically more easily tune it for optimal performance.fig.  <dig> boxplots of overall score on dream <dig> multifactorial networks with respect to the parameter of plsnet




figure  <dig> shows the influence of two main parameters  of tigress on the overall score using dream <dig> multifactorial datasets, where α ∈  controls the random re-weighting in each stability selection run and l is the number of lars  steps. the overall score of aracne for different kernel widths on dream <dig> multifactorial networks is shown in fig.  <dig> fig.  <dig> boxplots of overall score on dream <dig> multifactorial networks with respect to the parameters of tigress


fig.  <dig> boxplots of overall score on dream <dig> multifactorial networks with respect to the parameter of aracne




performance on the dream <dig> datasets
the three dream <dig> datasets were structured with respect to different model organisms, and were different in size. the expression data of the only one network  were simulated in silico, while two other sets of expression data were measured in real experiments in vivo. as in all dream challenges, in silico expression data were simulated using an open-source genenetweaver simulator  <cit> . the gold standard networks of dream <dig> were mainly obtained from two sources: gene ontology  annotations  <cit>  and regulondb database  <cit> .

each dream <dig> network data contain three files: network chip features, network transcription factors and network expression data. the file of network chip features records the details of each experimental condition in network expression data, which contain time series, perturbations and even replicates. however, as mentioned in section  <dig> , we do not use the information for inferring grns. and the methods compared in our experiments do not use the information as well. the file of network transcription factors records the genes that have been verified to be regulatory genes. typically, the number of regulatory genes is used as a parameter for grns inference methods to construct the model. the file of network expression data contains a n × p matrix, where n represents the number of experimental conditions and p is the number of genes, and the values in the matrix are the expression values of the genes on the respectively experimental conditions. in our experiments, all compared methods used these matrices as the input data and the results are given in table  <dig> table  <dig> performance comparisons of different grn inference methods on the dream <dig> networks

 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
the best results for each column are in bold. numbers in the “winner of competition” part of the table correspond to the best methods participating in the challenge as listed on the dream web site




table  <dig> summarizes the results of plsnet with default parameter setting  compared with those of other grn inference methods on the dream <dig> datasets. as seen in table  <dig>  plsnet achieves the best overall score, as well as the best individual auroc scores for network  <dig> and network  <dig>  anoverence achieved the best performance on the e. coli network , as it does include meta-information of the microarray chips to guide the network inference process.

since the number of regulatory genes on dream <dig> datasets is much larger than that of on dream <dig> datasets, it is more difficult to set the number of candidate regulatory genes k. in our experiments, we set k=p and observed that our method perform well in this setting. however, it should be noted that better results could be obtained if k is set to other values.

obviously, all grn inference methods achieved better scores for an in silico network  than for other two in vivo networks. one main reason for a poor performance of the inference methods for in vivo networks may be that experimentally confirmed pathways, and the gold standards derived from them, cannot be assumed completely. on the other hand, in silico datasets provide enough information to confidently reverse-engineer their underlying structure.

cpu time
in our experiments, aracne, clr and nimefi were implemented using the r package, while genie <dig>  tigress and our method plsnet were run in matlab. as plsnet is an ensemble method, we focus on the running time of ensemble methods rather than other grn inference methods. on the other hand, ensemble methods usually achieve better results than other grn inference methods.

table  <dig> gives an overview of the running times of some of the grn inference methods. these measurements were conducted using matlab , an intel core  i5-3317u, clocked at  <dig>  ghz,  <dig>  gb of ram memory and a 64-bit microsoft windows  <dig> operating system. note that we do not include nimefi for comparison due to the fact that nimefi is a method using multiple ensembles of grn inference methods, including genie <dig>  ensemble elastic net and ensemble support vector regression.table  <dig> comparisons of running times of different grn inference methods




as can be seen from the table, in terms of computational efficiency, plsnet performs best on dream <dig> networks and performs the second best on dream <dig> networks. genie <dig> performs best on dream <dig> networks as the size of the datasets is small. however, genie <dig> is more time consuming than plsnet when it is implemented on the big datasets.

CONCLUSIONS
in this paper, we presented plsnet, a new ensemble method for grn inference. plsnet expresses the grn inference problem as a feature selection problem, and solves it with the pls-based feature selection method combined with a statistical technique for refining the predictions. the influence of plsnet parameters was clarified in this paper, and we showed that further improvement may result from finer parameter tuning.

different from other ensemble methods, such as genie <dig> and tigress, plsnet aggregates the features selected by pls-based method. moreover, considering that if a regulatory gene regulates many target genes , it indicates an important regulator gene; we use a statistical technique to refine the inferred network in our method.

we evaluated our proposed method on the dream <dig> multifactorial and dream <dig> benchmarks and achieved higher accuracy than other state-of-the-art methods. furthermore, among ensemble grn inference methods, our method is computationally efficient.

additional file

additional file 1: code of plsnet. the matlab code of our proposed method 




abbreviations
aracnealgorithm for the reconstruction of accurate cellular networks

aupran area under the precision-recall curve

aurocan area under the receiver operating characteristic curve

clrcontext likelihood of relatedness

dreamdialogue for reverse engineering assessments and methods

genie3gene network inference with ensemble of trees

grngene regulatory network

nimefinetwork inference using multiple ensemble feature importance algorithms

plspartial least squares

plsnetpls-based gene network inference method

tigresstrustful inference of gene regulation using stability selection

we would like to acknowledgment three reviewers for helpful suggestions.

funding
this research was supported by research fund for national natural science foundation of china  under grant no.  <dig> and shenzhen technology development foundation grant no. cxzz <dig> 

availability of data and materials
the datasets of dream <dig> are available on http://www.synapse.org/#!synapse:syn3049712/files/.

the datasets of dream <dig> are available on http://www.synapse.org/#!synapse:syn2787209/files/.

authors’ contributions
sg designed the method, conducted the experiments, and wrote the manuscript. qj supervised the project. lc wrote the manuscript. dg gave the ideas and supervised the project. all authors read and approved the final manuscript.

competing interests
the authors declare that they have no competing interests.

consent for publication
not applicable.

ethics approval and consent to participate
not applicable.
