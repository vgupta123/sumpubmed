BACKGROUND
the genopolis gene expression database
the genopolis consortium operates an affymetrix genechip速 service, specialized in the transcriptional profile of cells and tissues related to the immune system and to the area of immunopathology.

large-scale gene expression analysis is of great relevance in the field of immunology to generate a global view of how the immune system attacks invading micro-organisms, maintains tolerance, creates a memory for past infections: fundamentals questions in immunology address how the immune system distinguish between self and non-self, and how immune cell differentiation and growth is regulated.

the genopolis microarray database was designed as a resource to support a focused scientific community and it was deployed to support the community studying dendritic cells functions and host-parasite interactions.  we present here both the software system and its current implementation.  the system presents a selection of features that differs from other microarray databases and that is ideal to support distinct groups of users working on a common subject.  in its current implementation, it provides gene expression data on a precise biological system that are homogeneous in terms of the measurement platform and the annotation process used.

annotation of microarray data
the importance of the characterization of microarray experiments is well understood  <cit> : a proper description of experiments' conditions and processes is a necessary condition to evaluate data generated with different experiment designs and instrumentations.

a set of guidelines called miame   <cit>  was proposed by the microarray gene expression data society  <cit> .  miame is a document that lists a minimum set of information to characterize a microarray data set. this includes information about the experiment design, the targeted experimental factors, the organism studied, the measurement platform and all the biological or data processing protocols that have been applied in order to extract data from the biological material.

a further effort has been made to define a representation of this information that can be machine-processable and may be used for data exchange across microarray related software applications.  result of this effort is the micro array gene expression object model , and its corresponding xml data exchange format, mage-ml  <cit> .  the mage object model describes the structure of the experiment, its components and relations. it is complemented by the use of standard collection of terms or ontologies.  the main ontologies used with mage are the ncbi taxonomy  <cit> , gene ontology  <cit>  and the mged ontology  <cit> .

at the moment of this writing the definition of a standard representation for microarray experiments is still undergoing significant development and new, more general, models and ontologies are being proposed 

microarray public repositories
public repositories are intended to provide a persistent access to gene expression data produced by the scientific community. they are designed to collect data relative to heterogeneous experiments, hence the importance of the use of a proper annotation.  to enforce their role of knowledge repositories, major scientific journals requires that data supporting publications must be deposited on a public repository.

array express  <cit>  has has been developed by the european bioinformatics institute  and has been modelled following the mage-om model. it is a reference resource for the development of annotations.  gene expression omnibus  <cit>  has been developed by the us national center for biotechnology information . it stores high-throughput molecular abundance data .  cibex  <cit>  is another repository from the center for information biology and data bank of japan. it is a miame compliant public repository, which stores a wide range of data, including mrna based microarray data, gene expression data obtained with sage technology, and mass spectrometry proteomic data.

public repositories are centralized resources that offer a public access to the community. they are not designed to support the needs of data management of single research groups.

microarray software
many microarray database systems are available to the scientific community and are suited to be operated by small research groups. they vary in the features offered and in their characteristics. almost all of them support miame experiment annotations, some present data analysis features and some include support for related laboratory activities .

two widely adopted database systems are base  <cit>  and maxd  <cit> .  base is a microarry database system implemented as a web application. it offers lims functionalities and a set of data normalization and analysis features that can be extended thanks to a plug-in architecture. an optional module allows the management of custom built arrays. one limit of base is that it has a limited support for a particular class of microarrays  that include the affymetrix genechip速 platform.  maxd is composed by a set of tools that support different microarray data related tasks, such as data curation, data browsing and analysis.  maxd supports a rich experiment description that can be customized in a particular installation by a responsible user . one limitation of maxd is its week support for a more complex scenario where multiple user groups have different access rights to the data.  among many other microarray database solutions we cite gecko  <cit> , microgen  <cit> , plasmodb  <cit> .

finally, several software tools exists that are specifically designed for the analysis of microarray data. these accepts as input tab-delimited text files, mage-ml files and sometimes they offer direct connection to specific databases.  the tab-delimited text file is the most common format. in this case all the experiment annotation is assumed to elaborated by the user before a selected set of data is analysed.  among these tools we cite genespring速 for its interactive graphical user interface, and bioconductor, an entire collection of open source tools and libraries for microarray data analysis implemented in the r statistical language.

dendritic cells transcriptomics and the genopolis database
within the genopolis consortium, we have used our database system to store information on dendritic cells.

dendritic cells are professional antigen presenting cells that are central to the induction and regulation of immunity. many genomic studies have been performed to interpret how dendritic cells respond to microbial and non-microbial inflammatory stimuli. in kinetic experiments, gene expression profiles of immature in vitro derived mouse or human dc have been compared with gene expression patterns of activated dc at different times after challenge with the activation stimulus  <cit> . the analysis of the entire kinetic data sets has revealed that dc undergo a profound reorganization of gene expression in the first few hours after activation and then they progress versus a new resting state that is clearly distinct from the original immature dc state  <cit> . improvement in the understanding of the functional complexity of dc maturation have been reached by the use of microarray experiments. this global studies have demonstrated the complexity of dc maturation at a molecular level  <cit> .

for these reasons we have chosen to populate our database with data collected from unstimulated dc  and dc that have been treated with live organisms and with their component in a time dependent manner. to investigate the effects of different stimuli on dc function, we have used the affymetrix genechip速. we took advantage of the previously described mouse dc line, d <dig>  <cit> . d <dig> cells are a splenic, myeloid and growth factor-dependent dc line that can be maintained indefinitely in culture in the immature state. this cell line can be driven to full maturation using different stimuli. moreover it is composed of highly homogeneous cells.

implementation
the data model
the data model underlying the genopolis database maps a set of concepts in the experiment annotation to objects that are grouped according to a tree structure .

this arrangement is adequate for most experiment designs and single channels arrays. its regular structure allows functions on the database content, such as consistency control, analysis and search to be implemented as simple functions on nodes that can be called in a tree traversal.

the objects implementing the experiment description are:

submitter: the scientific responsible of an experiment.

experiment: generic information about an experiment. experiments are associated to submitters.

source: the biological source  under study. an experiment can have one or more sources.

sample: a specific state of a source that is characterized by a time and a set of stimuli affecting this source at this time.

stimulus: information regarding a stimulus applied to a source in an experiment. this includes the time of application of the stimulus and its duration. when the same stimulus affects more than one sample within an experiment, this object is repeated for each sample. this minor flaw was chosen in order to maintain the objects organized as a tree.

hybridization: all information regarding the hybridization of a sample. this includes information on the array used  and the methods to extract and label the mrna. at least one hybridization must be associated to a sample.

measurement: a set of gene expression values derived from an hybridization. this includes information on the reading  of the microarray as well as the image analysis and normalization procedures used.

other objects that are not organized as elements of a tree are used to define protocols and arrays.

each element is characterized by several classes of attributes. some attributes are simple named text or integer values, such as an animal identifier or an age value for a source. some are relative to values that are defined in controlled vocabularies, such as the name of a cell line or of a tissue. information on protocols and arrays used is defined in external objects that are referenced within the description elements. finally each object accepts an informal natural language description to handle not explicitly supported information.

the genopolis database object model is intended to describe experiments in terms of their building blocks. it then analyse the structure of its content to derive properties. for instance by default different hybridizations relative to the same sample are considered  as technical replicates, while distinct samples with the same stimuli and attributes  are considered biological replicates.

architecture
the genopolis database is realized as a relational database managed by a web based application.  the object model the database is based on is implemented by a set of software objects  that abstract the underlying relational tables. hence, the resulting system is a n-tier architecture.  the current version of the genopolis database makes use of mysql  <dig> , but access to the sql layer is standard and wrapped by the business objects, so that it would be easy to port it on different systems.  the core of the system is a web based application written in php <dig> and currently deployed on apache and linux based web servers.

in order to support the experiment annotation described later, two distinct relational databases are used.  one database stores incomplete experiment descriptions while these are being assembled. another database contains data and descriptions of complete experiments and is available to the user for queries.  this distinction was made to improve reliability  and enhances performance, since read only instances of the database used for queries can be easily distributed on different machines, for instance on the nodes of a cluster.

the objects described above are organized in a tree structure and support recursive propagation of operations over the tree. one example of such operation is the checking of the consistency of the experiment description. this is implemented through an abstract check() method that is implemented for each object.  these objects also support rendering of information as html code for web forms  and for read only web pages. to implement this, each object representing an entity in the experiment description contains a list of objects corresponding to description items and implementing description types as strings, numbers, controlled vocabularies, free text, files. these objects are part of a distinct library called daolib , that allows the specification of their behaviour  and appearance .

this software engineering based approach eases the maintainability and upgrading of the system.  the system maintains cel files, image files and other attachments in a proper directory, and makes them available for download to authorized users. measurement files are kept as files while assembling the experiment description, then parsed and stored in a single indexed mysql table to support queries related to expression values.

finally, other maintenance functionalities are implemented outside a client-server paradigm. these include import of genechip速 descriptions from affymetrix mage-ml files , transfer of data between the two databases, export of its content to arrayexpress.

access control
the genopolis database supports a flexible access schema to its content where users can be distinguished by group memberships and roles .  for instance, a data set may be declared accessible to the members of a given research group, and only accessible with limited rights  to others.  in its current implementation the granularity of the access specification is the experiment: all annotation and data relative to elements that are part of the same experiment tree can be assigned as a whole to groups and users' access rights depend on their role within the group .  this serves also as a support for a distributed annotation process: within a group, some users can be designated as responsible of the definition of protocols, controlled vocabularies, array annotations, while other users may be responsible for the experiment annotation.

the access system is based on a custom designed object oriented api. this is based on three php classes: groupsecuritymgr , usersecuritymgr , objectsecuritymgr .  api abstraction and customization classes  provide an easy to use access point to the programmer.

mage-ml and arrayexpress export
the genopolis database can export its content in mage-ml. this feature has been implemented in order to provide an automated export to the arrayexpess public repository.  the implementation of this functionality is based on tab2mage. this tool, developed by the ebi, accepts the description of a single experiment in a simple tabular format and translates it into the equivalent mage-ml file.  producing the structure of this kind of tabular files has been straightforward, since our experiment model is similar the model represented in them.  the support for controlled vocabularies has made possible their mapping to terms of ontologies accepted by arrayexpress, such as the mged ontology. integration of these ontologies within our system is undergoing.

deployment
the genopolis database is currently deployed on a cluster architecture.  this is based on the debian linux distribution completed with the web server load balancing software "linux virtual server" and the high availability tool "heart beat".

web users requests are transparently distributed to available service nodes. this distributes the web server load and ensures availability of the system even in case of nodes failure. each node has a local copy of the database holding complete experiment description and data . this assures distribution of loads to different sql engines and an optimization of data access.

RESULTS
we present here the features provided by the genopolis database and discuss how they support the implementation of a community database.

experiment annotation process
the genopolis database supports a community building a common knowledge base, by implementing a work-flow for data and experiment annotation, where different users can add different contribution depending on their role and responsibilities. furthermore, it provides functions to check the consistency of its content and to dynamically create controlled vocabularies.  in detail, users with proper privileges can access a space where they can assemble experiments description and upload generated data. this can be done at different times, thanks to the ability of the system to save incomplete descriptions.  at any time users can ask the system to verify the completeness of the experiment description. upon this request, the application verifies that all required information is present, that all the descriptions that need to be defined with terms from controlled vocabularies are fulfilling this condition, and it furthermore checks the content of data files for trivial errors .  it also verifies that some constraints are met .  at the end of this verification process a report is generated and sent to responsible users.

when an experiment description is correct and all its data are present, a user can ask the system to make it available to the community . in this case the entire experiment description is scheduled to be transferred to the complete experiments database, its measurements files are parsed and the copies on the cluster nodes are updated .

some users within groups are responsible for protocols description, and a supervisor user is responsible for the curation of controlled vocabularies: new terms suggested by users in their experiment description are presented to this supervisor for approval. the supervisor can approve, deny or suggest new terms .

data access and exploration
several data access methods are provided by the database. one common idea in their design was to support intuitive and collaborative analysis of the database content. at any moment part of the database content can be exported as a configurable tabular file and imported in more sophisticated analysis tools.  an intuitive visualization interface provides a rich interactive access to the database content. its basic idea is that gene expression can be studied analysing the association between set of genes and set of conditions .  the interface allows the user to browse interactively the data, to visualize expression relative to a given set of genes and conditions, and to "move" to other genes or conditions related by the expression data or by their annotation.

this interface resembles a microarray data matrix: a left panel presents a list of genes and allows their selection , an upper panel presents a list of samples and options for their selection and sorting, and a centre panel shows actual microarray values. this panel offers several visualization options that varies depending on the cardinalities of the set of genes and samples. for n samples and m genes it presents views as heatmap, radar plots, tabular files and lines, while if an element has a cardinality of two it presents also a scatter plot. when a huge number of genes is selected, as is the case for all the data relative to some conditions, only the tabular visualization is provided.

both the genes lists and the samples list presents hyperlinks to information stored in the database  and to external resources, such as netaffx  <cit> .

many charts are provided with hyperlinks that popup information on the gene and condition relative to a single value. from this it is possible to navigate to related sets of genes. for instance, selecting a value for a gene under a condition will pop up a panel listing all the lists of genes  this gene belongs to. it is then possible to change the current selection of genes in the left panel to one of these lists and to update all the information provided accordingly.

a "discover" function allows users to search for genes or samples with a similar expression pattern as for a relevant subset of the data matrix . genes or samples lists can be updated with the results of these queries and accordingly all the information presented is re-organized.

overall, the genopolis database provides tools where, starting from a set of genes and stimuli of interest, the user can browse the database content investigating interesting associations between genes and samples revealed by their expression values.

management of searches and data sets
another interface provided by the genopolis database to access its data is the "batch query" interface. here both genes and samples can be searched. the difference with the interface presented before is that this aims at providing finer search features, at the expenses of interactivity. it also aims at management of search results.

concerning genes, sequence annotations can be queried using the usual srs-like approach . similarly, experiment annotation may be searched by keyword and relevant attributes.

in order to improve data management and collaboration, search results may be saved and later retrieved . support for storing and reloading of predefined genes lists, such as genes functional families, is also provided, as well as the ability to operate on lists with intersection and union operators.  saved search results are controlled by the access policy system, so that it is possible to define which user groups may have access  to them. saved genes lists may be used in all the query interfaces by authorized users.

we have used this feature in our instance at the genopolis consortium to manage functional families of genes that are relevant to immunology. this feature forms the beginning of a knowledge management system related to microarray data: for example, this makes possible for a researcher to share with his or her collaborators a list of genes he has found interesting while analysing some gene expression experiments. the batch query system has been implemented as a plug-in architecture that separates the code which search data, from the code which manages a search result. this makes easy to extend this interface and write new search functions or new data visualizations and operations.

export to public repositories
the genopolis database is designed as a community database and is intended to support group of users that trust each other and can share non public data. this is not in contrast and complements the role of public repositories.  in fact, we imagine our database being used to store a valuable collection of highly homogeneous data that can be shared  with confidence within a restricted community.  once an experiment has been investigated and research results need to be published and disseminated, it can be automatically uploaded to arrayexpress.

CONCLUSIONS
the genopolis database is a valuable resource to assist a community in building a knowledge base of gene expression data and to support its analysis.  we have used it to implement a resource managed by the genopolis consortium to provide immunology relevant data to the scientific community studying dendritic cells. this provides a homogeneous data set with a coherent experiment characterization.

one relevant feature of the genopolis database is the ability to export its content to arrayexpress . this complements the vision of a community database in that it allows private data to be shared among trusted participants, and then published to a public repository as this data becomes publicly available.

we believe that the idea presented by our database system and its implementation can be a starting point for similar developments in other communities.

availability and requirements
at the time of writing access to the genopolis database is subordinate to a proper agreement and the code is available on request from the author.  we plan to open part of the database content to the public, and to make the software available on bioinformatics.org.

authors' contributions
as has initiated this project and he is responsible for the overall design, the implementation of the core functions and the visual query interfaces.  mb is responsible for the batch query interfaces, the implementation of the access management schema, the arrayexpress export tool , the affymetrix mage-ml import and the daolib library.  ge is responsible for cluster adaptation and he is currently in charge of features development and users support.  mf and mm are responsible for the content and the operation of the running implementation of the genopolis microarray database.  mp ob, np and gm have contributed with ideas and feedback on the database design and implementation, as well as with their expertise in microarray data analysis.  fg and pc are responsible for the overall direction of the project and for its scientifc focus as a resource for immonology.

