BACKGROUND
pre-processing of affymetrix genechip® feature-level data has been a widely researched topic over the past few years. many of the commonly used algorithms utilize models where parameters are estimated using data from multiple arrays. these approaches are typically used in the normalization and summarization steps. examples of multi-array procedures are rma, gcrma, mbei, and, most recently, plier  <cit> . each of the algorithms have been extensively compared to one another based on a variety of dilution and spike-in series of data sets  <cit> . from these studies, measures of precision and accuracy have been utilized to determine advantages and disadvantages for each of these methods. in general, multi-array based methods outperform those that derive expression measures using data from just the array in question.

a problem associated with these algorithms that has not received much attention is the limitation they impose on data archiving. when data from a new study becomes available, all arrays are pre-processed together to obtain expression measures. because different data is used to define the normalization routine and estimate probe-effects, data from different studies might not be comparable because of this pre-processing bias. a solution is to group together the feature-level data for both experiments and re-run the pre-processing algorithm. however, this approach will be logistically impossible in the case of building large probe set-level reference databases. these databases can be used to quickly combine samples that may have been generated from a variety of different experiments into a user-defined data set based on some common attribute such as clinical or pathological status, treatment level, or technology-derived attribute. the lack of comparability between sets of samples normalized based on different schemes does not allow for archiving and continual updating of probe set-level data and ultimately prevents the analyst from combining disparately normalized samples into cohesive sets.

there is a need to develop summarization schemes that offer both the statistical advantages of multi-array algorithms such as rma, gcrma, mbei, and plier and the flexibility of a workflow that is not specific to a single set of samples. we utilize the rma model as an example methodology to demonstrate the feasibility of such an approach,

we have utilized an alternate rma workflow that includes two distinct steps:  training of an rma model based on a large number of biologically distinct affymetrix genechip samples from gene logic's bioexpress reference database and  application of the resulting rma model parameters to multiple test sets. we have named this alternate workflow, "reference rma" , to emphasize the reliance of this methodology on a standardized training set of samples exclusive of a test set. results in this paper are shown for the hg u133a affymetrix genechip array for a specific implementation of refrma trained using  <dig>  .cel files representing  <dig> different organ types from four different pathology states. we show that the application of such a biologically diverse model to test data results in similar probe set-level data when compared to classic rma outputs as measured by overall data structure, correlation, differential expression, and other metrics. furthermore, a model trained on a large training set of biologically distinct samples seems to be robust for tissues that were not used in its training. finally, we show that the model can be applied to data sets external to the site of microarray processing specific for the training set such that the model can be used universally.

RESULTS
training set for the "full refrma" model
two goals for building a common reference refrma model are to incorporate as much biological variability as possible into the training set and to appropriately balance the principal sources of variability such that there is not a large degree of overrepresentation of any one of the types. the gene logic bioexpress reference database is comprised of thousands of samples from  <dig> tissues and cell types, which are represented in up to four pathological categories  as determined by a board certified pathologist's review of each sample. individual brain regions were treated as separate organs due to their highly heterogeneous gene expression profiles.

selection of the samples was based on a two-step filtering system. the first step involved an initial balancing protocol that attempted to correct for unintended effects on the normalization due to organs that are disproportionately represented within the database. for instance, samples from organs such as liver, lung, and kidney have high numbers of samples, whereas samples from organs of more limited research may only have a few samples. a balanced pool of samples was created by capping the maximum samples per organ and pathological category at  <dig> samples and randomly selecting samples for those organs with sample numbers above the cap. this first filter resulted in a balanced pool of over  <dig>  samples. the next filter randomly selected  <dig>  non-blood samples from the balanced pool in order to accommodate computational memory limitations.

whole blood was considered a special case due to its unique expression profiles as compared with other tissue types, its relative importance in clinical genomics, and the usage of two types of blood processing protocols that have or have not undergone globin depletion procedures. the final number of samples used for the training set was  <dig>  after the addition of  <dig> whole blood samples available at the time of model training. a summarized list of the individual organ or cell types, their pathological status as determined by a board certified pathologist, and the number of samples within each category is provided as a supplemental file; see additional file  <dig>  a total of  <dig> tissue and pathological categories are present within the training set over the  <dig> represented organ and cell types.

results of affycomp as a comparative benchmark
the full refrma model trained as described above was used to summarize hg u133a arrays with spiked-in probe sets as part of the commonly used affycomp comparative benchmark system  <cit> . this system uses a variety of measures and diagnostic plots to assess ability of summarization methods to accurately and precisely estimate the nominal fold changes as a function of gene expression levels. full refrma was compared with classic rma, where the  <dig> spiked-in samples served as both training and test set, original mas <dig>  and mas5+ <dig> algorithms. the mas5+ <dig> algorithm adds a constant of  <dig> to the resulting mas <dig> values in order to stabilize variance. results of the comparative assessment are presented in table  <dig> and figure  <dig> 

specific descriptions of each metric are provided in the original publication describing the affycomp system  <cit> .

the overall interpretation from the affycomp results is that refrma outperforms mas <dig> summarization, but does not perform as well as classic rma where the training set and test set are identical. this is to be expected under normal circumstances given that classic rma is highly specific to its training set. the spiked-in nature of the experiment introduces an additional probe-level effect into the system and most likely contributes to the size of the disparity between classic and refrma, as classic rma will be trained on this effect and refrma will not. these results indicate a limitation to the applicability of refrma to data that has been heavily manipulated. the manipulation may be due to exogenous addition of probe, such as in the case of a spike-in data set, or may be due to other sample processing factors such as alternate amplification and labelling processes. in addition, the data suggests that a refrma model trained on a large, biologically diverse set of samples may not summarize highly tissue-specific probe sets as well as classic rma, although refrma may outperform single chip-based summarization methods such as mas <dig> 

application of refrma to true biological samples
to test the performance of the full refrma model on unmodified biological samples, a variety of normal control samples from multiple organs were extracted from the gene expression omnibus  database based on the descriptive fields within each sample's annotation  <cit> . random subsets of  <dig>   <dig>   <dig>   <dig>  and  <dig> arrays were selected from the available  <dig> arrays and used to train refrma models. each was applied to an exclusive test set of  <dig> arrays from the same normal geo population. note that, as the training set size increases, the more likely the  <dig> test arrays will have common characteristics. classic rma probe set summaries were also created using these same  <dig> arrays. correlation of each test sample summarized by refrma was calculated relative to the same test sample summarized by classic rma  using all probe sets. the mean correlation across the  <dig> test samples was then calculated. this process was repeated  <dig> times using random selection of both training and test sets to yield correlation distributions. boxplots of the correlation distributions relative to training set size are shown in figure  <dig>  the full refrma model  was also compared to classic rma using the same  <dig> randomly selected test sets over  <dig> iterations.

as expected, the correlation to classic rma increases as the refrma training set size increases until correlations approaching  <dig> are achieved. the full refrma model also approaches 100% correlation. the plot also indicates differences in correlation as a function of independence of training and test set arrays. as the geo-based refrma models randomly select from the same population as that of the  <dig> test set arrays, there are likely to be many common biological and technical factors such as microarray processing site, replicate arrays from the same treatment or disease group, etc. the full refrma represents a more independent training set. the slight drop in correlation suggests that this effect is observable, but not of substantial consequence.

the results generally indicate that the full refrma model can be applied to data external to gene logic's processes with good confidence.

data structure was assessed after application of separate normalization schemes using  <dig> exclusive sets of  <dig> liver normal samples from gene logic's bioexpress® database that were not used to build the full refrma model. for each probe set, the mean intensity was calculated by averaging individual expression values across the  <dig> samples in each set. ma plots of the mean probe set intensities are shown in figure  <dig> for the full refrma and classic models. the plots indicate the same general structure of data with similar distributions of both signal  and variability .

ma plots of the mean probe set intensities were also constructed for comparisons of a single set of  <dig> normal liver samples summarized using either classic rma, full refrma, or a similar version of the full refrma where all liver samples have been replaced with samples from other organs. the results are shown in figure  <dig> using y-axis scales based on the spread of data dictated by the biological variability from the figure  <dig> ma plots. the comparison of classic rma to full refrma results in an overall correlation over mean probe set intensities of  <dig>  and shows some spread of data primarily at the low end of expression. a slight systematic shift is observed at the low end of expression. it is not clear what this shift is due to, but is an indication of subtle systematic differences between small and large training set size models. the comparison of the full refrma and liver-naïve refrma models results in an overall correlation of mean probe set intensities of  <dig> . this high degree of correlation is most likely due to the low percentage of data removed from the training set for the liver-naive refrma model and suggests stability by design. therefore, almost identical probe set intensities result from a model either built with or without any single organ.

histograms for coefficients of correlations and variation are shown in figure  <dig> according to the classic rma and full refrma workflows. the correlation histogram is based on all possible pair-wise sample comparisons across  <dig> normal liver samples that were not used to build the full refrma model. the covariance histogram is based on each probe set's covariance across these same  <dig> normal liver samples.

the histograms indicate almost identical distributions for both probe set-based variation and sample-based correlation for both the classic rma and full refrma workflows with a slight unfavorable shift for full refrma compared to classic rma. this small shift can be viewed as the necessary "cost" associated with the use of a static normalization scheme for true biological samples. two small "bumps" in the distribution of classic rma correlations are evident. the bump centered at  <dig>  is explained by a single sample's correlation to the rest of the data set. we were not able to explain the smaller bump centered close to  <dig>  interestingly, both are resolved by the refrma model, which indicates potential differences between the two models. unfortunately, it is not clear as to whether this is a case of full refrma more successfully dealing with technical artifacts on the chip or if it is a case of full refrma diluting true biological effects.

fold change and p-value conservation is important to establish with any summarization algorithm. although it cannot be expected that different normalization and summarization techniques will select exactly the same probe sets, our goal is to show that a large number of probe sets are selected with both the classic rma and full refrma normalization schemes.

consistency of regulation events was compared for the case where the same model was used to summarize different test sets of  <dig> normal vs.  <dig> malignant liver samples using  <dig> bootstrapping iterations with sample replacement and for the case where classic rma and full refrma were used to summarize the same test set of  <dig> normal vs.  <dig> malignant liver samples  <cit> .

results are shown in figure  <dig> as a function of increasing thresholds of top regulated probe sets, also known as a "correspondence at the top"  plot more fully described in irizarry, et al  <cit> . for both fold change and t-test metrics, the consistency of regulation events based on selection of top regulated probe sets is higher for classic rma vs. full refrma for the same test set than when different test sets are summarized by the same model. this indicates that the variability associated with different test sets of arrays is higher than that of different summarization models and constitutes a positive outcome for the full refrma model as a viable summarization technique. in addition, full refrma and classic rma yield approximately the same degree of regulation consistency for both metrics when challenged with different test sets.

discussion
one of the limitations with the classic rma workflow and other types of multiple array-dependent normalization and summarization schemes is that the resulting models are usually applied to the same samples that were used in its training. this tight dependency between the training and test sets results in a situation where the probe set data cannot be archived in a continuously updated database in the absence of a static normalization scheme.

to counter this limitation, we have used the extensive content from gene logic's bioexpress® reference database of human samples to build a static normalization scheme that can be applied to incoming human data from the hg u133a array on a continual basis. we have shown that a full refrma model, trained on a widely varying number of biologically distinct samples, results in similar probe set intensities compared to the classic rma workflow as far as general data structure, similarity metrics, and number of regulation events. we have also shown that the full refrma model is applicable to data external to the processes underlying the bioexpress® database.

our conclusion from the above observations is that the full refrma model can generally be used to summarize an archival database on an ongoing basis for incoming samples. by applying the model to all samples, we can create a probe set-level expression database that is both consistent across organ and pathology category and provides the inherent benefits of rma summarization. this same observation may be transitive across other multi-array summarization algorithms such as gcrma, mbei, and plier or variants thereof. the appropriate reference objects would need to be trained and provided for each of these according to their basic input requirements.

reference database normalization schemes such as the full refrma model described can also be applied to samples in an ad hoc manner . analysts can use the normalization schemes on single sample set activities. a number of logistical advantages are inherent within such a workflow.

first, a pre-computed reference model can be used to alleviate memory-intensive calculations for studies of large sample sizes. this issue has been noted previously and has been addressed by re-sampling and partitioning methods  <cit> . models such as rma increase memory usage relative to the number of input samples for its training such that desktop computing may not be possible for sample sizes in the hundreds or thousands. pre-calculated models of appropriate training set scope would allow for a close approximation of the sample set-specific model, while circumventing memory constraints.

second, any one of a number of the models could eventually be used as a standardization mechanism across the industry if a large number of users find such models applicable and valid for their data sets. obviously, the degree of validation necessary for such an "industry-universal" model is extensive and is outside the scope of this publication. however, given the recent emphasis on microarray analysis standards, the development of a static normalization scheme on a widely varying training set for such algorithms as rma is a useful starting tool.

despite attempts to maximize the applicability of any reference model for the multi-array algorithms, there are potential technical and biological variables which may degrade their performance. microarray data generation protocols are comprised of many hands-on technical processes and reagents. the combination of all possible variants of each step and types of reagents prohibits claiming that any single model is robust for all variables. sources of technical variability include different labeling technologies, pmt settings, human operators, rna quality, reagent lots/manufacturer, and innate day-to-day variables. despite this multi-step process, technical variability has been reported to be among the smallest variability factors within organ systems in human and mouse, although these studies have not attempted to quantify individual technical factors and have not assessed cross-laboratory factors  <cit> . in our own experience, biological variability according to organ and pathological category is rather large, while technical variation is relatively small. the results of the geo-based assessment suggest that appropriate summarization across array processing centers is supported by the full refrma model.

in addition to normal technical variability associated with microarray data generation, there are more extreme deviations in sample preparation associated with small- or micro-sample amplification, laser-capture microdissection techniques, and multi-gene knockout experiments that may perturb the probe-level signal distributions beyond what is reasonable for a conventional training set. the ability of the full refrma model to properly summarize these types of purposeful deviations has not been investigated and cannot be claimed. this concern is also generally applicable to the other multiple array-dependent algorithms.

biological variables such as organ, pathology state, gender, age, race, and others are well represented within the training set of  <dig>  unique samples and the full refrma model should be relatively robust for these factors. we have demonstrated that samples from an organ naïve to a large-sample refrma training set are normalized almost identically to a large-sample refrma training set where the organ is well-represented.

finally, it should be noted that most applications of the rma workflow involve a relatively small number of experiments  obtained directly from .cel file data. we believe that the classic rma workflow should be utilized for these situations whenever possible due to the optimal applicability of a model to its component samples. the refrma workflow is valuable for situations where summarized expression data is archived within large, continually updated enterprise database systems or for alleviating memory constraints for experiments of large size, but in no way substitutes for the classic rma workflow when study designs permit the use of the latter.

CONCLUSIONS
in conclusion, a primary logistical issue associated with multiple array-dependent normalization and summarization algorithms is their reliance on a limited set of arrays to produce a model that is specific to that set. a reference model based on a training set comprised of a large, biologically diverse training set has been developed for the hg u133a genechip® arrays such that it can be applied to a wide range of sample organ types and pathology states.

