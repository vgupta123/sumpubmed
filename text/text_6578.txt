BACKGROUND
copepods are the largest and most diversified group of crustaceans  <cit> . they are ubiquitous and the most abundant aquatic metazoans. ecologically, copepods act as the most important link between phytoplankton and higher trophic levels in aquatic food webs. copepods are sensitive to environmental disturbance and they can be the bioindicator for the changes in water quality  <cit> . community shifts of copepods also provide sensitive indicator of climate change on marine biotopes  <cit> . thus, copepods are one of the most studied microorganisms in marine food webs and fisheries studies. the size of adult copepods ranged from  <dig> µm to  <dig> mm in size, while their numbers can range up to  <dig>  individuals per m <dig> of water  <cit> . positive identification of these organisms and completion of the work are thus hampered by their small size  and sheer numbers.

the identification of copepod species requires information of their morphology. body shape is useful to characterise the genera, but may not be useful to differentiate closely related species. at the species and finer level, the characters of specific appendages such as the fifth legs are required  <cit> . body shape and characteristics may however be useful to predict species in specific locations or habitats where the species are known or are low in diversity. nevertheless, image capturing and processing tools for rapid and objective digital recognition of copepods at the familial or ordinal level are useful to non-specialists and ecologists.

existing techniques in real time plankton-imaging-system are adequate for class/order-discriminations of plankton into major components  <cit> . one of the established studies known as zooscan digital imaging system described the zooplankton image processing and the semi-automatic recognition system using various machine learning methods  <cit> . in this semi-automatic recognition system, copepods were only covered in a few categories from the entire zooplankton community  <cit> . hitherto, identification systems for calanoid copepods have been described in a few studies by using diffraction patterns as a tool  <cit>  and the application of circular-harmonic filters  <cit> .

several classification methods such as neural network, structural, fuzzy and transform based techniques have been used in biological image identification systems but have not been employed for copepod classification. artificial neural networks   <cit>  have shown satisfying results in complex classifications of biological images such as insects  <cit> , microinvertebrates  <cit> , algae  <cit> , fish  <cit> , leaves  <cit> , butterflies  <cit> , protozoans and metazoans  <cit> , dinoflagellates  <cit>  and human helminth eggs  <cit> . an ann is a mathematical model composed of many processing units that communicate by interconnected variables  <cit> . multilayer structure of ann enables learning from complex input image features and generates single output  <cit> .

this study aims to automate identification techniques to ultimately classify marine copepods down to the lowest or species level using image processing techniques to extract shape descriptors as features and the ann algorithm as the classification tool. this approach is novel in copepods identification as previous studies only reported classification using diffraction pattern  <cit>  and circular harmonic filter  <cit> .

methods
the study's approach followed the methodology and system flowchart illustrated in figure  <dig> which are detailed as follows.

data collection
five genera of marine copepods commonly encountered in mangrove waters were examined: acartia , bestiolina , oithona , parvocalanus  and tortanus  . copepods were sampled from four stations from the upper estuary in the matang mangrove forest reserve  to near shore waters on the west coast of peninsular malaysia  . horizontal plankton tows  using paired  <dig> cm-diameter bongo nets  were made and collected plankton were preserved in buffered 10% formaldehyde. in the laboratory, collected copepods were then sieved through stacked endecott sieves of  <dig>  µm,  <dig> µm,  <dig> µm and  <dig> µm mesh sizes, and the sieved fractions were preserved in 80% alcohol in individual vials for a long-term preservation.

image acquisition
specimens of copepod were randomly pipetted onto a microscope slide from the preserved samples and each identified to species level under a compound microscope . to enable the dorsal aspect of the identified copepod to be imaged, often the copepod body had to be rotated. body rotation could be easily achieved by first placing two short nylon fishing lines  on either side of the specimen and gently moving a cover slip placed over them by using the tip of the index finger. the desired view of the copepod body was imaged by an olympus digital camera  connected to a computer installed with an imaging software   <cit>  for real-time viewing, capturing and storing of the images. the built-in function in cellsens called extended focus imaging  was used to create a single plane image with sharp, in-focus details and high contrast . the efi function recorded the image data as the sample was gradually focused through from top to bottom to obtain single dorsal image of the copepod with all body parts . besides, the contrast and brightness of the images were set to the best before they were captured using cellsens software. the resolution of the captured images was standardised  and all the images were saved in uncompressed tagged image file format  by renaming them according to the date when the images were captured.

image database
a simple image database was established to store and organise the captured images. upon verification by copepod experts, these images were indexed according to their taxa. thirty images for each species were stored as training set whereas twenty images of each species were stored as testing set.

image processing
image processing was done in three essential steps: image pre-processing, image segmentation and feature extraction. the image processing toolbox in matlab r2013a  <cit>  was installed on intel xeon  cpu e <dig> @  <dig> ghz,  <dig> gb ram, windows  <dig> professional  to conduct this study.

the captured images were pre-processed in the following steps :

1) the images were first converted to 2-dimensional grayscale images.

2) a median filtering with a 10-by- <dig> kernel was used to suppress the noise found in the images which mainly consisted of salt-and-pepper noise from the water.

3) a 2-d order-statistic filtering algorithm with 10-by- <dig> domain was applied to detect the edge of the copepods. in this basic gradient-based segmentation function, the edge was derived from the difference between the first ) and the last order-statistic filter ).

once the edges in the images were detected, the following steps were then taken for image segmentation where copepods were identified and segmented from unwanted particles in the images:

1) the images were converted to binary images with appropriate threshold.

2) the borders in the images were cleared using the imclearborder function and the holes that occurred during the process of converting the grayscale image into binary image were filled using the imfill function.

3) small particles  were excluded to ensure only the copepods are segmented for feature extraction.

4) the orientation represented by the angle between the x-axis and the major axis of the ellipse that has the same second-moments as the region of interest  was obtained using region properties function in matlab. image rotation was done using the imrotate function so that the roi has an orientation of  <dig> degrees.

5) the roi of the copepod was cropped by getting the coordinates of the boundary of copepods.

6) features were extracted from the shape descriptors represented by the binary images of the roi using region properties function in matlab. the measurements taken were area, convex area, eccentricity, major axis length, minor axis length, perimeter, solidity, equivdiameter ), extent and orientation.

7) as seen in the roi images of copepod, the lower part showed distinct shapes across the eight species. in view of this distinct attribute, a secondary feature was derived by assigning 60% of the roi image height measured from the posterior end  to the anterior end  of copepod body as the lower part of roi image. this ratio was selected after conducting several tests using a set of ratios . this derived feature was calculated as: 

percentage of area of the lower part of roi image

 =areaofqareaofp×100% 

where p is the total area of roi image and q is the area of the lower part of roi image.

feature selection
to avoid overfitting in the neural network training and to increase performance, not all the  <dig> extracted features were used. the extracted features were evaluated to make sure that only significant features were selected to classify the copepods into their respective taxa. forward stepwise discriminant analysis  was used to aid the selection of the most useful features . in order to visualise how well a selected feature clustered the specimens in the training set into the eight classes , 2d and 3d scatter plots were graphed  with different combinations of features as the axes.

neural network training
an artificial neural network  was used as the pattern recognition tool to classify the extracted features values into the eight classes . the architecture of the ann is a two-layer feed-forward network with sigmoid hidden  and output  neurons and the network was trained with scaled conjugate gradient backpropagation . a total of  <dig> sample images were used in the training set with  <dig> images from each class. the input data presented to the input nodes of the network contained seven selected features of each specimen from the training set, whereas the target data defined eight desired output classes. the  <dig> samples were then divided into three sets, the training set , validation set  and testing set . the data from the training set were used for network training; the validation set for measuring network generalisation and terminating training before overfitting; and the testing set for independent measure of network performance during and after training. the performance of the network training was evaluated using mean square error  and confusion matrices. the training stopped when the mse of the samples in the validation set started to increase indicating that the network generalisation stopped improving. the network was trained several times to get the trained network with best performance. another  <dig> independent samples  were used for system performance evaluation. the trained network was simulated using the testing data as input and the output was then compared to the predicted data and recorded in a confusion matrix.

RESULTS
feature selection
a total of  <dig> copepod features were initially extracted from the samples but only seven of them were finally chosen to avoid overfitting in the neural network training. the seven selected features were area, convex area, major axis length, minor axis length, perimeter, equivalent diameter and percentage of lower roi image. although fsda by default settings selected  <dig> features  as significant in the classification model, the final seven features were selected based on the f-value associated with their partial wilks' lambda . these features when visualized on the 2d and 3d plots gave clusters of species with little overlaps . interestingly, the secondary feature  is seen to separate genus oithona from genus parvocalanus .

neural network training
a two-layer feed-forward network was trained with back propagation algorithm based on ten neurons at the hidden layer and eight neurons at the output layer. the best trained network was obtained with  <dig> iterations. the best validation performance in the trained network had a mse of  <dig>  at epoch  <dig> . result from the confusion matrix showed overall  <dig> % of correct classification of all  <dig> samples in the training, validation and testing sets .

system evaluation
a graphical user interface  was created for the automated identification system as shown in figure  <dig>  the gui allows users to perform loading of input images, feature extraction, selection of network and species identification. the performance of the system was evaluated by comparing the output from the trained network to the identification result of the copepodologists using the testing dataset as the input. the testing dataset that was used to simulate the trained network was a new independent dataset not used for the network training. the results show that the technique presented in this study was capable of identifying most of the copepods correctly with an overall accuracy of  <dig> % . all a. spinicauda, b. similis and o. aruensis specimens were identified correctly; one specimen from t. barbatus and three specimens of t. forcipatus were misidentified as each other; two specimens from o. dissimilis was misidentified as o. simplex; two specimens from p. crassirostris were misidentified as o. aruensis and o. simplex; three specimens of o. simplex were misidentified as o. dissimilis and p. crassirostris. another confusion matrix  was prepared to show the classification result to genus level. an overall accuracy of  <dig> % was achieved where only one specimen from oithona and two specimens from parvocalanus were misidentified as each other.

as
bs
oa
od
os
pc
tb
tf
the data were classified into  <dig> species: acartia spinicauda , bestiolina similis , oithona aruensis , oithona dissimilis , oithona simplex , parvocalanus crassirostris , tortanus barbatus  and tortanus forcipatus .

aca
bes
oit
par
tor
the data were classified into five genera: acartia , bestiolina , oithona , parvocalanus  and tortanus .

discussion
the purpose of the study is to present an automated identification and classification technique for copepods based on the captured images to lighten and assist the work of non-specialists or ecologists. extended focus imaging  technique was used to capture copepod images under the microscope using cellsens software to produce high quality images of copepods; in order to provide more information and features that could be extracted. the antennae of specimens t. barbatus and t. forcipatus were removed as rotation to the desired dorsal aspect could twist its bulky antennae to awkward positions resulting in some feature values to deviate; this may lead to misclassification. although a desired dorsal-up orientation was required for image acquisition, this was not always perfect since the copepod body might tilt slightly. hence, image rotation was performed to make sure the sagittal plane of the copepod was perpendicular to the horizontal axis of the image. all captured images were stored in a simple image database to ease the retrieval of particular images for network training and system evaluation. from the results, an overall accuracy of  <dig> % was achieved for the testing set where the identification of a. spinicauda, b. similis and o. aruensis was 100% correct, while the identification of other species achieved 85% to 95% accuracy. a. spinicauda, b. similis and o. aruensis are distinct in terms of body size, shape and other features and are thus easily identified. o. dissimilis tend to be misidentified as o. simplex as they are from the same genus; same goes to t. barbatus and t. forcipatus from genus tortanus. o. simplex and p. crassirostris tend to be misclassified as the other because they have similar sizes and other features despite the use of an additional feature  to differentiate them. in terms of classification at genus level, an accuracy of  <dig> % was achieved showing an increase in accuracy compared to identification at species level. the seven features selected for neural network training produced an overall accuracy of  <dig> %. number of features for neural network training does not guarantee increase in overall performance. what matters most is the types of features selected. it is crucial to select only features that are able to cluster the specimens into distinct groups before the network training.

the present copepod identification technique used shape descriptors as distinguishing features and an ann as the pattern recognition tool to identify and classify copepods. this technique differs from those used by previous workers, such as zavala-hamz et al. , castro-longoria et al.  and alvarez-borrego & castro-longoria  who used correlation analysis of the diffraction pattern of digitised copepod images. in this study, the time taken for digitising the copepod images can be improved with the help of new technologies in plankton-imaging. thus, development in hardware technology will determine the future prospects and application of automated identification systems in ecological studies. in the future, we plan to use more genera including more species. besides, other aspects like gender and life cycle stages of copepods could be taken into consideration.

CONCLUSIONS
the present technique of automated identification of copepods to species level based on dorsal images of copepods under the microscope achieved an overall accuracy of  <dig> %. the approach used image processing technique to extract features from microscope images and an ann as the classifier. aquatic ecologists will find the automated identification method useful since samples processing time will be reduced and effort can be spent on other ecological related works. future work should focus on the enhancement of image acquisition and feature extraction techniques to accommodate large datasets covering more taxa. ultimately, the aim is to develop a fully automated identification system capable of identifying copepod specimens down to the lowest taxonomic level.

competing interests
the authors declare that they have no competing interests.

authors' contributions
skd headed the study, structured the whole research and contributed to the writing of the manuscript. llk collected specimens, designed and implemented the methods as his msc. study and played a major role in manuscript writing. cll assisted in sample collection and provided expert identification of copepods. cvc provided laboratory facilities and contributed to the writing of the manuscript. all authors contributed in this study. all authors read and approved the final manuscript.

supplementary material
additional file 1
sample images of copepods from eight species used in the study. the eight species included a. spinicauda, b. similis, o. aruensis, o. dissimilis, o. simplex, p. crassirostris, t. barbatus and t. forcipatus.

click here for file

 acknowledgements
this project was funded by the university of malaya's postgraduate research fund  and the university of malaya research grant .

declarations
publication charges for this article was funded by university of malaya page charge fund and university of malaya's postgraduate research fund .

this article has been published as part of bmc bioinformatics volume  <dig> supplement  <dig>  2015: joint 26th genome informatics workshop and 14th international conference on bioinformatics: bioinformatics. the full contents of the supplement are available online at http://www.biomedcentral.com/bmcbioinformatics/supplements/16/s <dig> 
