BACKGROUND
cancer arises as a result of genetic and epigenetic alterations in the genome. while most dna mutations are considered neutral passenger mutations, driver mutations can increase the fitness of a cancer cell allowing its clonal expansion. identifying driver mutations is crucial to elucidating tumorigenesis and revealing novel therapeutic targets. recent developments in next-generation sequencing technologies enable extensive identification of dna mutations in cancer as well as normal genomes. large-scale efforts such as the cancer genome atlas  <cit>  have uncovered tens of thousands of sequence variants. while the avalanche of sequence data has revealed the spectrum of genetic variations in cancer, the results are difficult to interpret, as the vast majority of mutations do not drive tumorigenesis. non-synonymous changes  are the most investigated group of genetic perturbations. these mutations vary greatly in their functional impact, depending on their position and function in the protein and nature of the replacement amino acid. several computational methods have been developed to predict the effect of any missense mutation on protein function, using evolutionary sequence comparison, structural constraints, and physicochemical attributes of amino acids. more recently, machine learning methods aim to specifically predict cancer-driving deleterious mutations, based on a wider set of attributes and training with sets of likely cancer mutations. these mutations form a subset of deleterious mutations in that they are positively selected during tumor evolution, but are negatively selected during organismal evolution. metapredictors that combine several methods have also been developed  <cit> .

in this study, we introduce and compare the results of several general and cancer-focused methods, using both known and novel testing sets. we discuss their individual strengths and highlight associated challenges as well as future prospects. we also examine the availability, coverage and inter-dependence of various tools.

materials and methods
datasets
we created a positive  test set of likely cancer driver mutations from the cosmic database   <cit> . from a total of  <dig>  missense mutations, we picked  <dig>  mutations  found in at least two tumor samples as likely driver mutations . since cosmic has been used to develop some of the methods reviewed, we also created a novel test set, from recurrent somatic mutations in colorectal carcinoma identified in a very recent study of the cancer genome atlas network  <cit> .  <dig> somatic missense mutations were found in at least two tumor samples but not seen in cosmic or dbsnp  <cit> . a second novel set of  <dig> recurrent unique mutations found in breast  <cit>  or colon cancer  <cit>  was similarly created.

our negative  set of likely non-deleterious variants was built from germline snps found in dbsnp . to avoid rare deleterious mutations and errors, we selected only snps with a minor allele frequency of at least  <dig> , resulting in a set of  <dig>  variants.

running predictors
we obtained sift  <dig> . <dig> from http://sift.jcvi.org and followed the default instructions to install and run. a java based pipeline was implemented to manage input and output data. we obtained polyphen- <dig> from http://genetics.bwh.harvard.edu/pph <dig> and followed the standard instructions for installation. condel scores for the combination of sift and polyphen- <dig> were calculated with a perl program provided by ensembl. we retrieved functional impact scores from mutationassessor, using http://mutationassessor.org. logre scores were derived with a java class to align wild-type and mutant protein sequences against pfam protein domain models   <cit>  using hmmer  <dig>   <cit> . the differences  of resulting e-values were used to calculate logre scores. snap was installed and applied in coordination with its developers from the technische universitaet muenchen. mcluster scores were calculated as described  <cit> . chasm scores were derived with cravat .

roc curves and specificity/sensitivity estimation
receiver operating characteristic  curves are composed of points that reflect the trade-off between true positive rate  and false positive rate  at varying threshold values. for each predictive method, the score range was divided into  <dig> bins, for which the proportions of variants from the positive and the negative set above and below the given threshold were calculated. variants that were not covered  by a method were excluded from the evaluation of that particular method. to assure the same number of mutations in the positive and negative sets, for each tool assessment the size of the neutral set was adjusted to the resulting depth of the covered non-neutral set with a preference for variants with high minor allele frequencies.

to calculate specificity and sensitivity values for each tool, we used score cutoffs that yielded the highest accuracy as measured by the proportion of correctly classified variations to the total number of variants in the test set.

metaprediction
following the methodology of the condel score  <cit> , we used the weighted average of normalized scores to combine multiple predictions into a unified classification. basically, normalized scores of each included tool and associated weights are used to calculate unified consensus scores. while the normalization of scores is straightforward, the calculation of weights requires reference cumulative distributions of true positives and true negatives. for mutations that are classified as deleterious by an individual tool, the weight of the normalized score reflects the probability that mutations with higher scores are not false positives based on the reference set. this probability is used as weight and increases with the score. on the other hand, for mutations that are predicted as benign, the weight reflects the probability that the mutation is not a false negative. therefore low probabilities imply low contributions to the consensus score. the calculation of weights is illustrated in additional file  <dig>  we used the cosmic set and the dbsnp set as reference sets to create the underlying cumulative distributions for weight estimation. raw scores of individual methods were normalized to values between  <dig>  to  <dig> . the weighted average score  is defined as:

 was=∑isi*wi∑iwi, 

 wherewi=1-ptiifvariantisclassifiedasdeleteriousintheithtoolwi=1-pdiifvariantisclassifiedastoleratedintheithtool 

si is the normalized score as calculated by the i-th tool, while wi is the weight for the given classification. weights were calculated on the basis of the proportions  of tolerated  or deleterious  variants with a normalized score higher than si as observed for cosmic mutations as positive set and dbsnp mutations as negative set.

RESULTS
overview of general tools for predicting the functional impact of amino acid changes
most algorithms for predicting the functional impact of non-synonymous mutations are based on the observation that evolutionary and structural constraints are non-randomly distributed on proteins. this is consistent with the stronger conservation of functionally important residues and the higher probability of damaging mutations to occur in the protein interior  <cit> . here we review some representative approaches  to provide some background for our assessment:

sift   <cit>  is a widely used pioneering method for identifying deleterious mutations using only evolutionary information. installation and usage are straightforward, and the method depends only on psi-blast  <cit> . sift identifies conserved protein residues based on multiple sequence alignment of homologous proteins, and calculates the probability for each of the  <dig> amino acid changes to be tolerated relative to the most frequent residue. mutations of highly conserved protein positions tend to be predicted as deleterious, whereas changes in lower conserved protein regions are more likely to be neutral. bi-directional sift   <cit>  is a modification of sift that attempts to classify both gain- and loss-of-function mutations. by calculating sift scores for both the mutant and wild-type alleles, it identifies potential gain-of-function mutations where the mutant residue is more similar to those found in homologous proteins. as b-sift is exclusively based on sift, its implementation is also straightforward.

mutationassessor  <cit>  has a more elaborate conservation-based approach. it distinguishes between conservation patterns within aligned families  and sub-families  of homologs and so attempts to account for functional shifts between subfamilies of proteins. specificity residues are defined by the clustering-based identification of homologous sequence subfamilies to determine functional specificity on the background of overall conservation. interestingly, specificity residues were found to be predominantly located in binding interfaces on the protein surface implicating them in protein interaction  <cit> .

in addition to conservation the feature space can be further increased by the inclusion of physiochemical characteristics. mapp   <cit>  and align-gvgd  <cit> , for example, combine both evolutionary conservation and physiochemical information. while most sequence-based tools are capable of predicting the functional consequence of any mutation in a protein with homologs in other species, some are restricted to the classification of a subset of amino acid alterations. for example, logre   <cit>  predicts only on pfam domains, by comparing the pfam score of the wild type and mutant alleles.

structure-based methods model the structure of a protein using a protein structure database, and then examine structural features such as solvent accessibility or crystallographic b-factor surrounding the substituted amino acid. predictors based exclusively on structural information have been clearly outcompeted. their coverage is relatively low due to the lack of available protein structures, and the isolated context of a crystal structure might not reflect the functional importance of certain residues in an interactive environment. for example, a multitude of solvent accessible residues such as posttranslational modification sites are fundamental for protein function, which is reflected in their conservation  <cit> , but not in their structural context. combining sequence and structure information can increase prediction accuracy to a certain degree  <cit> . polyphen- <dig>  <cit>  is the most prominent tool based on both sequence and structural information. it uses eight sequence-based and three structure-based features as input to a naive bayes classification. due to the diverse feature space, polyphen- <dig> is dependent on a variety of tools. for single amino acid substitutions it is therefore more straightforward to use the associated website .

to our knowledge the neural network-based tool snap   <cit>  spans the most comprehensive feature space. snap incorporates evolutionary constraints, structural features and protein annotation information. the most important single feature for snap prediction is conservation in a family of related proteins as reflected by psic scores  <cit> . as a result of the extensive feature space, snap depends on several other tools, which makes its installation complex. for a limited set of mutations it is possible to use snap's website.

these methods can give widely differing scores on the same variant, and have individual strengths and weaknesses. a combination of predictors may improve predictability. condel   <cit>  is a weighted average of the normalized scores from multiple methods. implementing condel is not complicated, but it involves the installation of various predictive methods and their supporting tools. condel scores can be derived for a limited set of specified mutations via the corresponding web application, and the ensembl database  <cit>  provides position-specific condel predictions that combine sift and polyphen- <dig> for every possible amino acid substitution in all human proteins.

overview of cancer-specific predictors
cancer driver mutations are a subset of deleterious mutations that decrease the organism's evolutionary fitness, while increasing cellular proliferation, survival or metastasis. cancer-specific mutation predictors mainly use frequency-based or machine learning techniques trained on recurrent cancer mutations that are likely to be drivers. a variety of statistical methods has been developed to determine increased mutation frequency. mcluster  <cit>  aggregates mutation data by mapping known disease related mutations to positions along conserved domains, and then mapping novel variants to those same conserved domains. conserved mutation-enriched domain regions reflect hotspots for cancer driving functional changes. the mcluster score expresses the probability of observing a cluster of certain size given the number of positions in the domain and the mutation frequency. as a consequence of the underlying methodology, only mutations that occur in protein domains can be scored.

chasm   <cit>  is a major machine learning approach that uses a random forest approach and is trained on cancer mutations from cosmic and other cancer-related resources. chasm uses an extensive set of  <dig> predictive features ranging from exon conservation to uniprot annotation  <cit>  and frequency of missense change type in cosmic. notably the latter feature was ranked as second most predictive feature. chasm is available via the web application cravat .

analogously to condel, canpredict  <cit>  uses a random forest classifier to combine results from different methods. it uses sift and logre to determine the functional impact of changes, and gene ontology similarity score   <cit>  to estimate the resemblance between the given mutated gene and known cancer-causing genes.

missense mutations from cosmic and dbsnp used for testing
to compare these methods, we created a positive test set of likely cancer driver mutations and a negative test set of likely benign variations . few driver mutations have been well validated, so we used data from the cosmic database of tumor-specific mutations. most of these are random passenger mutations, but a substantial minority of positions are recurrently mutated:  <dig>  of  <dig>  positions are mutated  <dig> or more times  and are likely to be enriched for driver mutations. common germline polymorphisms are likely to be largely neutral, so our negative test set consists of  <dig>  variants in dbsnp with a reported minor allele frequency of at least  <dig> .

the criteria for selecting these datasets are supported by an initial scoring of all variants using sift.  <dig> % of singleton cosmic mutations score as deleterious , while  <dig> % of mutations found in more than  <dig> samples score as deleterious . in contrast, dbsnp variants with higher minor allele frequencies are predicted to be substantially more benign . the same pattern was observed with polyphen- <dig> .

notably, these datasets do not represent a true gold standard in which all variants are either functionally deleterious or neutral, and there is in any case no uniform definition of functionality. however, they provide a sufficient enrichment in both classes of variants to be effective for comparison of methods. in general it is not straightforward to generate an optimal set for benchmark analysis. in contrast to the assessment of protein structure predictors, where the experimental structure gives a clear answer, the biology of underlying sets of missense mutations is far more complicated. we performed a relatively intuitive approach by taking recurrent somatic mutations as positive set. the overrepresentation of mutations of some canonical cancer genes in the cosmic set supports our selection. for example, tp <dig>  pten and egfr each have more than  <dig> mutations reported in cosmic.

coverage
we ran all predictors on both test sets . chasm, mutationassessor, polyphen- <dig>  sift, condel and snap were able to score most variants , each classifying at least 94% of cosmic mutations. however, the reliability of predictions varies depending on the features scored. for example, with sift, low sequence diversity in the aligned homologs decreases classification confidence. rare cases, where mutations could not be classified at all, can be explained by the absence of homologous proteins for evolutionary comparison. in contrast, logre and mcluster scored only 75% and 63% of cancer mutations respectively, since they can only predict within domain regions. they scored even fewer neutral variants , due to the relative scarcity of neutral mutations in domains. this limitation to classify only a specific group of variants can also be observed in other applications that are not further reviewed here. for example, approaches that are exclusively based on protein structures provide fewer predictions than conservation-based methods given the shortage of available protein structures opposed to the plethora of available sequence information.

prediction accuracy based on curated datasets
we compared prediction methods using a roc analysis: using a range of score cutoffs to predict a mutation as deleterious, we plotted the fraction of likely drivers scored as deleterious  against the fraction of likely benign variants scored as deleterious  for a given score threshold . each method was scored with an equal number of neutral and cancer-associated variants.

logre and mcluster were clearly outperformed by other methods. for logre, this agrees with a previous comparison  <cit> . mcluster, assumes that functionally important protein changes are enriched in conserved domain regions. the mcluster score of a given mutation increases with the frequency of all mutations from both the given dataset and curated disease-associated databases that occur in the same hotspot region. however, in our analysis the statistical power from the input set is depleted, as all mutations are counted as single events in our test set. table  <dig> lists the sensitivity and specificity values calculated on the basis of score thresholds that yielded the highest accuracies as defined by the proportion of correctly classified variants in relation to the number of all variants in the test set . in most cases the derived optimal cutoffs were similar to the thresholds recommended by the developers of the tools . in concordance with the resulting roc curves, the accuracies of logre and mcluster were 61% and 65%, respectively.

in comparison, we found sift and polyphen- <dig> to have maximum accuracies of 76% and 77%, respectively. saunders and baker  <cit>  showed that in general the additional inclusion of structural information  contributes to a slight increase in performance. this might also play a role for the marginally increased performance of polyphen- <dig>  the combination of polyphen- <dig> and sift as reflected by the condel score did not improve the accuracy significantly .

with an accuracy of 81% mutationassessor yielded the second highest specificity across all methods at any sensitivity. as reviewed above, the use of evolutionary information in mutationassessor differs from other sequence-based predictors. the methodology includes a refined class of conserved residues, termed specificity residues, to identify functional specificity on the background of overall conservation. specificity residues are conserved within a subfamily but differ between subfamilies presumably encoding functional diversity. for example, a d125n mutation in cdkn2a  from liver cancer is scored as deleterious by mutationassessor, because this residue is absolutely conserved as d in mammalian homologs , but is scored as neutral by other methods that include more distant homologs, such as those of fishes, where the wild-type residue is n. the co-crystal of cdkn2a with cyclin-dependent kinase- <dig>  shows that d <dig> is at the binding interface of the two proteins, close to serine  <dig>  of cdk <dig>  loss of this negative charge in the d125n mutant may substantially alter the binding affinity and so promote tumorigenesis.

interestingly the accuracy of snap  was lower than those of sift and polyphen- <dig>  despite its more elaborate feature set. chasm  was the only tool that outperformed mutationassessor in this assessment. chasm predicted 99% of the negative set as non-drivers. however, recurrent cosmic mutations were used to train the chasm predictor, and several properties in chasm's complex feature space are derived from cosmic. for this reason, the chasm performance in this test should be viewed with caution.

excluding chasm, the results of this assessment suggest that conservation based predictors, mutationassessor in particular, achieve the highest accuracies in distinguishing neutral from deleterious mutations. however, none of these methods gives correct classifications of all mutations in the test sets. as an example for likely misclassification, mutationassessor predicted the somatic g1007d mutation in phosphatidylinositol- <dig> -biphosphate 3-kinase , which was identified in haematopoietic, lymphoid and thyroid cancer, to be neutral, while all other methods defined the amino acid change to be deleterious. on the other hand, bromberg and rost showed that snap, which achieved relatively low sensitivity but high specificity in our assessment, outperformed competing approaches when using an independent dataset from four proteins   <cit> . difference in performance might reflect testing dataset bias, or that cancer mutations are inherently different from those enzyme mutations commonly used in various training and testing programs.

prediction accuracy based on novel recurrent somatic mutations
since chasm was explicitly trained on cosmic mutations, and other methods may have been refined with it, we created new, independent positive test sets, of newly-identified recurrent mutations in colorectal tumors   as well as recurrent somatic mutations in colon  <cit>  or breast cancer  <cit>   . we measured accuracy of each method on these new data and found similar results, with some notable differences :

overall, we see a slight drop in prediction accuracy. this may be due to a drop in the severity of mutations in these new sets, since they exclude highly recurrent mutations seen in cosmic. the most notable change is that chasm accuracy dropped from 89% to 50%, as all mutations from the positive set were predicted to be neutral. the reason for this drop is not clear, but it has to be noted that mutations matching to cosmic variants were ignored in this evaluation and these excluded mutations were the ones with the highest frequencies in the test sets. it should also be noted that the chasm algorithm was developed to predict both tumor suppressor mutations as well as oncogene mutations. in our particular test, our choice of using recurrent mutation biased the data toward oncogenic driver mutations, which might contribute to the poor performance by chasm. furthermore, it is important to note that the relative frequency of missense changes in the cosmic database is one of the  <dig> features used for chasm prediction. remarkably, this feature was shown to be the second most important feature for chasm prediction. we purposely exclude any known cosmic mutations in our independent test data, presumably causing the sharp performance drop by chasm. it would be interesting to determine whether the chasm performance might be more consistent across multiple test data sets if the cosmic mutation frequency is excluded from the  <dig> feature collections.

the prediction accuracies of the other methods dropped to a lower degree, but their relative rankings were consistent with findings from the cosmic set. the accuracy of polyphen- <dig> decreased from 77% for the cosmic set to 66% and 65% for the tcga set and the cobr set respectively, but achieved higher accuracies than sift or snap. for the tcga set, condel - as a combination of polyphen- <dig> and sift - marginally increased the accuracy from 66% and 65% respectively to 68%, and we found the same tendency for the cobr set . notably, mutationassessor performed best, with accuracies of 74% and 70% for the tcga and cobr set, respectively.

the observation that performances of individual methods can vary extremely between different test sets, is in concordance with findings from the critical assessment of genome interpretation  project  - an analogous approach to the critical assessment of techniques for protein structure prediction   <cit> .

combining individual predictors
to determine if multiple methods can be combined into a unified classification, we implemented metapredictors on the basis of weighted average scores  <cit>  . we used cumulative distributions of true and false positives from the cosmic set as reference to estimate weights . to validate the consensus classification on a dataset different from the reference set, we used the two sets of novel mutations. for both test sets, the performances of condel  and our metapredictor that combined polyphen- <dig> and sift predictions were almost identical , even though underlying distributions for weight estimation and cutoff optimization were different.

we examined several combinations of predictors and found that unifying predictions from polyphen- <dig> and mutationassessor, sift and mutationassessor, or polyphen- <dig> and sift achieved better predictions compared to other combinations. however, none of the combinations improved significantly on the best included predictor, and no combination improved on mutationassessor alone. this is in contrast to a previous report in which combining prediction results from logre, mapp, mutation asssessor, polyphen- <dig> and sift was shown to outperform each individual method  <cit> . the reason of this difference is not clear, but it is possible that only certain datasets are suitable for metaprediction approaches.

CONCLUSIONS
our independent assessment of commonly available tools reveals challenges and inconsistencies of existing tools. although the cancer-specific predictor chasm performed particularly well using cosmic mutations, we observed a dramatic drop in performance when using novel recurrent mutations not present in the cosmic database. other cancer-specific methods did not perform better than general tools for predicting the functional impact of amino acid changes. it is debatable what causes such performance difference. one major challenge is the generation of underlying datasets for training and testing. using recurrent somatic changes as positive set seems to be an intuitive and reasonable approach. however, there is no experimental evidence for the potential to be driver mutations in cancer. it is clear that machine learning-based approaches are essentially affected by this problem and need further improvement to become generally applicable. in contrast, sequence conservation-based approaches seem to be less affected by different testing datasets. in fact, mutationassessor provides consistently reasonable prediction results in this study. however, it is premature to declare any single predictor as the sole winner since we have identified many instances where an otherwise good predictor would completely miss obvious driver mutations. it is not obvious that metapredictors based on multiple approaches would produce the "silver bullet" cancer driver mutation predictor, therefore novel and more robust methodology development is still needed.

one idea for potential improvement is to train specialized predictors on different classes of putative driver mutations. functional driver mutations can impact both tumor suppressors and oncogenes, and the characteristics of these mutations are epected to be different. while tumor suppressors are likely impacted by inactiving mutations, oncogenes can be impacted by a more complex pattern. mutations that activate oncogenes may exert their effect by different mechanisms, such as utilizing residues that are evolutionarily more fit, inactiving a regulatory region to make a kinase constitutively active, or simulating the activated state of a protein. it is perhaps more practical to develop multiple specific algorithms for different classes of mutations, instead of develop a "one-size-fit-all" approach. with more validated, novel driver mutation data available, such robust and specialized prediction tools should be within reach.

competing interests
the authors declare that they have no competing interests.

authors' contributions
fg carried out the data analysis, programming and drafting the manuscript. ab helped to install and run predictors. gm helped to draft the manuscript. km carried out the structural analysis of specific mutations. zz initiated and supervised the project, and helped to draft the manuscript.

supplementary material
additional file 1
datasets used for assessments.

click here for file

 additional file 2
calculating the weights for metaprediction. following the methodology of the condel score  <cit> , we used the weighted average of the normalized scores to combine the results of multiple predictors into a unified consensus score. the weighted average score is calculated on the basis of normalized prediction scores and weights. weights are estimated from cumulative distributions of true positives and true negatives above given scores.

click here for file

 additional file 3
distribution and proportion of missense mutations predicted to be deleterious by polyphen- <dig>  the frequency of somatic mutations in the cosmic database correlates with the likelihood to be damaging according to polyphen- <dig> predictions . the global minor allele frequency of single nucleotide polymorphisms in the dbsnp database correlates with the likelihood to be benign according to polyphen- <dig> classifications .

click here for file

 additional file 4
calculating the optimal cutoff yielding the highest accuracy for each method. accuracy is defined as the proportion of true positives and true negatives in relation to all positives and negatives. the accuracy increases with the true positive rate  until the proportion of false positives outweighs. the peak of each curve reflects the optimal accuracy. the corresponding score thresholds were used to calculate specificity and sensitivity values for each method.

click here for file

 additional file 5
comparison of condel and our metapredictor. based on an roc analysis using the tcga set  and the cobr set  as test sets, the performances of our metapredictor and condel are almost identical. both approaches combine polyphen- <dig> and sift predictions, but use different underlying reference sets for weight estimation.

click here for file

 acknowledgements
we thank rachel karchin , guy yachdav , yana bromberg , boris reva , abel gonzalez-perez  and nuria lopez-bigas  for helpful discussions. special thanks go to slaton lipscomb  for our compute cluster and peng yue  for support of mcluster.

declarations
the costs for this article were covered by genentech inc.

this article has been published as part of bmc genomics volume  <dig> supplement  <dig>  2013: snp-sig 2012: identification and annotation of snps in the context of structure, function, and disease. the full contents of the supplement are available online at http://www.biomedcentral.com/bmcgenomics/supplements/14/s3
