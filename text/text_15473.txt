BACKGROUND
the smith-waterman  algorithm  <cit>  is a dynamic-programming-based approach to identify optimal local alignments of biological sequence pairs. due to its maximal sensitivity for local alignments, this algorithm is a fundamental operation in bioinformatics, including biological sequence database search, multiple sequence alignment  <cit>  and next-generation sequencing read alignment  <cit> . in biological sequence database search, the similarities between sequences can be inferred from optimal local alignment scores calculated by the sw algorithm. to calculate optimal local alignment scores, the sw algorithm has a linear space complexity and a quadratic time complexity. however, this quadratic time complexity makes the sw algorithm computationally demanding for large-scale sequence database search. this is further compounded by the rapid growth of sequence databases.

therefore, several heuristics such as fasta  <cit>  and blast  <cit>  have been proposed to accelerate the sequence database search, but not guaranteeing to discover optimal local alignments. these heuristics usually produce considerably good results, but might fail to detect some distantly related sequences due to the loss of sensitivity. hence, it has great significance to accelerate the sw algorithm so as to maintain optimal results. consequently, a lot of efforts have been made to parallelize this computation on high-performance computing architectures ranging from loosely-coupled to tightly-coupled ones. architecture examples include clouds  <cit> , clusters  <cit>  and accelerators  <cit> . recent acceleration approaches focus on the use of field programmable gate arrays , single instruction multiple data  vector execution units on cpus, multi-core cell broadband engine , and many-core general-purpose gpus, especially based on the compute unified device architecture -enabled gpus.

for fpgas, some approaches based on linear systolic arrays and custom instructions have been proposed. oliver et al.  <cit>  constructed a linear systolic array on a standard virtex ii fpga board to perform the sw algorithm with affine gap penalties. li et al.  <cit>  designed custom instructions to support massively parallel computing of the sw algorithm on an altera stratix ep1s <dig> fpga.

for simd vector execution units on cpus, most efforts have been concentrated on intra-task parallelization that accelerates the alignment of a single sequence pair. intra-task parallelization approaches can be generally classified into two computational patterns:  simd vectors parallel to minor diagonals in the alignment matrix  <cit> , and  simd vectors parallel to the query sequence by means of either a sequential  <cit>  or a striped layout  <cit> . the former pattern is runtime independent of scoring schemes, but has complicated data management and limited speedups. the latter pattern proves to be faster, but is runtime sensitive to scoring schemes. besides intra-task parallelization, some approaches based on inter-task parallelization have also been investigated  <cit> .

unlike intra-task parallelization, the inter-task parallelization computes multiple alignments in parallel in a simd vector. the major advantages of this parallelization are the independence between alignments in simd vectors and the runtime independence of scoring schemes. these two parallelization approaches provide a general framework for other architectures with simd vector execution units, such as cell/bes and general-purpose gpus. cell/be is a heterogeneous multi-core architecture comprised of one general-purpose power processor element and eight synergistic processing elements that serve as simd accelerators. on cell/bes, several approaches have been implemented  <cit> – <cit> , all of which are designed based on the striped approach  <cit> . for general-purpose gpus, liu et al.  <cit>  developed an initial opengl-based implementation. with the emergence of cuda programming model, several implementations targeting different generations of cuda-enabled gpu architectures  <cit> – <cit>  have been developed using cuda, among which cudasw++  <dig>   <cit>  is one of the fastest.

in this paper, we present cudasw++  <dig> , which yields faster sw protein database search by coupling cpu and gpu simd instructions and conducting concurrent cpu and gpu computations. similar approaches of coupling cpu and gpu computation have been investigated in  <cit>  and  <cit>  for phylogeny-aware alignment kernel and short-read alignment, respectively. to balance the runtimes of cpu and gpu computations, we have dynamically distributed all sequence alignment workloads over cpus and gpus, as per their compute power. for the computation on cpus, we have employed the streaming simd extensions -based vector execution units and multi-threading to speed up the sw algorithm. for the computation on gpus, for the first time, we have investigated a gpu simd parallelization approach using ptx simd video instructions. using the ptx simd instructions, we can obtain more data parallelism on gpus beyond the single instruction multiple thread  execution model implemented such as in cudasw++  <dig> .

we have evaluated the performance of cudasw++  <dig>  and three other top-performing algorithms: cudasw++  <dig> , swipe  <cit>  and blast+  <cit>  using both the swiss-prot protein database and a simulated database comprised of equal-length sequences. two kepler-based graphics cards, namely geforce gtx  <dig>  and geforce gtx  <dig> , have been used for all evaluations of our algorithm. on a gtx <dig> , cudasw++  <dig>  achieves a maximal performance improvement of  <dig>   times over cudasw++  <dig>  using the swiss-prot database and of  <dig>   times using the simulated database. furthermore, our algorithm gains an average performance of  <dig>   billion cell updates per second , with a maximum of  <dig>   gcups, on the swiss-prot database and an average performance of  <dig>   gcups, with a maximum of  <dig>   gcups, on the simulated database. in addition, cudasw++  <dig>  demonstrated significant speedups on average over swipe and blast+.

the smith-waterman algorithm
given a sequence s, define s to denote the ith residue of s, and si to denote the prefix of s ending at position i. given two sequences s and t, the recurrence of the sw algorithm with affine gap penalties is defined as

  hi,j=max{hi− <dig> j−1+m,ei,j,fi,j,0}ei,j=maxei− <dig> j−β,hi− <dig> j−αfi,j=maxfi,j−1−β,hi,j−1−α 

where hi,j, ei,j and fi,j represent the local alignment score of two prefixes si and tj with s aligned to t, s aligned to a gap and t aligned to a gap, respectively. m is the scoring matrix which defines the substitution scores between residues, α is the sum of the gap open and extension penalties, and β is the gap extension penalty. the recurrence is initialized as hi, <dig> = h <dig> j = e <dig> j = fi, <dig> =  <dig> for 0≤i≤|s| and 0≤j≤|t|. the optimal local alignment score is the maximal alignment score in the alignment matrix h and can be calculated in linear space.

gpu architecture
cuda-enabled gpus have evolved into highly parallel many-core processors with tremendous compute power and very high memory bandwidth. they are especially well-suited to address computational problems with high data parallelism and arithmetic density. a cuda-enabled gpu can be conceptualized as a fully configurable array of scalar processors . these sps are further organized into a set of streaming multiprocessors  under three architecture generations: tesla  <cit> , fermi  <cit>  and kepler  <cit> . since our algorithm targets the newest kepler architecture, it is fundamental to understand the features of the underlying hardware and the associated parallel programming model.

for the kepler architecture, each sm comprises  <dig> cuda sp cores sharing a configurable  <dig> kb on-chip memory. the on-chip memory can be configured at runtime as  <dig> kb shared-memory with  <dig> kb l <dig> cache,  <dig> kb shared-memory with  <dig> kb l <dig> cache, or  <dig> kb shared-memory with  <dig> kb l <dig> cache, for each cuda kernel. this architecture has a local memory size of  <dig> kb per thread and has a l1/l <dig> cache hierarchy with a size-configurable l <dig> cache per sm and a dedicated unified l <dig> cache of size up to  <dig>  kb. however, l <dig> caching in kepler is reserved only for local memory accesses such as register spills and stack data. global memory loads can only be cached in l <dig> cache and the  <dig> kb read-only data cache  <cit> . same as all previous architectures, threads launched onto a gpu are scheduled in groups of  <dig> parallel threads, called warps, in simt fashion.

to facilitate general-purpose data-parallel computing, cuda-enabled gpus have introduced ptx, a low-level parallel thread execution virtual machine and instruction set architecture   <cit> . ptx provides a stable programming model and isa that spans multiple gpu generations. for the kepler architecture, simd video instructions are introduced in ptx, which operate either on pairs of 16-bit values or quads of 8-bit values. these simd instructions expose more data parallelism of gpus and provide an opportunity for us to achieve higher speed for data-parallel compute-intensive problems. in this paper, we have explored ptx simd instructions to further accelerate the sw algorithm on kepler-based gpus.

methods
program outline
cudasw++  <dig>  gains high speed by benefiting from the use of cpu and gpu simd instructions as well as the concurrent cpu and gpu computations. our algorithm generally works in four stages:  distribution of workloads over cpus and gpus according to their compute power;  concurrent cpu and gpu computations;  re-computation of all alignments that have exceeded the 8-bit accuracy using cpu 8-lane 16-bit simd instructions; and  sorting of all alignment scores in descending order and output the results. figure  <dig> illustrates the workflow of our algorithm. in our algorithm, all subject sequences are pre-sorted in ascending order of sequence length.

workload distribution
our workload distribution in stage  balances the runtimes between the cpu and gpu simd computation. hence, the compute power of cpus and gpus should be taken into consideration in order to generalize our approach to different hardware configurations. our distribution policy calculates a rate r of the number of residues from the database assigned to gpus, which is calculated as

  r=ngfgngfg+ncfc/c 

where fc and fg are the core frequencies of cpus and gpus, nc and ng are the number of cpu cores  and the number of gpu sms, and c is a constant derived from empirical evaluations, i.e.  <dig>  and  <dig>  for the query profile and its variant, respectively. when using multiple gpus, our algorithm assumes that they have the same compute power and will calculate ng by summing up the number of sms on all gpus.

after obtaining r, we calculate the number nr of residues assigned to gpus as r times the total number of residues in the database. subsequently, all subject sequences assigned to gpus can be determined by summing the sequence lengths in ascending order until it reaches nr. all other subject sequences will be distributed to cpus.

cpu simd computation
in stage , the cpu simd computation consists of two steps. first, we compute the sw algorithm by splitting an sse vector to  <dig> lanes with 8-bit lane width. this allows aligning a query in parallel to  <dig> subject sequences following the inter-task parallelization model. secondly, we re-compute all alignments, whose scores have overflow potential, using 8-lane sse vectors with 16-bit lane width. we determine an alignment to have overflow potential by comparing its score with a score limit calculated by subtracting from  <dig> the maximum substitution score in the scoring matrix. if the score ≥ the score limit, the alignment is deemed to have an overflow potential and thus requires re-computation. our approach is based on the open-source swipe and more details about the specific implementation of the sse-based sw algorithm can be obtained from  <cit> .

in our algorithm, users are allowed to use multiple threads to conduct the cpu simd computation. since the workload  is known beforehand, we calculate the total number of residues in all assigned subject sequences and  equally distribute all residues over all threads using a sequence as a unit. this distribution aims to make each thread hold  the same number of residues, but not necessarily receiving the same number of subject sequences.

gpu simd computation
core ptx simd assemblies
we have implemented the recurrence in equation  with ptx simd assembly instructions. the code consists of ten assembly instructions for the recurrence and one instruction for obtaining the optimal local alignment score. figure  <dig> shows the ptx simd assembly instructions.

the figure shows that every instruction operates on quads of 8-bit signed values, corresponding to four independent alignments. variables h, n and he represent the alignment score vectors corresponding to matrix h, where h denotes the score vector of the four current cells, n the score vector of the four diagonal neighbours and he the score vector of the four upper neighbours. variables e and f represent the score vectors corresponding to the matrices e and f respectively, and s stores the current maximum alignment scores. for additions and subtractions, saturation instructions have been used to clamp the values to their appropriate signed ranges.

cuda-enabled parallelization
for quad-lane simd computing on gpus, four adjacent subject sequences  are assigned to a single thread, with each vector lane corresponding to each sequence. to facilitate data fetches for simd vectors, a two-dimensional sequence profile of size 4×l will be created for four sequences, where l is the maximum length of the four sequences. in a sequence profile, each row is a quad-lane residue vector represented as an integer data type, and is created by packing four residues of the same index in their corresponding sequences with each residue occupying  <dig> bits. to reduce the number of texture fetches, we have further packed four successive residue vectors using a uint <dig> vector data type for each sequence profile. thus, we can realize four residue vectors for four subject sequences by a single texture fetch. using a profile as a unit, we store all profiles in the texture memory following the same layout as in cudasw++  <dig> .

for the linear-space sw algorithm, we require two intermediate buffers to store one row for matrices h and e  respectively. instead of global memory, we have allocated them in local memory. since the kepler architecture has  <dig> kb per-thread local memory, theoretically we can support subject sequences as long as  <dig>  on gpus. our algorithm sets the maximum subject sequence length to be  <dig>  by default, but allows users to configure it at compile time because the two intermediate buffers have to be statically allocated in local memory.

the sequence length deviation generally causes runtime imbalance between threads, which in return can waste gpu compute power. in this regard, we have developed two cuda kernels based on two parallelization approaches: static scheduling and dynamic scheduling. these two kernels are invoked at runtime based on the sequence length deviation of the database. for both approaches, we compute the total number of thread blocks from the total number of sequence profiles, which is constructed from the workload assigned to the gpu. since each thread has its own intermediate buffers, the static scheduling parallelization launches all thread blocks onto the gpu at the same time, which is common for launching a cuda kernel. the parallelization will rely on the cuda runtime system to maximize the utilization of computational resources of gpus. besides the cuda runtime system, the dynamic scheduling approach attempts to intervene with the scheduling of thread blocks on gpus. this parallelization launches a small set of thread blocks of size nt to carry out the whole computation, regardless of the assigned workload. nt is defined as:

  nt=2nsm×nmrtntpb 

where nsm is the number of sms, nmrt is the maximum number of resident threads per sm supported by the gpu, and ntpb is the number of threads per thread block configured by the user. the dynamic scheduling parallelization works as follows. all sequence profiles are organized into sequence profile blocks, each of which has as many sequence profiles as the number of threads in a thread block. subsequently, nt thread blocks are launched to perform the computation, where a thread block processes a sequence profile block at a time. when a thread block finishes its current computation, this thread block will dynamically obtain an unprocessed profile block. this operation is done by the atomic addition function atomicadd() on global memory, which increments the index of global profile blocks. in our algorithm, both static scheduling and dynamic scheduling have used a thread block size of  <dig> 

our evaluation has found that dynamic scheduling performs slightly better than static scheduling when using the swiss-prot database , whereas the latter seems slightly better in the ideal case where all sequences are of equal lengths. based on the above observations, we have decided to employ the static scheduling approach for databases with very small sequence length deviation  and the dynamic scheduling approach for all others.

query profile variant
given a query s defined over an alphabet Σ, a query profile is defined as a numerical string set p = {pr | r є Σ}, where pr is a numeric string comprised of substitution scores required for aligning the whole query to any residue in Σ. the space complexity of the query profile can be calculated as o. in our algorithm we have employed the sequential-layout query profile  <cit> , which defines the ith element of pr as m, 1≤i≤|s|. the query profile is stored in texture memory and has been packed in the same way as in cudasw++  <dig>  to reduce the number of texture fetches.

to facilitate gpu simd parallelization, we have derived a variant of a query profile. by enumerating all residues in Σ, we define a query profile variant as a numerical set v = {vr | 0≤ r<|Σ|k} of |Σ|k entries, where vr is a vector of k substitution scores and r is an integer corresponding to the permutation of any k residues in Σ. vr stores all substitution score vectors for aligning the whole query to the k residues corresponding to r. the space complexity of a query profile variant can be calculated as o. like the query profile, this variant is also stored in texture memory. when k =  <dig>  each element of vr can be directly used in our quad-lane simd computation. however, the memory footprint is considerable even for short protein queries , and will cause more texture cache misses as the query length increases. in order to improve speed for long queries, our algorithm therefore uses k= <dig>  we represent each element of vr using the short integer data type, since the range of the char data type is generally large enough to store a substitution score. figure  <dig> shows an example query profile variant using k= <dig>  similar to the query profile, the variant has also been packed by representing four consecutive elements of each vr using the short <dig> data type. in this way, the variant can reduce the number of texture fetches by half compared to the query profile. on the other hand, to compute each cell vector , we have to extract and concatenate the substitution scores, from either query profile or the variant, to generate a substitution score vector. this requires some additional bitwise operations in our implementation. in this case, we can save six bitwise operations for each cell vector by using the variant, instead of the query profile. this makes great sense in terms of speed, considering that each cell vector requires only several assembly instructions as shown in figure  <dig> 

our algorithm employs both the query profile and its variant. in general, for short queries, more performance gains can be realized from the query profile variant because it can reduce the number of texture fetches by half and use fewer bitwise operations per cell as mentioned above. however, for longer queries, a query profile becomes superior due to its much smaller memory footprint and less texture cache miss. thus, we have calculated a query length threshold q to decide whether to use the query profile or the variant. for the kepler architecture, texture fetches are cached by the aforementioned read-only cache and l <dig> cache. since the l <dig> cache is usually much larger than the read-only cache, we have estimated q from the l <dig> cache size as

  q=l2_cache_size2∑k 

the estimation is empirical and works well in practice through our evaluations. q is used in the dynamic scheduling parallelization to cope with more general databases. for static scheduling which is only applied to databases with small sequence length deviations, we have found that a query profile variant usually leads to superior speed.

RESULTS
experimental design
we used the gcups metric to measure the performance of the following algorithms: cudasw++  <dig>  , cudasw++  <dig>  , swipe  and blast+ . we used  <dig> protein queries of lengths ranging from  <dig> to  <dig>  to search against two protein databases: the swiss-prot database  and a simulated database of equal-length sequences. the accession numbers of all queries are: p <dig>  p <dig>  p <dig>  p <dig>  p <dig>  p <dig>  p <dig>  p <dig>  q <dig>  p <dig>  p <dig>  p <dig>  p <dig>  p <dig>  p0c6b <dig>  p <dig>  p <dig>  q7tma <dig>  p <dig>  and q9ukn <dig>  listed in the ascending order of sequence length. the swiss-prot database consists of  <dig> , <dig> amino acids in  <dig>  sequences and has the largest sequence length  <dig> . the simulated database comprises  <dig>  sequences with each sequence of length  <dig> , containing  <dig> , <dig> amino acids in total.

all tests were conducted on a personal computer with an intel i <dig> 2700k quad-core  <dig>  ghz cpu and  <dig> gb memory, running the linux operating system . all gpu-based tests are carried out on the aforementioned gtx <dig> and gtx <dig> graphics cards. gtx <dig> has a single gpu that contains  <dig> sms  and  <dig> gb memory. gtx <dig> consists of two gpus, each of which contains  <dig> sms  and  <dig> gb memory. we turned off the error correcting code on both graphics cards and conducted all single-gpu evaluations on gtx <dig> as well as all dual-gpu evaluations on gtx <dig>  for all tests, the wall clock times were used to compute the gcups performance of all evaluated algorithms.

the cudasw++  <dig> , cudasw++  <dig>  and swipe algorithms used the default scoring schemes due to their runtime independence of scoring schemes. blast+ used the scoring matrices blosum <dig>  and blosum <dig> , with the default gap open and extension penalties. we used four cpu threads for the cudasw++  <dig> , swipe and blast+ algorithms, and used other parameters “-b  <dig> -v 0” for swipe and “-num_alignment 0” for blast+, respectively. cuda toolkit  <dig>  was used to compile cudasw++  <dig>  and cudasw++  <dig> .

evaluation on the swiss-prot database
we first compared the performance of all evaluated algorithms by searching the  <dig> queries against the swiss-prot database. figure  <dig> illustrates the performance of all evaluated algorithms for varying query lengths. for the swiss-prot database, cudasw++  <dig>  employs the dynamic scheduling approach for all queries. on gtx <dig> , cudasw++  <dig>  yields an average performance of  <dig>   gcups, with a maximum of  <dig>   gcups. highest performance is realized by short queries of lengths < <dig> due to the use of the query profile variant. in addition, a sudden performance drop can be observed as the curve moves to query length ≥ <dig>  this is because our cuda kernel switches to the use of the query profile for longer queries, giving up the query profile variant.

both cudasw++  <dig>  and swipe achieve nearly constant performance for all queries. cudasw++  <dig>  has an average performance of  <dig>   gcups on gtx <dig> , while swipe yields an average performance of  <dig>  gcups using  <dig> threads. cudasw++  <dig>  is superior to both cudasw++  <dig>  and swipe for every query, even if only using a single gpu. cudadsw++  <dig>  on gtx  <dig>  runs on average  <dig> ×  faster than cudasw++  <dig>  and  <dig>  ×  faster than swipe, while gaining a maximum speedup of  <dig>   over cudasw++  <dig>  and  <dig>   over swipe. blast+ shows performance fluctuations for different queries, especially in the case of bl <dig>  furthermore, blast+ is runtime sensitive to the scoring scheme used. it runs on average  <dig> × faster using bl <dig> than bl <dig>  on gtx <dig>  cudasw++  <dig>  is always superior to blast+ for each case, where the former achieves an average speedup of  <dig>  and  <dig>   over the latter using bl <dig> and bl <dig>  respectively. on gtx <dig>  cudasw++  <dig>  outperforms blast+ using bl <dig> for all queries, gaining an average speedup of  <dig>  and a maximum of  <dig> . compared to blast+ using bl <dig>  cudasw++  <dig>  gains an average speedup of  <dig>  and a maximum of  <dig> . however, our algorithm has a lower performance for two queries with the following accession numbers: p <dig> and q7tma <dig> 

evaluation on a simulated database
in addition, we have employed the aforementioned simulated database to compare all algorithms. on this database, we can avoid the computation waste of cpu and gpu simd instructions as all alignments in all lanes will be completed at the same time, and can also avoid the computational imbalance between threads within a warp and a thread block. figure  <dig> shows the performance of all evaluated algorithms on this simulated database.

compared to the swiss-prot database, all evaluated algorithms are able to improve their average performance. on gtx <dig> , cudasw++  <dig>  achieves an average performance of  <dig>   gcups and cudasw++  <dig>  of  <dig>   gcups. swipe improves its average performance to  <dig>  gcups and blast+ to  <dig>  and  <dig>  gcups using bl <dig> and bl <dig> respectively. similar to the swiss-prot database, cudasw++  <dig>  and swipe produce nearly constant performance over all queries, while blast+ fluctuates. cudasw++  <dig>  is still superior to cudasw++  <dig> , swipe and blast+ using bl <dig> in each case. on gtx <dig> , our algorithm gains an average speedup of  <dig>   over cudasw++  <dig> ,  <dig>   over swipe and  <dig>   over blast+ using bl <dig>  compared to blast+ using bl <dig>  cudasw++  <dig>  on gtx <dig> is superior for all queries except for the largest one, for which blast+ has a performance burst of up to  <dig>  gcups. on average, cudasw++  <dig>  on gtx <dig> can be considered on par with blast+ using bl <dig>  but on gtx <dig> runs  <dig> × faster.

other evaluations
in addition to the performance based on hybrid cpu-gpu parallelism, we have evaluated the performance of gpu-only cudasw++  <dig>  by disabling cpu threads. by default, the gpu computation only supports subject sequences of lengths ≤ <dig>  due to the limited gpu device memory. longer subject sequences  are distributed to the cpu. hence, for this evaluation we created a new sub-database by extracting all sequences of lengths ≤ <dig> from the swiss-prot database. this new sub-database consists of  <dig> % sequences and  <dig> % amino acids of the original swiss-prot database. using this sub-database, cudasw++  <dig>  will only conduct the inter-task parallelization stage because all sequence lengths are ≤ <dig>  in addition, we have disabled stage , which re-computes the very few alignments with indicative overflows on cpus.

figure  <dig> shows the performance comparison between gpu-only cudasw++  <dig>  and cudasw++  <dig>  on the single-gpu gtx <dig>  due to the large sequence length deviation of the sub-database, the dynamic scheduling approach is automatically selected by cudasw++  <dig>  for all queries. similar to the case of using the original swiss-prot database, we have also observed a performance drop because of the switch from the query profile variant to the query profile. from the figure, gpu-only cudasw++  <dig>  is superior to the cudasw++  <dig>  for all queries, yielding an average speedup of  <dig>  and a maximum speedup of  <dig> . in addition, cudasw++  <dig>  realized an average performance of  <dig>  gcups and a maximum performance of  <dig>  gcups, for all queries.

finally, we have evaluated the relative performance of cpu computation to gpu computation in stage , by searching all queries against the swiss-prot database on the gtx <dig>  we have measured the runtimes of both the cpu and gpu computation and then calculate their performance from their respective workload and runtime. figure  <dig> shows the performance ratio of the cpu to cpu computation in terms of runtime and gcups. from the figure, we can see that the runtime ratios of the cpu to gpu computation slightly fluctuate around  <dig>  for all queries. this reflects that our workload distribution between the cpu and gpu computation are well balanced. in addition, for longer queries of lengths > <dig>  the performance ratio of the cpu to gpu computation has also reached roughly stable values .

CONCLUSIONS
in this paper, we have presented cudasw++  <dig> , a faster sw protein database search algorithm, which gains high speed by coupling cpu and gpu simd instructions and carrying out concurrent cpu and gpu computations. for the first time, we have investigated a gpu simd parallelization based on cuda ptx simd video instructions. this parallelization enables us to gain more data parallelism beyond the simt execution model on cuda-enabled gpus. performance evaluation reveals that our algorithm gains significant speedups over three other top-performing algorithms: cudasw++  <dig> , swipe and blast+. on the popular swiss-prot database, our algorithm on gtx <dig>  yields a speedup of up to  <dig>   over cudasw++  <dig> , up to  <dig>   over swipe using  <dig> threads, and up to  <dig>   over blast+ with bl <dig> using  <dig> threads. with hyper-threading enabled, the performance of both swipe and blast+ against the swiss-prot database improves, albeit insignificantly. on average, compared to the aforementioned performance with  <dig> threads, the hyper-threading functionality can improve the performance by  <dig> % and  <dig> % for swipe and blast+ respectively, by using  <dig> threads. despite designed for the sw protein database search, our algorithm has also presented a general computing framework for heterogeneous computing with cuda-enabled gpus and is expected to make contributions to other research problems.

abbreviations
bl50: blosum50; bl62: blosum62; cpu: central processing unit; cuda: compute unified device architecture; gpu: graphics processing unit; gtx680: geforce gtx 680; gtx690: geforce gtx 690; fpga: field programmable gate array; isa: instruction set architecture; ptx: parallel thread execution; sse: streaming simd extensions; simd: single instruction multiple data; simt: single instruction multiple thread.

competing interests
the authors declare that they have no competing interests.

authors’ contributions
yl contributed the idea of concurrent cpu and gpu execution, programmed the algorithm, performed the tests, analysed the results and drafted the manuscript; aw programmed the algorithm, analysed the results and revised the manuscript; bs contributed the idea of using ptx simd video instructions, participated in the algorithm optimization, analysed the results and revised the manuscript. all authors read and approved the final manuscript.

