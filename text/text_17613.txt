BACKGROUND
microorganisms constitute a large fraction of the biodiversity on earth  <cit> , but the majority of microbial life is still unknown. improved knowledge about the hidden diversity of microorganisms is vital for a better understanding of evolutionary relationships and ecological processes among microorganisms  <cit> . sequencing of dna sampled from the environment has allowed us to venture into this vast diversity of unknown microorganisms. in particular, the introduction of pyrosequencing technologies has revolutionized our ability to explore this hidden diversity  <cit> . high throughput sequencing of genomic dna regions such as its, 16s and 18s rdna enables in-depth analyses of the genetic variation of eukaryotic and prokaryotic groups. these techniques have already been exploited to study the microbial community in various environments  <cit> .

analysis of the massive amount of data produced by new sequencing methods requires efficient and flexible bioinformatics applications that both fit the user's needs and the characteristics of the sequence data. there are several existing bioinformatics tools available that include various options for processing and clustering  <dig> reads, including fastgroupii  <cit> , rdp <cit> , mothur <cit> , seqtrim <cit> , qiime <cit> , scata <cit> , waters <cit> , cangs <cit> , pangea <cit>  and pyronoise <cit> . however, the majority of these programs are directed towards specific genetic markers or include only a few of the necessary analytic steps. furthermore, some of the analytic steps  normally require significant computational power, but many of the published bioinformatics tools are not implemented in a high performance-computing environment and must be installed locally. there is still a need for a comprehensive, user-friendly and flexible pipeline that transforms raw sequence data  into operational taxonomic units  and allows the results to be browsed easily.

in this paper we present clotu, an online, user-friendly pipeline for processing  <dig> amplicon reads. clotu is open access to academic users and is implemented on the bioportal bioinformatics web-service . as different users and datasets have different demands, we aimed to make clotu as flexible as possible, so analyses can be optimized by adjusting several criteria and parameters. the output of the pipeline shows detailed statistics about the number of sequences passing the different filtering steps, statistics of clusters of sequences  and blast hits.

methods
a typical raw  <dig> read obtained after sequencing with adaptors and tags  is illustrated in figure  <dig>  clotu includes three basic steps: 1) filtering and trimming, 2) clustering and 3) database search using blast . each of the three basic steps can be implemented through the web interface independently or collectively, and their respective parameters specified . a user manual for clotu is available on the bioportal .

input files
clotu requires three input files from the user: 1) one or several sequence files, in fasta format  <cit>  compressed zip file , 2) a text file, that specifies sequences used as tags, primers and adaptors  and 3) a text file, containing the fasta file names and file identifiers  to be added to each sample.

step1: filtering and trimming
clotu provides different options for filtering low quality reads.  <dig> reads in the sequence file can be removed by the user if: 1) the tag and primer sequences does not match the sequences in the tpa file, 2) sequences have incompatible end tag combinations, 3) one or more ambiguous nucleotides  are present  <cit>  and 4) sequences are shorter than the user-defined minimum length.

these options can be optimized by the user and implemented either in combination or independently. it is also possible to accept mismatches in tags and primers. a perl module included in the pipeline implements the needleman-wunsch algorithm  <cit>  and considers indels for pairwise alignment of tags and primers before filtering out low quality sequences. the user can also define the threshold for minimal sequence length .

sequencing by  <dig> pyrosequencing often results in ambiguous homopolymers. clotu provides an option where homopolymers above a certain length can be collapsed to a user-defined length, e.g. all homopolymers of length greater than six can be reduced to length six.

clotu allows trimming of tags, primers, and adapters . one of these options, the 'trim adaptor' option, removes exact and/or partial adaptor sequences found at the end of the reads. in order to reduce redundancy in the dataset before clustering, clotu also includes an option to remove all identical sequences. if this option is selected, clotu keeps track of all duplicate sequences and includes them in sequence abundance tallies for each cluster.

the filtering and trimming step produces four or five output files depending on the chosen parameters: 1) summary.txt summarizes the statistics of accepted sequences in tabular format for each basic step of the pipeline, 2) accepted.fas contains all accepted sequences in fasta format, 3) rejected.fas contains all rejected sequence in fasta format and 4) stats_log.txt lists the number of sequences in each sequence file compressed with zip. this file includes the parameters selected for the analysis, and detailed statistics regarding the number of accepted and rejected sequences for each of the activated filter and trim parameters. all invalid parameter settings and errors encountered are appended to this file. if the user has activated the 'collapse homopolymer' option, a fifth output file named homopolymers.html is also produced. the homopolymers.html allows visual verification of all sequences with homopolymers .

step 2: clustering of sequence reads
for clustering of sequence reads, clotu uses the single-linkage clustering method as implemented in the blastclust program. this clusters dna sequences based on pairwise matches using a blast algorithm  <cit> . the pipeline also provides the option to cluster dna sequences using the cd-hit package, an implementation of a greedy incremental clustering algorithm  <cit> . the user can define the minimum degree of pairwise sequence overlap as well as the sequence similarity threshold for clustering in both algorithms. the output file accepted.fas, containing all accepted sequences, is used as an input file for either clustering program. a typical blastclust output file consists of a sorted list of clusters of sequences separated by a newline character. the list is sorted first by cluster size and then alphabetically. sequence identifiers within a cluster are space-separated and sorted, first by sequence length and then alphabetically. the longest sequence in each cluster is used as a representative sequence of that cluster. a perl script creates a ready-to-use fasta file from the raw blastclust output. cd-hit produces ready-to-use fasta files and the longest sequence from each cluster is considered as the representative sequence. a perl script numbers the obtained clusters based on their abundance in the complete dataset. the clustering step also provides an option to exclude singletons, frequently used for reducing the impact of pcr and sequencing errors  <cit> .

the clustering step produces five new output files: 1) cluster_out.fas contains the representative sequence of each cluster, 2) cluster_info.txt lists brief statistics about the number of sequences in each cluster and in the whole dataset, 3) matrix_table_ <dig> xls lists the unique and identical  sequence count from each tags used in the study, 4) singleton.fas lists all singletons in the fasta format and 5) seqineachcluster.zip which includes separate ready-to-use fasta formatted files of all sequences in each of the clusters, obtained for further assessment with various multiple sequence analyses or bioinformatics applications. the file stats_log.txt from step  <dig> is appended with brief statistics on the clusters obtained.

step 3: taxonomic annotation of sequences using blast
taxonomic annotations are done by database searches using blastn against either user-defined databases or a downloaded version of the ncbinr database, maintained and updated on the bioportal server  <cit> . user-defined databases can be made available for a defined group of users or to all users of the clotu pipeline through the bioportal infrastructure. blast searches are done with user-specified settings of e-value threshold, number of score descriptions to report and number of pairwise alignments . as the ncbinr database contains sequences derived from environmental surveys lacking taxonomical information, the user can choose to remove such hits from the blast output files .

as a rough evaluation of the obtained clusters, clotu provides statistics about the degree to which the different clusters have best blast hits against the same database sequences. if many clusters have their best hit against the same reference sequences this may indicate that strict clustering parameters have been used, although this might not be universal for other sequences, including its.

the blast step produces five output files: 1) blastout.txt contains the results from blast searches in text format, 2) output_bp.html contains the parsed blast search results in color and tabular form, for easy visualization, 3) outfile_bp.txt contains parsed blast search results in text format, 4) outfile_bp.xls is a blast search result parsed file in microsoft excel  format and 5) matrix_table_ <dig> xls is the same as matrix_table_ <dig> xls produced in the previous step with the addition of an extra column for the top blast hit . all significant blast search hits reported are summarized and appended in stats_log.txt file. each of the parsed blast output files  also report all significant hits, along with the top hit that passed the blast parsing criteria, as well as brief statistics about the total numbers of hits and number of uncultured sequences reported.

implementation
clotu is written in perl v <dig>  and php  <dig>  and implemented on the bioportal at the university of oslo. bioportal is a web-based bioinformatics service and currently the largest high performance-computing environment for bioinformatics in norway. bioportal is freely available to academic users at the following url: http://www.bioportal.uio.no/. the available computer resources are  <dig> cores on a titan cluster  <cit>  at university of oslo. in addition, bioportal has access to all free or idle titan cores if needed . the titan cluster has linux nodes with  <dig> gigabytes of memory and 2× quadcore cpus or 2× dual-core cpus. the clotu and bioportal tutorials are available at the bioportal website  <cit> .

analysed dataset
a dataset including  <dig>  fungal its <dig> rdna sequences generated by  <dig> sequencing of eight environmental samples from four plant roots is used here to demonstrate the utility of the clotu pipeline. the fungal its <dig> amplicons were obtained through a nested pcr approach using the fungal-specific primer its1-f  <cit>  in combination with the primer its <dig>  <cit>  in pcr <dig> and fusion primers  based on its <dig> and its <dig>  <cit>  in pcr <dig>  the raw its <dig> sequences consisted of tags, forward primer, target sequence, reverse primer, reverse complement of tags used and adaptor . tags were used on both ends to be able to control for sequences with incompatible end tag combinations generated during sample pooling for emulsion pcr. although mainly overseen, such sequences with incompatible tag combinations have been reported as a serious problem in other publications  <cit> . the its <dig> dataset has been submitted to genbank  .

parameters selected for the analysed dataset
we did two separate analyses of the its <dig> dataset, each with two different settings, to evaluate and illustrate the different options available in clotu. in the first analyses  we searched for both the forward  and reverse  primers within the sequences, in order to filter out those that had not been fully sequenced. we did two separate runs of this analysis: one allowing no errors  in the primers, and one allowing for two errors in each primer. in the second analysis  we only searched for the forward primer , to also retain partially sequenced its <dig> fragments. again, we did two separate runs in this analysis allowing zero or two mismatches in the forward primer. the four different filtering parameter settings were each used with the two different clustering methods blastclust and cd-hit. the parameters for blastclust and cd-hit were 95%, 96%, 97%, 98% and 99% identity and 50% sequence coverage.

RESULTS
analyses of the its data
the processing of the fungal its <dig> dataset using different filtering settings is summarized in table  <dig> and  <dig>  about  <dig> % of the sequences were removed, as tags were not detected. requiring presence of both forward  and reverse  primers without errors in the sequences  resulted in a massive loss of sequences, almost 70% of the initial sequence number. allowing for two errors in the primers reduced this slightly . when the presence of only the forward primer was allowed  only 2% and  <dig> % of the sequences were filtered out, with no and two base pair primer mismatches, respectively. this indicates that a large proportion of the its <dig> amplicons in this dataset were not sequenced along the entire length. thus, sequences with incompatible tag combinations were detected only in analysis i . in analysis i, 2% of sequences were filtered out due to the presence of iupac dna ambiguity symbols. however, in analysis ii, a markedly higher proportion of the sequences contained ns; about 9% were filtered out in this step. this indicates that ambiguities are more frequently associated with incompletely sequenced amplicons. analysis i returned  <dig> and  <dig> unique its <dig> sequences while analysis ii returned  <dig>  and  <dig>  sequences . it is noteworthy that allowing for two mismatches raised the number of retained sequences by only ~1%.

table providing detailed statistics about the various filtering steps used on the example datasets. in analysis i both forward and reverse primers were searched for in the sequences . in analysis ii, only the forward primer was searched for . the filtering in analysis i resulted in  <dig> and  <dig> unique sequences while analysis ii resulted in  <dig> and  <dig> unique sequences.

table providing statistics about the clustering steps run on the example dataset. both blastclust and cd-hit were used for clustering the unique sequences  at 95%, 96%, 97%, 98%, and 99% sequence identity and 50% sequence coverage. the table also summarizes the statistics of blast-based evaluation method of clusters.

subscript b and c means results from blastclust and cd-hit respectively.

 <dig> tc  is the number of clusters obtained at sequence identity 95%, 96%, 97%, 98%, and 99% irrespective of number of sequences in each cluster, ts  is the number of cluster with single sequence.

 <dig> tbh  is the number of otus obtained; tubh  is the number of unique blast hits obtained from the tbh, es  is the number of blast hits excluding clusters with single sequence  only; ues is the unique number of blast hits obtained from es; os  is the number of blast hits obtained from singletons; uos is the unique number of blast hits obtained from os.

in analysis i the cd-hit clustering approach yielded almost the same number of clusters as blastclust irrespective of allowing zero or two bp primer mismatch, except when very stringent parameter settings  were used. in analysis ii cd-hit yielded more clusters than the blastclust approach, even when allowing up to 5% sequence divergence .

singletons, i.e. clusters including only one sequence, are to some extent considered a result of pcr and sequencing errors and often omitted from further analysis  <cit> . the clotu pipeline provides a separate fasta formatted file with all singletons, which enables a separate comparison to the reference sequence database  using blast. it is noteworthy that most of the top hits were to taxa not covered by the non-singleton clusters. this may reflect poor read quality of the sequences giving rise to random its sequences as the best matches  <cit> . alternatively, it may indicate the presence of many rare taxa within the samples being studied , and that removal of singleton clusters without further assessment in environmental sequencing studies may lead to the loss of valuable information  <cit> . in clotu, the 'remove singleton' option can be deactivated to include the blast top hits for even these clusters.

in both analyses i and ii, using 98% and 99% sequence identity, far more clusters appeared among the sequences when two base pair mismatches were allowed in primers. this may indicate that a higher proportion of low quality sequences have been included when allowing for two base pair errors in primers, resulting in additional clusters. to further evaluate the two clustering methods, blast searches were performed on the representative sequences from all clusters obtained using 95% to 99% of sequence identity and 40% to 80% sequence coverage. the blast results showed that stringent clustering parameters  had an impact on the number of clusters obtained in blastclust. cd-hit was found to be less sensitive in this respect .

in clotu, our example dataset with  <dig>  sequences took  <dig> seconds  for analysis i when the cd-hit clustering program was selected, and  <dig> seconds  when blastclust was used. the total time for calculation with either cd-hit or blastclust was below  <dig> seconds without blast searches.

clotu compared to other bioinformatics tools
clotu is one of a few web-based bioinformatics pipelines that can process raw  <dig> reads and return taxonomically annotated operational taxonomic units  ready for further downstream analyses. clotu includes some overlapping functionalities with several recently published pipelines such as the qiime <cit> , pangea <cit> , scata <cit> , cangs <cit>  and waters <cit>  but is different at some important points . clotu is a web-based service platform running on a high performance computing environment, while qiime, pangea, cangs and waters must be installed locally, making subsequent analysis of extensive datasets time consuming.

table providing comparable overlapping features with other pipelines qiime, pangea, scata, cangs and waters.

1fp = forward primer

2nd = not documented

3p = trimming of either tags or primer or adaptor but not all.

4clustering program; b = blastclust, c = cd-hit, m = mother, mb = megablast, bl = blast and o = otuhunter

compared to other pipelines, clotu provides a broad range of filtering options, with many unique functionalities, like filtering based on the presence of one or both primers and sequences with non-congruent tags. although mainly ignored, it has been shown that sequences with incompatible tag combination can be prevalent in some datasets  <cit> . clotu also allows the inclusion of a certain number of mismatches in primers as well as tags. the trimming options provided in clotu include trimming of only tags or both tags and primers. furthermore, clotu can detect partial adaptors at the end of the sequence when the amplicons are not sequenced completely.

in  <dig> sequencing, most sequencing errors arise from homopolymer stretches. clotu provides the option to collapse homopolymers with user specified settings. as far as we know, among the mentioned pipelines only clotu includes this functionality.

clotu provides two different clustering methods. blast searches with representative sequences from each cluster showed that the two clustering approaches mostly identified the same hits, with a few unique hits for some of clusters obtained using cd-hit.

pangea performs taxonomic annotation of reads and splits the dataset into classified and unclassified reads based on taxonomic affiliation before clustering. we would argue that such a procedure, relying on e.g. genbank matches, is problematic and may influence the clustering. it seems a better option to cluster sequences prior to taxonomic annotation. cangs and seqtrim do not provide clustering options. in the rdp pipeline, alignment is required before clustering, something that is highly problematic when working with more variable sequences than 16s.

one of the other useful features of clotu is that blast is integrated in the pipeline, making it unnecessary for the users to download databases for blast searches. in other pipelines such as qiime, pangea, cangs and pangea, the user needs to set up the database and blast program on their local computer for assigning taxonomic affiliation to the  <dig> reads.

in contrast to other pipelines, clotu provides several output files at every analytical step, allowing the user to explore their data more deeply in addition to obtaining high quality sequence files. clotu is available on bioportal, where output files can be used in several other bioinformatics applications already installed, maintained and routinely updated .

CONCLUSIONS
clotu has been constructed to be highly flexible so that users can choose different settings for different types of datasets. the user can choose at what stringency level to operate, i.e. whether only high quality long reads will be accepted for further analyses. we recognize that the current research field is developing extremely fast and that new requirements and options must be included in future versions of clotu, including novel tools for quality assessment of sequences  <cit> .

availability and requirements
project name: clotu version  <dig> 

project home page: http://www.bioportal.uio.no

operating system: platform independent

programming language: sql, perl, python and php

other requirements: none

license: gnu - gpl

any restrictions to use by non-academics: bioportal accepts academic email address only. test dataset for clotu is available at http://www.bioportal.uio.no/onlinemat/online_material.php.

authors' contributions
sk carried out all programming, analysis, and implementation on bioportal, drafted and wrote the manuscript. hk, tc and kst planned the study, supervised and helped to draft and write the manuscript. rb tested the program on different datasets. bhm and pe contributed with programming and implementation of clotu on bioportal. all authors read and approved the final manuscript.

supplementary material
additional file 1
clotu web-interface on the bioportal. the user can specify input files . the sequence file must be in the fasta format and compressed with zip. the user can then select different options provided in each step of the clotu.

click here for file

 additional file 2
output file of clotu showing homopolymers as defined by the user  in red and lower case.

click here for file

 additional file 3
output file of clotu showing the blast hits for singletons.

click here for file

 additional file 4
result files for analysis i and ii.

click here for file

 acknowledgements
we acknowledge tom kristensen, anke stüken, thomas haverkamp, marie davey, russell orr and two anonymous reviewers for valuable comments on the manuscript. jon bråte and dan kristofer ree for testing clotu. funding for this work was provided by the university of oslo, norway.
