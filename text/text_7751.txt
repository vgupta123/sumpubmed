BACKGROUND
high-throughput gene expression profiling experiments have increased our understanding of the regulation of biological processes at the transcriptional level. in bacteria  <cit>  and lower eukaryotes, such as yeast  <cit> , modeling of regulatory interactions between large numbers of proteins in the form of regulatory networks has been successful. a regulatory network represents relationships between genes and describes how the expression level, or activity, of genes can affect the expression of other genes. the network includes causal relationships where the protein product of a gene  directly regulates the expression of a gene but also more indirect relationships. modeling has been less successful for more complex biological systems such as mammalian tissues, where models of regulatory networks usually contain many spurious correlations. this is partly attributable to the increasingly multi-layered nature of transcriptional control in higher eukaryotes, e.g. involving epigenetic mechanisms and non-coding rnas. however, a potential major reason for the decreased performance is due to biological complexity of datasets which can be defined as the increase of biological variation and the presence of different cell types, which is not compensated by an increase in the number of replicate data points available for modeling. there is an urgent need to identify regulatory mechanisms with more confidence to avoid wasting laborious and expensive wet-lab follow-up experiments on false positive predictions.

the main paradigms of this paper are that regulatory interactions that are consistently found across multiple datasets are more likely to be fundamentally involved and that these regulatory interactions are easier to find in datasets with less biological variation. in the end, regulatory networks trained on less complex biological systems could thus be used for the modeling of the more complex biological systems. we do this using a novel computational technique that combines bayesian network learning with independent test set validation  and a ranking statistic. whilst bayesian networks and bayesian classifiers have been used with great success in bioinformatics  <cit> , an important weakness has been that, when trying to build models that reveal genuine underlying biological processes, a highly accurate predictive model is not always enough  <cit> . the ability to generalize to other datasets is of greater importance  <cit> . simple cross-validation approaches on a single dataset will not necessarily result in a model that reflects the underlying biology and therefore will not generalize well. our approach is to exploit multiple datasets of increasingly complex systems in order to identify more informative genes reflecting the underlying biology.

bayesian networks have been an important concept for modeling uncertain systems  <cit> . in the last decade several researchers have examined methods for modeling gene expression datasets based on bayesian network methodology  <cit> . these networks are directed acyclic graphs  that represent the joint probability distribution of variables efficiently and effectively  <cit> . each node in the graph represents a gene, and the edges represent conditional independencies between genes. bayesian networks are popular tools for modeling gene expression data as their structure and parameters can easily be interpreted by biologists.

bayesian classifiers are a family of bayesian networks that are specifically aimed to classify cases within a data set through the use of a class node. the simplest is known as the naïve bayes classifier  where the distribution for every variable is conditioned upon the class and assumes independence between the variables. despite this oversimplification, nbcs have been shown to perform very competitively on gene expression data in classification and feature selection problems  <cit> . other bayesian classifiers, which often have higher model complexity as they contain more parameters, involve learning different networks such as trees between the variables and therefore relax the independence assumption  <cit> . the logical conclusion is the general bayesian network classifier  which simply learns a structure over the variables including the class node. in this paper, we explore the use of the nbc, and the bnc for predicting expression on independent datasets in order to identify informative genes using classifiers of differing complexity.

accordingly, in order to optimize the classifier and choose the best method, we need to consider the classifiers' bias and variance. since bias and variance have an inverse relationship  <cit> , which means decreasing in one increases the other, cross-validation methods can be adopted in order to minimize such an effect. the k-fold cross-validation  <cit>  randomly splits data into k folds of the same size. a process is repeated k times where k- <dig> folds are used for training and the remaining fold is used for testing the classifier. this process leads to a better classification with lower bias and variance  <cit>  than other training and testing methods when using a single dataset. in this paper, we exploit bias and variance using both cross-validation on a single dataset and also independent test data in order to learn models that better represent the true underlying biology. in the next section we provide a description of the gene identification algorithm for identifying gene subsets that are specific to a single simple dataset as well as subsets that exist across datasets of all biological complexity. we used den bulcke et al.  <cit>  proposed model for generating synthetic datasets to validate our findings on real microarray data. moreover, we evaluate the performance of our algorithm by comparing the ability of this model in identifying the informative genes and underlying interactions among genes with the concordance model. finally, we present the conclusion and summary of our findings in the last section.

methods
multi-data gene identification algorithm
the algorithm involves taking multiple datasets of increasing biological complexity as input and a repeated training and testing regime. firstly, this involves a k-fold cross-validation approach on the single simple dataset  where bayesian networks are learnt from the training set and tested on the test set for all k folds. these folding arrangements have been used again for assessing a final model. the bayesian network learning algorithm is outlined in the next section.

the sum squared error  and variance is calculated for all genes over these folds by predicting the measured expression levels of a gene given the measurements taken from others. next, the same models from each k fold are tested on the other  datasets  and sse and variance are again calculated. these sse and variances are used to rank the genes according to their informativeness . those that are ranked highly in the single-dataset cross-validation experiments will be informative, specific to the single datasets experiment, whereas those that are ranked highly on the independent datasets should be informative in a more general sense in that they are predictive  and consistent  across datasets of all complexity. we evaluate the statistical significance of these rankings using a method proposed by zhang et al.  <cit> . the full details are outlined in algorithm  <dig> where traind represents the training data , and testd <dig> ... testdm represent the more complex test datasets, independent test data.

bayesian network structure learning
the goal of learning gene regulatory networks using bayesian network approaches is to establish the structure of the network and then to parameterize the conditional probability tables  <cit> . as the number of possible network structures is huge, learning the structure of a network has a high computational cost. since the effective learning of network structure engages a trade-off of bias vs. variance, the necessity of designing an algorithm in which it can generate an ideal structure for a given dataset, with a degree of biological complexity, is crucial  <cit> . in this study, instead of using well studied but unrealistic and sometimes not effective classifiers such as nbc and tree augmented networks , we use an optimization approach that uses a simulated annealing search and the bayes information criterion  as a scoring metric  <cit> . the advantage of simulated annealing over other methods  is that it aims to avoid local maxima  <cit> . we have chosen the bic as a fitness function as it is less prone to overfitting through the use of a penalizing term for overly complex models.

bayesian networks with more connections between their nodes require a higher number of parameters and as a result increase the complexity of the models exponentially  <cit> . therefore, we explore three different classes of model learning: the selective naïve bayes  where only links between a class node representing differentiation status and a gene are explored, a search that explores structures with links between genes but limiting each gene to having only one parent . limiting the number of parents in a bayesian network is common practise but can be considered a crude approach to reducing parameters. as a result we also explore a full unlimited structure learning  and learn these structures using the simulated annealing with the bic scoring metric . in this study, the initial state of the structure is an empty dag with no link. in order to alter the network structures, three operators have been used within the simulated annealing. these operators are adding, removing, or swapping links to generate a new network for validation. these alterations can be either accepted or rejected. the outline of this procedure can be found in algorithm  <dig> 

prediction and ranking
zhang et al.  <cit>  proposed a method to convert a set of gene rankings into position p-values to evaluate the significance of a given gene. however, this involved working with resampling techniques upon a single dataset. here, we use the ranking lists according to the model's average sse and variance for both the original simple dataset and the independent test sets in order to generate position p-values. this requires us to include, a number of random genes which can be counted as uninformative genes. by comparing the actual ranking of the gene with the null distribution we can calculate the position p-values. in this paper we are using three independent datasets so we do not need to use resampling in order to generate more gene rankings as zhang et al.  <cit>  did in their experiments. in addition, the different rankings will have different interpretations as some are based purely on the simple dataset whilst others are influenced by error and variance on the more biologically complex independent data.

datasets
with the aim of investigating the influence of the complexity of a gene expression dataset on the performance of classifiers in identifying the gene regulatory network, three gene expression datasets  have been chosen for this study . these three datasets are all concerned with the differentiation of cells into the muscle  lineage. during this process, mononucleated precursor cells stop to proliferate, differentiate and fuse with each other to become elongated multinucleated myotubes or myofibres. this in-vitro system mimics the formation of new muscle fibres in-vivo. the cell types differ between the different datasets:

• gse3858: embryonic fibroblasts 

• gse <dig> and gse1984: c2c <dig> tumor cell line that has the potential for differentiation into different mesodermic lineages 

also methods to drive cells into myogenic differentiation differ:

• gse3858: exogenous expression of the myogenic transcription factors are myod and myog.

• gse <dig> and gse1984: serum starvation

in addition, the study by sartorelli included different treatments that affect the timing and efficiency of the myogenic differentiation process. the time points for sampling differ between the studies . the class node reflecting the differentiation status had two possible states: undifferentiated  and differentiated . in the rest of this paper we call these datasets by the name of the first author .

data processing and analysis
the raw microarray data were normalized and summarized with the rma method  <cit> , using the affy package in r. only the  <dig> probesets common to the affymetrix u74a and  <dig>  used in mentioned studies were considered in the analysis. all datasets were standardized to mean  <dig> and the standard deviation  <dig> across the genes. for the scope of this paper, first, we selected for each dataset a subset of  <dig> genes most affected by the induction of differentiation. these genes were identified with student's t-test which compared samples from undifferentiated and differentiated cell cultures, disregarding the time of differentiation. an additional  <dig> genes were randomly selected to be able to calculate ranking p-scores described above and using the kolmogorov-smirnov test. for cross-validation we divided cao dataset into  <dig> folds, sartorelli into  <dig> folds, and tomczak into  <dig> folds based upon the number of samples in each dataset. simulated annealing has three attributes which should be set before starting the learning phase. it is crucial to set an appropriate initial temperature, sufficient number of iterations, and a convenient fitness function. in this study, the initial temperature has been set to  <dig> and it terminates at  <dig> . the number of iterations has been set to  <dig> for the first set of experiments only using most informative genes  and then we set the number of iterations to  <dig> since we added  <dig> uninformative genes to the network. the code is implemented in matlab 2007a using the bayes net toolbox  <cit>  to generate gene regulatory networks.

analysis of myogenesis-related genes
myogenesis-related genes are defined as genes associated with the gene ontology term "muscle development" supplemented with all genes strongly associated with myogenesis in the biomedical literature, as determined with the literature analysis tool anni v <dig>   <cit>  with the association score greater than  <dig> .

analysis of synthetic datasets
the use of datasets in which the underlying network is known enables us to validate the new algorithms that have been developed to identify gene regulatory networks and capture the most informative genes. den bulcke et al.  <cit>  proposed a new methodology to generate synthetic datasets where the network structure is known and biological, experimental, and model complexity can be manipulated. however, a disadvantage of this approach is that the generated networks can contain some overlapping pieces of the known network which may weaken the models being probabilistically independent  <cit> . whilst syntren uses resampling from potentially overlapping networks, the generated data undergoes a robust statistical cross-validation regime ensuring that any prediction is applied to unseen data. the focus of this paper is upon the prediction of increasingly complex datasets, sampled from some underlying biological process. consequently, these synthetic datasets can be used for validating the performance of our methodology in identifying the informative genes and the interactions among them in real microarray data. syntren  <cit>  generates networks with more realistic topological characteristics and since we use this application to investigate the impacts of biological, experimental, and model complexity on identifying informative genes using the same sub-network is an advantage. three datasets have been generated on the well-described network structure of e. coli  <cit>  which contains  <dig> number of nodes and  <dig> interactions. these datasets have been generated in a manner that they can match the key characteristics of real microarray datasets we used in this study . this enables us to investigate the possibility of reproducing similar results on synthetic data which can be easily corrected for differences such as number of samples and time points per dataset  and avoid weakening the probabilistically independent assumption of the generated datasets.

analysis of concordance between datasets
the study of the concordance between microarray datasets has increased considerably in the past few years  <cit> . however, a robust statistical method for examining the concordance or discordance among microarray experiments carried out in different laboratories is yet to develop. methods such as multiplication of gene p-values in order to generate a list of rankings for concordance genes showed bias towards datasets with higher significance level  <cit> . lai et al.  <cit>  proposed a promising methodology  to investigate the concordance or discordance between two large-scale datasets with two responses. this method uses a list of z-scores, generated using a statistical test of differential expression, as an input to evaluate the concordance or discordance of two datasets by calculating the mixture model based likelihoods and testing the partial discordance against concordance or discordance. additionally, the statistical significance of a test is being evaluated by the parametric bootstrap procedure and a list of gene rankings is being generated which can be used for integrating two datasets efficiently. in this paper we are using a set of gene rankings generated by this method to evaluate the performance of our model in identifying informative genes from multiple datasets with increasing complexity.

RESULTS
the aim of this study is to demonstrate firstly, the influence of model complexity in discovering accurate gene regulatory networks on multiple datasets with increasing biological complexity. secondly, to investigate if cleaner and more informative datasets can be used for modelling more complex ones. therefore, three public datasets that are concerned with the differentiation of cells into muscle lineage were chosen for this study. from a biological point of view, sartorelli is the most complex dataset since it involves different treatments influencing myogenesis. tomczak and cao are less complex datasets. it is difficult to say how their complexity relates since tomczak uses more heterogeneous stimuli to induce differentiation but has more time points, while cao uses more defined stimuli  and less time points. in order to meet the scope of this study, we evaluated the quality and informativeness of these datasets based on two criteria. firstly, we calculated the average correlations between replicates as a measurement of noisiness of each dataset. secondly, using student's t-test method, we counted the number of differentially expressed genes with the significance levels of  <dig>  and  <dig>  as a measurement of informativeness . although the average correlations between replicates in all three datasets are very close, datasets differ in number of significant genes they hold. tomczak is the most informative dataset as it includes the most number of significant genes and has a higher average correlation value for the replicate samples in the dataset which represent the lowest level of noise. in contrast, sartorelli contains the least differentially expressed genes with almost 12% of what tomczak contains. moreover, it has the lowest average correlation value and can be marked as the most complex dataset to model in this study as it has the highest noise level and the least number of informative genes. therefore, we ordered these datasets by increasing biological complexity in the following way: tomczak, cao, and sartorelli.

comparison of classifiers and network analysis
we now explore how the different classifiers performed on these three datasets. figure  <dig> shows the average error rate of the different classifiers trained on each given dataset. it can be seen that of the three classifiers, 1pb and npb generated the same pattern and have very close error rates on cross-validation  sets. however, it is evident that npb  performs poorer than 1pb on the independent test set, possibly due to overfitting as these models contain more parameters. even though snb performed poorly on both the cross-validation test and the independent data test, in some cases it could compete with npb which appears to be too complex to predict some of the independent datasets accurately. hence, 1pb has performed favorably, both in terms of average error rate and the difference between the cross-validation test and the independent data test .

according to mac nally  <cit>  simple models should be sought for various reasons. firstly, simple models are more stable and capable of not overfitting to noise in the data which will influence the performance of classifier with future data. secondly, they tend to provide a better insight into causality and interactions among genes. finally, reducing the number of parameters will decrease the cost of validating a model for current and future data. however, we need a model that matches the complexity of data sets. considering this argument along with our first set of results, we chose 1pb as a model that can capture the interactions among genes and does not overfit to noise. in order to understand the impacts of using different datasets for gene selection and training 1pb classifier , we need to analyse the performance of the 1pb classifier on the top  <dig>  genes in more detail.

additional file  <dig>  figure s <dig> represents the comparison of the error rate of the 1pb classifier on cross-validation versus the independent test. it is shown that the 1pb classifier trained on tomczak performed significantly better on cross-validation and sartorelli shows the lowest differentiation between cross-validation and the independent test with almost the same average error rate on the cross-validation set compared to cao. although the differentiation of average error rate on the cross-validation set and independent test set is high in tomczak, this model produced the best models in terms of the lowest overall error rate. this figure raises the idea that tomczak is the most informative dataset since it can model any dataset, regardless of the gene selection method, significantly better than the other alternatives. this will be discussed in more detail in the extraction of infotmative genes section.

comparison of gene selections with differing informativeness
we now look into how the different gene selections impact on the average error rate of the 1pb classifier for both cross-validation and the independent test. figure  <dig> demonstrates the performance of the 1pb classifier in modeling datasets generated using different gene selections. clearly, unlike sartorelli, genes selected from tomczak and cao show very good performances on cross-validation. however, by looking at the average error rate of 1pb on independent test sets, we can see that the models learnt on cao over-fitted the data and performed poorly on the independent test set  whereas sartorelli shows the lowest differentiation between the two sets. overall the tomczak selection performed the best both on cross-validation and the independent test.

it is important to adopt a methodology that can generate an accurate gene regulatory network, moreover, it is crucial to generate a model that can capture the significant genes and distinguish informative genes from uninformative ones. for this purpose, we added  <dig> randomly selected genes with high p-values  from the distribution. this also has the effect that it will increase the complexity of the datasets.

it is crucial to investigate if these findings are reproducible and are not prone to the number of samples and time points per dataset. therefore, we applied our model on three synthetic datasets that have been generated by manipulating the biological, experimental, and model complexity of their known network structure using syntren application  <cit> . additional file  <dig>  figure s <dig> illustrates that we can see a very similar pattern as we have seen on a real data where there is an increase on the average error rate of models learnt on multiple synthetic datasets with increasing biological variability. in the next section, before examining if these models can help us to capture the interactions in more complex datasets, we will investigate how well these models separate the informative genes from uninformative ones.

extraction of informative genes
in order to test the ability of classifiers to separate informative genes from uninformative ones, we have looked at the result of the kolmogorov-smirnov test  on the ranking of genes according to their average error rate using a given model. using this algorithm, we calculated the p-value, ks test, and the result of investigating the differentiation hypothesis along with the models' bias or variance. the results of this investigation are displayed in additional file  <dig>  table s <dig> where cao and tomczak performed very well on cross-validation both in terms of bias and variance. however, models learnt on sartorelli fail to separate between informative genes and uninformative genes as the scores are generally very low.

generally, tomczak outperformed sartorelli and cao and can be chosen as the most informative dataset in this study. models learnt on tomczak generated the lowest bias and variance and produced the best separation. in contrast, sartorelli is the noisiest and less informative dataset while it failed to handle any increases in complexity  and generates models with highest bias and variance which also cause disability to separate informative genes from the others. now the question is whether we can use a simpler and cleaner dataset to model more complex ones. in the next section we show how we tackled this question.

analysis of the use of simpler dataset to model more complex one
in this section, we investigate the improvement or deterioration of genes selected by tomczak on the sartorelli dataset. figure  <dig> shows the average improvement or deterioration of ranks of myogenesis-related genes, top  <dig> genes , and  <dig> randomly selected genes  in sartorelli. we compared the original rank of each gene  with its rank based upon the ability of a model trained on tomczak to predict gene's value in sartorelli. moreover, we evaluate the improvement or deterioration of genes rankings in our model with the ones generated using the concordance model described by lai et al.  <cit> . we can clearly see that the model learnt on tomczak can capture the informative genes in sartorelli and improve their rank whereas uninformative genes have been pushed down  in the ranking by the classifier. additionally, the improvement is even more pronounced for myogenesis-related genes with  <dig>  places in average, which is significantly better than others with p <  <dig>  generated using ks test, and as expected top  <dig> genes has been improved by  <dig>  places. even though both methods perform similarly on improving the ranks of top  <dig> and deteriorating the ranks of  <dig> randomly selected genes, the improvement of ranks for myogenesis-related genes are much more pronounced in our model than in the concordance model .

myh <dig> and tor3a are two examples of significant improvements in sartorelli dataset. myh <dig>  which originally ranked  <dig>  improved  <dig> places to rank  <dig> . during the learning phase it has been linked to four other genes of which three of them are myogenesis-related. these genes, in both datasets, have direct correlations and can represent each other in terms of prediction and validation. however, tor3a has a very low rank in both dataset and yet improved  <dig> places from  <dig> to  <dig> . it has been linked to prune which also improved  <dig> places . all three genes mentioned above have been selected as informative genes from tomczak and yet placed into the bottom  <dig> due to the quality of sartorelli dataset. these were some examples of the ability of model to pull out informative genes from a distribution .

although the overall improvement on myogenesis-related genes is significantly high, we were concerned why this model failed to improve the rank of some genes like id <dig> which dropped from rank  <dig> in sartorelli to  <dig> . in the learning process, id <dig> has been linked to  <dig> genes which are: fabp <dig>  rbm <dig>  x <dig>  and slco3a <dig>  now in order to answer the question, firstly, we validate the relatedness of these genes to id <dig> in tomczak dataset to investigate if they are significant and can represent id <dig>  secondly, we study the expression level of these genes in sartorelli to identify the reason why this model failed dramatically in predicting the id <dig> value.

additional file  <dig>  figure s <dig> demonstrates the expression level of id <dig> along with its parent/children in both tomczak and sartorelli datasets. in tomczak we can clearly see that there is an inverse relationship between id <dig> and the other  <dig> genes which is very significant. while the differentiation state changes, id <dig> drops from the expression level of approximately  <dig> to  <dig>  and similarly its relatives show an increase of about  <dig> points in their expression values. this supports the assumption of the relatedness of these genes to id <dig> in the learning process on tomczak dataset. however, considering that id <dig> is still very significant in sartorelli, id <dig> parent/children show no variation and simply are not significant. as a conclusion, this model failed to predict id <dig> expression value and as a result the rank of id <dig> dropped  <dig> places most probably due to the quality and biological variation of sartorelli dataset. since we aim to overcome the lack of overlap on the gene regulatory network studies across species and platforms, the natural extension of the work in this paper would be to explore how this model can be used on datasets from multiple biological systems with increasing complexity. moreover, it would be valuable to consider methods such as model averaging  <cit>  that has been shown better generalization in classifier's accuracy. consequently, it improves the performance of classifiers in identifying the most informative genes and avoids deterioration of cases like id <dig>  furthermore, dynamic bayesian networks can be adopted when learning from time-series data in order to handle auto-regulation and feedback loops, two key components of regulatory networks in biological data  <cit> .

CONCLUSIONS
in this study, we have investigated a number of different bayesian classifiers and datasets for identifying firstly, subsets of genes that are related to myogenesis and muscle differentiation, and secondly the use of cleaner and more informative datasets in modelling more biologically complex datasets. we have shown that an appropriate combination of simpler and more informative datasets produce very good results, whereas models learnt on genes selected from more complex datasets performed poorly. we concluded that simpler datasets can be used to model more complex ones and capture the interactions among genes. moreover, we have described that highly predictive and consistent genes, from a pool of differentially expressed genes, across independent datasets are more likely to be fundamentally involved in the biological process under study. in three published datasets, we have demonstrated that these models can explain the myogenesis-related genes  significantly better than others  since the improvement in their rankings is much more pronounced. these results imply that gene regulatory networks identified in simpler systems can be used to model more complex biological systems. in the example of muscle differentiation, a myogenesis-related gene network may be difficult to derive from in vivo experiments directly due to the presence of multiple cell types and inherently higher biological variation, but may become evident after initial training of the network on the cleaner in vitro experiments. in order to validate our approach, firstly, we evaluated our model on synthetic datasets and secondly we performed comparisons between our approach and the method of lai et al.  <cit>  which we call concordance model. it is shown that our model performs comparably in improving the ranks of informative genes and deteriorating the ranks of uninformative ones, but that the improvement of ranks for myogenesis-related genes is much more pronounced whilst additionally modelling the interactions among genes. however, it is necessary to develop other statistical measures so that the model can be quantified to distinguish different degrees of complexities and platforms whilst handling the auto-regulation and feedback loops within the network.

authors' contributions
sya, pach and at contributed equally to methods development and drafting the paper. pach provided the biological insight on the datasets related to muscle differentiation. at designed the algorithms and sya developed the codes. pach and at supervised the study. all authors analyzed the data, read and approved the final manuscript.

algorithm  <dig> - multi data gene identification algorithm
input: {traind, testd <dig> ...testdm, folds}

   for k = 1:folds

      learn bn using algorithm  <dig> on training folds of

      traind

      score sse on test fold k of traind

      score sse on all independent test datasets

      {testd <dig> ..testdm}

   end for

   calculate variance of sse over all k folds

   on traind and {testd <dig> ..testdm}

   create gene rankings: trainr_sse, train_var,

   {testr_sse <dig> ..testr_ssem} and

   {testr_var <dig> ..testr_varm} by ordering the genes

   on the respective sse and variance scores

output:: trainr_sse, train_var,

   {testr_sse <dig> ..testr_ssem}

   {testr_var <dig> ..testr_varm}

algorithm  <dig> - simulated annealing structure learning
input: t <dig>  maxfc, d

   fc =  <dig>  t = t <dig>  tn =  <dig> 

   c = 1/maxfc

   initial bn to a bayesian classifier with no inter-gene links

   results = bn

   oldscore = score

   while fc < maxfc do

      for each operator do

         apply operator to bn

         newscore = score

         fc = fc + 1

         dscore = newscore-oldscore

         if newscore>oldscore then

            result = nbc

         else if r < edscore/t then

            undo the operator

         end if

      end for

      t = t × c

   end while

output: result

supplementary material
additional file 1
this file contains  <dig> additional figures illustrating the results of our study in full details, as well as more information on the generation of synthetic datasets and the results of the kolmogorov-smirnov test.

click here for file

 acknowledgements
this work was funded in part by a royal society international joint projects grant .
