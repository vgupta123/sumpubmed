BACKGROUND
massively parallel sequencing of rna, known as rna-seq, provides unprecedented access to sequence and expression variation in the transcriptome  <cit>  and allows for additional insights into alternative splicing  <cit> , cis vs. trans gene regulation  <cit> , and micro-rna dynamics  <cit> . rna-seq experiments for gene expression analysis typically involve mapping 10’s of millions of short sequencing reads onto the reference dataset  of a model species, whose genome has been sequenced and gene models determined  <cit> . as next generation sequencing becomes more affordable , rna-seq is becoming increasingly attractive for quantitative studies of differential gene expression in non-model species, for which there is often much knowledge of the evolution and ecology but little or no genomic resources.

the non-model species community is rapidly harnessing the transcriptome, with an explosion of rna-seq studies published over the past 5 years, predominantly using the longer sequencing reads of the  <dig> flx technology for the generation of est databases containing sequence and snp information  <cit> . this community is now also beginning to use the illumina platform with excellent results, further decreasing the cost for transcriptome database construction and snp identification  <cit> . however, although the illumina sequencing platform is the main workhorse for quantitative transcript analysis, only a handful of studies have begun to use this platform to study expression variation in non-model species , primarily due to concerns over read mapping accuracy in the absence of a genome scaffold . given that the number of rna-seq studies in non-model species is expected to rapidly increase  <cit>  there is a pressing need to assess the performance of rna-seq in the non-model species context.

a researcher wishing to conduct rna-seq in a species lacking genomic resources faces a series of currently unanswered questions. these initially are queries of how much data is necessary to produce informative significant results, the price of producing such data and what sequencing platform to use. there are also concerns over the quality of de novo transcriptomes and their utility as scaffolds for mapping rna-seq reads compared to a high quality genome, or indeed any genome for the target species. an additional problem faced by the non-model community is the ability to draw functional information from the de novo assembly and expression results. combining reads per gene and annotating assembly contigs can be achieved by using the genome or predicted gene set of a related species as proxy. however, the level of bias and error this introduces is for the most part unknown, as is the effect of evolutionary distance between the proxy reference and the study species. here we directly address these questions in detail using rna-seq data and genomic resources available for homo sapiens.

RESULTS
de novo transcriptome assembly and assessment
rna-seq data were assembled in various combinations into eight different transcriptome assemblies  to assess the relative performance of different sequencing technologies and their utility in combination. to clarify, a ‘read’ is the short sequence output of the sequencing platform . a ‘contig’ is a contiguous sequence formed from two or more reads that are found to overlap. three of the tas were assembled using three replicate paired-end illumina runs of similar size , ta_illpr <dig> , ta_illpr <dig> ). a fourth ta combined all of the reads from these datasets into one assembly . the fifth also used all of this rna-seq data and incorporated an additional illumina rna-seq dataset in order to determine the effect of increasing the volume of data upon assembly performance . the sixth ta was created using only  <dig> rna-seq reads , while the seventh used the three pairs of illumina data plus this  <dig> dataset . ta_all  was assembled using all of aforementioned rna-seq data .

standard metrics of assembly quality
we initially assessed the de novo tas by comparing several standard metrics commonly used in ascertaining the quality of an assembly  <cit> : total number of contigs; longest contig length; mean and median contig length; n <dig> ; and the summed contig lengths . the amount and type of rna-seq data incorporated into the eight tas and the basic assembly metrics are summarized in additional file  <dig> table s <dig>  for the three tas created using replicate illumina rna-seq data , each gave near identical performance to each other but were all consistently inferior to the other five tas in terms of the basic assembly metrics. we subsequently focussed upon quality comparisons of the remaining five tas: ta_illprs, ta_all_ill, ta_ <dig>  ta_illprs& <dig>  and ta_all .

an optimal assembly will have near full length contigs similar to that expected from the actual transcriptome of the target species. the basic metrics shown in figure 1a & b suggested that ta performance was best with illumina data alone. ta_illprs and ta_all_ill had the largest contig mean, median and n <dig> lengths, whilst also having the lowest number of contigs. these metrics indicate that the ta composed solely of  <dig> reads  was of poorer quality than those composed purely of illumina reads. the assemblies comprised of both illumina and  <dig> sequencing data  also had a comparatively small mean, median and n <dig> contig length. these hybrid assemblies also had the greatest number of contigs, containing more than twice as many as the tas solely composed of illumina reads. however, the optimal assembly will also have a large summed contig length, and this metric provided a very different set of conclusions . for summed contig length, the hybrid assemblies performed much better than the pure assemblies with summed contigs lengths of: ta_illprs&454:  <dig>  mb and ta_all:  <dig>  mb, both of which being approximately twice as large as ta_all_ill  and over twice the size of ta_illprs . thus, despite having larger contigs, the de novo transcriptomes composed of pure illumina reads were overall much smaller.

de novo transcriptome assembly coverage metrics
the contrasting insights provided by the basic metrics illustrate their limited utility. metrics based upon contig lengths  do not provide quantitative insights into how much of the target species transcriptome is represented in the de novo ta. for transcriptome assembly in the context of generating a scaffold for rna-seq mapping, optimising the representation of the transcriptome is critical since the only rna-seq data that is analysed is that which can be aligned to a scaffold. here we calculated several additional metrics to gauge the quality of a de novo transcriptome assembly by taking advantage of the genomic resources for homo sapiens.

we assessed the integrity and completeness of the tas in terms of their recapitulation of the h. sapiens predicted consensus coding sequence  gene set. first, we quantified the size of the coding region of the de novo tas in comparison to the summed length of all ccds . given that one or more ta contigs may align to a given ccds, we used blastn to identify these relationships and calculate the regions that were covered of each ccds by at least one ta contig. that is, we only took the length of the ccds that was covered regardless of the number of different ta contigs that covered those regions . compared to the total size of the h. sapiens ccds dataset, the hybrid assemblies ta_illprs& <dig> and ta_all performed the best, covering 61% and 64% of the total size of the ccds dataset respectively, while ta_ <dig> had the smallest transcriptome coverage at 38%. second, we counted the number of h. sapiens predicted genes  hit by a ta contig in blastn searches . the two hybrid assemblies had the greatest number of ccds represented: 75% and 76% of the ccds being hit by ta_illprs& <dig> and ta_all respectively. of note is that although ta_ <dig> was the smallest in term of coding size , its coverage of the transcriptome as estimated by the number of ccds hit by this ta was similar to both of the tas composed solely of illumina reads .

in determining how successful the coverage of the actual transcriptome was in the de novo tas created here, we first note that the transcriptome from one tissue type is expected to contain fewer transcripts than that of the whole organism. one study estimates a figure of 70% of the genes of an organism’s genome  <cit> . given that the ccds dataset represents the entire transcriptome, and the rna-seq data obtained for this study derives from sequencing a human brain sample, we cannot therefore expect a coverage figure near 100%. in addition the rna sample was not normalized, so the rna-seq data were likely to primarily contain highly transcribed genes and miss many lowly expressed transcripts. the largest ta, ta_all, is  <dig>  mb and hits  <dig>  ccds. this is 64% of the size of the ccds dataset  and comprises 76% of the ccds transcripts .

while these two measures, total coding size and the number of genes represented in each ta, are very informative, knowing the proportion of each gene covered by ta contigs is also important . we therefore calculated what we term the contig reference ratio  for each of the ccds to ascertain the actual coverage of the transcriptome for the different tas. the crr therefore is the ratio of the length of the ccds uniquely covered by ta contigs divided by the length of that ccds . this metric directly indicates the amount of sequence in the ta that is informative, as it is the coding regions that can be used to align to divergent species and identify synonymous and non-synonymous snps. we initially calculated the mean and median crr across the five tas to assess the average coverage per gene across the transcriptome . the mean and median crr values were fairly consistent between the different assemblies, with the exception of ta_ <dig> that had lower coverage per ccds and therefore would provide less sequence information per transcript. the remaining four tas all had very high crr median and mean values, showing that the majority of the ccds represented in the tas have very high coverage .

finally, a stringent assessment of assembly performance was performed by calculating the number of ccds represented in a ta which had a >=90% crr . the illumina only tas, and especially the ta composed solely of  <dig> reads, performed poorly in comparison to the hybrid assemblies. the results of this metric are particularly informative when looked at in conjunction with the number of ccds represented in each ta . although the number of ccds hit by ta_ <dig> was comparable to that of the two tas composed purely of illumina reads , we can see that of those ccds hit, the crr is much lower. indeed, of the  <dig>  ccds represented in ta_ <dig>  only  <dig> % had a crr of  <dig>  or greater. this explains the discrepancy of the results for ta_ <dig> of total size  and number of ccds represented . ta_illpairs had  <dig> % of  <dig>  ccds represented with crr > = 90% and ta_all_ill has  <dig> % of  <dig>  ccds represented with crr > =90%. using these ‘genomic’ quality metrics, we found that while the ta_all performed best, with  <dig> % of the  <dig>  ccds represented having a crr of > =90%, the other hybrid ta, ta_illprs& <dig>  was similar in performance with  <dig> % of the  <dig>  ccds represented having a crr of > =90%.

closer analysis of the number of genes represented in three of the tas revealed that although there is a large area of overlap in the ccds in common between ta_illprs and ta_ <dig> , the tas created from either illumina or the  <dig> data hit different areas of the transcriptome . there were  <dig> and  <dig> ccds unique to ta_illprs and ta_ <dig> respectively, suggesting that these different technologies sequenced different areas of given transcripts. this was assessed further by looking at the crr values for each ccds represented in the pure illumina ta , the pure  <dig> ta , and the largest hybrid ta . the crr of a particular ccds was often much lower in the pure assemblies compared to the hybrid assembly . when the  <dig> and illumina reads were combined in the other hybrid ta  the crr of a given ccds was much longer, indicating that these reads are providing complementary coverage rather than similar coverage of a given ccds, with the results comparable in coverage to that of ta_all . this is similarly true when we look at the crr of the single longest ta contig per ccds ; in the single platform tas, although the illumina data does generate longer ta contigs compared to the  <dig> data, their combined data results in tas that have a greater number of longer contigs per ccds. this derives from the much larger coverage of the transcriptome by illumina runs coupled with the ability of the assembler we used to pull that data together correctly into contigs. thus combining data from these two different sequencing platforms not only increased the number of ccds, it also increased the coverage within a ccds by bringing together contigs that hit different areas of that ccds. in addition, the hybrid transcriptome assemblies resulted in contigs being formed for genes that were not present in assemblies composed of one type of sequencing platform .

comparison of expression profiles produced using different de novo ta scaffolds
in order to assess the performance of the different de novo tas as scaffolds for rna-seq expression analysis, we compared the use of a ta as a mapping scaffold to that of a predicted gene set from the well characterized reference genome of h. sapiens. since our focus in this study was upon the utility of de novo rna-seq for quantifying whole gene expression in non-model species, we assessed the accuracy and efficiency of drawing together sequencing reads that are from the same gene to calculate an expression value for that gene. in the latter part of this paper, we explore this mapping relationship in the non-model species case of using increasingly evolutionary divergent species  for grouping contigs by putative orthology .

given the highly fragmented nature of de novo tas, many genes are likely to be represented by several non-overlapping contigs. using such a ta as a scaffold for mapping rna-seq reads will result in the mrna reads for a given gene being split among these contigs. thus, in order to create an expression profile at the whole gene level, which is equivalent to mapping rna-seq reads to a predicted full length gene model, contigs of the same gene need to be grouped in order to sum their rna-seq reads. comparing the expression profiles produced when using de novo assemblies as the mapping reference versus using the h. sapiens ccds dataset was achieved by using clc genomics workbench to map paired-end illumina to the ccds unique gene set and to two of the de novo tas. the two tas investigated in this part of the study were ta_illprs and ta_illprs& <dig>  since the former represents the data likely to be acquired from a given rna-seq experiment, while the latter represents a higher quality ta within the reach of most non-model research systems. reads mapped to the ta contigs were then assigned to ccds genes by assigning each contig of a ta to a single ccds via blastn .

we first assessed the effects of scaffold on technical replicate data using three pairs of illumina sequencing runs . each of these runs were independently mapped to both the ccds dataset and to the two tas . expression was initially measured as the number of unique reads that map to a whole gene. scaffold had little effect on technical replicates, with replicates having >  <dig>  correlation . these correlations were further investigated using a mva  plot  <cit> , which provides insights into abundance-dependent biases  <cit> . for this analysis expression was measured using rpkm  values  <cit> . as is typical for rna-seq technical replicates, agreement among replicates is highly dependent upon expression level, with low expressed genes showing less agreement among replicates  <cit>  and this effect was essentially identical across scaffolds .

we then compared the mapping of one set  of the rna-seq read data directly to the ccds dataset versus two of the tas to assess the performance of de novo tas for whole gene expression analysis. directly mapping to the ccds dataset recovered expression data for  <dig>  genes, while going through ta_illprs or ta_illprs& <dig> provided data for  <dig>  and  <dig>  genes respectively. however, of those genes  that did have expression data in terms of number of unique reads from both methods the correspondence between them was extremely high . expression as rpkm was also measured for one comparison – that of mapping to ccds vs. to ta_illprs& <dig> , the results of which also showed a high degree of correlation. a mva plot was used to further assess the relationship between the ccds and ta_illprs& <dig> mapping . the distribution of disagreement between the two mapping methods was not a function of expression since the ta_illprs& <dig> mapping had a higher level of expression than the ccds mapping across the range of expression values. two separate and technical causes were observed. first, calculation of the rpkm values for the ccds mapping used the length of the ccds gene, while for the ta_illprs& <dig> mapping, only the length of the ccds gene covered by the ta was used . this caused an inflation of the ta values. second, the two mapping approaches were different. the direct mapping only quantified the reads that mapped uniquely to a given ccds. although the ta mapping used the same approach for mapping rna-seq reads to the individual contigs of the ta, each contig was assigned to its best ccds blast hit. this approach allowed for the collection of 5’ and 3’ utr regions into contigs that also overlapped with ccds genes, significantly inflating the ta mapping reads.

using increasingly divergent genomic reference species for rna-seq analysis
for species lacking a well assembled genome, annotating rna-seq reads is problematic. one route is to map reads to a de novo ta and then assign each ta contig  to a unique gene through a blast search against the reference gene set of the nearest genomic reference species . however, the evolutionary divergence between the target species  and the grs is likely to be a significant source of bias and error. for genes with high rates of evolutionary change there is a decreased likelihood of successful homology matching between the ta contigs of the target species and grs gene. it is therefore expected that as evolutionary distance increases, the ability to group contigs to a particular gene will decrease and potentially be accompanied by an increase in incorrect assignment of contigs to putatively orthologous genes. in addition, with increasing evolutionary distance, the most accurate expression information is likely to come from a biased set of genes, notably those having a high level of expression and low rates of evolutionary change . here we explore the magnitude of this effect by studying the decrease of information content and accuracy of rna-seq data gene assignment with the use of increasingly divergent grs as proxy references.

six species of increasing divergence from h. sapiens were chosen as genomic reference proxies, spanning a range of  <dig> to  <dig> million years divergence. this range was chosen as a likely range researchers may encounter in their choice of a grs. rna-seq reads were mapped to the most cost effective de novo ta that also performed well  and each contig from this assembly was assigned to the predicted genes from each divergent species using blastx . the orthology relationships were also determined between the h. sapiens ccds and grs gene sets using the reciprocal best hit method  <cit>  via blastp . the results of using these grs proxies were then compared with directly using the predicted gene set of the target species .

transcriptome coverage when using proxy grs
we first assessed the utility of the grs grouping approach by calculating the number of grs genes that hit the de novo ta using blastx . there is no appreciable difference in the number of genes of chimpanzee, orangutan, macaque and marmoset and that of the human dataset  that have ta contigs assigned to them. however, there is a decrease in the number of genes that have a ta contig hit when using the mouse gene set and a further drop when using platypus. there is thus a decrease in the number of genes that can be identified in the de novo transcriptome with evolutionary divergence, however this effect is only observed at the high end of divergence.

effect of using proxy grs on expression signal: introduction of error
in order to determine how much expression signal is lost via reduced contig assignment when using divergent species as proxy references, expression values were calculated for grs genes that are both represented in the de novo ta and have an rbh ortholog in the ccds dataset. by grouping ta contigs that hit grs genes orthologous to ccds, we could compare the expression signal between mapping to a ccds via a ta  and to the grs dataset via a ta . the correlation is fairly high for all taxa  except platypus . thus, while there was some loss of expression signal , using the grs as’gene’ grouping proxies was still informative.

in order to explore sources of error when using increasingly divergent grs proxies, we further examined the differences in expression values obtained via mapping ta contigs to the ccds or via one of the grs . points above the line of unity would be ccds that have fewer contigs assigned to it through utilisation of grs to annotate the ta. points below the line of unity, as well as some above it, are ccds that have contigs wrongly assigned to them during the blast search, resulting in a greater number of reads than the direct ccds mapping method. the extent of this error can be calculated by identifying the true subset of grs genes that are orthologous to human genes in the ccds dataset. since we previously assigned, via blastn, ta contigs to ccds genes, and have established ccds to grs rbh orthologs with high confidence using blastp, whether a given ta contig assignation to grs gene was correct can be determined . the blastp rbh between the grs and ccds datasets was assumed to be robust and so if a contig was wrongly assigned to a ccds , it is likely that blastx is the source of error.

the level of error  was found to increase as evolutionary distance from human increases . the error for chimpanzee was fairly low, at  <dig> %, and similar to orangutan , macaque  and marmoset . utilisation of mouse resulted in  <dig> % of the contigs being wrongly assigned, while for platypus error increased massively to  <dig> %. as mentioned above, error is likely to occur during the blastx of ta contigs and grs genes . we investigated whether increasing the stringency of the blast parameters decreased the level of error for two of the grs: chimpanzee and mouse. in both cases it did, with chimpanzee now having  <dig> % error, and mouse  <dig> % error. as expected this decrease was highest for the more divergent mouse. a repercussion of increasing the threshold identity in the blast searches is that fewer genes were annotated in the de novo ta ; mouse:  <dig> . the blastx parameters used must therefore be a tradeoff between the size of the transcriptome that can be annotated by using a divergent grs, and the level of error accepted.

ascertaining the level of bias when using proxy grs
we further investigated the potential sources of error and bias by gene set enrichment analysis using the go and kegg functional categories of the human ccds genes . first, we assessed whether there was any bias in the grs genes identified as ccds orthologs by ta hits of the grs datasets. for all the taxa investigated we observed a significant bias in many functional categories although there is no significant pattern of an increase in this bias with evolutionary divergence. however, when only genes that had no contigs incorrectly assigned to them were analysed a different picture emerged . first, there was an increase in the number of biased functional categories for all comparisons, although this was modest for most taxa. second, there was an increase in bias with divergence that mirrored the pattern of error. this trend was mainly due to the highly divergent platypus, where the number of biased functional categories rose from  <dig> to  <dig> when error was removed. this pattern suggested that the increased error in the most divergent species masked the higher bias in those species.

next we investigated bias in the gene expression results from the two different mapping approaches. we took the residuals from a fit of expression levels from the direct mapping of ta  to ccds against the expression levels obtained using grs proxies to annotate the ta contigs. residuals had a value of  <dig> when genes had identical expression levels in both methods. residuals were positive when they had fewer reads mapped to them from the method using grs proxies to annotate the ta contigs, and residuals were negative when ccds genes had more reads mapped to them using the grs proxies to annotate the ta contigs method. we expected that highly expressed and evolutionarily conserved genes would be over-represented among those having a residual of  <dig>  and that this bias would increase over evolutionary time. we therefore assessed whether there was any unequal distribution of gene functional categories among those having residuals =  <dig> vs. those having residuals ≠  <dig>  we found that there is a significant bias in a low number of functional categories for all taxa, except in platypus where the number of biased functional categories increases threefold above mouse . when investigating whether there was a difference between positive and negative residuals, we found no biased categories in any taxa .

our final analysis looked at general trends in the types of functional categories that were over and under-represented in our analyses . mitochondrion  and protein binding  categories were nearly always over-represented when using grs to annotate ta contigs, and in comparisons with platypus, transcription and translation related categories , rna splicing , ribosome ) were also over-represented. typically under-represented categories included a diversity of biological functions, from sensory perception of smell  and defence response to bacterium , to signal transduction . in general then, it appears that genes in the over-represented category, primarily represented by comparisons with platypus, included genes with very conserved housekeeping functions, while those being under-represented included categories of genes known to undergo more complex evolutionary dynamics .

discussion
analysing rna-seq data for gene expression has traditionally required genomic resources for the species of interest in order to map and annotate reads. greater sequencing depth and read length, more advanced assembly software  <cit>  and most importantly, lower costs, now make rna-seq an attractive alternative to designing and using custom microarrays for researchers wanting to study the transcriptomes of species that don’t have genomic resources. for such non-model species one route to using rna-seq for expression insights is to perform de novo transcriptome assembly and use this assembly as a scaffold for quantitative rna-seq mapping. while this has been done using the  <dig> platform , the small number of reads typically provided per run  makes this perhaps only accurate for the most highly expressed genes. currently in the literature there is much discussion about how many rna-seq reads are necessary to generate repeatable quantitative measures for middle to low expressed genes, with emerging empirical results suggesting at least  <dig> to  <dig> million reads are necessary . this strongly suggests that using the illumina platform, which can provide two orders of magnitude more reads for less than half the cost of the current  <dig> technology, is the best way forward for quantitative expression analysis. thus, here we have assessed the performance of illumina sequencing data in the non-model species context.

to date, only a handful of studies have applied the illumina approach for quantitative rna-seq expression analysis in non-model species. in their investigation of the transcriptome profiles of parasitized vs. non-parasitized plutella xylostella moths, etibari and colleagues assembled all of their illumina reads into a de novo transcriptome and consequently used this as a scaffold for mapping their differently parasitized groups. annotation of the p. xylostella transcriptome used a blast search in ncbi  <cit> , allowing them to identify differential expression of many metabolic and immune genes. a different study developed a pipeline that facilitates the assembly and annotation of non-model species transcriptomes through utilisation of the genomic resources of related organisms. this method allowed the researchers to perform expression profiling and also to increase the quantity and quality of sequence data available for their targeted species, the chinese hamster  <cit> .

the current study was motivated by questioning the general accuracy of the de novo approach exemplified by these two studies. while their conclusions are well justified, here we have worked to attain a deeper understanding of the potential errors and biases that might underlie such analyses. one major concern is the level of bias in the genes that are finally included in the analysis. genes assembled and annotated are not likely to be a random sample of the genome, since highly expressed genes will likely be assembled and annotated best. etibari et al.  <cit>  found no bias in go terms between their de novo transcriptome assembled for p. xylostella compared the silkworm bombyx mori, which diverged approximately  <dig> million years ago . however, the go terms that are liable to be shared between these two lepidoptera are themselves likely to be highly biased, as the greatest number of b. mori genes having annotations are those in common with the genomic reference species drosophila melanogaster. given the deep divergence of d. melanogaster from b. mori, which last shared an ancestor approximately  <dig> million years ago , the only genes likely to be functionally annotated are those with highly conserved function and constrained evolutionary dynamics. such housekeeping genes are thus very likely to be those highly expressed in p. xylostella, and thus unbiased with respect to the annotated genes in b. mori. the birzele et al.  <cit>  study used velvet to assemble their transcriptome. this is of concern given recent comparative assessment of transcriptome assembly software packages, which found velvet to perform among the worst software programs for use upon their transcriptome dataset  <cit> . we therefore wished to use an assembler which had previously been shown to perform well  <cit>  and so chose the clc method.

in order to assess the performance of rna-seq, we addressed several steps of this approach, beginning with de novo transcriptome assembly. the effect of sequencing technology and volume of data upon the quality of the de novo ta was assessed by comparing  <dig> different tas using rna-seq data for h. sapiens. in comparison to previous examinations of assembly performance that have used simulated data  <cit> , using data from h. sapiens gave us a unique combination of genomic insights and real world data. we find, as have others, that the standard metrics commonly applied may lead to a sub-optimal choice of ta  <cit> . while metrics solely based on contig lengths suggested that tas composed of only illumina reads performed best, in-depth investigation using genomic resources showed a different picture. by using blast to identify putative orthologous relationships between ta contigs and the predicted gene set of humans, the aligned region between the two could be determined. by dividing this aligned length by the full length of the predicted gene provides a ratio indicating how much of the coding region a ta contig has successfully reconstructed. here we have used this approach to calculate the entire amount of the predicted gene covered by all the different ta contigs in a given assembly, and referred to this as the contig reference ratio . after such comparison between ta contigs and their putative ortholog appeared in the first de novo transcriptome assembly  <cit> , similar ratios have been developed . we find the three most informative ratios are for: 1) all possible ta contigs , 2) the longest ta contig per ortholog , and 3) the sum of the ortholog length covered by all the ta contigs, which is then divided by the full length of the ortholog . while informative, all crr, which was used by o’neil et al.  <dig>  <cit> , inflates assumed ta performance since several contigs for the same gene may be quantified while providing no information as to the total amount of each ortholog a given ta covers. longest crr is perhaps the single best metric for assessing ta performance. ideally, the best ta would predict single contigs that covered the full length of each transcript, as well as the different isoforms, without any over prediction. here we have used the longest crr only once, for assessing our tas  and this provided very similar insights to that of our sum crr results. throughout our paper we have almost entirely used a sum crr because we wish to know how much of each gene we have covered in our ta, since maximizing coverage is necessary in order to generate a good scaffold for mapping the rna-seq data and this information is combined on a per gene basis.

availability of the ccds predicted gene set allowed us to ascertain the level of ta coverage for each gene. although pure illumina-based tas had fewer and longer contigs than both the pure  <dig> ta and the hybrid tas , the pure illumina tas also had a much lower coverage of the transcriptome compared to the hybrid assemblies, at both the individual gene and total transcriptome level.

using the hybrid ta as a scaffold produced rna-seq mapping results that were similar to directly mapping to the ccds predicted gene set from the h. sapiens genome. although there were approximately  <dig> fewer genes mapped when using the ta as compared to the ccds gene set, the correlation in whole gene expression values between these two methods was extremely high . similar high levels of correlation were observed across technical replicates when mapped to the hybrid ta assembly. while additional improvements could be made in the de novo approach, the correlation between the two approaches is already much higher than that observed in comparisons between rna-seq and microarray results . thus, hybrid ta assemblies, combining illumina and  <dig> reads, emerge as the best assemblies and scaffolds for rna-seq mapping. we should note that this study has utilised illumina rna-seq data that was available at the time, technology is advancing at a rapid rate and the quality of de novo transcriptomes that can be assembled with the latest sequencing data  will likely surpass what we show here. thus this study should be taken as a comparative study, and a conservative guide.

after mapping rna-seq reads to a ta , the contigs need to be assigned to genes for grouping and functional annotation. in non-model species, the ability to obtain significant biological insights into gene expression variation is limited by gene functional annotation. in model systems obtaining gene expression values and assigning these to a growing number of genes of likely biological function is well developed. non-model systems necessarily must tap into this reservoir of data using blast and assumptions of gene function homology, and the genome or gene set of a related but potentially very divergent species. while this approach can be successful , what effect does increasing evolutionary distance from the focal species have upon functional insights?

gibbons and colleagues investigated the accuracy of ortholog prediction between increasingly divergent species, using rna-seq data from one species and genomic proteome data from a grs  <cit> . they observed a decrease in the number of successfully identified orthologs  with increasing divergence. their study spanned a time-frame of  <dig> million years from the target species, with the two youngest grs being  <dig> and  <dig> million years divergent from the focal species. here we sought to investigate whether a negative effect of divergence is observed within the 0– <dig> million year time frame. although we expected that as evolutionary distance increased between the grs and h. sapiens there would be a significant decrease in the number of genes in the grs gene sets that found a hit in the de novo ta, this effect was weak up to  <dig> million years of divergence . a similar effect was observed when assessing the amount of each gene that was covered by ta contigs. thus there is little negative effect of using grs as reference datasets for the grouping contigs as divergence increases up to  <dig> million years, although beyond this age, the number of genes having good coverage assigned decreases.

these results also suggest that the use of proxy grs up to  <dig> million years divergent from h. sapiens for grouping ta contigs might result in only a small bias on expression levels compared to directly mapping rna-seq reads to the ccds dataset. within this time frame proxy grs are also likely to enable successful measurement of expression levels as a high correlation in expression between these two methods was found in all cases, even when comparing mus musculus , which is c. 75– <dig> million years divergent from h. sapiens . while this effect was moderate using grs species up to  <dig> million years divergent, comparisons using platypus as the grs showed both a dramatic increase in incorrectly assigned ta contigs and a lower correlation with the ccds mapped expression values . this identified error was mirrored in the gene set enrichment analyses, as incorrect contig assignment should be greatest for genes that have higher evolutionary rates, or conversely, lower for constrained genes . error is likely to accrue during the blastx search of the ta contigs against the grs dataset, and indeed when this blastx was repeated for two of the grs using more stringent parameters of identity less error was encountered. however, a repercussion of this was reduced coverage of the transcriptome in terms of genes that could be annotated.

several important limitations of our approach should be noted. first, there are certainly many species that do not have a genomic reference species less than 100my. while our approach would certainly aide such projects, researchers should be aware of the error and bias inherent in such analyses. fortunately, as the genomics era progresses available genomic reference species will increase. second, a large class of genes will lack homology between species, and this will increase with divergence. such orphan genes are likely to be involved in species-specific adaptations and potentially the most ecologically and evolutionary interesting aspects of a species transcriptome . therefore, there is a high likelihood that insightful results reside in careful analysis of that part of the transcriptome that does not hit a proxy reference genome and for which no known biological function is established. our analyses suggest that de novo analysis of orphan genes will be most insightful when such genes are assembled to their full length. careful examination of ta contigs for long open reading frames flanked by both 5’ and 3’ utrs may prove useful for such assessment . overcoming the bias against studying orphan genes is a challenge facing the entire research community.

a third limitation arises due to variation in recent gene duplication events among individuals, commonly referred to as copy number variants . when young, cnvs can be very difficult to detect in rna-seq data. when mapping rna-seq reads back to a full genome, which is usually derived from a single individual, differences among individuals in their cnv with reference to the genome can result in reads from several independent loci being mapped to a single locus, resulting in a spuriously inflated measure of single locus expression. this is certainly the case in the de novo approach we use here to obtain whole gene expression levels, as the contigs we assign to the same gene may derive from incomplete transcript assembly as well as recent duplication events. expression differences detected between biological groups using this whole gene approach necessarily must be studied in more detail, to assess the causal basis of the signal. we argue that this is true in both model and non-model systems alike, where there are likely to be significant differences between the scaffold genome and the individuals having their rna sequenced. finally, this is similarly true for splicing isoforms, as our whole gene approach pulls together expression across exons for the entire gene. to the extent that differences among groups arise from expression differences solely in specific exons, this will give rise to expression differences that necessarily must be investigated further to determine whether this difference is evenly distributed across the entire gene. a final point of importance is regarding the choice of transcriptome assembler. many papers are still emerging where groups have used poorly performing assembly software to assemble their transcriptome data. our results might not be obtainable with such software, especially as few programs handle hybrid data well. thus we encourage researchers to be aware of the latest advances in transcriptome assembly and use methods shown to perform well with their generated data  <cit> . in sum, our whole gene expression quantification provides a robust starting place for the identification of gene expression differences whose biological basis will require more detailed study, as should be common in any rna-seq study regardless of genomic resources.

CONCLUSIONS
our findings indicate that rna-seq data from non-model species can be successfully de novo assembled into quality transcriptomes. these assemblies can then be used with high performance, as scaffolds for mapping rna-seq read data for quantitative whole gene expression analyses. in order to functionally annotate de novo transcriptomes, proxy genomic reference species up to approximately  <dig> million years divergence from the target species can be utilised, generating results similar to those produced from using high quality predicted gene sets as scaffolds. although there is a reduction in the size of the annotated portion of the transcriptome assembly when using proxy reference species, and there is a significant amount of error, these effect sizes are relatively small until past 100my divergence. the use of more stringent parameters in blast searches reduces this error, but this also decreases the number of genes that are able to be annotated, thus producing a trade-off researchers should be aware of. the level of bias in the genes that are able to be annotated in the resultant transcriptome is also an important consideration, as highly divergent  genes are potentially missing from the analyses. as sequencing technology advances, as it will already have done since this study, the quality and amount of rna-seq data that will be produced and the ability of researchers of all disciplines to assemble and annotate transcriptomes of non-model species will increase dramatically, making all species amenable to such studies in the future.

