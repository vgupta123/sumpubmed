BACKGROUND
bioinformatic analyses involve a range of tasks and processes. diverse programs have been written for various bioinformatics applications using every available language. because of the size of bioinformatics datasets, computation time is not trivial, and efficiencies in computational speed are desirable. comparisons of the algorithm accuracy of different programs that undertake similar tasks have been published  <cit>  allowing assessment of the best algorithms to use for specific tasks. however, it is possible that the same program, written in different languages, or running under different operating systems, may exhibit significant differences in speed and efficiency. there is, at present, little direct data on the underlying speed and efficiency of equivalent algorithms written in different languages. while languages themselves have been benchmarked, such comparisons have not been done using algorithms that are relevant to bioinformatics  <cit> .

a typical bioinformatics program reads fasta files, holds the dna sequences in memory, performs different computing tasks on the sequences, and finally writes the results to a file. another common task in bioinformatics is text mining or text parsing. large amounts of data can be generated in different formats. because file formats can be different, linking programs in a pipeline is difficult, hence scripts are written to act as interfaces between programs performing the sequential parts of an analysis. scripts are also used to extract information from large data files, thus enhancing the presentation of results. these quick scripts are usually implemented in perl or python. consequently, any bioinformatics procedure has a number of areas where programming might be improved, these being: the space required to temporarily store data, the speed of computation, linkage between programs, and presentation of analyses.

in this paper we examined three commonly used tasks in biology, the sellers algorithm  <cit>  the neighbor-joining nj algorithm  <cit>  and a program parsing the output of blast  <cit> . in each case we tested the programs using different languages. this benchmark was conducted on both linux and windows, since the computer used had a dual boot. there were several reasons for this benchmarking exercise. we specifically wanted to determine if c would be faster than java for performing recombination detection, which is an inherently difficult computational exercise. we also wanted to examine the memory requirements of each program/language combination, since although memory capacity increases constantly and hardware gets cheaper, the large datasets in bioinformatics analyses can be a problem for desktop computers. we also wanted to compare a script language, such as perl, with the compiled languages java and c. to complete the comparison, "rival" languages were also included. these included c++, c# and python. the languages selected for this study were chosen on the basis that they are the most popular and frequently used for biological applications.

python and perl are often called script languages and when executed, are compiled in an intermediate representation without creating an intermediate file  and then interpreted. both languages use automatic memory management and have large free libraries. they are suitable for web scripting , parsing and pipeline implementation such as interproscan  <cit> .

c and c++ are fully compiled languages, suitable for system-intensive tasks.

java and c# are semi-compiled languages using automatic memory management. a java program is compiled in an intermediate-level code or bytecode then it is run by either an interpreter or compiler at runtime, in this case, the java virtual machine . in c# the intermediate-level code is called microsoft intermediate language and is run on the .net common language runtime engine.

volunteer projects have produced libraries or modules for biologists. the most popular open source projects, which are incorporated in the open bioinformatics foundation, are bioperl, biopython and biojava  <cit> .

RESULTS
the languages we investigated can be divided into  <dig> groups: the script group of perl and python; the semi-compiled group of java and c#; and the compiled group of c and c++.

firstly we compared languages within groups, then we compared the groups to each other , and finally we compared speed performance between windows and linux. in this paper we will refer to ease of coding as the number of coding lines needed to write a program, taking into account the availability of libraries, which is a factor in the number of coding lines needed for compiling a program.

perl versus python
perl clearly outperformed python for i/o operations. perl was three times as fast as python when reading a fasta file and needed half of the space to store the sequences in memory . from the results of the global alignment and nj programs python appeared to have better character string manipulation capabilities than perl. even though the nj program required reading a file, where python did not perform well compared to perl , the computation of the dissimilarity matrix was actually the most discriminating task, since more than 90% of processing time was taken up by this step for every language except c, where it took up 75% of processing time.

python was the worst performer for parsing a blast file , taking more than  <dig> minutes to process the file compared to perl, which took only  <dig>  minutes. this difference did not arise from any inability of python to handle large files, since it took only  <dig>  minutes to read the file without processing the lines. perl accomplished the same task in only  <dig>  minutes.

perl emphasizes support for common application-oriented tasks, by having built-in regular expressions, file scanning and report generating features. python emphasizes support for common programming methodologies such as data structure design and object-oriented programming.

java versus c#
c# appeared to require less memory than java for holding strings in memory, as demonstrated when reading dna sequences from a file . c# also needed less time to read this type of file. interestingly, java was slightly faster in the global alignment program  but much slower in the nj program . java regular expression implementation appeared to outperform c# . this difference did not arise through any inability of c# to handle large files, since it read these files faster than java did. java needed  <dig>  minutes whereas c# took only  <dig>  minutes to read the same file.

c versus c++
the performance of c and c++ was very similar . this is perhaps not surprising since c++ is an extension of c. when a c program was compiled with the c++ compiler we obtained near-identical results, but when c++ standard libraries  were used, the performances tended to slightly deteriorate. it is important to note that tokenization was twice as fast as regular expressions for parsing the same blast file, but it took more time to write the program using tokens.

group versus group
the global alignment example demonstrated that the semi-compiled languages  were nearly as fast as the compiled group , whereas the interpreted languages  were sixty-fold slower . in the nj program, the performance of c# was similar to c and c++, while java took significantly more time .

the biggest drawback for semi-compiled languages is their memory usage, since they required about  <dig> times more memory than c and  <dig> times more memory than perl .

java and c# appeared to be a compromise between the speed of c/c++ and the ease of coding of perl/python.

surprisingly, java performed better than perl during the regular expression benchmark.

in java it is possible to embed c code to enhance the efficiency of a program using java native interface  extensions. the equivalent in perl would be the external subroutine  extension. for example, the core of the nj program was written in perl, but when the subroutine calculating a pairwise comparison was written in c, it sped up the program from  <dig>  seconds to  <dig>  seconds. jni improved this speed to a lesser extent, from  <dig>  seconds to  <dig>  seconds. any loss of portability was compensated for by the gain in performance, since there was no need to rewrite the entire program.

windows versus linux
the relative performance of the tested languages did not change on windows but the overall performance changed depending on the program compared. only c# and python appeared consistently faster in every program on windows. in the global alignment program all the implementations performed better in the windows environment . in the nj  and the blast parser , c and c++ were both slower on windows whereas on windows, java and perl were faster in the nj example  but slower in the blast parser example.

the comparison of linux and windows has to be carefully interpreted, since the compiler implementations are different, as well as the operating system running them. in the end, speed and memory usage are the critical factors, since the user is looking for performance in the programs, not more generally in the os or compilers.

case study: blast server
a fast and memory efficient program can make a significant difference when running on a public server such as blast, which is queried millions of time a day. the obvious choice for such a computer intensive program was to use c with perl cgi for the web interface. if we consider that perl was nearly  <dig> times slower than c in the global alignment benchmark and that a query sequence of  <dig> nucleotides against the non-redundant database took roughly  <dig> seconds , then if the query is submitted a million times during the day, the total computation time would have increased  <dig> fold, taking considerably more server time. the same observation would apply for the memory usage. after choosing the appropriate programming language, it is also important to keep improving the base algorithm. new algorithms for analyzing phylogenetic relationships have reduced computing time from weeks to days, or even hours  <cit> .

discussion
all the programs examined here were written by the same programmer with different levels of experience in java, perl and c++. the other languages were implemented while learning them. even though the semantics of these languages is similar, since c influenced c++, c#, java, perl and python directly or indirectly, the philosophy of some of the languages is different and programs should be implemented according to the language paradigm. for example, perl programmers favor hash tables to arrays, coupled with a loop which is more widely used in c. it is also important to keep in mind that the hash function can be costly when adding a new value and the memory allocated would be larger than an array containing the same number of elements. the advantage of a hash table is the speed in retrieving some data, but when the programmer needs to examine sequentially all the values in the hash table, then a hash table should be avoided because of the extra cost occurring when adding the key-value pair. in the perl nj algorithm an implementation using an array to store the sequences appeared to be faster and more memory efficient than a program using a hash table. hence no hashtable was used in this benchmark. there is an important tradeoff between performance and convenience. perl and python allow reading and loading a file in memory in one statement. while this approach is convenient compared to reading and processing a file line by line, the operating system could start swapping memory out, thus slowing everything down.

object creation, garbage collection and memory recycling are costly in terms of cpu and memory usage, hence some precautions should be taken when creating objects and the number of objects should be reduced as much as possible. to prevent memory leaks or heavy applications, objects should also be reused when possible and immutable objects such as the string object in java should be avoided especially when temporary objects are created in frequently used routines. c# and java have a higher memory-size penalty for objects than other object oriented languages such as c++ due to their ability to use reflection. reflection is a powerful tool that contributes to the flexibility of these two languages. however this feature should only be used when needed, since reflection method calls have a substantial performance overhead, make the code harder to understand and errors are found at runtime instead of compile-time.

the way objects are accessed and stored in memory influences the performance of each language. c++, c# and java store objects as a block of data and access them via constant offsets, whereas objects in python are implemented as hash tables. there are several ways to create objects in perl. different data structures can be used, but most programmers use hashes, even though arrays are faster, prevent attribute collisions and take less memory.

it is worth noting that the perl implementation of the nj algorithm was substantially improved by converting each sequence to an array instead of using the substr function on the string of characters for computing the similarity matrix. although the program was 10% faster, the memory footprint showed a ten-fold increase.

expressiveness
the number of lines in a program varies from one programmer to another, and also on their willingness to shorten the code to the detriment of readability. it is important to emphasize that it is hardly possible to find a correlation between expressiveness and performance. nevertheless, a noticeable difference was observed , especially with regular expressions. in perl, a unique statement can be used to detect a pattern and the captured pattern is retrieved with the special variable $ <dig>  whereas in java the programmer has to instantiate a pattern object which is a compiled representation of the regular expression, then create a matcher object which performs match operations on a character sequence by interpreting the pattern object. the following examples illustrate the retrieval of a gi number from a fasta file:

perl:

print $ <dig> if/);

java:

pattern p = pattern.compile");

matcher m = p.matcher;

if) system.out.print);

language philosophies often explain differences in the relative expressiveness and readability of languages. for example, the philosophy of python is to take the clearest, simplest and most straightforward approach to writing a program, and to accept the resulting performance penalty. whereas perl gives more freedom to the programmer resulting, in some cases, in programs that are unreadable for non perl programmers.

factors such as performance and memory usage are important, but need not be the sole determinant when choosing a language. since time management is also an important factor, a language can be chosen for its library, future scalability, active community and interface to other languages.

while it is hard to define a learning curve for each language, advantages and disadvantages of each language can be found. memory management such as memory allocation makes tasks easier for java, c#, perl, python and perl programmers, even though memory usage should always be under scrutiny. the use of pointers in c and c++ can be overwhelming for a learner, and it may take some time to master their use. python is designed to be a highly readable language, frequently using english keywords, whereas the five other languages use punctuation.

platform independence can be a factor for choosing a language and can also facilitate its learning. java uses a virtual machine to run on different operating systems and since perl and python are stored in a text file and not in a binary file these scripts can be run on any computer having the appropriate interpreter.

the standard library diversity and size of java, python and c# are a major advantage compared to the other languages,. including sets of classes to create graphical interfaces, data structures , regular expression, database access and networking.

although the perl standard library appears smaller compared to java, python and c#'s, it benefits from a large community of programmers creating modules gathered by the cpan network  <cit> .

c has a very limited standard library supporting input and output streams, memory allocation, mathematics, character strings, and time values. the c++ library contains the c library as well as a class to manipulate string of characters and the standard template library containing containers or data structures such as algorithms, an improved string library and input/output stream libraries.

as shown previously in the global alignment example, java and perl can communicate with a program written in c, speeding up the program using jni and xs respectively. for example, if a computer intensive command based program written in c needs a graphical interface, an easy solution would be to use the swing library and the jni framework instead of rewriting the whole program in java. the possibility of a language to language interface is useful when some code is already written in one of them.

as well as c, the jni framework allows java to interact with c++ and fortran. the downside of this approach is the loss of portability. java can also interact with python using jython, which is an implementation of python in java.

some bioinformatics tasks, such as loading a fasta file or parsing a blast file, are so frequently used that it makes sense to reuse bits of code by creating libraries or modules. many programmers produce modules for the bioinformatics community and make them available through their websites. the most widely used libraries are bioperl, biopython and biojava. these open source projects belong to the open bioinformatics foundation and they provide toolkits with multiple functionality that make it easier to create customized pipelines or analysis.

unfortunately libraries with this level of organization and diversity are not available for c, c++ and c# even though some small libraries are available independently  <cit> 

in this paper we focused on the performance of languages, not on the performance of the algorithm implementations. for example the speed of the alignment program could be improved by using a one-dimension array of size n × m instead of a 2-dimensional matrix of size n × m. this approach would speed up the memory allocation, but this was not the goal of this benchmark.

in this paper, to find the fastest implementations we used profiling tools included in libraries or using compilation/execution options. profiling provides important information about applications, such as memory usage and the fraction of time spent in each function. by using profiling and a trial-and-error approach programs were significantly improved. we used the devel::dprof library in perl, the xprof option in java, the cprofile module in python, the default profiler in c# using -profile = default and the -pg compiler option coupled with the gprof program in c and c++.

CONCLUSIONS
as expected, c was the best performer in this benchmark, in terms of both speed and memory usage. but to achieve such performances generally requires more code because of the reduced standard library. this benchmark is only a preliminary test involving a limited number of analysis types. comparisons using different programs may change the relative performance of the languages. graphic interfaces are very important in biology, hence it would be interesting to compare the libraries available.

the best choice of language for a task would be according to the original philosophy, keeping in mind that java is portable web oriented language, perl is a powerful script language, python is an easily coded language and c and c++ are efficient languages used in operating systems and drivers.

performances can also vary depending on the compiler and version used. sun is constantly improving the java compiler and interpreter and other jvm implementations are also available such as kaffe  <cit>  and ibm's.

the primary motivation for this benchmark was to compare a recombination detection program in java and c. the recombination program written in java ran in  <dig> minutes and the new version in c ran in  <dig> minutes with the same dataset and the same parameters. this test involved some hundreds of sequences and a single gene target. given the rapid improvements in high throughput sequencing technologies, it is likely that tests involving orders of magnitude more sequences will be conducted in the future. savings in computing time will be essential for such analyses to be efficient.

