BACKGROUND
cell divisions and their regulation play important roles in disease and development. the cell cycle can be divided in two main periods: interphase and mitosis. during interphase the cell grows, duplicates its dna and accumulates nutrient and gene products required for mitosis. during mitosis, the cell splits itself and divides the genomic dna between the two daughter cells. the mitosis can be further subdivided into several distinct phases: prophase, metaphase, anaphase and telophase. the cell phases can be identified by their appearance in high resolution microscopy images. figure  <dig> shows examples of the typical appearances of the chromatin marker histone-gfp in different cell cycle phases. automated cell phase classification is an essential step in high-throughput image analysis of large populations of cells that enables quantification of cell cycle progression, which is very important for developmental biology, cancer cell study and drug discovery. for instance, measuring the duration of individual cell cycle phases under different genetic and drug treatment conditions can improve the understanding of biological mechanisms in oncological diseases and enhance the effectiveness of drug discovery and development  <cit> . cell phase classification is crucial for high-throughput image based screens, such as the mitocheck project that are aimed at identifying and characterizing genes involved in cell division  <cit> . several bioimaging research groups have addressed this challenging problem  <cit> . most studies involved 2d images  <cit> . one study dealt with 3d images, but cellular features were extracted from the most informative single slice  <cit> . dynamic features have been widely used for cell phase classification  <cit> , however as mentioned by  <cit> , tracking algorithms become less reliable and context information becomes less informative when the cells are densely populated or/and move at fast velocity. in recent years, confocal laser scanning microscopy  has become a common imaging modality to visualize fluorescently labelled cells in 3d. the extra dimension compared to conventional 2d microscopy promises to enhance the understanding of bio-molecular mechanisms. another application of automated cell cycle phase identification is the improvement of cell tracking in the analysis of time-lapse images. in live tissues, cells can move large distances. significant displacements in short periods  are especially pronounced in mitosis of drosophila embryos. since cell cycle phases occur in a fixed order, tracking can be improved using this prior biological knowledge. therefore, it is essential to develop a cell phase classification algorithm that utilizes 3d image information and does not rely on dynamic features extracted by cell tracking. in this article, we present an automated cell cycle phase classification algorithm for 3d images of live drosophila embryos.

methods
microscopy
the images stacks of drosophila embryo were recorded at 55- <dig> second time intervals using a zeiss  <dig> live confocal laser scanning inverted microscope and consisted of 66- <dig> slices of  <dig> x  <dig> pixels. the voxel dimensions in x/y/z were  <dig>  x  <dig>  x  <dig>  microns.

image processing, segmentation and creation of labelled datasets
the image stacks were first deconvolved using huygens professional  <cit>  to enhance the image quality. then interphase nuclei and mitotic chromosomes were segmented using a multi-level-set 3d segmentation algorithm  <cit> . data samples of nuclei were obtained from movies of two embryos. the first embryo was recorded during the syncytial blastoderm stage and gave rise to  <dig> samples representing the  <dig> phases of nuclear division cycles . the second 3d time series image dataset was acquired after cellularization during the cell divisions of the gastrulation stage and gave rise to  <dig> samples for each sample, we calculated a set of  <dig> 3d features  and assigned one of the five cell cycle labels.

3d feature calculation
humans recognize objects by their geometric and photometric characteristics. to mimic human vision, a set of  <dig> 3d shape, texture and intensity features was carefully designed and extracted.

volume
the volume v is equal to the total number of voxels inside the object times the voxel size. v = n×sx×sy×sz.

surface area
the surface area a is calculated using a voxel-based surface area estimation method  <cit> . prior to surface area calculation, segmented image stacks were interpolated to make each voxel isotropic using a shape-based interpolation  <cit> .

sphericity
humans tend to identify nuclei based on their round or spherical shape. sphericity ψ is defined as .

eccentricity
the eccentricity features e <dig>  e <dig> are defined as the ratios of the square root of the third and second eigen value to the square root of the first eigen value. the inverse of the square root of the eigen values is the corresponding equatorial radius of an ellipsoid fitted into a given 3d object.

mean and standard deviation of distance from surface to centroid
the voxels on the object surface are denoted as , and their distances to the object centroid are . the meanand standard deviation of surface to centroid distances are defined as  and .

mean and standard deviation of intensity
let the pixel intensities in 3d objects be denoted as . the mean and standard deviation of intensity are defined as  and .

3d texture features
texture was described using haralick texture features that are based on the 2d grey-level co-occurrence matrix   <cit> . in order to calculate 3d texture features, the grey-tone spatial dependence matrices pk are calculated in  <dig> instead of  <dig> directions. ng denotes the number of grey levels, which is  <dig> in our case. different displacement values of  <dig>   <dig>   <dig>  and  <dig> were tested, all of which showed similar classification results. to reduce computational expenses and feature space dimensionality, we set the displacement value to  <dig> only.

the following texture features were used in this study:

energy:  

entropy:  

correlation:  

where μx, μy, σx and σy are the means and standard deviations of px and py.

contrast:  

homogeneity:  

variance:  

sum entropy  

sum average  

sum variance  

difference entropy  

cluster shade  

cluster prominence  

difference variance

f <dig> = variance of px−y

max probability  

information measures of correlation  <dig>  

information measures of correlation  <dig>  

where hx and hy are the entropies of px and py and      

for a given 3d object, we have  <dig> angular gray-tone spatial dependence matrices. hence we obtain a set of  <dig> values for each of the above mentioned texture features. the mean and standard deviation of these  <dig> values served as the 3d texture features.

deviation between intensity-weighted and geometrical centroids
the geometrical centroid of a 3d object  is defined as . the intensity weighted-weighted centroid  is defined as . the deviation between intensity-weighted centroid to geometrical centroid  is defined as , which describes the intensity distribution within a 3d object. the motivation of this feature was to describe asymmetry of intensity distribution found in cells, such as condensed heterochromatin found at one end of an interphase nucleus.

feature reduction and classification
we used a set of feature reduction and selection techniques to reduce the dimensionality of the feature space, including principle component analysis , linear discriminant analysis , multidimensional scaling   <cit> , forward selection and backward elimination  <cit> . we tested several supervised machine learning methods to classify five different cell cycle phases, including the support vector machine   <cit> , probabilistic neural network , k-nearest neighbour , back propagation neural network . ten-fold cross validation was used for testing the trained classifiers. the overall classification accuracy  was defined as the number of true positives divided by the sum of true positives and false negatives. our datasets were imbalanced since cells are in interphase most of the time  . to overcome the bias towards the class with the highest frequency, we adopted a weighted-svm technique  <cit> . the weighted-svm approach achieved the best classification result when the weight of each class was inversely proportional to the square root of the number of training samples in its class.

visualization and validation of classification outputs
to validate the classification results, we designed a visualization tool. the classification results are superimposed on maximum intensity projections  of 3d image stacks together with the ground truth labelling by the human expert . if the classification result agrees with ground truth labelling, the label will be shown in white color, otherwise both of them will be shown in black color. the contour of each nucleus is drawn in red color, allowing the user to relate segmentation quality to classification performance.

RESULTS
we created two datasets of nuclei detected in 3d images of early drosophila embryos labelled with the live reporter histone-gfp that visualizes the progression through the phases of the division cycle . the first dataset contained  <dig> samples in various phases of nuclear divisions during in the syncytial blastoderm stage, while the second one contained samples of nuclei in proliferating epithelial cells during gastrulation. syncytial blastoderm and gastrulation are separated by cellularization that lasts approximately one hour. for each sample, we calculated  <dig> intensity, shape and texture features and assigned the respective cell cycle phase; interphase, prophase, metaphase, anaphase or telophase.

the performance of different combinations of feature reduction and machine learning techniques were evaluated using the post-cellular blastoderm dataset . the dimensionality after feature reduction was set to  <dig> for pca and mds, which is estimated from the intrinsic dimensionality of original data, and  <dig> for lda, which is limited by the number of classes  <cit> . all parameters were tuned for optimal classification accuracy. the best performance of knn was achieved when k was set to  <dig>  for bpnn,  <dig> nodes were used in the hidden layer. we used c-svm from the lib-svm library  <cit> . the gamma and cost for the svm were set to  <dig>  and  <dig>  respectively. svm outperformed other methods. feature reduction techniques  did not improve classification accuracy significantly.

the training set consisted of  <dig> samples in  <dig> cell cycle phases  of the post-cellular blastoderm . training was performed using  <dig> fold cross validation. svm=support vector machine, pnn= probabilistic neural network, knn=k nearest neighbour, bpnn=neural network with back propagation, pca=principal component analysis, lda=linear discriminant analysis, mds=multidimensional scaling.

we also used forward selection and backward elimination techniques to identify the dominant among the initial  <dig> features  <cit>  . we used pnn for feature selection, as other classifiers require repeated parameter tuning for every new combination of features. after forward selection, we achieved the highest classification accuracy of  <dig> % when we used the following  <dig> dominant features:  <dig> shape ,  <dig> intensity  and  <dig> texture features . using backward elimination, we identified the following  <dig> features that achieved a classification accuracy of  <dig> %:  <dig> were related to shape ,  <dig> to intensity  and  <dig> to texture . based on the feature selection results and exploratory data analysis , we selected the following  <dig> features for subsequent classifier training: sphericity, surface area, homogeneity mean, information measure of correlation  <dig> mean, difference variance mean, entropy mean, intensity standard deviation and deviation between intensity-weighted and geometrical centroids in the z direction.

classification performance varied between cell cycle phases , ranging from 66% for anaphase to 97% for interphase. the heterogeneity in prediction accuracy could be due to an imbalance in training dataset. mitosis occupies a relatively short period of the cell cycle. hence, interphase is predominant, while prophase and anaphase only represent 4% and 5% of total population. using weighted-svm, significantly improved the classification accuracy of prophase and telophase to  <dig> % and  <dig> %, respectively . we also determined classification performance of the weighted svm applied to a second dataset containing  <dig> nuclei of the syncytial blastoderm stage. we observed an overall classification accuracy of  <dig> % .

as development progresses from the syncytial blastoderm to gastrulation, nuclei are encapsulated into a cell membrane. upon cellularization, nuclei in epithelial cells elongate along the apical basal axis, leading to a change of nuclear shape from round to oval. despite the developmental changes, interphase nuclei and mitotic chromosomes have a similar appearance in syncytial blastoderm and gastrulation. to test if cellularization and differentiation change sample distribution in the feature space we performed training and testing of weighted-svm classifiers for samples from different developmental stages . cell cycle phase prediction of gastrula samples decreased from 90% to 50% when we used them as inputs for a svm trained using syncytial blastoderm samples compared to a classifier trained for the same stage. in the complementary experiment, the prediction of syncytial blastoderm samples decreased from 92% to 70%. when we combined samples from both datasets we obtained a more robust classifier that could predict samples from both developmental stages at over 90% accuracy.

discussion
we noticed that a large proportion of misclassified cells were wrongly predicted to belong to neighbouring classes . for instance,  <dig> anaphase samples were misclassified as metaphase, and  <dig> anaphase samples as telophase . this is not unexpected as phenotypic transitions of chromosomes during cell cycle progression happen gradually and there are no clear morphological boundaries between mitotic phases. both forward feature selection and backward feature reduction could reduce the feature set from  <dig> to  <dig> without compromising classification performance . feature selection had a slight advantage as it was computationally more efficient .

although nuclei at syncytial and gastrula stage are visually similar, the overall classification accuracy of syncytial samples applied to a model trained with gastrula data was only  <dig> %, while  <dig> % classification accuracy was achieved in the converse experiment . this might due to the following  <dig> differences: first, they are at different developmental stages, nuclei in syncytium stage have no membranes; second, they are from different drosophila embryos; third, the laser power and microscope settings might be different for these two datasets. the results indicate that classifiers trained using syncytium dataset cannot be used to classify cells at cellular blastoderm stage and vice versa. however, a unified classifier can be obtained when trained using combining datasets from two developmental stages. using this unified classifier, we could achieve over 90% classification accuracy for both datasets as shown in the last two columns of table  <dig>  this result shows that if the classifier is trained using more training samples containing all possible variations, a robust classifier can be obtained.

3d image stacks obviously contain more information than 2d images. therefore, it is conceivable that 3d possess a higher discrimination power than 2d features. since this notion lacks thorough evaluation and computing 2d features  is computationally less costly, it is worthwhile to address this issue in future research. one approach could involve producing 2d projections of 3d objects and testing the classification performance using 2d features extracted from 2d projections. alternatively, we could extract features from a single representative slice  as previously described  <cit> .

CONCLUSIONS
3d live cell imaging is becoming a common technique for the study of dynamic cellular processes in 3d tissues. accurate cell phase classification is one of the essential steps to automate 3d live cell imaging analysis. starting from an initial set of  <dig> shape, intensity and texture feature, we evolved a reduced subset of  <dig> dominant features without affecting predictive performance. weighted-svm was used to alleviate the problem of imbalanced training datasets. over 90% classification accuracy was achieved on two dataset consisting of over  <dig> cells . as in cultured cells, automated cell cycle classification in 3d tissues can be applied to the characterization of cell divisions phenotypes resulting from genetic perturbations in multi-cellular organisms such as drosophila, zebrafish or c. elegans. our method does not depend on dynamic features derived from cell tracking. as such, this approach can be used to improve the performance of automated cell tracking in live cell imaging.

authors' contributions
thd designed and implemented the feature extraction and classification methodology, performed data analysis and drafted the manuscript. wcp acquired the 3d images of live drosophila embryo, performed image segmentation and labelled the training sets. mw directed the project, was involved in conceptual design, data interpretation and drafting of the manuscript. all authors have read and approved the final manuscript.

competing interests
the authors declare that they have no competing interests.

