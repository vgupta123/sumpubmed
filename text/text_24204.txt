BACKGROUND
since the release of the dna sequence of the first human genome in  <dig>  which ushered in the shift from sanger sequencing to next-generation sequencing , thousands of human genomes and exomes have now been sequenced. the promise of human exome and genome analysis is to generate sufficient information to enable clinicians to provide patients with personalized medical care. yet, each human exome can contain as many as a million single nucleotide variants  when compared to the human reference genome. in order to determine which variants are most clinically relevant for an individual patient, it may be necessary to determine the frequency of minor alleles - not only in the general population, but in the specific population to which each patient belongs. thus, deep sequencing of large numbers samples in highly differentiated and admixed populations is critical. the  <dig> genomes project  aims to provide genome sequences for over  <dig> individuals from several distinct populations from across the globe  <cit> . the uk10k  <cit> , is another genome sequencing project with an objective to sequence over  <dig>  human genomes from different populations across the united kingdom. similarly, the nhlbi exome sequencing project   <cit>  has generated exome sequencing data from thousands of individuals with the goal of identifying genes and variants that contribute to heart, lung and blood disorders. the esp and uk10k cohorts contain individuals with disease and aim to define the relationship between phenotype and genotype, and associate genomic variation with disease risk, therapeutic safety, and efficacy and patient outcomes.

yet despite great effort to sequence thousands of individuals, current data alone may not be sufficient to allow clinicians to distinguish which variants are informative in local patient populations. the 1000g project has chosen to sequence greater numbers of individuals at very low sequencing depth—but with the potential risk that the data contains more sequencing errors and therefore less accurate allele frequency information. meanwhile, the uk10g will generate greater numbers of sequences at greater sequencing depth, but the represented populations are limited to those more prevalent in the uk. similarly, the individuals in the esp are more limited in their populations of origin, and are skewed towards individuals with a heart, lung or blood disorder. for the physician interested in personalized medicine, a more accurate metric would be a variant’s frequency in the local population of a state, county or city—the population in lancaster county, pa, with large amish contributions, might have an allele frequency spectrum substantially different than the local population in travis county, tx, where significant mexican-american and african-american populations are present.

one resource available for allele frequency determinations in the local population is banked newborn bloodspot samples routinely collected and used for mendelian disease screening of neonates using metabolite profiling. these de-identified blood samples could serve as a source for the determination of variant frequencies in a local area. yet, these samples are less than ideal because of their age and limited amount of genomic dna they contain. previous work has shown that these samples can be indeed sequenced using whole exome sequencing  <cit> . here we assess the effects of whole genome amplification on our ability to identify real variation in exome sequence data as an application for samples with limited material. specifically, we are interested in the number of single nucleotide variants  that are attributed to the amplification process compared to technical duplication. additionally, we have also examined the differences in variant sets identified from the same sample when using two different commercially available exome capture kits. our data should encourage more extensive utilization of nbs specimen archived around the globe for a variety of clinical and research applications.

methods
the study was approved by the institutional review boards of university of texas at austin  and texas a&m university . we obtained written informed consent from those participants who were ≥18 years of age at the time of enrollment or their guardians. gentra puregene blood kit  was used to extract genomic dna from 3 ml whole blood following the manufacturer’s protocol. a modified protocol was used for dna extraction from dry blood spots. briefly, 15 ~  <dig> punches of 3 mm disks were digested overnight at 55 °c by  <dig> ul proteinase k solution  in a  <dig>  ml eppendorf tube which containing  <dig> ul cell lysis solution. after digestion, samples were cool on ice for 10 min and  <dig> ul protein precipitation solution was added and mixed by votexing for 20 s. mixed samples were incubated on ice for 30 min and then centrifuged for 30 min at  <dig>  rpm, 4 °c. supernatant was transfer in to a new tube containing  <dig> ul isopropanol and  <dig> ul 20 mg/ml glycogen and mixed by invert  <dig> times. after 48 h incubation at −20 °c, samples were centrifuged at 4 °c,  <dig>  rpm for 30 min, dna pellet was washed once in  <dig> ul 70 % ethanol and resuspended in  <dig> ul dna hydration solution . dna was quantified using a qubit® dsdna br assay kit . the concentration for the tested samples were as following: a:55 ng/ul; b:49 ng/ul; c:47 ng/ul; 509:70 ng/ul; 527:61 ng/ul. 10 ng genomic dna was then amplified using the genomiphi dna amplification kit  following the manufacturer’s standard protocol. briefly,  <dig> ul of genomic dna  was added to  <dig> ul sample buffer and was heated to 95 °c for 3 min to denature the template dna. the sample was cooled and mixed with  <dig> ul reaction buffer and  <dig> ul phi <dig> enzyme and incubated at 30 °c for 16– <dig> h. after amplification, the phi <dig> dna polymerase was heat-inactivated by a 10-min incubation at 65 °c. the whole genome amplified  product was then quantified using the qubit® dsdna br assay kit , the concentration of the wga products were as following: aw:300 ng/ul, bw:235 ng/ul, cw:330 ng/ul.

briefly,  <dig>  ug of genomic dna was sheared to an average fragment size of 200 bp using the covaris e <dig>  fragments were purified using ampurexp beads  to remove small products , yielding  <dig> ug of material which was end-polished, a-tailed and adapter-ligated according to the manufacturer’s protocol. the libraries were subjected to minimal pcr cycling and quantified using the agilent high sensitivity dna assay. libraries were combined into pools for solution phase hybridization using the illumina truseq™  exome enrichment kit. captured libraries were assessed for both quality and yield using the agilent high sensitivity dna assay and kapa library quantification kit. massively parallel sequencing was performed with six samples per flow cell lane using the illumina hiseq <dig> platform and sbs chemistry to generate 100 bp paired-end reads . the sequencing resulted in about 20–30x coverage across the exome. sequences were aligned using bwa  <cit>  to the human genome . variants were predicted using gatk  <cit>   using default parameters and filtered using the gatk hard filter.

rufus sequence filtering
rufus  is a reference independent method for identifying variants between next generation sequence data sets. it is based on a kmer-based approach that identifies sequence reads that contain unique dna between two or more sequence libraries. the elimination of reference mapping or whole genome assembly from variant detection may reduce the rate of false positives caused by incorrect mapping without a reducing sensitivity. first, jellyfish  <cit>  produces kmer counts for each samples set of fastq files independently. rufus uses these counts to determine which kmers are unique to a sample. filtered fastq files are generated with reads with only unique kmers and thus reads containing a mutation compared to the comparison sequence library. filtered fastq files where then used for alignment and variant calling, using the same method as the unfiltered fastq files.

RESULTS
technical replication
in order to determine the effect of whole genome amplification  on snv detection, we first needed to determine the concordance of snvs in technical replicates ; in this case exome sequences from the same sample, using the same exome capture kits and processed with the same analytical pipeline. using the classical method for snvs determination with alignment by bwa and variants detection and filtering  by gatk, we identified  <dig>  snvs in the two runs from sample  <dig>  and  <dig>  snvs in the two runs from sample  <dig> . consistent with previous studies  <cit> , roughly 85 % of the snvs are concordant between the technical replicates, with greater than  <dig>  snvs in each replicate not identified in the other. when we apply strict filtering, comparing genotypes predicted from greater than 10x depth in both samples, the rate of concordance increases to 98 %, with on average about 11 k snvs per sample. yet this filter removes 41 % of positions examined.fig.  <dig> comparison of snvs in biological replicates. a comparison of technical replicates, where both sets of sequences data from each pair is process for sequencing using the same method. b comparison of biological replicates, the set labeled with the “w”, was subjected to whole genome amplification prior to library construction and sequencing



we decided to apply a reference-free sequence comparison tool, rufus. using this method, we observe a dramatic improvement in technical replicate concordance. rufus selects sequence reads that contain differential k-mers present in one replicate but missing from the other. variants were then called using only these reads. this removes all reads that do not contain unique sequence between the samples, thus removing reads that do not represent variation between the sample but may contribute false positives due to mapping errors. this method identifies only two discordant snvs from the technical replicates of each sample, suggesting that much of the discordant variant calling using bwa/gatk may be introduced by mapping errors, particularly in regions of low complexity  <cit> .

comparing variant calls from amplified nbs and native genomic dna
in order to determine the effect of genome amplification, we generated sequencing libraries from the same subject where one of the replicates was amplified by whole genome amplification  using phi <dig> dna polymerase. for gdna and using “map first” method for snv determination - comparing sequence reads to human reference genome build  <dig>  for variant calling), we identified  <dig>  snvs in subject a,  <dig>  snvs in subject b and  <dig>  snvs in subject c . using wgadna, bwa/gatk snv calls resulted in  <dig>   <dig>  and 78 % concordance respectively, between variants called in the gdna and wgadna from the same subject. there are  <dig>  ,  <dig>   and  <dig>   snvs not detected in wgadna, and an additional  <dig> ,  <dig>  and  <dig>  snvs detected in wgadna, but not in gdna . using a mapping first approach, these results suggest the discordant rate of wgadna compared to gdna is similar to technical replicates,  compared to on average  <dig>  % in technical replicates.

to explore the filtering parameters that would decrease the number of false positives, we examined the concordant rate at 1x, 10x, 20x and 30x , where a genotype is predicted with the given depth in both samples. without a hard filter, the concordance rate increases from  <dig> to 93 %, and has 89 % of snvs concordant for 10x, which would predict on average 15 k additional snvs in the wgadna compared to gdna. when a hard filter is imposed, the concordant rate is  <dig>   <dig>   <dig> and 81 % for 1x, 10x, 20x and 30x respectively. however the total number of positions meeting these depth requirements is greatly diminished, with only 17 % retained in the 10x group and less than 1 % retained in the 30x group. of the predicted snvs, the vast majority  are not novel in the  <dig> build of dbsnp. of the snvs detected in wgadna and not detected in gdna, about 1/ <dig> are novel for those with depths > 10x.

using rufus, we identified  <dig>   <dig> and 38 k discordant snvs when comparing the rufus variant calls from the wgadna and gdna libraries for subjects a, b and c, respectively. this result emphasizes that about half of discordance in calls results from the errors in alignment.

contrasting kmer variant call discrepancy between wgadna and gdna exomes of the same subject to kmer calls between technical replicates, we observe greater discordance between wgadna and gdna than seen in technical replicate exomes . nevertheless, the discordance between wgadna and gdna when using a method where reads are filtered using k-mer profiles is dramatically lower than the discordance of snvs from technical replicates when using a traditional snv detection method, where all reads are considered . even when using the rufus to filter reads which reduces overall snv discordance in samples from the same subject, biases remain, indicating that the amplification does introduce spurious variation. artifactual variation produced by wga represents less than 7 % of the total variation in these samples; however, the impact of this false-positive call rate on the utility of the data may be substantial.

capture kit variant comparison
additionally, we wanted to know the implications of using different exome capture kits to create libraries. therefore, we generated libraries from four subjects using the agilent sureselect and illumina exome capture kit in order to determine whether capture kits produce the same variant profile. of the snvs predicted to be present in any of the subjects, about 31 % of the total snvs predicted  were identified in samples produced by both exome capture kits. using the gatk hard filter, only 28 % of the  <dig>  filtered snvs are concordant between capture kits. high levels of non-reproducible variant calls may therefore be obtained when attempting to compare results from exome sequencing of the same subjects when alternative capture probes/targets and their respective reagents are employed. similar to previous findings  <cit> , we found over  <dig> regions of the genome, covered by only one of the two capture kits . in overlapping regions, there are still some differences in sequencing depth , leading to differences in snv density . these results suggest that because there are few regions that are well covered by both kits, sample preparation procedures could be more important than informatics methods in generating a list of complete snvs. when comparing exomes in populations, researchers must be mindful of these technical challenges. its recommended to  only compare snvs detected in each dataset ,  to match sample preparation for controls and cases in disease association studies and  validate with targeted resequencing.fig.  <dig> comparison of sequence coverage and depth in biological replicates. circos generated plot, where the outer most ring represents the chromosome of the human genome, followed by the regions of the genome with unique coverage in the illumina capture kit  and agilent capture kit , followed by a histogram of sequencing depth of each kit and a histogram of snv density



CONCLUSIONS
in conclusion, despite these technical challenges, we do believe that nbs are valuable resources for population genetics. we are amidst an era of sequencing and sample preparation innovation and are encouraged that newer preparation kits promise to do more with less material, which would make wga unnecessary. in the case of wga, we believe that these errors are randomly distributed in the exome , therefore each variant will be rare to a whole population. in large case/control studies, the very rare variants found in one sample are often filtered.

additional file
additional file 1: figure s <dig>  concordance rates. plot represents the concordance rates between technical replicates and biological replicates , where positions are only considered, when sequencing depth is greater than the coverage . plus sign and down triangle are additionally filtered by the gatk hard filter. 



abbreviations
nbsnewborn bloodspot samples

dnadeoxyribonucleic acid

gatkgenome analysis toolkit

ngsnext-generation sequencing

snvssingle nucleotide variants

1000g <dig> genomes project

espexome sequencing project

brandi l. cantarel yunping lei contributed equally to this work.

competing interests

the authors declare that they have no competing interests.

authors’ contributions

hz conceived of the study and helped to draft the manuscript. yl participated in study design and carried out the experiments. dw and blc performed data analysis and draft the manuscript. af performed the data and statistical analysis. gbm participated in data analysis. jr participated in the sequence analysis and manuscript. rhf participated in study design and helped to draft the manuscript. all authors read and approved the final manuscript.

this work was supported by national institute of health  to rhf.
