BACKGROUND
the paper presents a methodology for exploring long dna sequences, of the order of millions of bases, by means of their information content. we bring together two of pieces of our work, a bayesian compression model and a graphical exploration tool, and give examples illustrating the methodology.

compression is used to find the features of a sequence and common features that relate one sequence to another. linear information content sequences are then used to locate various kinds of common information. genomic subsequences or regions identified through this process can then be further investigated.

the compression problem is to calculate the information content per base, producing an information sequence. information is relative, i.e. it depends on the context. the context can include one or more other sequences and hence information content can relate two or more sequences.

note that an information sequence is 1-dimensional; operations such as difference, zoom, smooth and threshold are efficient, taking linear time and space. this is in contrast to the traditional 2-dimensional plots of one sequence against another which must be stored at low resolution for long sequences.

any per element compression model can be used to create an information sequence. here we use our approximate repeats model   <cit> , however, other statistical models that produce an information sequence could be used. we present the arm, introduce our tool to manipulate information sequences, and explore its use for the red alga cyanidioschyzon merolae  <cit>  and the malaria strain plasmodium falciparum  <cit> .

methods
dna sequence compression
we wish to examine the information content of sequences. information content and compressibility are inherently related: low information content implies high compressibility and high information content implies low compressibility. so, if one has an efficient encoding of a sequence, then it can be argued that one has a good model of that sequence. from shannon  <cit>  we know that an efficient encoding is related to its probability by the log likelihood. that is, information i = -logp, where p is the probability of m occurring.

when trying to make an inference from some data using a bayesian technique, we attempt to maximize the posterior probability, p = p × p/p for hypothesis h and data d. if our model  has a nuisance parameter about which we do not care to make an inference, we should sum over all possible values for this parameter. this is necessary when using sequence alignment to infer how related two sequences are. if we are only interested in whether the sequences are related or not we should sum over all possible alignments  <cit> .

the way that compression models for dna handle repetition can be broadly classified as substitutional or statistical. a substitutional model uses some form of pointer back to an earlier instance of a repeated subsequence to encode a later instance. on the other hand, a statistical model encodes the sequence element by element using a probability distribution over the possible values of the next element in the sequence. the distribution can be formed as a blend of opinions derived from the base distribution and from the length and fidelity of matches between recent history and earlier parts of the sequence. a statistical method can directly yield a per element information sequence, in addition to deriving a compressed encoded sequence. however, there is no simple natural way to derive a per element information sequence for a substitutional model.

significant advances in substitutional compression models for dna include: biocompress  <cit>  and biocompress- <dig>  <cit> ; and the more recent dnacompress  <cit> . and for statistical models: loewenstern and yianilos  <cit> ; korodi and tabus  <cit> ; and cao et al.  <cit>  who also produce a per element information sequence. the approximate repeats model  used here, and described in the next section, is at heart a substitutional model yet it behaves much like a statistical model.

it is worth noting at this point that not all applications of compression need the production of an information sequence. the encoded sequence may be sufficient. and sometimes just the length of the encoded sequence may be enough, for example when searching for the best in a class of models. however, our work here requires a per element information sequence.

approximate repeats model
here we choose to use the approximate repeats model   <cit>  to provide per element information sequences. any good per element compression scheme could be used. the arm is designed to compress dna sequences well. compression values given in  <cit>  and  <cit>  show that the arm is rarely bettered on common data sets and then only marginally. it is a bayesian model that applies minimum-message-length inference  <cit> .

dna sequences often have regions that are highly similar, with only a few differences. given the double-stranded nature of dna, it is also common for dna to contain reverse-complementary repeats – sometimes called palindromes – due to complementary matching in the reverse direction of a to t, c to g and vice versa. the arm compresses a sequence by finding each region that is similar to a previously encountered region and encoding it as "similar to this other region, but with these changes". it also looks at the reverse-complement of the sequence so far to find similarities. 

the arm considers a dna sequence a base-pair  at a time from left to right. each bp may have originated in one of two ways:

 <dig>  it may have been generated from a base model. this base model can in principle be any sequence model. we have typically used a low-order markov model.

 <dig>  the bp may have been generated as part of a repeated region. a repeated region is specified by first giving the position in the sequence where this region is repeated from; a uniform distribution is used to encode this position.

the description to this point is quite similar to the ziv-lempel  <cit>  algorithm. the difference is in how a repeated region is treated: each bp from a repeated region may be copied, deleted or changed, or a bp may be inserted. the length of a repeat is encoded using a geometric distribution; while this may not be ideal, it allows for a more efficient algorithm.

notice that this method of treating repeated regions is very similar to the way local-alignment algorithms  <cit>  are used to model sequence variations. this is quite deliberate, the arm is in effect aligning a sequence against the sequence already seen. it achieves good compression in regions that would have good alignment scores. the implementation of the arm supports both simple gap costs and affine gap costs. it is possible to view a two-dimensional plot of the self-alignment used in the arm but such an image is a very coarse way to look at the results. for example, for a sequence of a million elements, each pixel in the image would represent roughly one thousand bases. thus it is necessary to find a better way to deal with the compression results, we suggest using a 1-dimensional plot of the information content.

the per element information content for a sequence under the arm is formed by a bayesian blend of all possible explanations for the current element. outside of repeat regions, the base model provides the most probable explanation. as an approximately repeated region starts to be matched, the base model is still the most probable and the repeat carries little weight. as more of the repeat region is matched, its contribution increases providing a relatively smooth transition in the information sequence.

often there are many competing sequence alignments that are almost equally good. this also happens within the arm. a region may be quite similar to a number of earlier regions and we do not want to pick just one of them to copy from. these repeated regions may be treated as mutually-exclusive hypotheses, and since we do not care to make an inference about which one is the best, we sum over all of their probabilities, in effect removing a nuisance parameter. this also allows the arm to trade-off the frequency and length of a repeat against its fidelity.

the arm has a small number of parameters – probabilities for the beginning of a repeat, for the possible mutations and for ending a repeat. an iterative em algorithm is used to converge on the best set of parameter values: first, the arm is used with some initial values for these parameters. then the results from applying the model are used to estimate new values for the parameters. these new parameters replace the initial values and this two-step process is iterated until it converges.

1-d information content viewer
infov is a java platform used to explore the structure of sequences using arbitrary compression models. it provides functionality to import biological sequences such as dna, use compression models to generate information content sequences, and interactively display multiple plots for the analysis. this tool also provides various functions to manipulate sequences such as smooth, cut, append, calculate the difference between numeric sequences, and find the reverse complement of dna sequences. additionally, infov annotates how sequences are derived; this includes the storage of the model parameters and functions used to create sequences. figure  <dig> illustrates the displays for the compression of chromosome  <dig> of cyanidioschyzon merolae alone; the troughs showing self repetition. however, infov is particularly useful for performing comparisons in different contexts, such as in figure  <dig> where a difference plot is used to highlight information, at the peaks, contributed by the context. these figures are discussed in the next section.

the current implementation of infov is focused on dna sequences and includes the arm. however, it has a generic, extensible design, which enables the analysis of other type of sequences, such as character and numeric sequences, and the use of other compression models.

RESULTS
we applied the arm to find approximate repeats within each of chromosomes  <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig> and  <dig> of c. merolae  <cit>  and between pairs of chromosomes. the 1-d information content graph, i, is given in figure  <dig> for chromosome  <dig>  it has been smoothed, displaying the average of a  <dig> wide sliding window. we can easily store the whole graph and dynamically explore the low information areas. the window size should be of the order of the feature being searched for. typically, one looks for large features first. the viewer facilitates zooming-in and re-smoothing with smaller window size, to either further investigate regions or to find smaller features. subsequences of interest can be saved to file for further investigation starting, say, with a blast search. this figure also shows the history window for the plot.

in this case, we find repeated regions from  <dig> to  <dig> corresponding to  <dig> to  <dig> in chromosome  <dig>  and another from  <dig> to  <dig> corresponding to  <dig> to  <dig> in  <dig>  the first region is a probable myo-inositol 2-dehydrogenase  <cit>   and the second contains a hypothetical protein.

importantly, all of these plots are 1-dimensional. they can be computed at full resolution and stored, even on a small computer. we used the arm but the same can be done for any  statistical compression model. common operations such as difference, smooth, zoom and threshold can be performed quickly in linear time. a difference plot shows what new information the addition of a context tells us about a sequence; features already revealed by the original context, here chromosome  <dig> alone, are discounted by the difference.

we also investigated the subtelomeric regions of c. merolae. pairwise comparisons i confirmed known results  <cit> . we summarize the results in figure  <dig> showing that the subtelomeric regions for chromosomes  <dig>   <dig>   <dig> and  <dig> belong to element p and those for chromosomes  <dig> and  <dig> belong to element ph. notice that chromosomes  <dig> and  <dig> do not compress well in their contexts.

our final example is for chromosome  <dig> of p. falciparum  <cit> . the p. falciparum genomic sequence is approximately 80% at rich. it should be noted that the base markov model and the repeat-region model within the arm are not troubled by this bias which is shared by both the source and target of a repeat and hence cancels out without causing false positive signals. information sequences derived by the arm are directional. to this point, only left to right sequences have been derived. figure  <dig> shows a difference plot of i - rev)) where revcomp gives the reverse complement of a dna sequence and rev simply reverses the resulting information content sequence. the sequence from the first term is computed left to right; the second is computed right to left and then reversed. such difference plots highlight the first and last instances of approximate repeated subsequences.

most of this difference plot gives values close to zero. but at both ends there are large differences from the baseline reflecting the known repetitive structure of chromosome ends for p. falciparum. the differences in sign are just a result of reversal and subtraction. telomere-associated repeat elements include rep <dig>  and the var, rif and stevor genes that are involved in its virulence  <cit> .

the above examples illustrate how to use linear information sequences to highlight similarities within a genomic sequence, including the first and last occurrences, and to find similarities in the context of other sequences. this is the basis of our methodology for exploring long dna sequences.

smoothing derived information sequences is an integral part of the process. information sequences can be quite busy without smoothing. window sizes of roughly the size of what is sought are necessary. typically, one starts with a large window size which is successively reduced as more detail is investigated.

the methodology for comparing long dna sequences by information content is as follows:

 <dig>  look for repeat regions from i. find the first instances of repeats as well using i - rev)).

 zoom in and capture interesting  regions for further investigation.

 reduce the smoothing window size to find smaller repeat regions.

 <dig>  repeat the above applying different contexts using i - i.

CONCLUSIONS
information is relative to what is known. a sequence y can be compressed firstly in a context ctx <dig> and then in a context ctx <dig> where ctx <dig> is ctx <dig> plus a sequence x. the difference between the information sequences for y|ctx <dig> and for y|ctx <dig>  i.e. i - , shows the new information that x gives us about y. mere background statistical properties of y and x, that were already known from ctx <dig> and/or y itself, are discounted.

we have shown how to use 1-dimensional information sequences derived from long dna sequences for the comparison of a sequence with itself and with additional contexts. a methodology has been outlined to identify sequence similarities for subsequent investigation. importantly, exploration of full-resolution information sequences is carried out in linear time and space. the information sequences can be computed from within our tool, or computed off-line and imported.

authors' contributions
ls ran the arm over p. falciparum and investigated the resulting information sequences. sj ran the arm over the c. merolae data and investigated the resulting information sequences. jb developed the code to the information content viewer. la developed the arm and the use of associated contexts, and the methods to investigate information sequences. dp redeveloped the code for the arm and contexts, and developed the viewer. td developed the arm, methods to investigate information sequences, and the information content viewer. all authors read and approved the final manuscript.

