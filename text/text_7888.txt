BACKGROUND
the advent of pyrosequencing technologies such as the  <dig> sequencing platform by roche 
 <cit>  has revolutionized the field of genomics meaning researchers can undertake large-scale genomic studies that would have been complex, difficult and even impossible prior to such technologies 
 <cit> . current  <dig> technology allows the generation of as many as one million high quality sequence reads with read lengths of up to  <dig> base pairs. the production of such large volumes of sequence data means that manual curation of quality and errors, as could be done with traditional sanger sequencing, is no longer feasible. one of the major limitations of pyrosequencing is that sequence quality is not consistent, either within a read or between reads generated in the same sequencing run 
 <cit>  and, thus, downstream analysis of such data may be compromised as a result of low quality data 
 <cit> . the quality scores for the current generation  <dig> sequencing platforms are similar to phred scores 
 <cit>  and represent the probability of a base call error at each individually called base in a read 
 <cit> . these quality scores range from  <dig> to  <dig> and are log-scaled, meaning that scores of  <dig> and  <dig> represent a probability of an incorrect base call of  <dig> in  <dig> and  <dig> in  <dig> respectively. as with most sequencing approaches, the quality of sequence data generated using  <dig> pyrosequencing decreases linearly across a sequence read 
 <cit> . thus, in many instances it is imperative to undertake quality filtering of  <dig> sequence data prior to subsequent analysis. quality trimming generally entails some form of iterative removal from one or both ends of a sequence read with the primary goal being to ensure that the resultant read is of high quality. quality trimming tools range from strict approaches that have zero tolerance of low quality base calls in the output reads through to averaging approaches that maximize read length by allowing the inclusion of a proportion of low quality base calls within an output read 
 <cit> . the algorithms used by averaging approaches differ greatly, ranging from approaches such as clean_reads 
 <cit>  and prinseq 
 <cit>  that use a window-based approach to iteratively trim sequence reads until the user-defined quality threshold is satisfied within the window, to fastx 
 <cit>  that iteratively trims nucleotides from a sequence read until the percentage of low quality bases in a read satisfies a user-defined threshold. while all of the reads in such approaches will satisfy the mean quality score threshold, the algorithms used can result in tools that ‘over-trim’ reads resulting in the loss of data that, if included, would be both high-quality and informative.

here, we describe a quality trimming algorithm  that uses a novel averaging approach that ensures the output of high quality reads from high throughput sequence data while maintaining the maximum possible length of the output sequences. to enable its use by a broad range of researchers, qtrim is available as a standalone executable for individuals with computational expertise and as a web-interface for individuals with little, or no, bioinformatics experience.

implementation
qtrim is executed as a standalone software package for command-line use and integration into sequencing analysis pipelines. two versions of qtrim can be invoked using the python script. the first is a “simple” version that only outputs the trimmed sequence data. a second, “graphical” version  also outputs graphs plotting the quality score trends across all reads, the prevalence of read lengths and the mean quality scores both before and after trimming. further, a web-based interface is also available  for individuals wishing to quality trim their data using the graphical version of qtrim prior to further downstream analysis using other web-based tools.

qtrim takes as input a fastq file or a fasta file with its associated .qual file. qtrim execution requires three parameters to be set by the user. the quality threshold is the mean quality that each trimmed read must satisfy, the second defines the minimum allowed read length  a read can reach during trimming before being discarded, while the final parameter  defines the window size to be used during trimming. if no window size is defined at input the default value is set to the user-defined minimum allowed read length. the qtrim algorithm comprises three sequential steps  with the first step iteratively trimming single nucleotides from the 3′ end of a read until it’s mean quality score satisfies the quality threshold. the second step is a sliding window approach that evaluates the mean quality score of the last n number of nucleotides at 3′ end . if the mean quality score of the bases within the window is not satisfied, a single base is deleted from the 3′ end and the window is reset. once the quality threshold within the window is satisfied, the final step iteratively trims all nucleotides from the 3′ end until the quality score of the last nucleotide in the read ≥ quality threshold value. if the length of the resulting trimmed read is less than the minimum allowed read length the read is discarded. a further option in qtrim enables trimming to occur simultaneously at both the 5′ and 3′ ends.

RESULTS
the performance of qtrim was evaluated on two previously generated  <dig> datasets with extreme differences in untrimmed quality scores. while in an ideal world sequencing using high-throughput sequencing platforms would only output high-quality sequence data, the various steps involved in sample preparation and sequencing means that, in many cases, non-optimal sequence data is output from a sequencing run. rather than discard such data, a sensitive trimming approach will enable individuals to “rescue” any high quality present as the result of a sub-optimal sequencing run. the good quality  <dig> sequence data used here originates from a metagenomic project sequencing bacterial 16 s genes from seawater sponges . this data was generated using the roche/ <dig> flx platform and good quality was defined as sequence reads with comparable read lengths with consistently high quality scores at called bases until close to 400 bp . the poor quality input data was also generated using the roche/ <dig> flx platform and originated from a study of hiv drug resistance 
 <cit> . this data was characterized as having particularly variable read lengths with low quality nucleotide calls prevalent throughout the entire read .

the performance of qtrim was compared at two quality threshold levels  against prinseq 
 <cit> , the lucy algorithm 
 <cit>  as implemented in clean_reads 
 <cit> , the modified-mott algorithm implemented in geneious 
 <cit> , fastx 
 <cit>  and 454/roche’s newbler v <dig> . each of the methods was evaluated on the basis of total number of trimmed reads output, the mean read length of the output reads as well as on the basis of trimming speed. for each method, all trimmed reads were confirmed to satisfy the quality threshold  to ensure that there was no bias in the evaluation step towards approaches that favour untrimming to maximize read length by outputting longer reads that do not satisfy the quality threshold. the best approach should output the highest number of trimmed sequencing reads that satisfy the quality threshold with the longest average read length.

when applied to the good quality data, qtrim and prinseq perform equally well and outperform all other methods , with  <dig> trimmed reads with a mean length of  <dig> nucleotides output by qtrim and  <dig> trimmed reads with a mean length of  <dig> nucleotides output by prinseq in the q <dig> threshold analysis. in the more stringent q <dig> analysis, the number of output reads remained similar to that of the q <dig> analysis however the mean read length reduced to  <dig> and  <dig> nucleotides for qtrim and prinseq respectively. for both the q <dig> and q <dig> analysis all of the other approaches output a comparable number of trimmed reads to qtrim and prinseq, however their average read lengths were significantly shorter .

when applied to the poor quality data, prinseq and qtrim were, by far, the two best performing approaches  with  <dig> trimmed reads with a mean length of  <dig> nucleotides output by qtrim and  <dig> trimmed reads with a mean length of  <dig> nucleotides output by prinseq in the q <dig> threshold analysis. the lower quality of this data is reflected in the much shorter trimmed reads output from the analysis when compared to the trimmed read lengths output by the analysis of the good quality data. this is further evident when the stringent q <dig> analysis of the poor quality data was undertaken with the average trimmed read length reducing from  <dig> nucleotides  to  <dig> nucleotides  for qtrim and from  <dig> nucleotides  to  <dig> nucleotides  for prinseq. further, the dramatic reduction in the number of reads output for all methods in the q <dig> analysis , indicates that, for many sequence reads, they were of too low quality to pass the minimum read length threshold.

upon comparison with all other approaches, qtrim performs equally as well as the best of these methods . the trimmed reads output by prinseq are, on average, slightly longer than those output by qtrim . upon further examination, however, this is as a result of prinseq outputting a higher number of low quality bases  at the 3′ end of its trimmed reads. for example, prinseq output 8% as many low quality bases than qtrim in the q <dig> trimming of both datasets tested here, and outputs 17% and 25% as many low quality bases in the q <dig> trimming of the poor quality and good quality datasets respectively. we find that this is the case in all of the methods that use an averaging approach for quality trimming. as soon as the minimum quality score in a read satisfies the quality threshold, the read is output as trimmed without any further analysis. in qtrim, however, we employ a further two steps that ensures that low quality bases at the 3′ end of quality trimmed reads are removed. thus, while the reads may be slightly shorter than those output by prinseq, users can have a high level of confidence that quality is consistent across the length of the quality trimmed reads output by qtrim. further, as there is no window size that needs to be defined by the user for the initial trimming step, qtrim results are not susceptible to error by a poorly user-defined window size. setting the window size too small in a windowing approach such as prinseq would mean that while the quality threshold is satisfied within the window, it is not satisfied across the entire output read.

finally, the operation of qtrim is twice as fast as prinseq  on a standard desktop computer with a 2 ghz intel® core™ duo cpu and 2gb of ram figure 
 <dig> 

CONCLUSIONS
qtrim is a fast, highly sensitive and accurate algorithm that outperforms all available approaches for quality trimming of  <dig> sequence data. a noteworthy feature is that it enables sensitive trimming of sub-optimal sequence data thereby enabling researchers to undertake downstream analysis on lesser quality sequence data that otherwise may have been discarded. the command line python version of qtrim can be easily incorporated into sequence analysis pipelines, while the web interface enables users with little or no bioinformatics experience to undertake quality trimming of their high-throughput sequencing data.

availability and requirements
project name: qtrim

project home page:http://hiv.sanbi.ac.za/tools/qtrim

operating system: macos, linux

programming language: python v <dig>  or v <dig>  

other requirements: executables – nothing, source code – biopython, numpy, matplotlib

license: gnu gpl v <dig> 

any restrictions to use by non-academics: commercial use may be restricted and such users should contact the corresponding author for further details.

competing interests
rks, bl, vbb, mbjm and gpm have no competing interests. sat has delivered training workshops in conjunction with roche  as well as having conference attendance sponsored by roche .

authors’ contributions
rks developed the algorithm and implemented the code for the python version of qtrim while bl designed and implemented the qtrim web interface. vbb, mbjm and gpm generated the  <dig> data used in the study. sat conceptualized the project, supervised the work and wrote the final version of the manuscript. all authors read and approved the final manuscript.

