BACKGROUND
researchers have undertaken large genome-wide association studies , linkage analyses and candidate gene studies to elucidate underlying variations to better understand complex biological paradigms. these individual genotyping approaches typically explain up to 25%  <cit>  of the heritable risk of common, complex polygenic disease and usually miss potentially relevant rare alleles  <cit> . nevertheless, gwas have identified many regions that require additional studies to further identify the causative variants within them. recently, the advent of next-generation sequencing  technologies  <cit>  has enabled researchers to catalogue and estimate the contribution of many different types of medically important genetic variants  that have the potential to explain new aspects of the not yet identified heritability  <cit> .

ngs technologies clearly have a higher throughput than traditional sanger sequencing at a significantly lower per base cost, enabling the reading of whole genome in a short period of time  <cit> . nevertheless, whole genome sequencing is not time or cost effective if the researcher is only interested in a small percentage of the genome in a large number of samples. therefore, numerous targeted ngs  approaches have been developed to allow selecting and enriching intended regions from a dna sample before entering into the ngs pipeline  <cit> . by selective recovery and sequencing of only genomic regions of interest, a t-ngs approach can be more cost-effective and result in considerably less weighty data to handle and analyze  <cit> . several standardized t-ngs approaches exist that allow whole exome sequencing for mendelian disorders  <cit> . additionally, special-purpose and customized t-ngs approaches allow gene loci of interest to be analyzed that are not sufficiently addressed by exome approaches/kits.

the targeted enrichment methods described so far fall mainly into three categories: hybridization capture, pcr/amplification-based and selective circularization approaches. these methods differ in several aspects such as the use of solution versus solid-phase hybridization, probe design, cost per sample and workflows with implications for automation. in fact, each method has its own advantages and disadvantages  <cit> . in choosing a target-enrichment approach there can also be many points to consider and balance, such as genomic complexity and nature of the region of interest, study specific needs and objectives, desired fold enrichment, specificity as well as available budget.

when ‘indexing’ strategies are applicable during the process  <cit> , a multiplex t-ngs approach can enable the researcher to efficiently leverage the massive throughputs offered by ngs platforms and process more samples in parallel. molecular barcoding protocols can be used to index different samples together within the same sequencing run. in doing so, the sequencing costs can be amortized across each sample resulting in lower per sample sequencing costs and the ability to quickly process enough samples to achieve the necessary statistical power in an experimental design.

genomic dna  is often a limiting resource and whole genome amplified  gdna is usually prepared/used within many human disease studies to preserve the original precious resources. however, the effect of wga gdna on variant discovery from t-ngs data is unclear and needs careful evaluation  <cit> . to process wga samples we need to use a target-enrichment method that shows a high specificity in order to tackle, to some extent, bias issues that can be introduced during wga preparation. the recent benchmark experience with the leading target-enrichment technologies  <cit>  concluded that both pcr- and circularization-based methods are superior to hybrid capture methods with respect to achieved specific and uniform sequence coverage, albeit they are not able to target large regions in a single experiment, which is in contrast an advantage of hybrid capture approaches.

to this end, the objective of this work was to  evaluate the accuracy of variation discovery within t-ngs data obtained from matched non-amplified and preamplified wga hapmap gdna samples, and  test the effect of sample multiplexing for cost- and time-saving reasons, at different stages of the sequencing workflow, on key enrichment metrics. we targeted  <dig> discrete exons involved in cancer  <cit>  using a combined t-ngs workflow of a microdroplet-based pcr sample enrichment pipeline  and a ngs technology platform . the results suggest that using wga as a starting material and pooling pcr-based enriched samples before sequencing don’t substantially impact on the performance of the analyses.

methods
the here established workflow and study design are shown in figure  <dig> 

samples tested
in this study we evaluated six hapmap gdna samples , members of two family trios . we tested samples ids na <dig>  na <dig>  and na <dig> of family id  <dig>  and na <dig>  na <dig>  and na <dig> of family id  <dig>  whole-genome amplification of the same three gdna samples of family id  <dig> was prepared following standard protocol of genomiphi v <dig> amp kit  <dig> rxs . in each wga reaction, one μl gdna  served as a start material. a typical wga gdna yield of 4– <dig> μg gdna  with average product length of > <dig> kb was achieved. after verifying the quality of the dna/wga samples, the enrichment of the intended target regions of all nine samples, six non-amplified gdna and three matched wga gdna, were undertaken using droplet-based multiplex pcr  as described below.

targeted genomic sequences and primer panel design
the raindance technologies “ <dig> member primer panel” targets  <dig> consensus cds exons from  <dig> different genes thought to contain somatic mutations involved with cancer  <cit> . amplicons were designed as described by sjoblom et. al. the amplicons contained in the raindance “ <dig> member primer panel” represent  <dig>  amplicon bases . amplicons were selected to represent several different design parameters that include: amplicon length , amplicon gc content  and primer tm . the raindance “ <dig> member primer panel” contains  <dig> unique primer droplets, one for each amplicon in the panel. the forward and reverse primers for each amplicon are synthesized and combined into a single primer aliquot in the well of a standard microtiter plate. each primer droplet contains an equal concentration of the forward and reverse primer . the primer aliquot is then reformatted to create an emulsion containing many primer droplets that are identical to each other, each containing a single primer pair. the primer droplets are  <dig> μm in diameter with a volume of eight pl per droplet. each primer droplet is evaluated for its size and morphology to ensure each primer is represented at the same concentration. an automated counting process quantifies the number of primer droplets generated from each primer aliquot. the different primer droplets are then mixed together to ensure that each primer panel has the same number of each unique primer droplet.

genomic dna fragmentation
genomic dna samples were fragmented using a nebulization kit  following the manufacturer’s recommended protocol:  <dig>  μg of gdna was re-suspended in  <dig> μl shearing buffer  containing 10% glycerol ) and was nebulized at 6– <dig> lb per square inch  for  <dig> s to produce 2– <dig> kb dna fragments. fragmentation of the gdna to 2– <dig> kb produces the optimal template size for the amplicons size distribution represented in the raindance “ <dig> member primer library”. sheared gdna was precipitated by adding  <dig> μl  <dig> m sodium acetate, ph  <dig>  ,  <dig> μl  <dig> mg/ml mussel glycogen  and  <dig> μl 100% isopropanol  mixed and stored overnight at −20°c. the samples were then centrifuged at the maximum speed for  <dig> min at 4°c. the supernatant was removed,  <dig> μl of cold 80% ethanol  wash buffer was added and the dna pellet was spun down by centrifugation at the maximum speed for  <dig> min at 4°c. the pellet was air dried and re-suspended in  <dig> μl  <dig> mm tris–hcl, ph  <dig>  . fragmented genomic dna was run on a  <dig> % agarose gel to confirm that the genomic dna was in the correct size range , data not shown.

genomic dna template mix
in order to prepare the gdna template mix,  <dig>  μg of the purified fragmented gdna was added to  <dig>  μl 10× high-fidelity buffer ,  <dig>  μl of mgso <dig> ,  <dig>  μl  <dig> mm dntp ,  <dig>  μl betaine ,  <dig>  μl of rdt droplet stabilizer ,  <dig>  μl dimethyl sulfoxide  and  <dig>  μl  <dig> units/μl of platinum high-fidelity taq  the samples was brought to a final volume of  <dig> μl with nuclease free water, teknova .

merge genomic dna template mix and primer panel droplets: rdt  <dig> instrument
pcr droplets were generated on the rdt  <dig>  one droplet at a time using the manufacturer’s recommended protocol. all of the resulting pcr droplets were automatically dispensed as an emulsion into a single pcr tube and transferred to a standard thermal cycler for pcr amplification. each sample generated an emulsion containing more than  <dig> , <dig> droplets in which each droplet contained a single-plex polymerase chain reaction  that targeted one of the  <dig> targets defined by the raindance technologies “ <dig> member primer panel”. each amplicon was represented by multiple unique pcr droplets .

pcr amplification
samples were cycled in a bio-rad ptc- <dig> thermal cycler with the following profile: 94°c for  <dig> min;  <dig> cycles at 94°c for  <dig> s, 58°c for  <dig> s, 68°c for  <dig> s; 68°c for  <dig> min and hold at 4°c.

breaking emulsion
after pcr amplification the emulsion of pcr droplets were broken, to release each individual amplicon from the pcr droplets, using the manufacturer’s recommended protocol.

pcr product clean up
each sample was purified over a minelute column  following the manufactures recommended protocol. the sample was eluted off the column with  <dig> μl of the qiagen elution buffer. the purified amplicon dna was then run on an agilent bioanalyzer to confirm that the amplicon profile  matches the predicted histogram distribution .

solid sequencing library construction and sample indexing
the sequencing libraries were constructed according to the standard fragment library preparation of the solid  <dig>  system protocols . six individual sequencing libraries were prepared using the enriched non-amplified gdna pcr products and indexed with barcodes  <dig> to  <dig> . three other libraries were prepared using the enriched wga gdna products and indexed with barcodes  <dig>   <dig> and  <dig>  . in parallel, to test the performance of sample pooling before library preparation, equimolar portions of each of the six non-amplified gdna enriched products  were pooled together in duplicates and library ids 768_1l and 768_2l were prepared. in total,  <dig> standard fragment libraries were prepared  . for each library  <dig> - <dig>  μg enriched gdna/wga/pool was used.

purification of the solid libraries
after library preparation, sizing, quantification and quality control of the prepared solid libraries were performed on agilent bioanalyzer  <dig> . a typical electropherogram obtained  showed a primer-dimer peak between  <dig> and  <dig> bp . these primer-dimers, and other unincorporated dntps, primers, salts and other contaminants, were removed and pcr amplicons > <dig> bp were recovered according to the standard procedure of agencourt ampure kit . removal of the primer-dimers from the solid library construction and sample indexing step was necessary to reduce the carryover of these products into the library. after the purification step, sizing and quantification of all the generated libraries were measured again on the agilent  <dig> bioanalyzer  shows a typical electropherogram after purification).

pooling strategies of indexed samples
we evaluated here the performance of sample indexing and pooling before and after the empcr step. after library purification, empcr was carried out for three different scenarios : a) nine individual empcrs were carried out for the non-amplified gdna’s  and the wga gdna’s . b) two empcr reactions were carried out from the two pooled samples before library construction: emulsion ids 768_1em and 768_2em. c) equimolar portions of five of the non-amplified gdna libraries  were collected and one empcr was performed ). library id 763l with bc  <dig> was not pooled with the afore-mentioned five gdna libraries due to its low concentration, which was only appropriate for one empcr of the individual library id 763em. finally, after performing all the afore-mentioned empcr reactions, a single pool of equimolar amounts of the obtained individual empcr products from non-amplified gdna emulsion ids 759em, 760em, 761em, 762em, 763em and764em was generated and processed in parallel ). therefore, a total of  <dig> empcr reactions were performed for all the tested comparisons .

ngs using solid  <dig>  system platform
the sequencing was carried out on the solid  <dig>  system platform  using standard fragment library protocol and lengths of  <dig> bp according to the manufacturer’s instructions . the principle steps of the solid sequencing protocol are well covered  <cit> . here each enriched product  was run on a single well/spot of an octant slide. a total of  <dig> wells/spots were used , i.e. one complete octant slide  and five spots  of a second octant slide , for these experiments to sequence the  <dig> different sequencing samples . the solid platform interrogates each base by two separate probe hybridizations , which has the advantage of improved base calling accuracy . the color space reads are translated into  fasta code during alignment to a reference genome, which is performed off the machine, on a high performance computer cluster.

mapping the solid sequencing data
solid sequencing reads  were aligned to the human genome  using the clcbio genomics workbench   <cit>  with a custom raindance workflow plug-in, and in-house perl scripts. before assembly, the reference genome was annotated with the  <dig> amplicon targets, consisting of  <dig> discontiguous regions, using a gff file . primer locations of non-overlapping amplicon targets were omitted from analysis as snp detection is not possible under the primer as the pcr will generate amplicon product for these regions from the primer and not the gdna. default settings for reference assembly  were used. non-unique reads were mapped randomly to possible placements. all aligned sequence reads were exported in sam  <cit>  format.

sequence variant identification
single nucleotide sequence variants were identified using the clc bio genomics workbench , using default settings with the following exceptions: minimum allele frequency was set to 10%, minimum coverage was set to  <dig>  maximum coverage was set to  <dig> . only snps that were located in amplicon target regions, excluding primer locations, were analyzed. nucleotide coverage of known snp positions in the target regions were extracted using a perl wrapper in combination with samtools  <dig> . <dig>  <cit> . samtools pileup files were combined with a perl script. nucleotide sequence data reported are available in the genbank databases ) under the study accession number erp <dig>  <cit> ).

data analysis
snp concordance was determined by comparing hapmap genotype data  to snps found using the clc bio genomics workbench. caucasian  hapmap snps from na <dig>  na <dig>  na <dig>  na <dig>  na <dig>  and na <dig> were downloaded from  <cit> . snps detected from the solid sequencing data were also compared to snps from dbsnp, build  <dig>  a perl script was written to extract all known snps from the six hapmap samples.

snps were considered heterozygous if non-reference allele frequency was 10-90%. snps were considered homozygous if non-reference allele frequency was equal to or greater than 90%. for a snp to be considered detected, the snp had to have at least five reads per allele. therefore a heterozygous snp had to have at least  <dig> counts per position to be considered “detected”. only detected snps were used for concordance calculations.

RESULTS
the experimental workflow and investigated samples are summarized in figure  <dig>  several experimental alternatives were performed to investigate the effect of using wga gdna material and different pooling strategies on the performance of selective recover of genomic sub-regions of interest and on variant detection.

sample throughput, sequence capacity and enrichment metrics
genomic alignment and snp detection were carried out as described in methods. on average, 66% of the sequencing reads that aligned to the human genome , mapped to the target regions. this on-target percentage, or specificity, appeared unaffected by the pooling strategy used. however, a slight decrease in specificity was observed in the wga samples. for example, specificity of sample na <dig>  na <dig>  and na <dig> dropped from  <dig> %,  <dig> %, and  <dig> % for non-amplified gdna to  <dig> %,  <dig> %, and  <dig> %, respectively, for the wga samples.

the c <dig> coverage was high  across all of the non-pooled samples indicating a success of each primer pair to produce an amplicon. all of the expected amplicons in this panel  produced a pcr product. amplicons with low coverage might result from the inability for the sequencing chemistry to sequence through the sequence context of the amplicon.

although coverage at 20×  varied, it correlated to mean base coverage as expected. however, normalized base coverage  was consistent throughout all the samples , suggesting that the utilized enrichment process is robust and reproducible. for samples with mean base coverage of at least  <dig> reads per base, c <dig> was at least 90%. for all samples that had a mean target base coverage of  <dig> reads per base, the percentage of bases that were covered at least once  was greater than 98%. also, c <dig> increased to  <dig> - <dig> % when mean base coverage was greater than 1000×. in addition, the results not only showed adequate average coverage and enrichment folds for reliable snp discovery, but also adequate uniform coverage of the barcoded and pooled samples before and after empcr . a low number of reads of the samples indexed with bc <dig> was observed , compared to all other indexed samples with other barcodes. consequent lower coverage  and snp detection rates  were also observed – while the concordance rates were not similarly affected. the substantial underrepresentation of samples indexed with bc <dig> has also been revealed in other in-house multiplex experiment including bc <dig> on human gdna samples using different sample enrichment technologies .

- reads: total sequencing reads per sample.

- mapped: percentage of total reads that could be aligned to the human genome .

- on-target: percentage of mapped reads that align to the target regions.

- adoc: average depth of coverage of target base.

- c1: percentage of target bases that are covered by at least one sequencing read.

- c20: percentage of target bases that are covered by at least  <dig> sequencing reads.

- coverage  <dig> × mean: percentage of target bases that are covered by at least  <dig> × of adoc. note that one barcode  was underrepresented .

- gdna: genomic dna; wga: whole-genome amplification; empcr: emulsion pcr; bc: barcode.

- detection: percentage of snps that are covered by at least five sequencing reads.

- concordance: percentage of detected snps that matched the hapmap  genotype. due to the underrepresentation of barcode  <dig>  in the pools  <dig> and  <dig>  the detection and concordance rates were lower .

- gdna: genomic dna; wga: whole-genome amplification; empcr: emulsion pcr; bc: barcode.

altogether, the results shown in table  <dig> demonstrate good performance on both non-amplified gdna and wga gdna samples with no substantial difference in the sequence performance among the samples and reveal specificity of  <dig> % ±  <dig> % and uniformity  of  <dig> % ±  <dig> %.

as a higher coverage depth is a pre-requisite for somatic and rare variant identification in particular, the samples were re-analyzed to calculate the coverage beyond 20-fold  in our experimental design . the c <dig>  c <dig> and c <dig> for the individual samples, which were each sequenced in a separate octet , maintained high levels of average coverage across the target region . the individually barcoded samples expectedly showed lower coverage at c <dig>  c <dig> and c <dig> . these results suggest that this t-ngs methodology may be applied for the analysis of genetic variations in cancer genes.

variant detection and concordance - snp concordance with hapmap genotypes
to determine the concordance of the variant detection, the generated sequences per hapmap sample were compared to their reference genotypes and across the different sample treatments . summary concordance data is shown in table  <dig>  in total  <dig> snps were compared and false negative detection rates were estimated . in general, the results shown in table  <dig> indicate low false negatives . individually sequenced samples showed a modestly lower false negative detection rate  than that of the corresponding pooled gdna and wga gnda paired samples . the snp detection rate correlated with the mean base coverage, and was unaffected by the pooling strategy. importantly, the wga gdna samples showed nearly similar concordance rate to that of the non-amplified gdna samples . overall, concordance averaged  <dig> % and generally remained unchanged, regardless of the applied pooling strategy.

efficiency and detection snp rates of non-barcoded and pooled samples
the sequencing results of the two technical replicates  were used to analyze different enrichment measures, variant detection rates, and the reproducibility of the method. samples 768_1l and 768_2l were pooled from sample id’s  <dig>   <dig>   <dig>   <dig>   <dig> and  <dig> and represented hapmap samples na <dig>  na <dig>  na <dig>  na <dig>  na <dig>  and na <dig>  respectively . since genotyping data from na <dig> was limited for all positions that were considered, genotypes were inferred from the non-barcoded samples and used for comparison. because we were inferring genotypes from the sequencing data, it allowed us to generate a larger snp set which also included non-hapmap and non-dbsnp  snps. these non-dbsnp snps could represent valid, potential novel snps.

this strategy to infer snps with confidence stemmed from the knowledge that we have selected samples from hapmap trios and the inferred snps followed mendelian patterns of inheritance within each trio. furthermore the inferred snps were observed and concordant between replicate samples built into our experimental design  for hapmap family  <dig> 

after genotypes were calculated for these positive control snps , a cumulative genotype was calculated for the pool. snp detection in the non-barcoded, pooled samples were such that the non-reference allele had to represent at least 1% of the total allele count for a given nucleotide. the minimum number of counts for each non-reference allele was varied  to optimize sensitivity and specificity . the lowest false snp discovery rate  in the technical replicates was detected at a stringent coverage parameter . the reverse holds true at lower  coverage; we reached 40% false discovery rate .

- minimum read count for snp call: minimum number of non-reference allele counts required for a snp to be considered detected.

- positive control snps: positive control snps generated from the non-pooled, non-barcoded data . since the hapmap genotyping data was incomplete, even for known snps, we attempted to create a positive control set of snps within the targeted regions. if the snp was detected within samples 759– <dig>  a combined genotype was determined for that snp position. for example, position x was determined to have a “cg” genotype in sample  <dig> and position x had the reference genotype of “cc” in samples 760– <dig>  the predicted allele frequency would be  <dig> % . in the non-pooled samples, a snp with a non-reference allele frequency of 10-90% was considered a heterozygote. a homozygous snp in non-pooled samples was defined as having >90% non-reference allele frequency. the number in this column represents the total number of snps that have a non-reference allele within a given pooled sample. note that these positive control snps include hapmap samples with rs ids, non-hapmap samples with rs ids, and potentially novel snps.

- positive control snps found: this number represents the number of positive control snps that were detected in a given pool with a given set of parameters.

- total snps detected: this number represents the total number of snps found in a given pool with a given set of parameters. this number contains the “positive snps found” plus other snps. it is assumed that most of these snps are false positives since this number decreases significantly if you increase the stringency of your snp detection parameters. however, some novel snps could exist in this set.

- sensitivity: in this case, this is simply the percentage of positive controls snps found in a given pool with a given set of parameters. sensitivity decreases as snp detection stringency increases.

- false discovery rate: this was defined as /total snps detected *  <dig> 

actual allele frequencies in the two pooled samples before library preparation  correlated well  with predicted allele frequencies of the pooled gdna samples . the non-reference allele frequencies were very consistent between the two technical replicates, as illustrated in figure  <dig> with high pearson correlation coefficient .

minor allele detection and mendelian inheritance quality check
the two pooled samples before library preparation  were also evaluated to detect minor alleles represented in the pool based on the known reference genotypes for each of the individual samples within each pool. the predicted minor allele frequency  for each sample was calculated by combining the genotypes of each of the six individual samples within the pooled sample. the actual minor allele frequency was calculated for each snp within the sequenced samples. boxplots were generated for the three smallest expected mafs . in each case, the predicted frequency and the actual frequency were in agreement as shown in figure  <dig> 

in addition, by evaluating family structure, we did not detect any errors in the mendelian patterns of inheritance of genotypes between the parents and the offspring within each trio .

discussion
optimizing t-ngs methods with unbiased performance using non-amplified and amplified  gdna samples is necessary to enable statistically powered large-scale studies. even if the cost of routine sequencing of the human exome and whole-genome becomes affordable in the near future, multiplexed t-ngs will serve alongside as a downstream validation and diagnostic tool to reach sufficient coverage with less sequencing, enabling the investigation of a higher number of samples in parallel. more specifically, t-ngs provides more power to catalogue most types of variations present in clinically relevant subsets of the genome at a fraction of the cost of whole-genome sequencing. therefore, using mixed approaches, for instance whole-genome sequencing at low-coverage followed by t-ngs at higher coverage, may become more applicable in the coming years  <cit> .

in the present study, we tested the performance of combining a microdroplet-based pcr targeted sequencing approach to ngs and demonstrated its utility in t-ngs of  <dig> cancer exons throughout the genome of different comparisons. we evaluated the performance of standard gdna  versus whole-genome amplified  gdna samples as well as testing different sample indexing strategies from the sequencing workflow, namely pooled samples before library preparation  versus individual samples, and pre- versus post-empcr with sample indexing using solid molecular barcodes. the results of t-ngs of  <dig> cancer exons demonstrate sequencing specificity of  <dig> % ±  <dig> %, uniformity  of  <dig> % ±  <dig> %, concordance of  <dig> % ±  <dig> % and no mendelian inheritance errors. we have also demonstrated the ability to detect minor allele frequencies within pools of six non-barcoded non-amplified gdna samples. these results show the possibility to process wga gdna samples at nearly similar performance to that of standard non-amplified gdna samples without showing significant allelic bias/difference in enrichment metrics and variation detection among non-pooled and pooled samples. for instance, 95% of the targeted regions in the six hapmap samples that were tested  were covered with at least 20× coverage while maintaining a  <dig> % average genotype concordance across all of the samples.

the results show that combining the applied target enrichment approach with ngs technology provided many advantages. this t-ngs approach leverages the sensitivity and specificity of the pcr to efficiently capture and represent the sequence context from different genomic regions  <cit> . the stringency and flexibility to allocate primers to the targets of interest are required to tackle complex genomic regions of high homology  and repetitive elements  <cit> . the uniformity of the sequence coverage across all the targeted regions in the indexed samples allows for efficient use of ngs sequencing capacity. typical uniformity with a panel achieves greater than 85% of bases within  <dig> × of the mean coverage. this level of performance allows for predictable sequence coverage beyond what is reported in table  <dig> with the appropriate amount of sequencing per sample . the utilized ngs platform, with its high throughput, allows accurate snp detection as argued  <cit>  and shown here. inadequate enrichment and/or coverage depth, which is not the case in our study, can cause failure to detect real nucleotide variation , which may lead to higher false-negative rates in particular for heterozygotes  <cit> . in fact, comparable coverage depth and uniformity of the tested  <dig> exons have been achieved using other ngs technology platforms,  <dig> flx and illumina . as illustrated in table  <dig>  parallel detection of both homozygous and heterozygous genotypes, points to the efficiency of the tested workflow and indicates that little, if any allelic bias has been introduced during sample enrichment and sequencing processes.

one exception to the observed even distribution of all tested bar-coded samples was the lower representation of samples indexed with bc <dig>  we supposed at first that this might be due to inaccurate quantification and pooling; i.e. lower representation of bc <dig> in the original libraries before pooling/enrichment, either due to a pipetting error or a wrong dna concentration measurement during library preparation. surprisingly, we have also observed the substantial underrepresentation of indexed samples with bc <dig> in other multiplex experiments using a different sample enrichment technique, hybridization-based sequence capture, in three successive runs  <cit> . so we considered bc <dig> as an outlier and we recommend avoiding it in future experiments. in addition, the relatively high snp false discovery rate  of the non-barcoded technical replicates , although it seems to be dependent to some extent on coverage depth, it indicates that pooling enriched gdna samples before library construction, using the current t-ngs approach, may not be a sensible option. we have mainly tested this pooling option to access the reproducibility of the established workflow . these results in general emphasize the need to achieve higher coverage to reduce the snp false discovery rate. applying of a similar pooling option to enriched wga samples will likely result in worse data/performance; due to a potential cumulative impact/bias from different dna amplification reactions. instead, we recommend pooling the samples before or after empcr in the course of the ngs protocol .

another clear limitation in our study, which needs to be acknowledged, is the relatively low percentage of mapped reads to the human genome . the percentage of mapped reads depends on several factors, such as ngs technology platform, target-enrichment approach, mapping approach, and software and analytical approaches. using the same target region and raindance amplicon library on different ngs technology platforms resulted in opposite numbers of produced reads and mapping percentages to the human genome . while the long-read ngs platform  generated a lower total number of reads , the percentage of mapped reads was as high as 84%. in contrast, only up to 40% of the  <dig> to  <dig> million reads produced by the short-read ngs platforms  mapped to the human genome. this might indicate that shearing of the enriched pcr amplicons during preparation of the sequencing libraries for the short-read ngs platforms  leads to generation of fragments that are ambiguously mapped to several locations of the genome . in fact, clc bio and other mapping tools, such as bwa, randomly map these ambiguous reads to one of the ‘possible’ locations. in addition, we found recently that the quality of snp calling was substantially affected by the choice of mapping strategy and analytical tools  <cit> . for example, we showed that the tested widely-used snp-callers do not seem to be well-trained to handle enrichment data, and thus produced a significant fraction of false positive as well as negative snp calls. moreover, changing the mapping settings or using another software version can result in different enrichment metrics. this observation was confirmed here using a newer version of the clc bio workbench software , which, for instance, improved the mapping specificity to up to 56% . the drop in mapping percentage, while apparently worrisome, can still be satisfactory as long as it does not impact on the accuracy of the downstream snp calling. in other words, achieving a high and even coverage at intended bases  and good on-target percentage , as shown in our study, ensure accurate snp calling.

the “barcoding” approach holds promise to enable the sequencing of large numbers of samples, and allows for the identification of rare and novel variations in the intended loci as well as variant carrier post-sequencing. comparing the results of multiplexed barcoded samples pre- and post-empcr revealed similar performances of both schemes . therefore we recommend pooling samples before empcr to save money, time, and effort. indeed, the best design is to index samples and pool them before enrichment. testing pre-enrichment sample multiplex was unfortunately infeasible using the applied target-enrichment method and due to the limited length of the generated sequence reads of the utilized solid platform . if we consider  <dig> bp sequencing reads as an example, then we would expect that at least ≥5-10% of the sequencing capacity will be lost to sequence only the pcr primers . sample pooling before target enrichment is possible using array/hybridization-based sequence capture methods and no loss in sequence capacity is expected, since the binding oligos/probes are kept fixed on the array and only the enriched genomic products are eluted from the array and sequenced  <cit> . the array-based sequence capture approach may however be limited with regard to selection of complete genomic regions due to repeat masking before designing certain capture probes.

as a final point, due to the knowledge of the exact start and stop position of each amplicon within the primer library, the necessary amount of sequencing required for a given sample can be precisely calculated, depending on the level of coverage that is required. for the  <dig> amplicon library used in this study, the sum total of amplicon bases was  <dig> . the amount of sequencing required to achieve 100× average coverage, which results in >85% of the bases represented at a minimum coverage of 20×, is  <dig> , <dig> bases. the total reads for the 6× pool  was  <dig> , <dig> total reads and  <dig> , <dig> reads on target, resulting in  <dig> , <dig> bases per octet. this would have allowed up to  <dig> samples to be pooled per octet or  <dig> samples per flow cell and  <dig> samples per run on the solid v <dig> system . another practicable scenario to improve coverage for larger target regions could be using a lower degree of multiplexing  on a quarter of a sequencing slide  instead of on an eighth of a slide . following such a strategy would allow more sequencing room and subsequent higher coverage magnitude; by decreasing the inherent effect of slide’s physical separation that decreases the overall number of sequences obtained. in addition, recent rapid improvement of ngs technologies would in principle allow a higher level of sample multiplexing to bring per-sample cost down further.

CONCLUSIONS
in this study, we have demonstrated the ability to combine pcr solution-based targeted sequencing and the high throughput of ngs to process samples that have been pooled and indexed at several different steps within the targeted sequencing workflow. for standard gdna we found no significant difference in the sequence performance among the samples tested on the short-read abi solid platform: the sequence specificity  was ~65%, the uniformity was ~85%, and the genotype concordance was 99%. although we here did not test pooled wga gdna samples, the performance of our non-pooled wga samples showed sufficient promise to merit more extensive investigations in the future. in summary, the ability to generate high quality and uniform sequence data across wga and pooled gdna samples using the described t-ngs approach may allow researchers to achieve the necessary statistical power within their studies to elucidate the underlying biology.

abbreviations
wga: whole genome amplification; ngs: next generation sequencing; t-ngs: targeted-nsg; gwas: genome-wide association studies; gdna: genomic deoxyribonucleic acid; empcr: emulsion polymerase chain reaction; bc: barcode; maf: minor allele frequency.

competing interests
james brayer, jason warner, jeff olson and darren link are employees of raindance technologies.

authors’ contributions
ae, jb, af designed research; jo, dl, jb performed sample enrichment using droplet-based pcr technology; ae, mbs, pr, af conducted ngs sequencing; jw and mf performed data analysis and submission; ae, jw, jb interpreted the data; ae wrote the first draft of the manuscript; jb, jw, mf, mbs, pr, ss, srj., af proof-read and edited the manuscript; ae, jb, ss, pr, af coordinated the project. ae, jb revised the manuscript. all authors read and approved the final manuscript.

supplementary material
additional file 1
table s <dig>  an overview of the rdt  <dig> member panel. table includes individual tabs describing the amplicons, primers and gff.

click here for file

 additional file 2
figure s <dig>  raindance genomic dna template droplet and primer droplet merge. pcr droplets are generated on the rdt  <dig> instrument . for a single sample, the gdna template mix and the raindance  <dig> member primer library and four consumables are required, namely rdt  <dig> chip, rdt  <dig> template input/output vial, rdt  <dig> collect input/output vial, and a pcr tube strip, axygen scientific. the rdt  <dig> instrument generated each pcr droplet by pairing a single gdna template droplet with a single primer droplet. the paired droplets flow past an electrode embedded in the chip and are instantly merged creating the pcr droplet. all of the resulting pcr droplets were automatically dispensed as an emulsion into a single pcr tube and transferred to a standard thermal cycler for pcr amplification. figure s <dig>  a and b comparison of dna fragment distribution of raindance  <dig> member primer panel bioanalyzer trace with raindance  <dig> member primer library predicted amplicon profile. comparisons of the dna fragment distribution of raindance  <dig> member primer panel bioanalyzer trace  with the predicted profile . as shown here, the amplicon profile obtained from the agilent bioanalyzer results  nicely matches the predicted histogram distribution . figure s <dig>  removal of primer-dimer peaks using agencourt ampure kit.  a typical electropherogram obtained showed a primer-dimer peak between  <dig> and  <dig> bp . b) the primer-dimer peak  were removed after purification of the solid fragment library  using the standard procedure of agencourt ampure kit . figure s <dig>  coverage uniformity across all the barcoded and pooled samples before  and after  emulsion pcr. a comparable distribution of average depth of coverage  across libraries pooled before and after emulsion pcr  is shown here. barcoded libraries pooled after empcr ), showed more uniform adoc. samples assigned to barcode  <dig>  showed the lowest adoc.

click here for file

 additional file 3
table s <dig>  overview of sample processing: raindance sequence enrichment, solid sequencing library construction and sample indexing, emulsion pcr and sequencing. the samples were enriched on the rdt <dig>  followed by shearing and standard library construction according to the solid  <dig>  protocol . six individual libraries were prepared using the enriched gdna products and indexed with barcodes  <dig> to  <dig> . three additional libraries were prepared using the enriched wga products and indexed with barcodes  <dig> to  <dig> . to test the performance of each step, the non-amplified samples were pooled before and after the library preparation process. pre-library preparation pools were created by combining an equimolar portion of the  <dig> individual gdna. the samples were pooled together and processed as single samples . post-library preparation pools were created by combining equimolar portions of each individual sample post library preparation. a post library preparation pool was generated before empcr  and after empcr . the resulting pcr products were sequenced on a solid  <dig>  system using  <dig> bp fragment libraries. table s <dig>  clc bio snp detection parameters. the following parameters were used for snp detection through the clc bio genomics workbench : maximum coverage  <dig>  maximum gap and mismatch count  <dig>  minimum average quality  <dig>  minimum central quality  <dig>  minimum coverage  <dig>  minimum variant frequency   <dig> . variant count threshold  <dig>  window length  <dig>  in the non-pooled samples, a snp with a non-reference allele frequency of 10-90% was considered a heterozygote. a homozygous snp in non-pooled samples was defined as having >90% non-reference allele frequency. table s <dig>  coverage metrics clc bio genomics workbench . table s <dig>  sequence data generated using  <dig> flx and illumina of the same target regions . table s <dig>  sample multiplexing calculation for the rdt  <dig> member panel and solid sequencing platform.

click here for file

 additional file 4
table s <dig>  an overview of all snps and genotypes detected. genotypes from non-barcoded pooled samples. table includes both inferred and non-inferred genotypes.

click here for file

 acknowledgement
this study was supported by the german ministry of education and research  through the national genome research network  and the irn-f project of the dfg cluster of excellence “inflammation at interfaces”. the research leading to these results has received funding from the european community's seventh framework programme  under grant agreement n°  entitled readna. we wish to thank also lena bossen, catharina von der lancken, ilona urbach, susan ehlers  for technical assistance. we would also like to thank preethi srinivasan for helping in data analysis.
