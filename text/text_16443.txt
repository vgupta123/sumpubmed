BACKGROUND
transcription and translation are the means by which the cells interpret and express their genetic information  <cit> . only part of the transcribed sequences carries information to codify proteins . in other words, even though mrna can be translated in its entirety, only a section of this mrna is translated into amino acid  <cit> . therefore, given a molecule of mrna, a central problem of molecular biology is to determine whether it contains cds and thereafter to discover which protein will be codified. the region of the mrna sequence where the initiation of the protein synthesis process occurs is called the translation initiation site .

control of the initiation of translation is one of the most important processes in the regulation of genetic expression  <cit> . thus, determining the tis is not a trivial task; it is of great relevance for genetic inference. a high level of accuracy of prediction could be useful for a better understanding of the protein obtained from the sequences of nucleotides  <cit> .

normally, translation begins in the first atg of the mrna molecule that has an appropriate context  <cit> , but can begin in a different codon  <cit> . depending on the position of the synthesis initiation in the mrna strand, the triplet of nucleotides selected for the synthesis can vary, also altering the amino acids generated. the lack of knowledge about the preservative features in the process of identifying the initiation of translation makes the prediction of the tis a complex task. for this reason, computational methods which identify patterns can be used with the aim of extracting the implicit knowledge involved in this process  <cit> . since  <dig>  the prediction of the tis has been studied extensively using biological methods, statistics and computational techniques  <cit> . initially, statistical methods were exploited with the aim of discovering patterns in positive sequences. the pioneering work of kozak  <cit> , a statistical analysis of the sequences of  <dig> mrnas of eukaryotic cells, revealed that some positions in the sequences of mrnas, relative to the tis, are very stable, determining the kozak consensus  <cit> , gccccatg, where there is a predominance of these nucleotides in positions - <dig> and + <dig> 

another statistical analysis was conducted by cavener et. al  <cit>  on the start codon  and the stop codons , and an algorithm was developed to analyze the frequency of the nucleotides and the multiple positions of the nucleotides. in the work developed by kozak  <cit> , a proportion of 79% of adenine  in position - <dig> was identified  while cavener et. al  <cit> , using  <dig>  vertebrate sequences, obtained a 58% probability of a being in the aforementioned position.

nakagawa et. al  <cit>  conducted comparative analyses between  <dig> species, including animals, fungi, plants and protists, revealing the existence of consensus for different species. based on this analysis, the following regions of consensus were identified: the presence of a purine  in position - <dig>  the presence of a or c in position - <dig>  the presence of c in position + <dig>  the position - <dig> had already been discovered by kozak  <cit>  and was confirmed by this study.

different computational methods have been applied to the prediction of the tis including artificial neural networks   <cit> , support vector machines   <cit>  and the gaussian model  <cit> . utilizing artificial neural networks, stormo et. al  <cit>  classified the sequences of escherichia coli using codification of  <dig> bits  and windows of  <dig>   <dig> and  <dig> nucleotides centered on atg. pedersen and nielsen  <cit> , however, trained artificial neural networks using a database of vertebrates which was processed to obtain the correspondent sequences of mrna. of these sequences, only those with the tis annotated and with at least  <dig> nucleotides in the upstream region and at least  <dig> in the downstream region were selected. the resultant base had  <dig>  atgs,  <dig>   being tis and the other  <dig>   being non-tis. in this study, windows of  <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig> and  <dig> nucleotides centered on atg were used. the codification used was the same as that of stormo et. al  <cit>  - binary of  <dig> bits. pedersen and nielsen  <cit>  obtained sensitivity, specificity and accuracy of 78%, 87% and 85%, respectively. the authors also conducted an analysis of the sequences to reveal that features are important for distinguishing tis from non-tis. it was discovered that position - <dig> is crucial in the identification of the tis and this corroborates with the other studies cited.

hatzigeorgiou  <cit>  also used ann to classify sequences of human cdna, achieving accuracy of 94%. the author utilized two modules: consensus-ann  and coding-ann . the consensus-ann module evaluates the tis candidate and its most immediate neighborhood through a window of  <dig> nucleotides. the sequences were extracted from positions - <dig> to + <dig> and the binary codification of  <dig> bits was used. the coding-ann module evaluates the upstream and downstream regions of the tis candidate and operates with windows of  <dig> nucleotides. the final method is the integration of the modules where scores are calculated for each atg of the molecule and the first atg which offers a score above  <dig>  is considered the tis of the molecule.

using svm, zien et. al  <cit>  achieved accuracy of  <dig> % for the same database as pedersen and nielsen  <cit> . the authors also used the same size of window  and the same codification. they showed how to obtain improvements using a new kernel function called locality-improved kernel with a small window in each position. the locality-improved kernel emphasizes correlations between the positions in the sequence that are close to each other and a size of  <dig> nucleotides upstream and downstream is empirically determined as optimum. in other words, the modification was to favor local correlations between nucleotides while dependencies between nucleotides in distant positions were considered of little importance or nonexistent. with this kernel function, the authors obtained sensitivity, specificity and accuracy of  <dig> %,  <dig> % and  <dig> %, respectively.

at a later date, zien et. al  <cit>  improved these results through a more sophisticated kernel function known as the salzberg kernel. the salzberg kernel is essentially a conditional probabilistic model of the positions of dinucleotides. using this kernel, the authors obtained an accuracy of  <dig> % for the same database. li et. al  <cit>  utilized two new proposals for the identification of the tis. firstly, they introduced a class of new kernels based on string edit distance, called edit kernels, to be used with svm. according to the authors, the edit kernels are simple and have significant and probabilistic biological interpretations. next, they converted the downstream region of an atg into a sequence of amino acids before applying svm. they demonstrated that the approach they adopted is significantly better .

nobre, ortega and braga  <cit>  conducted experiments to discover the tis using  <dig> nucleotides in the upstream and downstream regions, in addition to svm with simple kernel functions. inspired by a study conducted on the frequency of triplets of positive and negative sequences, they presented a new codification methodology. instead of individually codifying each nucleotide, the codification was done per triplet, with a sliding window of size  <dig>  the authors obtained a 50% reduction in the number of entries. in order to balance the data, they used the smote algorithm  <cit>  to replicate minority class samples. the authors worked with bases of five organisms extracted from the refseq database  <cit> : danio rerio, drosophila melanogaster, homo sapiens, mus musculus and rattus norvegicus, under six levels of inspection. tzanis et. al  <cit>  developed a methodology for the prediction of the tis, called mantis, with three main components: consensus, coding region classification, and atg location. the coding region classification component involves training a model to classify whether or not the atg of a sequence is the tis. they utilized features selected from previous studies  <cit>  and pga  to obtain the lowest number of non-correlated features, since many are correlated to each other. the consensus component uses markov rules which capture not only the probability of occurrence of a nucleotide in a determined position, but also how the occurrence of a base interferes with the occurrence of another in the region close to the atg . the atg location component is considered a new model, being based on the location of the atg in the sequence in accordance with the ribosome scanning model  described by kozak  <cit> . the final stage of mantis is the fusion of the decision of the components, the output being the estimated probability of an atg being a tis instead of a simple true/false decision. for the prediction, four classification algorithms were used: naive bayes, c <dig> , k-nearest neighbor and svm, obtaining an average accuracy and adjusted accuracy of  <dig> % and  <dig> %, respectively.

tikole and sankararamakrishnan  <cit>  used ann with two hidden layers to predict the tis in sequences of human mrna in which there is a week kozak context. the authors stated that the translation initiation site has a weak kozak context if purine and guanine are absent in positions - <dig> and + <dig>  respectively. they obtained sensitivity of 83% and specificity of 73%.

in contrast to other authors, zeng et. al  <cit>  created an algorithm with the aim of constructing representative, dependable and readily available databases free from redundancy in order to facilitate the evaluation of the efficiency of the algorithms used for predicting the tis. to prepare these databases, they considered three different features: the molecular weight , the isoelectric point  and the hydrophobicity index  profile.

saeys, abeel, degroeve and peer  <cit>  evaluated the performance of several tis recognition methods at the genomic level, and compared them to state-of-the-art models for tis prediction in transcript data. the authors concluded that the simple methods largely outperform the complex ones at the genomic scale, and proposed a new model for tis recognition at the genome level that combines the strengths of these simple models.

sparks and brendel  <cit>  demonstrated that improvements in statistically-based models for tis prediction can be achieved by taking the class of each potential start-methionine into account, pending certain testing conditions. they developed the metwamer package for tis prediction and demonstrated that the proposed model based on perceptron is suitable for the tis identification task.

having identified that the problem of predicting the tis is highly imbalanced and that the oversampling methods, which have already been used in the present context, significantly increase computational complexity, this study proposes an undersampling class balancing method, m-clus. this is particularly important for large databases where oversampling techniques are not viable as they significantly increase the size of the databases involved.

in addition to the balancing method, this study also investigates the integration of features into positive and negative sequences, attempting to increase the measures of performance.

finally, a methodology for the inclusion of acquired knowledge  by the classifier is proposed, where, from the model obtained by training using upstream region sequences and the tis, the sequences of the downstream region are first classified and later included in new training. this methodology increases the rate of precision of all the evaluated databases.

this paper is organized as follows: firstly, the “methods” section shows all the steps used in this study for the prediction of tis. to test the proposed methodology the organisms mus musculus and rattus norvegicus have been used as a reference. the “results and discussion” section presents the results obtained by the proposed methodology for these two organisms. once defined, the best configuration was tested with larger databases such as arabidopsis thaliana, caenorhabditis elegans, drosophila melanogaster and homo sapiens. this is detailed in the “validation of the methodology with other databases” section. the “comparison with other tis prediction tools” section provides a comparison between some existing tools for predicting tis and the methodology proposed in this study. finally, the “conclusions” section presents the final considerations.

methods
this section describes the methodology used to develop the proposed tis prediction model, namely: description of the database used, the form of extraction of the positive and negative sequences from the mrna, balancing methods, the classifier used, the inclusion of features, incorporation of the knowledge acquired by the classifier, the measures of performance and the validation process used.

database
since the proposed method requires a large amount of testing , it was initially tested with the smaller databases, mus musculus and rattus norvegicus, and then expanded to organisms which have a larger amount of mrna: arabidopsis thaliana, caenorhabditis elegans, drosophila melanogaster and homo sapiens. all databases were extracted from the public database refseq  <cit>  and relate to the organisms under the reviewed inspection level already evaluated by nobre, ortega and braga  <cit> .

extraction of the positive and negative sequences
in order to use the svm classifier, positive  and negative  sequences were extracted through an implemented tool, predicttis  <cit> , with variations of windows of the following sizes: -8+ <dig> , -12+ <dig>  -20+ <dig>  -30+ <dig>  -40+ <dig>  -50+ <dig>  -60+ <dig>  -10+ <dig>  -50+ <dig>  -10+ <dig>  -10+ <dig>  -8+ <dig>  -12+ <dig> e -12+ <dig>  initially, experimental tests were conducted with windows of symmetrical size, for example -12+ <dig>  however, tests with asymmetrical windows proved to be more efficient. the executable file predicttis is available for download from  <cit> .

the sequences were extracted only from files containing the minimum number of nucleotides in the upstream region of the window. thus, all the files that did not contain this number were disregarded. having extracted fragments of negative sequences from the database, there were two possible classifications in accordance with the alignment of the atg with the tis: in frame or out of frame. if a sequence is in frame with the tis, this means that it is aligned with the tis. in other words, the start of the atg is a position which is a multiple of  <dig> of the upstream and downstream regions with regard to the tis. figure  <dig> presents examples of extraction of positive and negative sequences given a molecule of mrna. the tis is determined by atg, highlighted in red, and is represented by positions + <dig>  + <dig> and + <dig>  figure  <dig>  presents an example of a positive sequence. parts  and  of figure  <dig> present examples of out of frame and in frame negative sequences, respectively.

in this study, two approaches for the extraction of positive and negative sequences were considered. in the first, all sequences that had atg and were not the tis were considered negative. the second approach, called inclusion of acquired knowledge , considered that all atgs that are in the downstream region had no classification, at first. this is considered since these atgs are not evaluated by the ribosome scanning model .

total quantity of mrna for organisms mus musculus and rattus norvegicus are respectively  <dig> and  <dig>  download in 05/03/ <dig> 

from this table, it should be observed that the problem is highly imbalanced, justifying investment in balancing methods. it should also be noted that the number of positive sequences extracted is not equal to the number of mrna molecules, since only those sequences that had cds greater than or equal to  <dig> nucleotides  were extracted . additionally, some molecules were discarded as they did not start with the atg codon . the problem of class imbalance applied to all other window sizes analyzed.

in accordance with the main authors in the literature, the sequences were codified using the  <dig> bits codification scheme mentioned in the review of the current state of research.

class balancing
in the field of classification, a database is described as imbalanced when there are much fewer cases of some classes than others  <cit> . this type of problem is of great importance since datasets with this characteristic can be found in many areas. many learning systems assume that classes are balanced and, as a result, these systems fail to produce a classifier that is capable of accurately predicting the minority class in the presence of data containing imbalanced classes  <cit> . very frequently, the classifiers tend to value predominant classes  and ignore the least frequent classes  <cit> .

the problem of predicting the tis is inherently imbalanced since a molecule of mrna has only one atg that codifies protein, while all the others are non-tis. for the organisms mus musculus and rattus norvegicus, for example, there is an average disproportion of 1: <dig> and 1: <dig>  respectively. this disproportion is 1: <dig>  1: <dig>  1: <dig>  1: <dig> and 1: <dig> for arabidopsis thaliana, caenorhabditis elegans, drosophila melanogaster, homo sapiens and nasonia vitripennis, respectively.

it is worth noting that the problem would be even greater if evaluation of tis was performed at the dna level since the imbalance in this case would be far greater than at the mrna level.

the sampling methods for class balancing aim to alter the distribution of the training data in order to increase the accuracy of its models  <cit> . this is achieved by eliminating cases of the majority class  or replicating cases of the minority class . in the literature, these are known as random undersampling and oversampling methods that do not use heuristics in the elimination/replication of cases and those that do  <cit> .

according to batista et. al  <cit> , various authors agree that sampling methods that do not use heuristics can cause unwanted disturbances in the models generated. the simple replication of minority class cases can cause overfitting, while the random elimination of majority class cases can remove important information for the learning process.

in this study, the following balancing methods were used:

• random undersampling this method randomly eliminates majority class cases with the aim of matching the quantity of minority class cases. it is used in this study to evaluate and validate the other methods used and proposed.

• sbc  a method of undersampling proposed by yen and lee  <cit>  where the main idea is that there are different clusters in the database with different features. the complete database, composed of the minority and majority classes, is grouped into k clusters. from these clusters, samples of the majority class are selected according to the proportion of samples of this class  and the minority class  in each cluster i. the number of samples of the majority class selected in cluster i, represented by , is calculated by equation  <dig> .   

where m × sizemi is the total majority class samples selected that should be in the final training file and m indicates the proportion between the majority and minority classes; in this case 1: <dig>   is the total number of majority class samples to the number of minority class samples in all clusters. thus, equation  <dig> determines that more majority class samples would be selected in the cluster which behaves more like the majority class samples. in this study, the k-means clustering method was used with  <dig> clusters, a quantity already evaluated by yen and lee  <cit> .

• m- clus  the main characteristic of the method proposed in this study is the creation of a clustering with the sequences of the majority class. from this clustering, the most significant characteristics of each cluster are selected for the training stage. clustering is an unsupervised classification of patterns  in groups. intuitively, each group is composed of patterns that are similar to each other and dissimilar to the patterns of other groups  <cit> .

in order to create the clustering, the k-means algorithm proposed by macqueen  <cit>  was used, and applied to situations in which all of the variables are quantitative and the dissimilarities between them can be measured in a euclidean distance  <cit> .

the algorithm begins with the choice of the k elements that form the initial seeds. this choice can be made, among other methods, by selecting the first k observations, in a completely random manner or even in such a way that its values are very different.

once the initial seeds are chosen, the distance of each element in relation to the seeds is calculated. the element is placed in the group that has the least distance  and the centroid is recalculated. the process is repeated until all of the elements are part of one of the clusters. after grouping all of the elements, an attempt is made to find a partition better than one generated arbitrarily. to this end, the degree of internal homogeneity of the groups is calculated using the residual sum of squares  which is the measure used to evaluate the quality of a partition. after the calculation, the first object is moved to the other groups and verified for an increase or decrease in the value of the rsq. if there is a change, the object is moved to the group that generated the largest increase. the rsq of the groups is then recalculated and the process moves to the next object. after a certain number of iterations or when there are no further changes, the process is interrupted  <cit> .

for the purpose of balancing, the quantity of clusters k varied between the total , half  and one third  of the number of minority class sequences; and for each cluster, one, two and three sequences are removed, respectively. in order to select the sequences, those with the smallest distance to the centroid of the cluster are removed.

inclusion of features
in this study, in addition to its own sequence, some features reported in previous studies were included. thus, by generating the training and test sets, a combination was formed between the extracted sequences and the selected features: presence or absence of an atg upstream in frame with the tis, presence or absence of a stop codon in the following  <dig> nucleotides  <cit> , presence or absence of the codons ctg, gac, gag and gcc in the downstream region in frame with the tis  <cit> .

an atg upstream in frame can be explained by the ribosome scanning model, which scans from region 5’ to region 3’ until it finds the first atg which contains a translation context. thus, an atg closer to region 5’ has a high probability of being the tis. consequently, the presence of an atg in the upstream region in frame with the tis could indicate that the initially predicted tis has less chance of being the actual tis. this fact was also reported by rogozin et. al  <cit>  who demonstrated that a negative correlation exists between the quality of the context of the initiation of translation and the number of atgs in the upstream region. this characteristic proved to be of great relevance to this study since the best results were obtained when this characteristic was included and combined with others.

the presence or absence of stop codons  in frame in the downstream region in the following  <dig> nucleotides is explained by the biological process of translating the in frame codons into amino acids. the translation process ends when a stop codon in frame is found. therefore, the presence of any in frame stop codon in the following  <dig> nucleotides indicates that the protein should not have more than  <dig> amino acids. this is less than the majority of existing proteins, indicating that the atg may not be the tis  <cit> .

some features presented in previous studies, such as positions - <dig> and + <dig> and the size of the upstream and downstream regions, were not considered as they are implicit in the extracted sequences.

support vector machines
support vector machines  is a machine learning technique founded on the inductive principles of structural risk minimization. these principles originate from statistical learning theory  <cit> . characterized as a machine learning algorithm capable of resolving linear and nonlinear classification problems, the main idea of classification by support vector is to separate examples with a linear decision surface and to maximize the margin of separation between the other training points  <cit> .

the svm works as follows: given a set of training data xi, , each with an input vector xi ∈ ℜn and corresponding binary output yi ∈ , the objective is to separate the class - <dig> vectors from the class + <dig> vectors.

the svm-light version implemented by t. joachims  <cit> , available at http://svmlight.joachims.org, was used here. a 4th order polynomial function was adopted and the trade-off between training error and margin was  <dig> , defined by testing tirelessly .

inclusion of acquired knowledge
as shown in figure  <dig>  the scanning model supposes that the ribosome is first connected to region 5’ of the mrna and travels in the direction of region 3’ until it finds the first atg of the sequence  <cit> . however, there are exceptions: as a result of poor context , the first atg could be ignored. considering this ribosome scanning model, it can be observed that only the atgs in the upstream region of the tis and the tis itself have classification. thus, all other atgs that are in the downstream region, a priori, has no definite classification. that is, there may be an appropriate context for atg with tis in the region downstream, and this is not only because the ribosome have already started the translation into an atg before. figure  <dig> presents this model: the ribosome, not identifying the first atg of the sequence as the tis, moves to the second, third or more atgs, classifying them as non-tis until it finds the atg that it classifies as tis. in this sense, there is no exact classification for any of the atgs in the downstream region of the tis  <cit> .

taking this into account, this study presents a methodology that uses the model created from the negative sequences of the upstream region and the positive sequences  to classify the negative sequences in the downstream region. based on the classification obtained by this model, these sequences are classified and a new model is trained, thus obtaining the final model. in this new model, the number of positive sequences may increase since the system can identify a candidate tis in the downstream region. this process of including acquired knowledge  is shown in figure  <dig> 

in accordance with this methodology, the following steps are followed:

 <dig>  obtain a model, considering only the positive sequences  and the out of frame  negative sequences  contained in the upstream region ;

 <dig>  classify the atgs in the downstream region using the model generated in the previous step ;

 <dig>  new training with all of the sequences, including those classified by the previous step . in this stage, there is a decrease in the class imbalance due to the inclusion of sequences classified as positive by the model. thus, the proportion of 1: <dig> was reduced, approximately, to 1: <dig>  and 1: <dig> . the disproportion was reduced to 1: <dig>  1: <dig>  1: <dig>  1: <dig> and 1: <dig> for arabidopsis thaliana, caenorhabditis elegans, drosophila melanogaster, homo sapiens and nasonia vitripennis, respectively.

measures of performance
five measures were used to evaluate the performance of the classifier: accuracy , precision , sensitivity , specificity  and adjusted accuracy   <cit> .

accuracy measures the proportion of correct predictions, as described in equation  <dig>    

where tp, tn, fp and fn denote the number of true positives, true negatives, false positives and false negatives, respectively.

precision measures the proportion of possible tis that are definitely tis .   

sensitivity, also known as the true-positive rate, refers to the percentage of correct items within the positive class. in other words, it measures the proportion of tis that were correctly classified as tis .   

specificity, also known as the true-negative rate, refers to the percentage of correct items within the negative class. in other words, it measures the proportion of non-tis that was correctly classified as non-tis .   

adjusted accuracy is the average of the sensitivity and specificity measures .   

all results presented in the “results and discussion” section are based on these measures using the concept of cross validation. in addition to these performance measures, an alternative method for assessing the performance of these classifiers is the analysis of roc curves  <cit> . an roc graph can be used to analyze the relationship between false negatives  and false positives  or true negatives  and true positives  for a given classifier.

validation
10-fold cross validation was used, identified by kohavi  <cit>  as the most efficient form of evaluation for selecting models. the process of cross validation used in this study followed the methodology suggested by machado  <cit> , where the imbalanced database is initially divided into ten subsets. nine subsets are reserved for training while only one is destined for testing. the training set is then balanced by the application of the balancing methods described above. this data is used in the svm during training and tested with the reserved subset. this process is repeated ten times and after the final repetition, the average performance and standard deviation are calculated.

RESULTS
evaluation of the window size
considering the databases of mus musculus and rattus norvegicus, extensive experiments were conducted with the aim of evaluating the size of window which offers the best performance. tables  <dig> and  <dig> shows the results os this tests. the numbers between brackets are the corresponding standard deviations. observing these tables, it can be observed that as the size of window increases there is an increase in the accuracy and specificity rates. on the other hand, there is a fall in sensitivity . increasing the window size in the upstream and downstream region at the same time causes the sensitivity and specificity rates to counter each other. in other words, when one increases, the other decreases, as shown in figure  <dig>  and .

these results were obtained using class balancing and the m-clus method. no features were considered and the method of including acquired knowledge, inaknow, was not used.

these results were obtained using class balancing and the m-clus method. no features were considered and the method of including acquired knowledge, inaknow, was not used.

in an attempt to avoid this effect and improve the performance of the classifier, windows of asymmetrical sizes were exploited. from figure  <dig>  and , it can be observed that increasing the size of the downstream regions results in an increase in specificity and a decrease in sensitivity; consequently, the size of this region should not be very large so as not to interfere with the rate of sensitivity but should not be too small to guarantee a good rate of specificity.

on the other hand, when there is an increase in the upstream region, there is a significant decrease in sensitivity  and ). thus, there is evidence that sensitivity is related to the nucleotides in positions close to the tis. in other words, the context in which the ribosome initiates translation in a given atg are the nucleotides before and after the atg that is being validated. this corroborates the study of hatzigeorgiou  <cit>  which used the ann consensus model with a window size of  <dig> nucleotides, from - <dig> to + <dig>  and verified that this model was sensitive to the stable region of the tis. tzanis et. al  <cit>  also used a component which analyzed the region around the tis, from - <dig> to + <dig>  using markov chains to capture the consensus pattern, indicating that for the identification of the tis it is important to examine a restricted area around it.

among the tests conducted, the window size of -10+ <dig> generated the best results, improving the adjusted accuracy, represented by the average of the sensitivity and specificity.

evaluation of the features included
from tables  <dig> and  <dig>  it can be observed that the inclusion of features improves the performance of the classifier. a comparison of the tests with no features with those which included atg + stop + gag, reveals an increase of approximately  <dig> % and 6% in the rate of sensitivity observed for mus musculus and rattus norvegicus, respectively. moreover, the rate of specificity did not vary much at approximately  <dig> % and  <dig> % for mus musculus and rattus norvegicus, respectively.

these results were obtained using a window size of -10+ <dig> and the m-clus method. the method of including acquired knowledge, inaknow, was not used.

theses results were generated using the balancing method proposed in this study, m-clus, and a window size of -10+ <dig>  these tests were also applied to other sizes of window, -50+ <dig>  -12+ <dig> and -10+ <dig>  and this behavior was observed in all situations. thus, the inclusion of features is relevant for increasing the sensitivity of the classifier.

however, there are features which, when added to the sequences, slightly decreased the performance of the classifier . for example, for mus musculus, adding the features ctg or gag or gag or ctg + gag or gac + gcc, causes a decrease of approximately  <dig> % in the rate of sensitivity. for rattus novergicus, adding the features ctg + gac + gac + gcc or stop + gcc causes a decrease of approximately 3% in the rate of sensitivity. however, this variation is too small to be considered a decrease in the performance of the classifier.

interestingly, the characteristics which gave the best performance by the classifier for the organism mus musculus also gave the best performance when applied to the rattus norvegicus organism. table  <dig> presents the sixteen most important features, noting the sensitivity for the two organisms analyzed.

the following are the main features that were highlighted: atg + stop + gag, atg + stop + ctg + gac + gag, atg + stop, atg + stop + ctg + gac. in addition to this, the atg upstream in frame characteristic is highly relevant since the best results were obtained by the combination of this with other features. it is worth emphasizing that there is a significant increase in sensitivity of  <dig> % and 4% for mus musculus and rattus norvegicus, respectively, when only the atg upstream characteristic is considered.

thus, the tests conducted demonstrate that the classifier achieves good performance levels when it considers only the positive and negative sequences . however, it also demonstrates that it is possible to increase performance by including features deemed relevant for the context considered.

evaluation of the balancing methods
a comparison of the results obtained by the other balancing methods analyzed, presented in table  <dig>  shows that when no balancing method is used the rate of sensitivity is very low at  <dig> % for mus musculus and  <dig> % for rattus novergicus. this occurs because the database is imbalanced and the classifier therefore learns a lot about the negative class  and little about the positive class . thus, the system tends to find a large number of false negatives, and, through equation  <dig>  it can be observed that the sensitivity decreases with an increase in fn .

these results were obtained using a window size of -10+ <dig>  the features atg + stop + gag. the inclusion of acquired knowledge, inaknow, was not used.

this fact supports the authors machado  <cit>  when they state that the classifiers generated from imbalanced databases present high levels of false negatives for rare classes which is problematic when these are the classes being studied.

the use of any of the balancing methods analyzed increases sensitivity by around 40% for both mus musculus and rattus norvegicus. the method of balancing proposed, m-clus, performed better than all other methods, especially with regard to the rate of adjusted accuracy. for the organism mus musculus, the best performance compared to the rate sensitivity refers to the method m-clus. as for the rattus norvegicus best value for the rate sensitivity is given to using the sbc method, but there is a drop in rates of accuracy and specificity and hence in the adjusted accuracy. the random undersampling method is slightly better than the sbc method, its use being of interest because it is a simple method to implement. an analysis of the rate of precision reveals that the performance is  <dig> % and  <dig> % without the use of any balancing techniques. this rate is significantly reduced when a method is used to conduct the balancing. this can be explained by the fact that when no balancing method is used, the classifier learns little about the positive class. consequently, few samples from the test set are classified as positive and few false positives are therefore generated. as the rate of precision evaluates how many possible tis  are actually tis, this rate is of great value since few examples are classified as tis and, consequently, few are false positives. in other words, as the precision is given by pr = tp/, the rate increases with the reduction of fp .

finally, it is important to emphasize the necessity of presenting all measures of performance since it is possible to have a system with a very high level of accuracy but which presents practically no knowledge with respect to the class of interest.

with the objective of improving the level of precision, a new methodology, described in the background section, was planned, namely the method of including acquired knowledge. the results are presented below.

evaluation of the method of including acquired knowledge
the use of the methodology of including acquired knowledge , described in the background section, increased all the rates evaluated, especially the rate of precision which increased by 39%  for mus musculus. the rates of sensitivity, specificity and adjusted accuracy increased by  <dig> %,  <dig> % and  <dig> %, respectively. for rattus norvegicus, the increase was  <dig> %. however, the accuracy value was still low. this can be explained by the small amount of positive sequences  due to the fact that 91% of mrna molecules were disregarded by initiating translation at positions prior to  <dig> nucleotides .

when analyzing the results of experiments for the organism rattus norvegicus, a significant improvement in the rate of sensitivity  was observed when using the inaknow methodology, meaning that the classifier learned better from positive sequences. as for the rates of accuracy and specificity, there was a slight drop of  <dig> % and  <dig> %, respectively.

the significant improvement in the rate of precision is due to the reduction in the number of samples classified as false positive. this reduction occurs in accordance with the ribosome scanning model  <cit>  which does not evaluate the atgs in the downstream region of the tis where there may be sequences of atg with the appropriate context to be the tis.

using the proposed methodology, the sequences of the downstream region of the tis are initially classified via a previously generated model, using only the known tis sequences and the negatives from the upstream region and those which are out of frame. only after this initial classification will these sequences form part of the final training and test sets.

the sequences that were in the downstream region but which possess the necessary features to be the tis will form part of the positive sequence set since, as per the ribosome model, these sequences can become the tis if no atg with the appropriate context has been found. using this methodology, 14% of the sequences that were in the downstream region were classified as positive for mus musculus and  <dig> % for rattus novergicus. these rates were  <dig> %,  <dig> %,  <dig> %,  <dig> % and  <dig> % for arabidopsis thaliana, caenorhabditis elegans, drosophila melanogaster, homo sapiens and nasonia vitripennis, respectively. this methodology, therefore, is of fundamental importance for obtaining a classifier with a high rate of precision and demonstrates how the knowledge acquired by the classifier is relevant for classifying sequences with an unknown classification a priori.

validation of the methodology with other databases
once the methodology was fully tested for mus musculus and rattus norvegicus and the best settings for each of the tests was identified , larger databases were also evaluated.

thus, based on the best configuration obtained, the databases of the organisms aradidopsis thaliana, caenorhabditis elegans, drosophila melanogaster, homo sapiens and nasonia vitripennis, which were extracted from the refseq database, were also validated. the number of positive, out of frame negative sequences in upstream and downstream regions are presented in table  <dig>  with and without the inclusion of the acquired knowledge methodology .

total quantity of mrna for organisms arabidopsis thaliana, caenorhabditis elegans, drosophila melanogaster, homo sapiens and nasonia vitripennis are respectively  <dig>   <dig>   <dig>   <dig> and  <dig>  download in 05/03/ <dig> 

although the m-clus method offered a slightly better performance than the random method for mus musculus and rattus norvegicus, it requires greater computational time than other methods for clustering all sequences in the training file. since the clustering was performed using the k-means algorithm with the euclidean distance function, the distances of all sequences from possible initial centroids were calculated. k corresponds to the number of sequences from the minority class. each time the centroids were modified, the distances of all sequences to the new centroids were also recalculated, searching k clusters with greater similarity between the sequences of the group and higher dessimilaridade between groups. this greatly increases the processing time for large databases.

thus, as there is a significant delay in executing the m-clus algorithm, and since, according to the results already presented, its performance is similar to the random method, we used the random undersampling method in conjunction with the knowledge inclusion method , which produced good results. in table  <dig>  it can be observed that the rates increased with the use of inaknow, especially the precision which increased by  <dig> %,  <dig> %,  <dig> %,  <dig> % and 5% for aradidopsis thaliana, caenorhabditis elegans, drosophila melanogaster, homo sapiens and nasonia vitripennis, respectively. that is, with inaknow, the model better learns the true positives since it demonstrates a higher rate of correctly identifying those which are truly positive.

this is probably due to the fact that the inaknow method improves the knowledge of the model by recovering more positive sequences, thus yielding an increase in precision. these sequences are extracted from the downstream region and are assumed as negatives a priori.

however, sensitivity decreased most for homo sapiens , for interval confidence between  <dig> % and  <dig>  for a confidence level of 95%. analyzing the results of each fold, we find that folds  <dig>   <dig> and  <dig> are the ones responsible for this decrease, as per table  <dig>  further studies will be carried out to analyze these sequences added by inaknow.

in general, the low sensibility can be attributed to two causes. firstly, the model polarized the acquisition of knowledge because it adjusted to a larger number of negative than positive sequences. in the present approach, this situation does not occur due to the fact that the training set was balanced. secondly, the training set contains false negative sequences. in both cases, parameter fn from equation  <dig> tends to increase, diminishing the value of sensitivity.

from examination of the mus musculus and rattus norvegicus databases, analyzed in table  <dig>  it is clear that they contain less positive sequences than negative sequences . thus, it is beneficial to increase the number of positive sequences through the inaknow method. this increased the precision. conversely, in table  <dig>  it is observed that there are some databases where the number of true positive sequences is larger than the number of true negative sequences . since the inaknow method adds new sequences that have been identified as positives, which are extracted from the downstream region, the difference between the two types of sequences increases.

in this situation, which is less common , the present approach performs the balancing. that is, it increases the number of negative sequences using downstream sequences. it is important to note that it is not assumed that sequences in this region are all negatives. this can lead the model to increase the value of the false negative  parameter and consequently decrease sensitivity. taking this into account, the search for knowledge associated with the sequences that are not tis seems important. we believe that the proposed inaknow method can evolve, incorporating new knowledge that confirms that the downstream sequences are truly negatives. from this perspective, it would be possible to create acquired knowledge inclusion models that are more robust.

comparison with other tis prediction tools
the methodology used in this study is compared with the first-atg  <cit> , netstart  <cit>  , tis miner  <cit>  , and atgpr  programs.

the first-atg method, proposed by kozak , proposes that the tis of a molecule of mrna is the first-atg. for every molecule where tis genuinely is the first-atg, a tp  is added and each molecule where the tis is not the first-atg, a fp  is added.

to interpret the results reported by the netstart tools, the methodology adopted by sparks and brendel  <cit>  was used. since this method is a tis classifier and not a tis prediction system, if the prediction given to the tis is “yes”  a true-positive is counted. if it is not, a false negative is recorded. for every negative in the upstream region of the system set, the prediction is counted as a true-negative and false-positive results are not accounted for. the web interface and its vertebrate-specific parameters were used. for the tis miner and atgpr tools, the same methodology was used with the default settings.

all raw output generated by these tools on our test data is available as supplementary information at  <cit> .

CONCLUSIONS
as demonstrated in this study, the task of predicting the tis is not a simple problem to resolve. innumerable methods have been evaluated in the literature and this study presents a new methodology for finding the tis based on balancing methods, including features and the concept of knowledge inclusion. what the authors aimed to do throughout the development of the study was to present methods which find tis which are actually tis. this was also done with a concern for the number of sequences used.

since this problem is intrinsically imbalanced, undersampling class balancing methods were evaluated and the m-clus undersampling method was also proposed. undersampling methods, in contrast to oversampling methods which replicate the number of sequences, have the advantage of working with a much smaller number of sequences which appreciably reduces computational processing. this is particularly important in large databases like that of homo sapiens, drosophila melanogaster, arabidopsis thaliana and caenorhabditis elegans, analyzed in this study.

considering the performance measures evaluated, the proposed balancing method proved to be very promising, offering the best results when compared to the random undersampling balancing method, sbc and classification without balancing. with m-clus, there was an increase of  <dig> % in the rate of sensitivity and  <dig> % in the rate of adjusted accuracy, indicating that investment in balancing methods is necessary to resolve the problem. however, the precision was reduced by  <dig> %, a problem which was resolved by the inclusion of acquired knowledge.

however, the proposed method also has a disadvantage since the number of interactions to get the best clusters demands a very large computational processing time. in larger databases this may be limiting and in this study, due to time constraints, the random balancing method was used to balance the larger databases since this was also efficient for the proposed problem. two solutions to this problem are being worked on: 1) create heuristics to limit the number of iterations performed to obtain the best clusters, and 2) implement the methodology in a parallel and distributed manner, rather than sequentially.

there was an increase of up to  <dig> % in precision when knowledge acquired  by the classifier was included in the new training set. this is due to the reduction in the number of samples classified as false positive in accordance with the ribosome scanning model  <cit>  which does not evaluate the atgs in the downstream region of the tis where there may be sequences of atg with the appropriate context to be the tis.

the inclusion of certain features with the extracted sequences was also analyzed and it was concluded that, in general, this improves the performance of the classifier. the inclusion of features such as the presence of atg in the upstream region of the tis improved the rate of sensitivity by approximately  <dig> % for mus musculus and 4% for rattus norvegicus.

finally, according to the tests conducted on window size, there is evidence that sensitivity is related to the nucleotides close to the tis. in other words, the context for the ribosome to initiate translation in a determined atg are the nucleotides before and after the atg that is being validated. the window that generated the best results had  <dig> nucleotides in the upstream region and  <dig> in the downstream region .

in light of all the arguments presented, it is concluded that the methodology proposed contributes in a significant way to the prediction of the tis.

competing interests
the authors declare that they have no competing interests.

authors' contributions
ls and fc have developed the methods and conducted the tests. cn, lz and jm have provided the expertise and all three authors have drafted, read and approved the manuscript.

