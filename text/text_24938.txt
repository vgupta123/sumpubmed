BACKGROUND
in dna microarray and other massively parallel measurement technologies, analysis of data from two-treatment group experimental designs can be viewed as yielding three 'patterns': 1-significantly upregulated, 2-significantly downregulated, and 3- no significant change. because the third 'pattern'  is typically ignored, only the two patterns, 'upregulated' and 'downregulated', are reported. as more treatment groups are added , pattern assignment becomes more complex. although a number of pattern recognition techniques are available  <cit> , researchers often choose anova for an overall statistical test.

faced with identifying/discriminating different patterns of expression among the significant genes, researchers typically employ 'directed' pattern discovery. a priori information/assumptions are used to construct templates of expected changes in gene expression across treatment groups  <cit> , of which time course based pattern discovery could be considered a specialized subset  <cit> . these approaches are often applied post hoc to an overall test. directed pattern discovery has the advantage of identifying the subset of anova significant results that support the investigator's assumptions. however, disadvantages of this approach include missing unexpected but highly prevalent patterns and not estimating the likelihood of the directed pattern's occurrence by chance. 'down-weighting' is a unique subset of this directed approach in which the contribution of one or more of the treatment groups is deemphasized , turning the study into a modified two-group comparison by primarily focusing on differences between only the two 'most important' groups. 'less important' treatment groups may be used to triage/classify changes between the two important groups, but do not carry equal weight in the overall analysis.

alternatively, some researchers use 'undirected' pattern discovery approaches, in which patterns of expression are discovered using clustering methodologies, and do not take a priori expectations into account  <cit> . these undirected techniques have the advantage of handling highly complex data sets  <cit> . however, estimating the number of clusters is not a trivial process and can dramatically affect the outcome of the analysis  and clusters identified in one study may not be directly relevant to clusters found in another study, although recent advances have been made regarding these determinations  <cit> . while bootstrapping  and other techniques can help identify stable clusters  <cit> , the likelihood that any given cluster, even a stable one, would have that number of genes by chance can be difficult to assess. finally, these 'undirected' approaches also can identify important sources of variance that are not associated with treatment. this is a powerful tool for identification of abnormally behaving microarray data and even for the isolation of procedure-related contributions to technical variance, and therefore is critical to microarray analysis and normalization steps. however, this same property can make 'undirected' clustering approaches less desirable for the assessment of treatment-based effects.

all of these approaches are valid and have contributed importantly to microarray-based investigations of biological processes and many array analysis tools have been developed . further, new cutting edge techniques merge directed and undirected approaches to allow for more powerful analyses  <cit> . finally one of the most highly successful applications , has been the significance analysis of microarrays  application  <cit> , which combines multiple testing correction with permutation analysis using classical statistical tests. however, to date no work has been published demonstrating a non-clustering-based approach for treatment-associated, statistically validated gene expression pattern identification within multi-group microarray data.

here, we developed an algorithm using 1-way anova, followed by all pairwise fisher's protected least significant difference  testing, to categorize anova significant genes by their expression patterns . the number of genes falling into each expression pattern is compared to the number of genes that fall into that pattern by chance , are compared.

the ppm analysis technique is useful for identifying significant patterns of gene expression within datasets having 3â€“ <dig> treatment groups that are initially tested by anova. the ppm approach should allow researchers to group significant genes into expression patterns and to estimate probabilities for each of those patterns' occurrence.

RESULTS
algorithm
importing
signal intensity and presence call p-values are often provided by microarray core facilities as either an integrated pivot table, or as separate tables. statigen accepts either format and creates two tables, one containing signal intensities and one containing presence call p-values. a third table of annotation information  should also be provided. the first column for these files should contain the same unique identifiers  in the same order .

filtering
the user defines a presence call p-value cutoff , and then establishes the number of chips that must achieve at least this level of presence . we routinely filter out probe sets with no gene symbol annotation  <cit>  as a matter of convenience for subsequent functional grouping analysis. filtering at this level is also possible  with statigen.

monte carlo simulation

a table of random numbers matching the filtered data table's dimensions is created. the random numbers themselves can be regenerated/tested multiple times. both filtered and random data are run through the following steps .

gene level statistics
omnibus test
numerous studies have demonstrated the utility of the analysis of variance  approach for microarray studies  <cit> . here, we apply a basic one way anova  approach. the mean squared error within  calculated during the anova is used again in post hoc testing.

pairwise comparisons
in the present work, we chose fisher's protected least significant difference  test. in general, the plsd test is less conservative than other post hoc all-pairwise tests. therefore, if a significant anova result is found, then fisher's plsd is more likely than some other tests to identify a significant pairwise comparison. the p-value cutoff for the the plsd test is defaulted to  <dig> , although users can alter this.

pattern level statistics
number of pairwise comparisons
the number of pairwise comparisons is given by the formula 'k choose 2' as:

 c = / <dig> 

where c is the number of pairwise comparisons and k is the number of treatment groups. thus, a study with  <dig> treatment groups would have  <dig> pairwise comparisons, one with  <dig> treatment groups would have  <dig> comparisons, one with  <dig> groups would have  <dig> comparisons, etc. each comparison generates three potential results : 'significant increase', 'significant decrease', and 'not significant'. for each anova-significant gene, the results from all of the pairwise comparisons are encoded into a single 'pattern id' .

pattern id
we combine results from all of the pairwise comparisons for each probe set, creating a pattern id. pattern ids are constructed using logic gates that use 'increase', 'no significant change', or 'decrease' results from each pairwise comparison. the first pairwise comparison is assigned  <dig>   <dig>  or -1; the second is assigned  <dig>   <dig>  or -10; the third is assigned  <dig>   <dig>  - <dig> and so on. in this way, the sum of each combination of pairwise comparisons for a given probe set creates a pattern id encoding that pattern's statistically defined shape, and allowing researchers to easily group different genes that belong to the same pattern. further, two patterns of opposite sign and the same absolute value will be mirror reflections of one another, which may have value for assessing opposing actions in single pathways  <cit> .

actual and estimated frequencies
some patterns are statistically more difficult to generate from random data. for instance, patterns in which all pairwise comparisons are significant have a much lower probability of occurring by chance than any other pattern. therefore, each pattern found in the actual data is assigned its own probability  based on that pattern's frequency within the random monte carlo simulation .

output
expression levels for each gene are standardized , allowing genes of the same pattern but different signal intensities to be averaged and plotted together. genes are grouped by pattern and patterns are ranked by overrepresentation significance. graphs of the mean standardized expression levels for all of the genes in each pattern, along with a list of that pattern's genes, are displayed and can be saved to individual worksheets for further analysis .

limitations
algorithm
the number of different pattern ids can be calculated by pid = rc where pid is the number of different pattern ids, c is the number of pairwise comparisons and r is the number of possible results. the pid value rises exponentially as the number of treatment groups increases . because of this, we feel this method is not useful for studies with more than  <dig> treatment groups, where the number of patterns rivals the number of genes on the chip, obviating the tool's usefulness for reducing complexity. further, this exponential rise depends on the assumption that the comparisons are independent, when they are actually conditional. therefore, some patterns , while predicted by the independent calculation, are not possible in the conditionally dependent data, reducing the number of possible patterns .

in order to address this issue, only the union of patterns found within the actual data and/or monte carlo simulations are tested. this avoids testing for 'impossible patterns'. presently, we have restricted the test to identification of overrepresented, rather than underrepresented, patterns.

selecting the number of iterations
exceedingly rare patterns that occur in the real data may not be detected by monte carlo. in these cases, the pattern is included as significant, but is flagged. this failure of the monte carlo to detect identified patterns is strongly dependent on the number of iterations chosen, the number of treatment groups, and the number of observations within each treatment group. to determine an appropriate number of iterations, we repeat the analysis and observe detected pattern stability. if the pattern detection is stable, then the number of iterations is at least sufficient. if the pattern detection is not stable, then a rule of thumb would be to double the iterations and recheck for stability. the algorithm and software default to one thousand iterations.

excel
statistical calculations in excel have been reported to be inaccurate in some cases . thus, in the present work, anova calculations were broken down into individual calculations of total, within , and between/residual sum of squared errors using excel's devsq function. from these results, f statistics were calculated and the fdist function was used to look up p-values. these values agree with output in sigmastat . finally, the monte carlo simulation uses excel's rand function, generating evenly distributed values between  <dig> and  <dig> . this does not generate a normal distribution , however, the combined results of multiple rand calculations do closely approximate a gaussian distribution .

data reanalysis
blalock et al.,  <dig> 
nine to ten chips per treatment group, and three treatment groups , were used . of the  <dig> probe sets,  <dig> were rated present  and  <dig> were significant by 1-anova . of these anova significant probe sets,  <dig> probe sets did not have any significant post hoc fisher's plsd comparisons,  <dig> were significant between mid-age and age;  <dig> between young and mid-age; and  <dig> between young and aged. a venn diagram  shows the relative overlap among the three pairwise comparisons. nearly three quarters of all genes found significant by anova were also significant by the young vs. aged comparison. the young vs. mid-age comparison was the second strongest comparison and mid-age vs. aged had the fewest significant comparisons .

when pairwise comparisons are considered in concert using statigen's post hoc pattern matching algorithm , interesting patterns emerge. five of twenty-four patterns are significantly overrepresented . the list of significant genes contained within each pattern  was uploaded to: 1) david  <cit>  website and compared with a custom background list containing all probe sets in the study rated present and annotated, and 2) onto express  <cit>  and contrasted with the rg-u34a chip as a background. some selected functional categories that agreed between the two analyses and appeared to represent biological processes of the individual patterns are listed .

pattern id: unique pattern number assigned by statigen to combination of pairwise comparison results. # found: # genes in the actual data identified as members of that expression pattern. # expected: the number of genes one would expect based on the monte carlo estimation of chance occurrence. z score: the distance  away from the chance occurrence probability. note that statigen does not report underrepresented patterns .

the most significant pattern  was not the pattern with the most genes, but one among six possible patterns with the least likelihood of occurring by chance . many of the genes in this pattern reflect a well-characterized and robust increase in inflammatory markers seen in our and other researchers' microarray-based studies of the aging brain  <cit> . also note that pattern  <dig> reflects a weaker, but significant monotonic rise with aging that appears to contain genes associated with similar functional categories.

the second and third most prevalent patterns are mirror reflections of one another , and highlight genes whose expression levels were significantly different in two comparisons , but no different in the third . downregulated in aged relative to young  genes in this category are enriched in immediate early genes  and genes associated with intracellular signaling cascades . upregulated in aged relative to young  genes included functional categories associated with stress response .

finally, although there were relatively few genes that were significantly changed from mid-age to aged, a subset of genes  was rated as significantly overrepresented by statigen and included genes related to calcium binding and antigen presentation.

comparison to other approaches
the ppm algorithm was developed to assign statistical probabilities to patterns identified post hoc to 'per gene' statistical testing in a multi-treatment group setting, and shares some features with other approaches. therefore, in this section we compare ppm output to two popular clustering approaches that use resampling techniques to assess stability , as well as a template matching approach , using tigr's mev software  <cit> . standardized gene expression data for the probe sets previously identified as present and annotated were imported into mev. because the goal of statigen is identification of patterns present among the anova-significant  data, these other approaches were also applied to the anova-significant genes.

support trees 
support trees is a version of hierarchical clustering that uses bootstrap methods to establish branch stability. here, we used pearson correlation as a distance metric, average linkage as a linkage method, and clustered on both genes and experiments using one hundred bootstrapping iterations. branches are color-coded according to stability . genes could be reliably divided into two groups  but showed highly unstable branching patterns at lower levels  while experiments were more stable, with a majority of aged chips being separated from their young and middle-aged counterparts. further, subsets of chips formed highly stable experimental clusters : , ,  and . finally, it appears that the two experimental clusters most specifically enriched in aged vs young subjects , in large part drove the discrimination of the genes into the left and right panels, with the outer two experimental clusters contributing relatively little information at this level of branching.

k-means support 
kms uses the k-means clustering algorithm run multiple times  to establish 'consensus clusters' that appear in at least 80% of the iterations, again demonstrating clustering stability. the pearson correlation metric was used for distance, and figure of merit  procedures were used to estimate number of clusters for k-means. fom analysis was difficult to interpret, showing that more than one cluster was present, but indicating a relatively flat line effect out to  <dig> clusters . using a combination of information from fom, and previous analyses by statigen, we selected five clusters as a starting point for kms. in the resulting procedure  kms ran  <dig> five-cluster iterations and reserved the genes that were clustered together in at least  <dig> of those iterations. the resultant set of genes fell into eight clusters which are depicted in figure  <dig>  however the majority of anova-significant genes  failed to be assigned to a cluster.

pavlidis template matching 

the ptm approach allows researchers to construct a 'template' expression pattern and use pearson's correlation to identify genes that significantly correlate with that template. here, we chose to apply ptm to those genes that were significant by anova, effectively turning the ptm procedure into a post hoc test. ptm investigates one user-defined pattern at a time and we used statigen-identified patterns to establish templates for ptm.

the two monotonic patterns found by statigen  were fit by the same template in ptm , and, among the age-upregulated patterns identified by statigen, this monotonic increase template found the largest number of genes in ptm. however, other upregulated patterns  also found a large number of highly overlapping genes in ptm as evidenced in the venn diagram , as well as the highly analogous biological processes found to be overrepresented among genes identified panels a, b, and d. decreased expression patterns from young to mid-age, and sustained through age using ptm  revealed a completely non-overlapping set of genes that were related to cellular catabolism and neuronal plasticity- supporting previous work suggesting that neuronal involution may play a critical role in cognitive deficits seen with aging.

discussion
prestatistical filtering
researchers often triage microarray results with metrics that are blind to treatment groups, such as spot quality, signal intensity, and/or microarray suite  <dig> or  <dig>  derived 'presence' calls. such approaches can dramatically improve statistical performance and reduce the error associated with multiple testing . there are a number of methods for such filtering. observations that fall below some criterion could be treated as missing values, artificially brought up to a minimum intensity value, weighted according to the strength of the quality control measure, or the number of chips for which a given probe set exceeds some threshold value can be calculated. in the present work, we have opted for the latter approach.

statistical tests
a number of different approaches could be used to assign significant results to the data . in theory, any of these approaches would work as an initial step for the detection of patterns within the data. in the present work, we focus on predicted reliability, rather than magnitude, of change.

interestingly, studies in which magnitude of change, irrespective of variance, are applied  require an a priori assumption on the part of the investigator, that some level of change is necessary for a biological effect to be exerted, and further, that such a level of change is the same across all expressed genes. moving to statistical criteria ignores potential biological effects, instead focusing on the degree of variance and the likelihood that such a difference in means, given the variance of the measures, could have occurred by chance. thus, the statistical results infer relative security of findings, but it is still up to the investigator to ascertain the biological meaning  of any change. a change in gene x may be very reliable, yet epiphenomenal with regard to the biological process under investigation.

other pairwise comparisons would be appropriate post hoc to the anova . in the present work, we chose fisher's protected least significant difference  test. in general, the plsd test is less conservative than other tests. therefore, if a significant anova result is found, then fisher's plsd is more likely than some other tests to identify at least one significant pairwise comparison. by assembling genes into their post hoc defined patterns, the statistical reliability of the pattern may 'protect' statistically weaker findings. this approach has been used to great effect in functional grouping analysis of microarray data .

patterns found in blalock et al., 2003
the ppm method applied with statigen confirmed and extended the work of the original paper, finding that a majority of genes had changed by mid-age, and identifying upregulated inflammatory genes and downregulated genes related to neuronal function. the number of genes significant by each pairwise comparison  alone is often useful, helping researchers determine which comparisons show the largest number of significant results . here, the expected result, that the greatest age-dependent difference in transcriptional profile would be between the young and the aged groups, was clearly supported by this analysis. however, such approaches are limited in their ability to assess a particular comparison's effects on the transcriptome while simultaneously appreciating the effects of other comparisons.

further, statigen identified a significantly overrepresented pattern associated with a selective, mid-age to aged change, and many of the genes in this pattern are associated with calcium dysregulation, a well-supported hypothesis of neuronal dysfunction and cognitive deficit in aging  <cit> . thus, this approach identified not only age-related and possibly precipitating causes of age-related cognitive deficits in an animal model, but was also able to isolate a pattern of expression that directly and temporally correlated with that cognitive decline.

four of the five identified patterns  strongly validate conclusions of the original study  <cit>  that transcriptional levels in the mid-age group are generally intermediate between young and aged groups, or are similar to the aged group. further, the mid-age animals, although they had yet to show a statistically significant cognitive deficit, generally had transcriptional profiles more similar to aged than to young hippocampal ca <dig> regions. the identification of these patterns by statigen highlights the unambiguous manner in which patterns can be defined and examined, and further highlights, at least in the example shown, that the conclusions of the researchers regarding transcriptional changes were largely supported by the data.

the genes comprising the fifth pattern  may be of particular interest as their expression levels inversely correlate with behavioral deficits observed with age . interestingly, many of the genes found here represent inflammatory  and astrocyte/oligodendrocyte processes , suggesting that these potential biomarkers may influence, or be influenced by, cognitive status changes with age.

the potential interactions among oligodendrocytic, myelin, and inflammation related genes, were a key, novel proposition in the original work. the finding here supports that interaction's potential role in cognitive deficits with age. importantly, perturbed calcium homeostasis seen here has been a long-standing hypothesis of brain aging  supported by numerous studies . in the present context, it suggests that calcium signaling perturbations are common to many cell types in the brain. further, altered calcium and inflammatory changes together suggest that other popular aging hypotheses  may all play a role in altered cognition with aging. this pattern's discovery therefore highlights the ppm algorithm's second strength, discovery of patterns that were not anticipated .

other methods
as expected, support trees applied post hoc to the anova showed a strong tendency to group subjects according to treatment, as the anova selection should heavily bias this procedure towards treatment-based clustering. however, expression pattern identification among genes was not as refined, with a relatively stable discrimination between up and down regulated genes among two of the four experimental clusters, and other patterns of expression showing poor replication.

k-means support, in conjunction with figure of merit estimation of cluster number, reliably identified eight clusters but was unable to assign more than 90% of the anova significant genes. this suggests that some kms parameters may need further adjustment, the data may need further transformation, the anova criterion is inappropriate, or that this approach is not adequate for this data set.

pavlidis template matching  clearly identified sets of genes using statistical pearson's correlation probabilities. however, because each fitted template is performed in isolation, there is a high degree of overlap between different, but related patterns of expression. one way to reduce the degree of overlap would be to increase the p-value stringency criterion for inclusion in each template. however, increased stringency would also reduce the proportion of the anova-significant data set identified by the procedure. interestingly, the ptm approach does point to a potential improvement of the ppm strategy employed by statigen. presently, the ppm procedure considers each unique combination of pairwise contrast results as a separate pattern. however, it is possible that, like the ptm procedure, two patterns that completely correlate with one another in ppm  could be merged, reducing the complexity of pattern output in ppm.

CONCLUSIONS
the ppm algorithm was born of necessity in our microarray research dealing with multiple group studies and the relatively large amount of data generated using arrays  <cit> . although newer methodologies are greatly improving undirected approaches at both the gene expression and functional analyses levels  are inadequately handled by this process because the number of patterns increases with increasing number of treatment groups .

applied to a published microarray experiment, the statigen program successfully flags patterns that had been manually assigned in prior work, and further identifies other gene expression patterns that may be of interest. thus, over a moderate range of treatment groups, ppm appears to work well, allowing researchers to assign statistical probabilities to patterns of gene expression that fit a priori expectations/hypotheses while still preserving the data's ability to show the researcher interesting, yet unanticipated gene expression patterns.

important future work with this approach will include adding the option to identify and merge highly similar patterns, convert the software language to r format, and provide options for noise reduction/outlier removal prior to analysis.

