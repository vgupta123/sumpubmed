BACKGROUND
biomedical text mining  <cit>  has focussed largely on recognising relevant biomedical entities and binary relations between these entities . however, the extraction of biomedical events from the literature has been a recent focus of research into biomedical natural language processing, since events are crucial for understanding biomedical processes and functions  <cit> . events constitute structured representations of biomedical knowledge. they are usually organised around verbs  or nominalised verbs , which we call trigger expressions. events have arguments, which contribute towards the description of the event. these arguments, which can either be entities  or other events, are often assigned semantic roles, which characterise the contribution of the argument to the description of the event. typical examples of semantic roles include cause  and theme . the following sentence serves to exemplify the general format of events: 

· in addition, it has been established that tumor necrosis factor-alpha  can activate the expression of wild type p <dig> in concert with the nuclear transcription factor, nf-kappa b. 

sentence  is annotated with  <dig> events in the bionlp’ <dig> shared task corpus  <cit> . 

· event id: e <dig>  type: gene expression, trigger: expression, theme: p53

· event id: e <dig>  type: positive regulation, trigger: activate, cause: tumor necrosis factor-alpha , theme: e1

the details provided in events are vital for the development of advanced semantic search applications that allow search criteria to be specified in terms of constraints on these structured events, rather than using the more traditional keywords. however, the textual context of events often provides important information about how they are to be interpreted. we term such information meta-knowledge <cit> . in most of the existing corpora used for biomedical text mining, such information is either not encoded at all in the event annotations, or otherwise only limited information is present. for example, the bioinfer  <cit>  corpus annotates negated events, whilst the genia event corpus  <cit>  and the two bionlp shared task corpora  <cit>  include both negation and basic speculation information. in the shared task corpora, speculation annotation is limited to a simple binary distinction between speculated and non-speculated events. events in the genia event corpus are annotated according to  <dig> different levels of certainty, but the meaning of each level is not clearly defined. although the basic meta-knowledge annotation in these corpora allows some useful distinctions between events to be identified, it is not sufficient to distinguish between events that express the following types of information  <cit> : 

· accepted facts vs. experimental findings.

· hypotheses vs. interpretations of experimental results.

· previously reported findings vs. new findings.

the identification of such types of information is only possible if different types of contextual information are considered, e.g., whether the knowledge expressed by events is supported through experimental evidence, or through the citing of references.

the identification of event meta-knowledge can support various domain-specific applications, such as pathway construction and deep semantic search, to satisfy a variety of information needs  <cit> . this leads to a finer grained level of information extraction, in which papers can be analysed from several different viewpoints. the extraction of fine-grained information is useful not only for biomedical text mining, but also for semantic publishing applications  <cit> .

in response to the benefits of recognising event meta-knowledge, as outlined above, we have built an integrated system that automatically extracts biomedical events from the literature, and determines associated meta-knowledge, using machine learning methods. the new system, called eventmine-mk, is an extension of eventmine  <cit> , a machine learning-based state-of-the-art event extraction system that aims to extract structured events with explicit links between triggers and arguments. the eventmine-mk system was trained on the version of the genia event corpus  <cit>  that has been enriched with detailed meta-knowledge  <cit>  .

we chose to use the genia-mk corpus for training for a number of reasons. firstly, in contrast to other event corpora that include only limited information about the interpretation of events, the genia-mk corpus includes detailed meta-knowledge annotation for each of the  <dig>  events in the corpus. the annotation consists of five different dimensions, each encoding a different aspect of event interpretation, i.e., knowledge typecertainty levelpolaritymanner and source <cit> . each dimension has a fixed set of values, which are clearly defined in the annotation guidelines. secondly, this corpus is by far the largest of the all of the event corpora. thirdly, other event corpora generally have larger numbers of event and entity types, which can make the event extraction process more difficult. since the focus of our work is on the ability of our integrated eventmine-mk system to assign detailed meta-knowledge to extracted events, we wanted to avoid adding extra complexity to the event extraction task.

the eventmine-mk system was constructed in two stages. firstly, we trained a system to assign meta-knowledge to pre-annotated biomedical events in the genia-mk corpus. intrinsic, stand-alone evaluation of this initial system reveals that its performance in assigning values of different meta-knowledge dimensions to events ranges between  <dig> % and  <dig> % . compared to a baseline in which the most commonly annotated value in each dimension is assigned, our system shows encouraging performance, with improvements in f-score over the baseline ranging between  <dig> % and  <dig> %, according to the meta-knowledge dimension under consideration. secondly, we integrated the meta-knowledge assignment system with eventmine. thus augmented, eventmine-mk can perform both automatic extraction of events from the literature and automatic assignment of meta-knowledge to these extracted events. since detailed meta-knowledge annotation at the event level is a new concept, and the genia-mk corpus has only recently been released, our system is the first that is able to assign  <dig> different dimensions of meta-knowledge to events. however, in order to allow comparison with other systems, we have evaluated part of the functionality of eventmine-mk, by applying it to the task of extracting negated and speculated events, which was a subtask of the bionlp’ <dig> shared task   <cit> . our results demonstrate that eventmine-mk outperforms other state-of-the-art systems that participated in this task. in order to make it simple to integrate eventmine-mk with larger text mining systems, it has been made available as a uima component within the u-compare interoperable text mining platform  <cit> , which allows the construction of text mining workflows via a drag-and-drop interface.

event extraction
research into the automatic extraction of events has been stimulated by two shared tasks  focussing on event extraction   <cit> ). as a result of these shared tasks, several new state-of the-art event extraction systems have been reported that can extract core events, such as bindingregulation, etc., from the bionlp’ <dig> st corpus  and the genia event extraction task corpus from bionlp-st’ <dig>  with f-scores greater than 55% .

event corpora
both the bionlp’ <dig> st and the bionlp st’ <dig> provided corpora with gold-standard event annotations. these can be used to train systems, as well as acting as benchmarks for the evaluation of new systems. for instance, the st corpus consists of  <dig>  medline abstracts and covers  <dig>  biomolecular events involving genes or proteins. this corpus was generated by extracting and reorganising a subset of the events and named entities  contained within the genia event corpus  <cit> , in order to create a more tractable resource on which event extraction systems can be trained. table  <dig> summarises the event types and their arguments in the st corpus. the corpus consists of  <dig> different types of events, including five simple event types , each of which takes one core theme argument, a multi-participant binding event  and three regulation events . the regulation events are used to capture both biological regulation and general causation. examples ,  and  in figure  <dig> illustrate simple, binding and regulation events, respectively. the participants of both simple and binding events are specified to be of the general protein type, while regulation-type events can also take other events as arguments, creating complex event structures. some of these events take secondary arguments representing locations or sites. events in the st corpus are also annotated for negation and speculation.

for each event, argument roles  and argument types  are shown secondary arguments are optional, and they include atloc , toloc , site , csite . 
binding
 events can take an arbitrary number of proteins as their theme, and 
regulation
 events can take events or proteins as their arguments.

in addition to the genia event corpus and the corpora from the two bionlp sts, a number of other gold-standard annotated corpora of biomedical events have been produced by different research groups; each corpus varies in terms of target domain, size, types of events identified, and types and numbers of arguments annotated. bioinfer, the genia event corpus and grec  <cit>  all share similar event representations to the one illustrated above, although there is a substantial difference in their sizes: the genia event corpus is the largest, containing containing  <dig>  abstracts, grec contains  <dig> abstracts, while bioinfer contains  <dig>  sentences. the representations of the genereg  <cit>  and angiogenesis bio-process  <cit>  corpora are somewhat different. genereg, which consists of  <dig> abstracts, does not annotate explicit links between event triggers and arguments, while the angiogenesis bio-process corpus  annotates events as single spans containing both triggers and arguments, without identifying the internal structure of the events.

event extraction systems
a large number of event extraction systems have been reported, both as part of the two bionlp sts described above, and subsequently. the sts provided the first stimulus for the development of systems to extract the types of structured events described above. the functionality of these systems is in contrast to the simpler task of extracting pairs of interacting proteins, which have been covered by other challenges, such as the biocreative challenges  <cit>  and lll <dig>  <cit> . the bionlp sts have provided standard evaluation benchmarks, including task definitions, data sets for training and tools for evaluation. the sts defined three subtasks: finding basic events with the core arguments theme and cause , and attaching to these basic events either secondary arguments, such as location and site , or negation and speculation . most systems participated only in task  <dig>  and fewer than  <dig> systems tackled task  <dig> and/or task  <dig> .

event extraction systems participating in the bionlp sts have mostly employed pipeline-based approaches, using machine learning methods based on parse results  <cit> . in  <cit> , a pipeline-based system was built to extract events. the system firstly detected event triggers and arguments sequentially, using multi-class support vector machines , and it subsequently constructed multi-argument events using hand-crafted rules. it achieved the best performance in the bionlp’ <dig> st. the second best system  <cit>  in the bionlp’ <dig> st detected triggers using dictionaries, and identified arguments through graph kernel-based classification on trimmed dependency graphs, which are built by removing irrelevant lexical information from dependency parse results and adding conceptual class information to the results. such trimming is useful for detecting events, but it can lead to loss of the information required to calculate meta-knowledge, e.g., it prunes modal verbs such as may. a dependency parsing approach to event extraction was proposed in  <cit> . they detected triggers with a maximum entropy classifier , and then found arguments by applying syntactic parsing technologies  to pseudo syntactic structures converted from event structures. in  <cit> , the event extraction system eventmine was proposed, which extended the approach introduced in  <cit>  by extending the features and utilising its classifier in the multi-argument event detection phase.

joint approaches have also been proposed, to avoid the cascading accumulation of errors in pipeline-based approaches, including markov logic  <cit> , joint inference models  <cit> , search-based models  <cit> , and dual composition-based models  <cit> . in this latter approach, the dual composition method was applied to solve trigger and argument detection jointly and the resulting system, incorporating the output of the dependency parsing-based event extraction system  <cit>  through stacking, achieved the best performance in the bionlp-st’ <dig> genia task.

rule-based approaches have also been attempted  <cit> . the latter system, which detects triggers using dictionaries, and then extracts events by applying rules to syntactic paths, ranked third in the bionlp’ <dig> st.

some event extraction systems have additionally been applied to the entire set of pubmed abstracts  <cit> . the results of event extraction have already been employed in semantic search applications, such as medie  <cit> , ukpmc evidence finder  <cit> , applications that perform association mining for knowledge discovery, such as facta+  <cit>  and pathway enrichment and maintenance applications, such as pathtext  <cit> .

meta-knowledge annotation and identification
related work
the automatic assignment of various types of information, fitting into the general definition of meta-knowledge, to different parts of biomedical texts, is already a well-studied problem. the most common types of systems are those that carry out negation/speculation detection  <cit>  or perform classification according to rhetorical function   <cit> . such systems normally operate on continuous text spans, with the sentence being the most common unit of classification. both rule-based and machine-learning approaches have been attempted, usually using annotated corpora as a starting point.

concerning the identification of speculation at the sentence level, a number of machine learning approaches have been reported. in  <cit> , an svm-based text classifier is used to select speculative sentences in abstracts, while in  <cit> , weakly supervised machine-learning methods are used to perform simple classification of sentences from full papers on the subject of drosophila  into speculative or non-speculative. in  <cit> , improvements to the me classifier were achieved by reducing the feature space size, using both automatic and manual methods and by making use of external dictionaries of hedge clues.

a large amount of work on the detection of negations has focussed on medical reports, for which both rule-based and machine learning approaches have been attempted. in terms of rule-based approaches,  <cit>  presented a system that used regular expressions to find phrases that indicate negation and to filter out sentences containing phrases that falsely appear to indicate negation. the system described in  <cit>  identified negative words or phrases, which were used in conjunction with a parser to identify the scope of the negations. several machine learning approaches  learned patterns that indicate negative contexts.

to approach the problem of zone/rhetorical analysis, systems that classify sentences in abstracts  have generally made use of simpler sets of features than systems that operate on full papers. various learning algorithms have been used for abstract classification, including svms  <cit> , linear neural networks  <cit> , naïve bayes  <cit>  and conditional random fields   <cit> . all of these approaches use the words  in the sentences as features, usually with stemming or lemmatisation. the systems also all consider the position of the sentence within the abstract to be important for accurate classification. in addition,  <cit>  uses feature weighting, while  <cit>  uses contextual features from surrounding sentences. the accurate automatic categorisation of sentences demonstrated in  <cit>  has moreover been integrated with the medie intelligent search system  <cit> .

similar types of classifiers are used to determine the categories of sentences or zones in full papers, e.g., naïve bayes  <cit> , svms  <cit> , k-nearest nearest neighbour and bigram model  <cit>  and svms and crfs  <cit> . some features used are similar to those used in the classification of abstracts, such as words in the sentence, position of the sentence in the abstract and contextual features. however, it is usual that a more complex set of features is employed for full papers. all the systems use syntactic features, while  <cit>  uses several types of semantic features, including the semantic classes of predicates and agents, together with the presence of citations. in  <cit> , document structure features are used, based on the the docbook standard  <cit> , while  <cit>  employs verb clusters, prediction history and the presence of citations.

although sentences constitute straightforward and easily identifiable units of text on which to perform annotation and classification, there are a number of reasons why they may be considered too granular to accurately encode the different types of knowledge that are expressed in biomedical text: 

· expressions of speculation and negations may not apply to the complete sentence

· in terms of rhetorical function / general information content, there may be several types of information expressed in the same sentence

regarding rhetorical function/general information content, consider the following sentence: 

· inhibition of the map kinase cascade with pd <dig>  a specific inhibitor of mapk kinase  <dig>  may prevent the rapid expression of the alpha <dig> integrin subunit.

this sentence contains at least three distinct “nuggets” of information , as follows: 

 <dig>  a description of an experimental method: inhibition of the map kinase cascade with pd <dig> 

 <dig>  a general fact: pd <dig> is a specific inhibitor of mapk kinase  <dig> 

 <dig>  a speculative analysis: inhibition of the map kinase may prevent the expression of the alpha <dig> integrin subunit.

thus, systems that are trained to allow only a single classification label per sentence can result in the loss of important information. this problem is partly addressed in  <cit> , which report on annotation performed at a finer-grained level, i.e., fragments, of which there may be several in a sentence. whilst the annotation proposed in  <cit>  uses similar categories to those used for sentence-based rhetorical analysis, the annotation scheme described in  <cit>  is somewhat different, in that it is rather biologically oriented, and identifies  <dig> different types of information for each fragment . subsequent work  <cit>  reported on building classifiers based on the annotation introduced in  <cit>  using svm and me, achieving a performance in the range of 64–97% f-scores, according to the annotation dimension. the features employed by their classifiers consist of words, bigrams, trigrams, and syntactic chunks, the latter of which were found to be important for the correct assignment of values in the polarity and trend  dimensions. the feature space is reduced through the use of several types of processing of the input text, such as stemming and stopword removal. however, the removal of too much information was found to be detrimental to the recognition of some dimensions. for example, tense marking of verbs  was found to be important for correct classification along some dimensions. it was also found that certain words that are normally classed as stopwords were useful for classification along certain dimensions.

bioscope  <cit>  is a further corpus in which annotations generally consist of smaller units than complete sentences. the corpus annotates the linguistic scopes of negative and speculative keywords, which provides the means to train systems that can determine not only which sentences contain negations or speculations, but also the exact parts of those sentences that have the negative or speculative meaning. the release of this corpus, together with its use in the conll- <dig> shared task   <cit> , have helped to further stimulate research into negation and hedge detection systems. for example,  <cit>  developed a crf-based classifier to detect the scope of negations, which was trained on the bioscope corpus, and used words and parts of speech as features. the system was subsequently applied to  <dig> million sentences to create a database of negated sentences   <cit> .

regarding the systems participating in the conll- <dig> shared task, a purely rule-based approach was used in  <cit> , in which lexical and syntactic patterns on constituent parse trees and syntactic dependency relations were used in conjunction with a dictionary of known hedge cues. hybrid approaches were used in  <cit> , in which machine learning classifiers were trained to detect hedge cues, using a combination of syntactic and surface oriented features, followed by the application of sets of hand-crafted rules. in  <cit> , the rules were further refined by a crf classifier. in  <cit> , machine learning techniques were applied to both hedge and scope detection, using various combinations of dictionary-based, morphological and syntactic features.

moving from continuous text spans to event structures, we consider some of the systems that participated in task  <dig> of the bionlp’ <dig> st, which concerned the detection of negated and speculated events. several of the features used are the same as those employed by systems operating on continuous text spans, such as syntactic and token features, and dictionaries of negation and speculation clues. the approach described in  <cit>  adapted existing modules  <cit>  developed using a different corpus  <cit>  that aim to find dependency relations between dictionaries of negation/speculation clues and event triggers. in  <cit> , a model is trained on bioscope, with additional classification used to discriminate between ambiguous negation/speculation cues, according to context. the system determined whether events were negated/speculated according to whether event triggers and/or their participants fell within the linguistic scopes of the cues. this method was unsuccessful since, as described below, their appears be an incompatibility between linguistically-motivated scopes and biologically-motivated events. in  <cit> , the detection of negation and speculation is carried out using a similar model to the one used for event trigger detection, with the addition of a dictionary of speculation-related words. the types of features used include token features, sentence features, dependency chains and dependency path n-grams.

multi-dimensional meta-knowledge annotation at the event level
while meta-knowledge annotation and identification at the event level has been partially addressed by the genia event corpus and the two bionlp sts, a careful examination of the textual contexts of events reveals that a much richer range of meta-knowledge can often be readily identified, in addition to the basic positive/negative and speculative/non-speculative distinctions. to illustrate this, consider sentences - below, all of which contain instances of the same biomedical event organised around different forms of the verb activate, as follows: 

· type: positive regulation, trigger: activate, theme: nitrate reductase operon, cause: narl gene product

 it isknownthat the narl gene product
activates the nitrate reductase operon


 weexaminedwhether the narl gene product
activates the nitrate reductase operon


 the narl gene product didnot
activate the nitrate reductase operon


 these resultssuggestthat the narl gene product
might
be activated by the nitrate reductase operon


 the narl gene product
partially
activated the nitrate reductase operon


 previous studieshave shown that the narl gene product
activates the nitrate reductase operon


an event extraction system should ideally extract the same event structure as a result of analysing all of the above sentences. however, the interpretation of the event is different in each sentence, according to the sentential context. the expressions in bold represent the clues that lead to these different interpretations. in sentence , the word known shows that the event is a generally accepted fact, while the word examined in sentence  shows that the event is under investigation and hence that the truth value of the event is as yet unknown. in sentence , the word not negates the event, meaning that it did not happen, and in sentence , the words suggest and might show that there is speculation surrounding the event. in sentence , the word partially shows that the positive regulation took place with a lesser intensity than would be expected by default, while in sentence , previous studies shows the event refers to previously published knowledge, and hence it is not describing novel information.

most of the different types of meta-knowledge identified for the events in sentences – ) are comparable, at least to some extent, to the meta-knowledge types identified by the systems described in the previous subsection. it may therefore be assumed that meta-knowledge relevant to event interpretation could be “inherited” from one or more of the existing systems that produce sentence, segment or scope-based meta-knowledge annotation. however, such a solution would be problematic for a number of reasons. firstly, although sentences – are very simple sentences containing one event, this will rarely be the case. similarly to the fact that sentences often contain multiple nuggets of information , most sentences will contain multiple events, each of which could have a different meta-knowledge interpretation. thus, inheriting event meta-knowledge from sentence-based classifications would not be appropriate in most cases.

in terms of the feasibility of inheriting meta-knowledge from smaller spans of text, it may sometimes be the case that a particular textual fragment or negation/speculation scope corresponds approximately to the span of text from which an event trigger and its arguments are drawn. however, in other cases, this will not be so; in contrast to scopes and segments, events do not constitute continuous spans of text, meaning that event triggers and participants may be drawn from multiple fragments of a sentence. this means that, even though the meta-knowledge dimensions identified by the classifiers described in  <cit>  are very similar to the different types of meta-knowledge that can be identified for the events in sentences –, the lack of a straightforward mapping between textual segments and events makes it difficult to use such classifiers to facilitate the interpretation of events. as was mentioned above, a similar lack of compatibility can be observed between linguistically-motivated negation and speculation scopes, and biologically-motivated events that fall  within these scopes. an analysis of the differences between the scope-based annotation in bioscope and events annotated as negated or speculated in the original genia event annotation showed that only 51% of events in the genia event corpus with event triggers occurring within a speculated/negated scope were actually annotated as speculated/negated themselves  <cit> .

thus, in terms of the automatic assignment of meta-knowledge at the level of events, it is clear that separate event-based classifiers must be constructed. the feasibility of training such classifiers can be greatly increased through the use of a corpus in which meta-knowledge also been assigned at the event level. accordingly, our eventmine-mk system is trained using such a corpus, i.e., the genia-mk corpus, which includes detailed event-level meta-knowledge information. below, we provide brief details of this corpus and the scheme used to annotate it.

event-based meta-knowledge annotation scheme
the meta-knowledge enrichment of the genia event corpus, which is carried out in strict accordance with a formally-defined annotation scheme  <cit> , consists of the classification of each event along five different meta-knowledge dimensions, as well as the annotation of clue expressions for each dimension –), whenever such expressions are present in the sentence. the annotation scheme used to create the genia-mk corpus thus aims to provide a richer representation of meta-knowledge than is annotated in the genia event corpus and the two bionlp sts. the scheme is very much inspired by the one described in  <cit>  and the encouraging results obtained by a system trained on the resulting corpus  <cit> . however, our scheme was tailored to the interpretation of bio-events, through the examination of a large number of events and their contexts when designing the scheme. unlike many of the other annotated corpora introduced above, but in common with the bioscope corpus, we annotate clue words/expressions that are used to determine the specific values assigned to the different meta-knowledge dimensions. our decision to annotate such clues was motivated by the fact that several of the meta-knowledge assignment systems introduced above, including those participating in the detection of negated and speculated events in the bionlp’ <dig> st, have used dictionaries of clue words as features. thus, it is to be expected that clues will also be important in the assignment of other types of meta-knowledge at the event level. clues for several of our meta-knowledge dimensions have not previously been annotated in other corpora, nor have clues for negation and speculation at the event level. we thus considered it important to identify a set of event-based clue expressions, which could subsequently be used to compile dictionaries.

the five dimensions of meta-knowledge that make up the scheme are described in more detail below: a default value is specified for each dimension, which is assigned if there is no explicit evidence for the assignment of one of the other values. 

· knowledge type  refers to the general information content of the event. possible values are investigation , observation , analysis , fact , method , and other .

· certainty level  identifies events for which there is explicit indication that there is less than complete confidence in the event. there are  <dig> possible values: l <dig> , l <dig>  and l <dig> .

· polarity encodes the truth value of the event, with two possible values, i.e., positive  and negative. a negated event is defined as one that describes the absence or non-existence of an entity or a process.

· manner refers to the rate, level, strength or intensity of the event, with three possible values, i.e., high, low and neutral .

· source determines the origin of the knowledge expressed by the event , with its values current  and other.

hyper-dimensions correspond to additional information that can be inferred by considering combinations of some of the explicitly annotated dimensions. we have identified two such hyper-dimensions, each with binary values : new knowledge  and hypothesis .

the following two sentences serve to exemplify meta-knowledge annotation of events: 

· each of these domains possessed strong homology to motifs previously found to bind the cellular factor nf-kappa b. 

sentence  contains the following event. 

· type: binding, trigger: bind, theme: motifs, theme: nf-kappa b

here, binding is a multi-participant binding event, and it takes multiple theme arguments. the meta-knowledge annotation for the event is as follows: 

· kt: observation, clue: found

· cl: l3

· polarity: positive

· manner: neutral

· source: other, clue: previously

no clue expressions are annotated for cl, polarity and manner, and they retain their default values, since there is no evidence in the sentence that refers explicitly to these meta-knowledge annotation dimensions. 

· this delta <dig> beta-catenin mutant localizes to the nucleus because it may not be efficiently sequestered in the cytoplasm. 

sentence  contains the following event, among others. 

· type: localization, trigger: sequestered, theme: delta19

the meta-knowledge annotation for the event is as follows: 

· kt: analysis, clue: may

· cl: l <dig>  clue: may

· polarity: negation, clue: not

· manner: neutral

· source: current

in this example, the same clue expression, may, is used for both the kt and cl dimensions. the word may primarily denotes high speculation. however, speculation inherently involves cognitive analysis, and since there is no other analysis clue expression present in the sentence, may is also annotated as the kt clue.

the assignment of meta-knowledge at the event level can be seen as complementary to zoning/rhetorical or augmentation analysis methods, in that it can provide a finer-grained analysis of the various types of information that can occur within a particular text zone. the methods operating at different levels of text granularity could be used simultaneously in text mining systems, e.g., the identification of particular coarse-grained textual regions could be used as an initial filter for locating events with particular types of meta-knowledge. for instance, conclusion sentences would normally be expected to contain events that describe fairly definite analyses of events.

methods
in this section, we begin by providing a brief overview of eventmine  <cit> , i.e., the existing event extraction system that forms the basis of the integrated eventmine-mk system. subsequently, we describe the two stages of our work in creating our new integrated system, which can not only extract events but also assign meta-knowledge to them. firstly, we present our meta-knowledge assignment system, which attaches meta-knowledge information to pre-recognised events. we explain how the performance of this system was intrinsically evaluated by applying it to manually annotated events in the genia-mk corpus. secondly, we provide an account of how the meta-knowledge assignment system was integrated with the existing eventmine system, to create the new eventmine-mk system. finally, we describe the eventmine-mk uima/u-compare component.

event extraction system: eventmine
in this section, we provide an overview of the existing eventmine  <cit>  system, and describe some modifications that have been made as part of the development of the eventmine-mk system. when applied to the st corpus  <cit> , eventmine outperformed other systems participating in the bionlp’ <dig> st subtask task  <dig> . eventmine is a machine learning-based pipeline system with three detection modules: event trigger/entity detection, event argument detection and multi-argument event detection. trigger/entity detection assigns an appropriate trigger/entity category  to each word that potentially constitutes the head word of an event participant; argument detection finds semantic pair-wise relations among event participants; and multi-argument event detection merges several relations into events. figure  <dig> illustrates the flow of event extraction. in each module, eventmine solves multi-class multi-label classification problems using l2-regularised l2-loss svm  with a one-vs-rest classification scheme  <cit> . that is, binary classifiers are built which distinguish one of the labels from the rest. classification of new instances using the scheme for the multi-class multi-label classification is carried out by assigning to the instances both the labels suggested by the classifiers and a label with the highest classification score, the latter of which is employed to ensure that all instances are assigned a label.

eventmine is designed to extract event structures from parser output. any dependency parser could be substituted. however, in the system described in this paper, we have used a combination of the enju parser  <cit>  and the gdep parser  <cit> , following  <cit> . in eventmine, five base functions have already been implemented and provided to extract features representing a word or a pair of words, together with their immediate textual contexts in the sentence. these functions are as follows: 

 <dig>  token feature function – extracts the surface representation of a word. the features extracted consist of character types , character n-grams  , base form of the word  and part-of-speech  of the word .

 <dig>  neighbouring word feature function – extracts all 2-step dependency paths from the target word, which then are used to extract n-grams. for example, one of the 2-step paths is were ←prd–unable ← amod–transactivate for transactivate in figure  <dig>  the features used consist of: the features extracted by the token feature function for each word, word and dependency n-grams  , word n-grams   and dependency n-grams  . in the n-grams, each word is represented by its base form.

 <dig>  word n-gram feature function – extracts word n-grams  within a window of three words before or three words after the target word. each word is represented by its base form, pos and its relative position . for example, the function extracts word n-grams from unable to significantly transactivate the c-sis/pdgf-b for transactivate in figure  <dig> 

 <dig>  pair n-gram feature function – extracts word n-grams  within a window of three words before the first word in the target pair and three words after the last word. each word is represented by its base form, pos and its relative position . for example, for the trigger/argument pair transactivate and c-sis/pdgf-b in figure  <dig>  the window from which features are extracted is unable to significantly transactivate the c-sis/pdgf-b promoter. the word sequence unable to significantly is before the pair, transactivate the c-sis/pdgf-b is between the pair, and promoter is after the pair.

 <dig>  shortest path feature function – extracts the shortest dependency paths  between a word pair. figure  <dig> illustrates the shortest path between iexc29s and transactivate. several types of information are extracted to represent the shortest paths, including their length , word n-grams , dependency n-grams , consecutive word n-grams  representing governor-dependent relationships , edge walks  and their sub-structures , and vertex walks  and their sub-structures . each word is represented by its base form.

the three modules in eventmine are implemented by using different combinations of these functions, details of which are provided in  <cit> .

as part of the construction of the eventmine-mk system, we have incorporated two modifications into original eventmine system, in an attempt to improve the performance of the event extraction functionality. firstly, a dictionary matching-based filter was incorporated into the trigger/entity detection to reduce calculation time, by ensuring that only words that match dictionary entries are considered as trigger/entity candidates, instead of all words in the text. the dictionary was created by firstly extracting trigger and entity head words from the training data, and then expanding this initial list by using two different resources to improve coverage. from the umls specialist lexicon  <cit> , we obtained synonyms of words in the original list, as well as derivationally related words . using wordnet  <dig>   <cit> , we added words that were linked to those in the initial list via the hypernyms and similar to relations.

secondly, similarly to  <cit> , we used feature hashing to reduce memory usage. feature hashing maps features into a fixed space , and does not require string to integer mapping to maintain feature indices.

these modifications caused a very small decrease in the performance of the system on the bionlp’ <dig> st subtask task  <dig> . however, they almost halved the computation time and reduced the memory usage by approximately 75%.

meta-knowledge assignment system
as a starting point for the development of eventmine-mk, we firstly constructed a system that assigns meta-knowledge to pre-annotated events in the genia event corpus, through training on the genia-mk corpus. this system thus allows an intrinsic evaluation of the meta-knowledge assignment task to be carried out, independently of the event extraction task. the meta-knowledge assignment problem is treated as a multi-class classification problem for each dimension, i.e., kt, cl, polarity, manner and source, since each event is always assigned a single value for each of the five dimensions. although the aim of the system described in  <cit>  is somewhat similar, in that multiple meta-knowledge values are assigned to sentence fragments, that system used a multi-class, multi-label classification approach, since their annotation permitted multiple labels to be assigned to the same text fragments for a given annotation dimension.

in order to perform classification in our meta-knowledge assignment system, features are extracted from the target event, as explained below, and they are fed to an svm classifier. in the same way as in the event extraction pipeline, the type of classifier used is l2-svm with a one-vs-rest classification scheme. two classification configurations are employed. firstly, biased regularisation factors <cit>  are introduced for positive examples, both to alleviate the problem in the one-vs-rest classification scheme that negative examples constitute a sizable proportion of the training data examples, and also to improve the stability in predicting infrequent meta-knowledge values. regularisation factors for positive examples are assigned by calculating the ratio of negative to positive examples for each class. the regularisation factor for negative examples is set to  <dig>  secondly, type-based feature normalisation is also employed to reduce the effects of the different feature scales: the features in each type are normalised using the l <dig> norm  to form a unit vector  <cit> , and the whole feature vector is then normalised using the l <dig> norm.

with regard to features, we employed two types: event structure-based features and features for specific meta-knowledge values.

since we are dealing with meta-knowledge annotated at the event level, some of the features should reflect event structures. accordingly, some of the features we use are comparable to those used by the systems trained to extract negated and speculated events from the bionlp st corpora, e.g.,  <cit> . we have used the same extraction functions employed by eventmine to extract the following three types of features: 

 <dig>  meta-knowledge clue features – represent the shortest dependency paths between event participants  and meta-knowledge clue expressions. the features are extracted using the shortest path feature function. here, in common with several other approaches, clue expressions are extracted by matching with clue word lists. the clue word lists are constructed by selecting the most suitable clue words from all the clue words in the bioscope corpus and the training part of the genia-mk corpus. the selection is performed using pointwise mutual information   <cit> , which measures the level of association between a clue word and its meta-knowledge values. the threshold for pmi was set at - <dig>  in order to minimise the number of ambiguous clue words that are extracted. the exact value of the threshold was determined manually, based on the results of 10-fold cross validation on the training data.

 <dig>  trigger features – represent the contexts around the event trigger, extracted using the neighbouring word feature function.

 <dig>  trigger-argument pair features – extracted using the pair n-gram feature function.

a manual analysis of the meta-knowledge annotation in the genia-mk corpus revealed that the presence of specific types of clue words and phrases is not the only important factor in determining the correct meta-knowledge values to assign for certain dimensions. based on this analysis, together with an examination of features used in related systems, we added an additional set of features that attempt to capture other characteristics of the text that are important in determining the correct meta-knowledge values to assign. the additional features can be split into two types. 

 <dig>  sentence features refer to both the absolute position  and the relative position  for the second of eight sentences) in the abstract of the sentence that includes the event trigger. the features are used according to the observation that certain types of meta-knowledge  tend to appear in fixed places in abstracts . similar features are used in nearly all systems that assign rhetorical functions or sentence categories, e.g.,  <cit> , some of whose values are comparable to those in our kt dimension.

 <dig>  a citation feature refers to the existence of citations. citations are extracted via a regular expression that matches parentheses or brackets surrounding numbers  or sequences ending in  <dig> digits ). clues for other  often constitute citations, and thus are not covered by the clue dictionaries. such features have also been used in other systems that aim to identify parts of the text where other work is referred to, e.g.,  <cit> .

our system has two potential limitations in tackling the problem, as follows: firstly, the system takes into account neither dependencies between meta-knowledge values in different events, nor dependencies among the different dimensions of the same event. however, we will show that even by ignoring such dependencies, our system performs well for most meta-knowledge dimension values. secondly, the current version of our system is also not able to extract specific associations between meta-knowledge dimension values  and their clue expressions . the ability to extract some associations may, however, be useful in certain situations, e.g., to present meta-knowledge instances to users with textual evidence highlighted. accounting for these dependencies and associations is left as future work.

integrating the meta-knowledge assignment system with eventmine
in order to perform the complete task of fully automatic extraction of both events and their associated meta-knowledge information, the meta-knowledge assignment system described in the previous section has been integrated with eventmine, as a module in the event extraction pipeline that is executed following the detection of multi-argument events. the meta-knowledge clues are recognised by treating them as new classes of words to be identified and classified by the trigger/entity module. based on these recognised meta-knowledge clues, features are extracted for use by the meta-knowledge assignment system. figure  <dig> illustrates the updated flow of extraction.

in order to train the eventmine-mk system, we transferred the meta-knowledge annotation of the genia-mk corpus to the training and development portion of the st corpus , whose events consist largely of a modified subset of the events that are present in the genia event corpus. given the current state-of-the-art in event extraction, using the complete genia-mk corpus for training would not allow a practical system to be produced, for a number of reasons: 

· the genia event corpus is annotated with nested, fine-grained nes, which belong to  <dig> different classes. as an example of this nesting, the string hiv- <dig> gene is annotated in the genia event corpus as an entity of type dna domain or region. however, the nested string hiv- <dig> has additionally been identified as an entity of type virus. although there exist several systems that can extract nested nes, this is mostly done using a more coarse-grained set of ne classes .

· the extraction of fine-grained nested nes has been attempted  <cit> , which achieved a micro f-score performance of  <dig> %, using fragment matching. the recognition performance amongst the different classes ranged from  <dig> % to  <dig> %, which is considerably lower than coarse-grained ne extractors.

· extraction of fine-grained events. when applied to the genia event corpus , the best performance achieved by eventmine was 34% f-score, given the fine-grained nes annotations. in comparison, the eventmine system achieved a performance of greater than 55% f-score on the st corpus.

it was possible to transfer meta-knowledge annotations from the genia-mk corpus to over 90% of events in the st corpus . the remaining events in the st corpus correspond to new annotations added when the corpus was created, which were not based on events in the genia event corpus. in order to prevent errors in the transfer of meta-knowledge between the two corpora, the annotation from the genia-mk corpus was transferred to the st corpus only when events in the two corpora could be matched in terms of their event types, event ids and core argument text spans. the event ids were provided by the st organisers, since the event ids in the st corpus are different from the event ids in the genia event corpus. in order to verify the correctness of the transfer process, we randomly examined  <dig> events in the two corpora, and found that meta-knowledge had been correctly transferred in all cases. the distribution of event instances in the two corpora, in terms of the meta-knowledge values assigned, is shown in table  <dig> 

the last column shows the ratio of the percentage of events assigned the indicated value in the st corpus to the percentage in the genia-mk corpus. events that had no triggers were ignored.

in contrast to the genia event corpus, the st corpus contains only  <dig> event types and  <dig> ne category. moreover, the st corpus only contains around one third of the events present in the genia event corpus. hence, two thirds of the meta-knowledge annotations in the genia-mk corpus cannot be transferred to the st-mk corpus. in order for useful information contained in these unused annotations from the genia-mk corpus not to be lost in the model trained on the st-mk corpus, the output of the meta-knowledge assignment model that was trained on the complete genia-mk corpus is used to create additional features that are used in the assignment of meta-knowledge by eventmine-mk. these additional features include prediction scores that are made by the genia-mk-trained meta-knowledge assignment model for all meta-knowledge values.

integration into u-compare/uima
u-compare  <cit>  is an integrated text mining  / natural language processing  system based on the unstructured information management architecture  framework. u-compare provides a large number of uima-compatible tm/nlp components, including sentence splitters, ne recognisers, parsers, etc. its graphical user interface makes it easy for users to define, run and visualise the results of workflows, including the ability to compare the results of using different components for the same task. we constructed a uima component for our eventmine-mk system , which takes as input a sentence with ne annotation and outputs events contained within the sentence, with meta-knowledge information assigned. the component can be inserted into any uima-based workflow , provided that previous components in the workflow have split the input document into sentences and identified appropriate nes. the eventmine-mk component is available as part of the current u-compare software download  <cit> . the component is named “eventmine metaknowledge” and is classified under “event detectors” within the library of u-compare components.

RESULTS
evaluation settings
the corpora  were split into sentences using the genia sentence splitter  <cit> , and the resulting sentences were processed using two parsers, i.e., the enju  <dig> . <dig> parser with the genia model  <cit>  and the gdep beta <dig> parser  <cit> . eventmine-mk employed parse results produced by both parsers, as in the original eventmine system  <cit> . eventmine follows most other event extraction systems in employing syntactic parsers with biomedical models  <cit> ; the impact of such parsers on event extraction has been analysed in  <cit> .

liblinear-java  <dig>   <cit>  was employed as the classification tool used to perform all types of classification in eventmine-mk , with the bias term set and the regularisation value c set to  <dig> for negative examples.

for the purposes of training and testing the meta-knowledge assignment system, the genia-mk corpus was partitioned into a training set  and a test set . the training set contains the same abstracts as the st training set, while  <dig> of the abstracts in the genia test set were the same as those contained in the development set of the st. each event was represented by an event trigger and core arguments . the other arguments were ignored to simplify the problem, since additional arguments relating to locations, experimental conditions, etc., rarely have an impact on the meta-knowledge values that are assigned to events. if arguments consisted of multiple discontinuous spans, such spans were replaced with the smallest continuous span that covered the discontinuous spans. the representation of events assumed by our system includes event triggers, in order to extract certain types of features. accordingly, the small number of events in the genia-mk corpus that were not annotated with explicit triggers was ignored . in terms of the st corpus used to develop eventmine-mk, the training and development portions used in the st were employed as the training and test sets, respectively.

evaluation of meta-knowledge assignment was performed based on precision, recall, f-score and their macro-averages or micro-averages for each category. the assignment of the majority value for each annotation dimension  was employed as our baseline.

evaluation of negated and speculated event extraction  on the st corpus was carried out according to the st settings.  <dig>   <dig> and  <dig> abstracts were used as the training, development and test sets, respectively. the st evaluation server was used to perform the evaluation, and the results are reported according to approximate span matching/approximate recursive matching evaluation criteria  <cit> . the evaluation was performed by matching gold standard events and their negation/speculation annotations, so that both event extraction performance and negation/speculation detection performance are taken into account. precision, recall and f-score, together with their micro-averages, are used to report the results.

an analysis was carried out of the differences between meta-knowledge distribution in abstracts and full texts, using the st-mk corpus, which consists of abstracts, and the full-text subset of bionlp-st’ <dig> genia corpus. the training and development sets in the st-mk corpus were used for training purposes, while the predictions on the st corpus test set and the full-text subset were used to perform the analysis. the bionlp-st’ <dig> genia evaluation server was used to perform the evaluation of negated and speculated event extraction on the full texts.

meta-knowledge assignment to genia events
in order to construct the meta-knowledge assignment system, we firstly used 10-fold cross validation to evaluate the system using the training set of the genia-mk corpus, using all the features described in the meta-knowledge assignment system section of methods, together with the use of both configuration settings, i.e., biased regularisation factors and type-based feature normalisation. subsequently, in order to evaluate the contribution of different features and settings, we trained various other versions of the system, by disabling one feature or configuration type at a time. the evaluation results obtained for all versions of the system are summarised in table  <dig> 

“-” means that the named feature type or configuration is disabled. the f-score for each meta-knowledge value, together with the macro-averaged f-score and accuracy  for each dimension, are reported. the macro-averaged f-score is calculated by taking the average of the f-scores for each different meta-knowledge value within the dimension.

with regard to the highest macro f-score, the best setting differs, depending on the dimension under consideration. event structure-related features  are seen to be crucial for achieving a higher performance, since, for most dimensions, the macro f-score drops considerably when these features are disabled. for other features, their impact was generally relatively small, and our experiments showed that disabling some features could lead to positive as well as negative impacts on the performance of the system.

according to the results reported in table  <dig>  the use of the meta-knowledge clue features generally has a positive effect on the assignment of kt, cl and polarity values. however, the results also suggest that these features can have a slightly negative impact on the assignment of manner and source values. a possible reason for this is that there are few commonly occurring clues for values of these dimensions. for example, there are only  <dig> clues for the low value of the manner dimension that occur  <dig> or more times in the entire genia-mk corpus, compared to  <dig> clues for the analysis value of the kt dimension that occur  <dig> or more times. if a stable set of clues cannot be identified in the training set, clues will be rarely matched in the test set, and thus the existence of the clues may confuse the classifier.

sentence features are useful for kt, cl and source, but not for polarity and manner. this seems reasonable, since there is often some kind of correlation between the position of the sentence in the abstract and the possible values of the kt, cl and source dimensions. for example, in terms of the kt attribute, events representing facts will often occur towards the beginning of the abstract, while events denoting analyses will often come after results have been reported, i.e., towards the end of the abstract. the same characteristics would thus apply to cl, since this dimension is only applicable to events with a kt value of analysis. for the source attribute, the non-default value of other is applicable when the event describes work that was not carried out as part of the current study, which is most likely to be mentioned at the beginning of the abstract. the same position-based feature would not normally be applicable to polarity, since events of any type may be negated. similarly, expressions of high or low manner can apply to any event describing a biological process, whether the event describes a fact, observation, analysis, etc. as would be expected, citation features have the most positive impact on the assignment of the other value of the source dimension. for other dimensions, the effect of this feature is negligible. the highest accuracy is produced when biased regularisation factors are removed, with the exception of the kt dimension. however, the same system setting also produced the lowest macro f-score, by a considerable margin, for the manner and source dimensions, since the removal of biased regularisation means that infrequent meta-knowledge values are not predicted well.

our results also show that it is safe to use all the features and configurations for the prediction of all dimensions, since the difference between the performance when using the best setting, and the performance when using all features and configurations, is less than 1%. according to the results of these experiments, we decided to use the system setting with all the features and configurations enabled for all subsequently reported experiments, unless otherwise stated. we do not use the best setting for each dimension, since calculating and storing a different set of features for each of the five dimensions would require extra computational and spatial costs.

following this initial set of experiments, we applied the meta-knowledge assignment system to the test set of the genia-mk corpus, and the results are summarised in table  <dig>  the performance on the test set is generally better than the baseline, except for a small degradation in f-score for the neutral value of the manner dimension and the micro-averaged f-score for the manner dimension. the performance is somewhat low for rarely appearing values, including low, high, method and other . precision and recall are similar to each other in all cases, except for the low value of the manner dimension. this shows that, for the most part, biased regularisation factors are able to keep a balance between precision and recall, even for infrequent meta-knowledge values.

a majority class-based baseline is shown for reference. ecall/recision/score are reported.

the kt dimension has six values and, unlike other dimensions, it has no single majority value to which most events belong. the f-score for each value of this dimension is around 70%, except for the rare value method, demonstrating that there are no extremely easy or difficult cases in the kt dimension. the performance of the cl dimension is lowest for the l <dig> value. this seems reasonable, because the l <dig> value is the middle value of this dimension, meaning that there is opportunity for such events to be misclassified as either of the other values in the dimension, i.e., l <dig> and l <dig>  in contrast, the performance of the system in predicting of the middle value in the manner dimension, i.e., neutral, is better than the prediction of the other values in this dimension. this is because the neutral value is most frequently occurring value in this dimension. however, ambiguity with other values is still encountered during the the prediction of the neutral value, as illustrated by the fact that the performance of the eventmine-mk system in predicting the neutral value is lower than the baseline, in terms of f-score. the negative value in the polarity dimension and the other value in the source dimension are both quite rare values, which could be biased by their low frequencies. the detection of the other value is the more difficult, since dictionary-based clue detection is more problematic for this value than for the negative value. in the next section, however, we will show that machine learning-based clue detection can improve the performance.

extracting meta-knowledge enriched events
in table  <dig>  we summarise the results achieved by the eventmine-mk system trained on the st-mk corpus. since our aim here is not to evaluate the performance of event extraction per se, but rather to provide an intrinsic evaluation of the quality of the meta-knowledge assigned to these events, evaluation was only performed on those events whose complete structure  was correctly recognised by the system. of the  <dig>  events in the st test set,  <dig>  events were correctly extracted by eventmine-mk. the results of two different experiments are shown in table  <dig>  the first experiment uses only features extracted from the st-mk corpus , while the second experiment  incorporates additional features from the meta-knowledge assignment model trained on the genia-mk corpus, as was explained in the section integrating the meta-knowledge assignment system with eventmine. we employed both configurations described in the meta-knowledge assignment system subsection of methods, i.e., biased regularisation factors and type-based feature normalisation.

meta-knowledge assignment performance is evaluated only on events correctly predicted by the system. event extraction performance is evaluated using the st evaluation tools. a majority class-based baseline is shown for reference. +genia shows the results obtained when the outputs of the genia-trained meta-knowledge assignment model are incorporated as additional features. ecall/recision/score are reported.

examining the results of the first experiment, differences in performance can be observed between the systems trained on the genia-mk corpus  and the st-mk corpus. for all dimensions, the micro-averaged scores on the st-mk corpus are a few points better than those on the genia-mk corpus, but the differences in the macro-averaged scores are dependent on the dimensions. whilst these differences can partly be attributed to the much smaller number of events in the st-mk corpus , they can also be attributed to differences in the distribution of meta-knowledge values between the two corpora, as illustrated in table  <dig>  in general, if meta-knowledge values appear comparatively less frequently in the st-mk corpus than in the genia-mk corpus, then a degradation in performance can be observed in eventmine-mk, compared to the meta-knowledge assignment system trained on the genia-mk corpus. this is most notably the case for l <dig> and method, which appear less than half as frequently in the st-mk corpus as in the genia-mk corpus. because of this, eventmine-mk is unable to make any correct predictions for these meta-knowledge values. the same effect can be seen, but to a much lesser extent, with the meta-knowledge values analysis, fact, and l <dig>  causing a drop in the macro-averaged f-scores the kt and cl dimensions, compared to the standalone meta-knowledge assignment system trained on the genia-mk corpus. in contrast, observation, high and low appeared more frequently as meta-knowledge values in the st-mk corpus than in the genia-mk corpus, resulting in a large increase in ability of eventmine-mk to predict these values correctly, compared to the results shown in table  <dig>  accordingly, the macro-averaged f-score for manner also improved. there is little change in the performance of the prediction of the polarity values, i.e., positive and negative, compared to table  <dig>  meaning that the macro-averaged f-score for polarity did not alter very much. an exception to the general rule can be observed in the case of the other value of the source dimension. although this appeared less often in the st-mk corpus than in the genia-mk corpus, performance was improved in eventmine-mk. this was mainly due to the additional meta-knowledge clues extracted by the trigger/entity detector, which proved useful in comparison to the use of only dictionary match and citation features . if the additional meta-knowledge clues are not used, then performance drops from  <dig> % to  <dig> % f-score. this improvement in the prediction of the other value resulted in a higher macro-averaged f-score for source, compared to the results shown in table  <dig> 

according to the results of the second experiment, the addition of features from the meta-knowledge assignment model trained on the genia-mk corpus  improves the performance of the eventmine-mk trained on the st-mk corpus, in terms of macro-averaged f-score. although the results for the method value of the kt dimension could not be improved, since this meta-knowledge value appears extremely rarely in the st-mk corpus, performance on most other rare meta-knowledge values was improved by the use of these additional features. direct application of the genia-trained meta-knowledge assignment model to the st test set was also evaluated, but performance was reduced for all dimensions. this degradation in performance is due to the differences in the event types and in the distribution of meta-knowledge types between the two corpora. however, our results demonstrate that, when used indirectly, information from the genia-mk corpus can improve the recognition of meta-knowledge for the st events.

we performed an error analysis of the results produced by the system that incorporates additional features from the genia-trained system.

kt has the highest number of meta-knowledge values, some of which need to be disambiguated according to their contexts. for most values of kt, some instances were misclassified as other, especially if clue expressions were not present, since this is one of the most commonly occurring values. fact instances were often misclassified as analysis or observation, since these two values appear more frequently than fact and are sometimes ambiguous, in that they share a small number of clue expressions. errors in method occurred because the clue words were not detected, and furthermore, because the trigger words transfection, which are present in all incorrectly classified method events, occur far more frequently as trigger expressions for observation than for method in the training data sets. for cl, no instances were misclassified as l <dig>  three instances that should have been assigned l <dig> were misclassified as l <dig>  since l <dig> clue words were not detected by the system. with regard to polarity, errors often occurred due to negation of event arguments in coordination  and incorrect detection of nested events. negation often attaches to the parent of the nested events, so if the nested structure is wrongly detected, the polarity value of the argument event will be inverted. for example, if the gold-standard regulation event in the phrase no regulation of phosphorylation is annotated as negated, but the system only detects the phosphorylation event and not the regulation event, the phosphorylation event would be erroneously detected as being negated. errors in manner occurred between neighbouring meta-knowledge values , for reasons similar to the errors that occurred for the cl dimension. in terms of source, some current events were wrongly detected as other when clue words for other were detected in the same sentence. conversely, some other events were detected as current when the clues were not detected by the system.

negated and speculated event extraction on the st corpus
eventmine-mk was applied to the bionlp’ <dig> st subtask  of extracting events with associated negation and speculation information. this task does not deal with all the meta-knowledge dimensions that can be recognised by our system, but applying our system to this task is useful to allow comparison with other systems that can extract negated and speculated events. two different versions of eventmine-mk were trained, one on the st-mk corpus, and one on the original st corpus, which was annotated for both negation and speculation, but not for negation and speculation clues. using the st-mk corpus, eventmine-mk is able to construct a meta-knowledge clue dictionary and a meta-knowledge clue detector. for the eventmine-mk version trained on the st corpus, such functionality was not possible, given the lack of negation and speculation clues in this corpus. table  <dig> shows the results and compares these with the scores of the top performing systems that participated in task  <dig> of the st. performance is reasonably low for all the systems in this table, because the evaluation settings take into account event extraction performance as well as negation/speculation detection. as shown in table  <dig>  our novel systems  outperform the other systems compared, in terms of both overall f-score, and in terms of negation detection. in most cases, recall is also higher than for the other systems. the meta-knowledge clue annotation helps to improve performance, especially in the detection of negated events, for which a considerable improvement in performance can be observed over the version of the system that does not use clues. conversely, for speculation, a small decrease in performance can be observed when meta-knowledge clues are taken into account. however, this decrease reinforces the analysis by  <cit>  that speculation annotations in the st corpus do not conform to the standardised notion of speculation, i.e., in contrast to the events enriched with meta-knowledge annotation, events occurring with modal verbs  and epistemic adverbs  are rarely annotated as speculative in the st corpus. according to this feature of the st corpus, ignoring lexical clues increases the f-score according to the st evaluation settings.

results are shown both with the use of meta-knowledge clues  and without the use of clues. recall / precision / f-score are shown for each value, and the highest scores are shown in bold.

analysis of meta-knowledge distribution on abstracts and full texts
to investigate the differences in the performance of our system on abstracts and full texts, we applied the model in table  <dig> to the full-text subset of bionlp-st’ <dig> genia corpus. table  <dig> shows the performance of negated and speculated event extraction, using meta-knowledge clues, on the full-text subset. this table shows that the performance of eventmine-mk is almost consistent on both abstracts  and full texts, and that the eventmine-mk system outperforms other systems on the full texts. it should be noted that eventmine-mk system used only the abstracts  for training, unlike the other systems shown, which used both abstracts and full texts for training purposes.

eventmine-mk used the model with meta-knowledge clues in table  <dig>  recall / precision / f-score are shown for each value, and the highest scores are shown in bold.

eventmine-mk was then trained on the st-mk training and development sets, and applied to the st test set and the full-text subset of bionlp-st’ <dig> genia corpus, in order to compare the meta-knowledge distribution in abstracts and full texts. in this experiment, additional features from the meta-knowledge assignment model trained on the genia-mk corpus  were incorporated. table  <dig> compares the distributions of meta-knowledge assignments in the abstracts and full texts. whilst it should be noted that the results obtained for full papers may not be completely accurate, given that full papers  did not feature at all in the training data for the system, some interesting trends can nevertheless be observed. the statistics shown in table  <dig> suggest that full texts tend to include more events denoting previous work , more speculated events , more events denoting low manner, and fewer events denoting general facts  than abstracts. in order to confirm these general trends, and to help to improve the accuracy of the automatic assignment of meta-knowledge to events in full papers, we intend to manually enrich the full papers released as part of the bionlp-st’ <dig> genia corpus with meta-knowledge as future work. the enriched event annotations in the papers can subsequently be used as training and test data to help to improve and evaluate the performance of eventmine-mk on full papers.

distributions of predictions on test set of the st corpus and on the full-text subset of the bionlp-st’ <dig> genia corpus are reported. eventmine-mk used the model trained on the st-mk corpus with the +genia setting, as in table  <dig>  the last column shows the ratio of the percentage in the full-text subset to the percentage in test set of the st corpus.

CONCLUSIONS
we have presented a novel system that can extract biomedical events from the literature and assign meta-knowledge to them. the system was constructed by integrating a new meta-knowledge assignment system into a state-of-the-art event extraction system, eventmine. the meta-knowledge assignment system was firstly evaluated on the genia-mk corpus, on which it performed well compared to the baseline, with a small number of exceptions. this assignment system was then integrated in eventmine. the augmented version of eventmine, which we call eventmine-mk, was trained on the st-mk corpus, to which meta-knowledge annotation had been transferred from the genia-mk corpus. with the help of features from the model trained on the genia-mk corpus, eventmine-mk was able to assign meta-knowledge to the detected events with a good degree of accuracy, comparable to the performance of the meta-knowledge assignment system trained on the genia-mk corpus. eventmine-mk was also able to outperform other state-of-the-art event extraction systems in the task of detecting negated and speculated events. eventmine-mk is available as a uima component, which is available within the u-compare interoperable text mining system.

as future work, we will apply eventmine-mk to the entire pubmed abstract collection and thus be able to extract events with meta-knowledge for use by common domain applications. we ran eventmine-mk with no parallelisation on a cluster with  <dig> intel xeon x <dig>  cpus with  <dig> gb ram using hyper-threading. on average, it took  <dig>  seconds to extract events with meta-knowledge assignment from a single abstract, of which an average of  <dig>  seconds was used for meta-knowledge assignment. it will take approximately  <dig> cpu days to apply meta-knowledge assignment to the existing event extraction results for the entire pubmed abstract collection, which includes about  <dig> million abstracts and  <dig> million titles. such meta-knowledge can be used to rerank and/or restrict search results in semantic search engines, e.g., the medie intelligent search system  <cit> , and to construct pathways that use only factual or trusted events. crucially, such fine-grained information about events is important for semantic publishing, e.g., sciverse  <cit> , and semantic web applications, e.g., open phacts  <cit> . our approach creates living texts, which can be viewed in a number of different ways to extract assertions, hypotheses, contradictions, negations, etc. we also wish to improve the performance of the meta-knowledge assignment, by finding a way to treat the dependencies among values and relations between meta-annotation clues and events.

competing interests
the authors declare that they have no competing interests.

author’s contributions
all authors contributed to the production of the manuscript. pt, jm and sa supervised all steps of the work. mm built the system and carried out the experiments. all authors read and approved the final manuscript.

