BACKGROUND
pair-wise protein-protein interactions  are the building blocks of complexes and pathways which carry out different biological processes. correctly identifying the set of interacting proteins in an organism is useful for deciphering the molecular mechanisms underlying biological functions and for assigning functions to unknown proteins based on their interacting partners. even for model organisms such as yeast, most ppis have not been discovered yet.

a number of high-throughput experimental approaches have been applied to determine the set of interacting proteins on a proteome-wide scale. these include the two-hybrid  screens  <cit> , which detect both transient and stable interactions and mass spectrometry methods, that are used to identify components of protein complexes  <cit> . however, both methods suffer from high false positive and false negative rates  <cit> . for instance in yeast, roughly  <dig>  interactions have been predicted by various high-throughput methods, but only a small number  are supported by more than one method. in addition to experiments that directly test for ppi, there are many indirect sources that may contain information about ppis. for example, it has been shown that many interacting pairs are co-expressed  <cit>  and expression of proteins found in the same complex is in some cases controlled by the same transcription factor  <cit> . sequence data has also been used to infer such interactions . each of these datasets provides partial information about the interacting pairs. these findings suggest that direct data on protein interactions can be combined with indirect information to improve the success of protein interaction prediction.

researchers have recently suggested a number of methods to predict protein interactions by combining both direct evidence and indirect information. most studies have been carried out in yeast. jansen et al.  <cit>  combined multiple data sources using a bayes classifier for ppi predictions in yeast. lin et al.  <cit>  compared jansen's method with two other classifiers, random forest  and logistic regression  and found rf to be the best among them. qi et al.  <cit>  extended this comparison to include three more classifiers and additional 'gold standard' datasets. their results confirmed that rf performs best among all classifiers for this task and have also indicated that support vector machines  are preforming very well on this task.

zhang et al.  <cit>  constructed a decision tree to predict co-complexed protein pairs by integrating genomic and proteomic data. ben-hur et al.  <cit>  used kernel machines for this task. yamanishi et al.  <cit>  predicted pathway protein interactions using a variant of kernel canonical correlation analysis. compared to yeast, human is more complex and there are fewer attempts at predicting human ppis so far. rhodes et al.  <cit>  employed a sum of likelihood ratio scores strategy to predict human ppi confidence. brown and jurisica  <cit>  derived a more reliable set of human ppis using evolutionary information. all of the above methods were shown to improve the success of ppi prediction when compared to direct data alone. the improvements are not just from the perspective of predicting novel interactions but also for the purpose of stratifying the many candidate interactions by confidence. while useful, the above methods do not address two important problems in this domain. first, these classification methods estimate a set of parameters that are used for all input pairs. however, the existing biological datasets contain many missing values and highly correlated features. thus, different protein pairs may benefit from using different feature sets. the second problem is that biologists who want to use these methods to design experiments cannot easily determine which of the features contributed to a resulting prediction. since different researchers may have different opinions regarding the reliability of the various features, it is useful if the method can indicate, for every pair, which feature contributed the most to the classification result.

in this paper we address the above challenges using a mixture-of-feature-experts  method. we divide the biological datasets into several groups. each of the groups represents a specific data type and is used by a feature expert  to predict interactions. results from all experts are combined such that the weight of each expert depends on the input sample and thus varies between input pairs. this weight can also indicate the importance of the features used by this expert for predicting a pair. we applied our method to predict ppis in yeast and human. using precision vs. recall curves and auc scores we show that the mfe method improved upon traditional classification methods that were previously applied for predicting ppis. for a specific yeast pathway, the pheromone pathway, we show that it is possible to extract confidence information from the weight distribution, in addition to providing new predictions.

methods
there are many biological data sets that may be directly or indirectly related to ppis. we tried to collect as many as possible for yeast and human.

feature set
for the various data sources, each of them has its own representative form. for example, protein sequence is in the form of a character string, which means the order of amino acids as they occur in a polypeptide chain. gene expression data is usually a vector of expression values across multiple time points for a specific gene. synthetic lethal data describes that a pair of genes having mutations together would affect the cells inviable or viable. so how could we combine these different forms of data together?

we present the converting process briefly in figure  <dig>  for each data set that represents a certain gene/protein's property, we figured out one natural way to calculate the similarity between two genes/proteins with respect to the specific evidence. for instance, for two proteins' sequence information, we use blastp  <cit>  sequence alignment e-value as one feature for this protein-protein pair from the protein sequence evidence. for other data sources, similar procedures were pursued to make the features for a protein pair. for data sets directly describing a protein/gene pair, we used them directly as features, like synthetic lethal evidence. concatenating all these features together then gave us the feature vector describing a protein-protein pair.

feature set for yeast
for yeast we collected a total of  <dig> feature attributes from  <dig> different data sources . three data sources are derived from the direct high-throughput yeast ppi data sets  <cit> , with two from mass spectrometry and one from high-throughput yeast-two-hybrid screens. these evidence describe pair of proteins directly and thus are used as feature items in the feature vector. six data sources represent each gene's functional annotations from  <cit> . the 'similarity' features derived from them represent how similar two proteins occur in the certain annotation space or from a specific function perspective. four other different sources derived features that describe the similarity between two genes from sequence and structure perspectives. the remaining attributes are all based on indirect high-throughput experimental data. for example, this includes gene expression  <cit>  correlations. all related data sources and how they were converted into features representing pair of proteins have been described in details previously in  <cit> .

feature set derived for pairwise protein-protein interaction prediction in yeast. we used a total of  <dig> features from  <dig> different data sources. the first column lists the feature expert to which the feature source was assigned. we have designed a total of four experts: p, f, s and e . the second column lists the name of the feature source. the third column lists the number of attributes from each source. the fourth column presents the average percentage of pairs for which information is available using this feature source. all related data sources and how they were converted into features have been described in details previous in: .

feature set for human
for human we collected a total of  <dig> feature attributes from  <dig> different data sources . collecting data for human proteins is much harder than for yeast because several data sets that are available for yeast are not yet available for human and there exist much more human proteins than yeast.

feature set derived for pairwise protein-protein interaction prediction in human. we collected a total of  <dig> features from  <dig> different data sources. the first column lists the feature expert to which the feature source was attributed to. unlike yeast, for human we had a total of three experts: f, e and s . the second column lists the name of the feature source. the third column lists the number of attributes from each source. the fourth column presents the average percentage of pairs for which information is available using this feature source.

similarly as in yeast, three kinds of 'similarity' features were derived from gene ontology  functional information, according to the two proteins' positions in the three ontology structures. in human, tissue distribution is an important property to describe a gene/protein. we used a binary feature to indicate if two proteins are expressed in the same human tissue or not. gene expression features were derived from sixteen expression sets in ncbi gene expression omnibus database  <cit> . protein sequence alignment score was used as the another feature source. homologous ppi was derived from the yeast protein-protein interaction datasets. domain-domain interactions were derived based on the hypergeometric distribution and calculated for each candidate protein pair in the same way as in yeast feature set.

feature properties
there are several feature properties we need to consider when designing computational approaches for the ppi prediction task. . most biological datasets are noisy and contain many missing values. for example, in the y2h derived features listed in table  <dig>  interactions involving membrane proteins are unreliable or missing. in both table  <dig> and table  <dig>  the fourth column lists the average coverage of each feature source. as can be seen, different features have varying degrees of missing values. the average coverage of the  <dig> groups in table  <dig> ranges from  <dig> % for y2h to over  <dig> % for gene expression and 100% for sequence based features. . . the derived features are heterogeneous. some features are categorical  while others are continuous . in addition, some of them are highly correlated features . . finally, there is the issue of weighting these different data sources. different protein pairs may benefit from using different feature sets in the prediction process. for every pair it would be useful for computational techniques to provide information about how features contribute to the classification predictions. for biologists who want to use these methods to build new hypotheses, integrating this information and their expert knowledge could assist lab experimental design.

feature experts
overall, these biological data sources can be divided into four feature categories, which are referred to as feature experts in this paper:

 <dig>  expert p: direct high-throughput experimental ppi data. this category contains those data sets that directly detected interaction relationships between proteins. they were derived through high-throughput biological experiments such as y2h screens and mass spectrometry.

 <dig>  expert e: indirect high-throughput data. this category includes those experimental data sources that were generated through high-throughput techniques and represent certain aspects of genes/proteins other than ppi relationship, such as gene expression and protein-dna binding.

 <dig>  expert s: sequence based data sources. this category includes those features that represent how similar two proteins are based on sequence or structure information. for example, this expert includes domain information and gene fusion data.

 <dig>  expert f: functional properties of proteins. this category contains information about how similar two proteins are in terms of functional annotations such as biological process, protein localization, protein class, and essentiality.

note that in human there are only two very small y2h data sets  <cit>  available. we therefore currently do not have a 'p' feature expert for human data. as more data sets become available, this feature expert can be generated for human as well.

after splitting, the features within experts are derived from similar data sources and are roughly homogeneous when compared with each other. usually biologists could give opinions and make comparisons on general categories of biological evidence. thus, it would also be useful for computational methods to provide automatic information about how several feature categories  contribute to every predicted interaction pair. the derived computational importance together with biologists' expert knowledge could assist the further prediction analysis and the design of lab ppi experiments. in this work, we divided features into four experts. apparently, the number of experts to be split into could be different. the splitting depends on the need of the application and the analysis ability of the biologists who would validate the predictions.

mixture-of-feature-experts 
using our experts setting, features are grouped into four  or three  categories. while the features are heterogeneous overall, within feature experts, attributes are roughly homogeneous and are derived from similar data sources. our main intuition in using the expert-based structure is to investigate the relationship between these homogeneous feature groups in terms of predicting ppis and to compare the importance of experts contributing to each prediction. this provides a principled way for selecting informative feature types during the prediction process.

we design a method called mixture-of-feature-experts  to achieve the above computational properties. as figure  <dig> shows, our framework can be viewed as a single layer tree, with feature experts at the leaves. each expert uses one of the dataset groups to predict ppis. a root gate is used to integrate predictions from multiple feature experts. the weights assigned to each of the experts by the root gate depends on the input set for a given pair. intuitively, this framework is analogous to the following process: each feature expert gives their opinion about how likely the investigated pair interacts and then the gate creates a final decision by the weighted sum of the experts' predictions. moreover, these weights are local and specific to the current example pair.

in the following sections, x describes the input feature vector variable and y represents the target output variable. input variable x represents d-dimensional feature vectors built from features in table  <dig> or table  <dig>  target variable y ∈ {- <dig>  1} means whether a protein pair interacts  or not .

given our feature experts setting, the conditional probability of the target variable y given the input variable x could be written as:

 p=∑mpp 

where m is a set of hidden data and indicates which expert was responsible for generating each example data pair. having i experts, m is a i-dimensional indicator vector variable. that is, all entries in m are  <dig> except for one of the entries which is set to  <dig>  the sum is over all configuration of variable m. in other words, target class label y is dependent on the input data x and the choice of expert m. the choice of m is also dependent on the input x. p is modeled using the root gate, while p is modeled by each feature expert in our framework. the graphical model view of mfe method is illustrated in figure  <dig>  this bayesian network structure expresses that the target variable y is dependent on the input vector variable x and the multinomial random variable m. it is essentially a modification of the probabilistic mixture-of-experts  model  <cit> .

using a training set including n examples, the n-th example pair is described using , y). for n =  <dig> to n, each data example , y) has a corresponding vector m. the dimension of vector m is equal to the number of feature experts: i . with i =  <dig> to i, n =  <dig> to n, each entry of this vector mi is as following:

 mi={ <dig> if using feature expert i for example n <dig> otherwise. 

thus, based on equation  the conditional probability p|x) is formulated specifically as:

 p|x)=∑i=1ip=1|x,v)p|x,mi= <dig> ωi) 

where wi are the model parameters used for feature expert i and v contains the model parameters used for the gate.

in general each expert can take any form such that the expected value of their probability density is consistent with the form of the problem. in this work, we use binary logistic regression for each of the feature experts. for the i-th expert  we write:

 p|x,mi= <dig> ωi)=11+exp)) 

similarly, the root gate can take any functional form that is consistent with a probability distribution. for instance  <cit>  used multinomial logit models for the gates. here, we extend the binary logistic regression to model the multinomial probability distribution of variable m through voting. this is analogous to using the one-versus-all strategy to transform a i-class classification into i binary logistic regression problem  <cit> . first binary logistic regression model is run once for each output branch of the root gate. next, modified probability weights are calculated for each branch by combining all the branch models. each branch of the root gate controls the weighting of a certain feature expert in our work. for the i-th branch  vi represent the logistic regression parameters for this branch and variable ci represents the binomial probability distribution from this branch. thus,

 p=1)=11+exp)) 

then by normalizing over all branches, we get the multinomial probability distribution of variable m as below:

 p=1|x,v)=p=1)∑j=1ip=1) 

this means that p = 1|x, v) depends on the input attributes ) and it represents the gate weight for expert i when predicting the n-th pair. in all of the above logistic regression steps, we apply ridge estimators to infer stable regularized parameters.

in summary within our feature experts framework the interaction prediction from mfe is a weighted sum of the opinions from each feature expert. the weights assigned to each expert are controlled by the input feature values as well as by the feature experts.

expectation-maximization 
based on the probabilistic model in equation , learning in mfe architecture is treated as a maximum likelihood problem. the model parameters include the gate parameters v and the expert parameters ωi.

we compute the log likelihood by taking the logarithm of the products of p|x) as follows,

 ll=∑n=1nlog=1|x,v)p|x,mi= <dig> ωi)) 

in the following we use Θ as the set of all the parameters including both experts and gate parameters. jordan and jacobs  <cit>  have proposed an expectation-maximization  algorithm for adjusting parameters in me architecture. the em algorithm is an iterative approach for maximum likelihood estimation . each iteration of an em algorithm consists of two steps, the e-step and the m-step. for the t-th epoch, model parameters are represented as Θt.

in the e-step we compute the posterior probability hi using equation . hi represents the posterior weight for expert i in predicting pair n once both the input and the target output are known. hi is derived using bayes rule:

 hi=p=1|x,y,Θt) 

 =p=1|x,Θt)p|x,mi= <dig> Θt)p|x,Θt) 

 =p=1|x,vt)p|x,mi= <dig> ωit)∑j=1ip=1|x,vt)p|x,mj= <dig> ωjt) 

by decomposition of the expected complete data-likelihood, the m-step reduces to separate maximization problems  <cit> , one for each expert and gate. in our mfe framework it solves the following maximization problems: for each expert,

 ωit+1=argmaxωi∑n=1nhilog|x,mi= <dig> ωi)) 

and for the root gate,

 vt+1=argmaxv∑n=1n∑j=1ihjlog=1|x,v)) 

each of these maximization problems are themselves maximum likelihood problems  <cit> . equation  is simply the general form of a weighted maximum likelihood problem in the probability density p|x, mi =  <dig>  ωi). given our expert choice, the log likelihood in equation  is a weighted log likelihood ) for the logistic regression model. an efficient algorithm known as iteratively reweighted least-squares  is available to solve this maximum likelihood task  <cit> .

equation  involves maximizing the cross-entropy between the posterior probability hj and the prior probability p = 1|x, v). this cross-entropy is the log likelihood associated with a multinomial logistic gate model in which the hj could be treated as output observations. thus the maximization in equation  is a maximum likelihood problem for a generalized linear model and can also be solved using irls technique.

overall the em algorithm could be summarized as the following iterative process:

 <dig>  for each data pair , y), compute the posterior probability hi using the current values of the parameters.

 <dig>  for each expert i, solve a maximization problem in equation  with observation {x,y}n=1n and observation weights {hi}n=1n.

 <dig>  for the root gate, solve the maximization problem in equation  with observation {x,y}n=1n and observation weights {{hi}n=1n}i=1i.

 <dig>  iterate by using the updated parameter values until a termination criterium is satisfied.

handling the missing feature value problem
as pointed out, biological datasets contain many missing values and this problem is an important obstacle in achieving significant improvements in prediction performance.

the simplest approach to handle the missing feature items is to fill those missing entries by certain values. for example, for a real-valued feature the filled value could be the mean of the feature column or for a categorical feature we could use the most common value. in the following sections we use the term 'mfe-fm' to represent the mfe method while using mean estimates for missing values .

we apply a more principled strategy to handle missing feature values. specifically, for each feature that has low feature coverage, this strategy add an extra feature column to represent the feature availability. for d =  <dig> ..d , xd represents the d-th feature column and g describes the ratio of missing cases for feature xd. if g is larger than a predefined ratio, we add a new, binary, feature column x to represent the availability of feature xd. that is, if for an example pair the feature xd is missing, this new feature x would be set to  <dig>  otherwise it would be set to  <dig>  the method now uses this new feature and can learn different parameters for observed and estimated features. totally if there are p original feature columns that have new feature columns added, the final feature vector then grows to be d + p dimensional. while this strategy increases the size of our feature set, it is still very small  compared to the total number of protein pairs .

in our mfe framework, since the weighting depends on the input features, by this adding features strategy our classifiers can use the present/absent information to modify the weights of different feature experts. similarly this strategy could also improve the classifiers used by each feature expert. in the following sections the term 'mfe' means the mfe method when using this added extra features strategy.

RESULTS
we first discuss the reference sets and evaluation strategies used in performance comparisons. next we present results for comparing the mfe method to several popular classifiers for predicting protein interaction pairs in yeast and human.

reference set 
any classification algorithm requires a training set. in our work for the positive set, there are a small number of interacting protein pairs that have been reliably determined by small-scale laboratory experiments. this set serves as our positive standard for this learning problem. for yeast, ~ <dig> interacting protein pairs were extracted from the database of interacting proteins   <cit> . for human, ~ <dig>  protein-protein interaction pairs were extracted from the human protein reference database   <cit> . both sets were filtered to exclude self-interactions.

unlike positive interactions, it is rare to find a confirmed report on non-interacting pairs. considering the small fraction of interacting pairs in the total set of potential protein pairs we use a random set of protein pairs, excluding those interacting pairs that are known, as the negative set. in yeast, it is estimated that roughly only  <dig> in about  <dig> possible pairs actually interacts  <cit> . in human, this ratio is even smaller, roughly  <dig> in several thousands of possible pairs is estimated to interact. thus, over  <dig> % of our random data is indeed non-interacting, which is probably better than the accuracy of most training data.

combining the positive and negative ppi sets, a reference set  is then constructed for use as training/testing sets when applying learning methods.

evaluation strategy
based on the reference set, we use the following two measures to evaluate the performance of our predictions, precision vs. recall curves and auc scores .

in precision vs. recall curves, precision refers to the fraction of interacting pairs predicted by the classifier that are truly interacting . recall measures how many of the known pairs of interacting proteins have been identified by the learning model. the precision vs. recall curve is then plotted for different cutoffs on the predicted score.

receiver operator characteristic  curves plot the true positive rate against the false positive rate for different cut-off values of the predicted score. it measures the trade-off between sensitivity and specificity. the area under the roc curve  is commonly used as a summary measure of diagnostic accuracy. it can take values from  <dig>  to  <dig> . in some cases, rather than looking at the area under the entire roc curve, it is more informative to only consider the area under a portion of the curve. in our prediction task, we are predominantly concerned with the detection performance of our models under conditions where the false positive rate is low. for example, r <dig> is a partial auc score that measures the area under the roc curve until reaching  <dig> negative predictions. similarly r <dig> is the partial auc score when reaching  <dig> negative predictions.

performance comparison
to measure the ability of the mfe method to predict ppis, we compared it with four other popular classifiers that have been suggested in the past for this task: logistic regression , naïve bayes , support vector machines  and random forest . our mfe method is implemented using matlab. standard toolkits are used for the other methods. specifically, the svmlight toolkit was used for svm  <cit> . logistic regression and naive bayes were obtained from the weka machine learning tool box  <cit> . random forest was from the berkeley rf package  <cit> . the input feature vectors to these methods are exactly the vectors from table  <dig> or table  <dig> with missing values filled.

all comparisons were based on the following training and testing procedures. in yeast, we randomly sampled a training set containing ~ <dig>  protein pairs to learn the decision model. then we sampled a test set  from the remaining protein pairs, and used the trained model to evaluate the performance of the classifiers. the above steps were repeated  <dig> times for each classifier and average values are reported. similar procedures were pursued in human where the training and the testing sets included ~ <dig>  examples. for each evaluated classifier, parameter optimization was carried out in all cases in identical train-test fashion.

based on the estimated ratio of interacting versus non-interacting pairs in yeast and human, we have roughly ~ <dig> to ~ <dig> positive ppis in each test run. for the training set, we up-sampled the positive examples in a pre-processing step, which resulted in roughly ~ <dig> positive examples for each training run in human and roughly ~ <dig> positive pairs for each yeast training. this sampling strategy reduces the problem of too few positive examples in the training set without affecting the performance significantly  <cit> . figure  <dig> plots the average precision versus recall curves of these five different methods for the yeast ppis prediction and figure  <dig> is for human. in both figures, the curves derived from mfe approach dominate the other four methods in most of the low recall ranges.

average auc and partial auc scores for six classification methods for ppi prediction in yeast. lr: logistic regression; nb: naive bayes; rf: random forest; svm: support vector machine; mfe: mixture-of-feature-experts; mfe-fm: mixture-of-feature-experts with missing features filled. average auc and partial auc scores are reported and the standard derivations for each score estimation are also listed in the table. mfe scores are highlighted and it clearly achieves better auc/r50/r <dig> scores compared to the other five.

average auc and partial auc scores for six classification methods for ppi prediction in human. lr: logistic regression; nb: naive bayes; rf: random forest; svm: support vector machine; mfe: mixture-of-feature-experts; mfe-fm: mixture-of-feature-experts with missing values filled. average auc and partial auc scores are reported and the standard derivations for each score estimation are also listed in the table. mfe scores are highlighted and it again achieves better auc/r50/r <dig> scores compared to the other five classifiers.

the last two rows of table  <dig>  list the auc and partial auc scores of mfe-fm and mfe methods in yeast. mfe clearly achieves better performance compared to mfe-fm . this means that by explicitly indicating the availability of feature attributes our method improves the classification outcome. similar conclusions could be drawn for human as shown in table  <dig> 

the methodology we propose, of feature experts, is very general. as discussed in the 'methods' section, the number of feature experts the heterogeneous data sets are split into could be different. the splitting essentially depends on the need of the application and the preference of the biologists who would analyze and/or validate the predictions. at the limit case, we can assign each feature to an individual expert. to test this we carried out one new experiment for the human prediction task treating every feature as its own expert. as the results  indicate, this does not improve the performance of the algorithm, perhaps because it leads to overfitting of the parameters.

discussion
biologically, it is of particular interest to identify the extent to which heterogeneous data sources carry information about protein interactions. an analysis of the contribution of different features can also help uncover relationships between different data sources that are not directly apparent.

analysis of feature importance is important on the global scale as well as for the prediction and analysis of specific protein pairs. we therefore ask the following questions:  how do the different features affect ppi prediction performance overall? and  how do the different features contribute differently for each example pair? we have explored these two questions using the yeast results.

global feature importance
to control data collection costs, it is important to select only informative data types globally. once informative data types are identified, one does not need to use unnecessary data sets when solving similar network inference problems for other sets of proteins or for other organisms. this can significantly speed up prediction of ppis in new species, as well as when updating predictions on model species such as yeast and human with new data sources.

to identify overall feature importance among our feature experts, we remove feature experts one by one, and run the mfe methods on the remaining three experts. we then examine how the performance changes. table  <dig> lists the score changes of r <dig> and auc after removing the experts one by one. the less the score changes the less important is the feature expert. we found that removing the sequence expert 's' had the least impact on both scores. the indirect high-throughput data expert 'e' ranked second from the bottom in the prediction of yeast ppi's.

global feature expert importance can be measured by the decrease in auc and r <dig> scores when removing the expert in the mfe method. the first column lists the four feature experts. the second and fourth column list the r <dig> and auc scores when applying mfe while only using the remaining three experts. the third and fifth column list the changes between these r <dig> and auc scores and the full experts version. for definition of p, f, s, e experts, see details in the 'feature' section and table  <dig> 

it is surprising that removing expert 'e'  does not hurt performance much. this is seemingly in contradiction to previous estimations in which tree based feature ranking methods ranked gene expression features very highly  <cit> . note that, when the feature sets are not grouped, the wide availability of gene expression data and its high coverage may result in an increased use of this feature, even though it may lead to overfitting. as our results suggest, splitting the data into more homogeneous groups  may help increase the prediction accuracy by decreasing its reliance on these high throughput data sources.

feature importance for specific protein pairs
for each predicted pair it would be useful for computational techniques to provide information about which features contributed to the predictions for that pair. our mfe method naturally reveals how each feature category contributes to the interaction predictions. the posterior probability from equation  could be treated as the level of contribution from each expert to the final prediction. then for a specific candidate protein pair, these values could give a detailed description about how each expert contributes to the integrated prediction.

to demonstrate the utility of this unique capability of the mfe method to reveal feature importance in specific predictions, we investigated a specific yeast pathway; the yeast pheromone response. for this pathway we compare the contribution of different experts in the known and predicted interacting pairs. figure  <dig> presents the known interactions in this pathway as determined by the kegg database  <cit> . in this pathway the yeast mating factors mat alpha/a bind to their cognate membrane receptors ste2/ <dig>  members of the g protein coupled receptor family. subsequent binding and activation of the g protein induces a map kinase signaling pathway via g protein activation  <cit> .

we selected  <dig> proteins that are known to participate in this pathway and applied the mfe algorithm to classify the  <dig>  potentially interacting pairs. the training set included  <dig> positive pairs and  <dig> negative  pairs. none of these pairs contained any of the known  <dig> proteins in this pathway. the positive versus negative ratio in this set is roughly the same as the ratio we used for the performance comparisons. we determined a prediction threshold using the training set.  <dig> of the  <dig> pairs had scores above the threshold and were thus predicted to be interacting. among them,  <dig> interactions  had been experimentally validated. the remaining  <dig> pairs are new predictions.

CONCLUSIONS
one of the most important goals of computational ppi predictions is to suggest biological hypotheses regarding unexplored new interactions that are testable with subsequent experimentation. among high scoring predictions, the most interesting ones can be chosen by an individual investigators using intuition and specialized knowledge.

this paper addresses two important problems for the ppi prediction task. first, previous classification methods estimate a set of parameters that are used for all input pairs. however, the biological datasets used contain many missing values and highly correlated features. thus, different samples may benefit from using different feature sets. the second problem is that biologists who want to use these methods to select experiments cannot easily determine which of the features contributed to the resulting prediction. since different researchers may have different opinions regarding the reliability of the various feature sources, it is useful if the method can indicate, for every pair, which feature contributes the most to the classification result.

in this paper we propose a mixture-of-feature-experts  approach to address the above two challenges when predicting protein-protein interactions. diverse high-throughput biological datasets are split into homogeneous feature experts. each expert uses a subset of the data to predict protein interactions and expert predictions are combined such that the weight of each expert depends on the input data for the predicted protein pair. this method is useful for overcoming problems in achieving high prediction performance arising due to missing values which are a major issue when analyzing biological datasets. in addition, the weights can be used by biologists to determine confidence in the prediction for each pair. we have shown that this algorithm improves upon previous methods suggested in yeast and human for this task. extensions of this approach to other species are straight forward when more information becomes available.

we believe that as the prediction task becomes harder  the need for methods that can accommodate high levels of missing values and are directly interpretable by biologists increases. the next step will be to apply our method to interaction prediction tasks related to important types of human proteins where missing values and the small number of positive examples are major obstacles in obtaining of an accurate protein interaction map.

list of abbreviations used
• y2h: yeast-two-hybrids;

• ppis: protein-protein interactions;

• mfe: mixture of feature experts;

• mfe-fm: mixture-of-feature-experts with missing values filled;

• me: mixture of experts;

• em: expectation maximization;

• lr: logistic regression;

• nb: naive bayes;

• rf: random forest;

• svm: support vector machine;

competing interests
the authors declare that they have no competing interests.

authors' contributions
qyj carried out the feature experts method designs, performed the methods implementation and analysis and drafted the manuscript. jks participated in the design and analysis of the study and helped to revise the manuscript. zbj participated in the method design and analysis and helped to draft the manuscript. all authors read and approved the final manuscript.

