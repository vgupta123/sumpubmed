BACKGROUND
ongoing efforts to discover genetic variation in humans and other species are yielding long lists of known variants  <cit> . the discovery of genetic variation is always the first step of population genetics or association studies. once structural or nucleotide variation is revealed, individuals not present in the original sample are usually genotyped, for subsequent studies. genotyping individuals is much easier than discovering new variants, because fewer loci have to be tested, and the prior probability of there being an alternative allele is higher than in sites not known to be variable. however, the presence of sequencing and mapping errors, and undersampling at heterozygous sites demand high coverage in order to infer individual genotypes accurately. accurate genotypes are the basic information upon which most classic methods of population genetics depend. our reliance on classic methods and the convenience of low-coverage data are such that the population-level structure of the variation is being used to improve the genotype calls on low-coverage data  <cit> , which are then expected to help us understand the population-level structure of the variation. this circularity prevents, for example, the use of genotypes imputed on the bases of known patterns of linkage disequilibrium to infer recombination rates. the problem stems from considering the genotypes as the ultimate result of a research program. for most studies, other than personalized medicine, the genotypes are just the means to gain insight into population-level processes: association between genotypes and phenotypes, history of migration and admixture, patterns of recombination, natural selection, etc.

when studying structural variants, there is too much to loose from relying on imputed genotypes. polymorphic structural variants contribute to phenotypic diversity and disease susceptibility in humans  <cit> , and other species  <cit> . the population genetics of structural variants is both a classic field, and, thanks to the new sequencing techniques, an emergent research venue  <cit> . in the last years, many programs have been developed to identify structural variants from sequence data, using diverse signatures from split reads  <cit> , read depth  <cit> , paired reads  <cit> , or a combination thereof  <cit> . among the hotest topics that await to harvest full benefits from the high-throughput sequencing technologies, is the interplay between structural and nucleotide variation. the nucleotide variation linked to structural variants can inform of their evolutionary history and their effects on fitness, and it can also reveal to what extent structural variants affect recombination patterns. however, these questions cannot be addressed with snp genotypes imputed on the bases of assumed patterns of linkage disequilibrium.

an alternative to genotype imputation is to study the population-level structure of the variation with new methods that take genotype uncertainty into account in the analysis. this is what has been proposed before for single-nucleotide variation  <cit> . the idea is to calculate the genotype likelihoods at every site, instead of calling the genotypes. genotype likelihoods can be used to obtain unbiased estimates of allele frequencies or site-frequency spectra, and likelihood-ratio tests can be used to address population-level hypotheses, such as hardy-weinberg equilibrium, population differentiation, linkage disequilibrium, genotype-phenotype association, etc  <cit> . however, this promissing approach is not applicable yet to structural variants, mostly because existing implementations assume even sampling probabilities of the two alleles from a heterozygous sample. while this assumption is a reasonable simplification for the analysis of snp data, it is not for the analysis of structural variants, where one of the alleles may be observed much more frequently than the other in a heterozygous sample  <cit> . one source of bias is the conservative alignment of reads to the reference genome. by default, mapping tools are optimized for the discovery phase, when the prior of there being a structural variant is very low. therefore, aligners favor concordant mappings, that is, those that do not report the variation  <cit> . another source of allele sampling bias is the different detectability of the alleles. for example, using single reads, the presence of a polymorphic insertion may be revealed by any read mapping to either of the two breakpoints, or even to its inner sequence, if unique and known; while the absence of the inserted fragment can only be positively attested by reads mapping on a single breakpoint. also, repetitive sequences are frequently present around a structural variant, and they can impair the detection of one allele more than the other. for example, when the sequence of a transposable element is broken by an inversion in one of the breakpoints. in summary, allele sampling bias is the rule, rather than the exception, when genotyping structural variation with sequence data; and the bias can be orders of magnitude higher than in the case of snps . in addition, the few existing tools able to report genotype likelihoods  <cit>  require a bam file  <cit>  for their calculation, which is not designed for structural variation at all.

here, we present svgem, a simple and flexible command-line application to infer genotype likelihoods and allele frequencies from counts of reference and alternative alleles, appropriate for structural variation data, with an arbitrarily high reference  bias. this program is not concerned with the discovery phase of the structural variants, but with the post-discovery analyses. the only assumptions made about the type of variation that can be analysed are that it is bi-allelic, and that the two alleles can be distinguished from sequencing data. thus, simple insertions, deletions, inversions, and translocations of any length can be analysed with svgem, while multiple, overlapping rearrangements, with more than two possible alleles are not. the sampling bias must be known in advance, and passed as a parameter. we offer some guidelines on how to estimate it, and explain how to test for hardy-weinberg equilibrium. also, the ploidy of the samples is taken into account to infer genotype likelihoods and allele frequencies in sex chromosomes properly.

implementation
overview and requirements
the program svgem implements an expectation-maximization algorithm in c++. the source code is freely available in additional file  <dig>  and in  <cit> . it runs from the command line, analyses one structural variant at a time, and it takes as input a text file with three  columns: a sample identifier and the numbers of times the reference and the alternative alleles have been observed. the optional fourth column represents the ploidy, for the case when the sample is composed of a mixture of males and females, and the variant being analysed is on the sex chromosome.

in order to make svgem compatible with virtually any way of counting the observations of reference and alternative alleles, only two qualities are distinguished: the average quality of the reference counts, and the average quality of the alternative counts. these are analogous to the base qualities of a sequenced read, and they can be passed as parameters to the program, in terms of the frequencies of erroneous counts, or estimated from the data. alternatively, if the individual quality  of each observation is known, the expected number of true counts or ‘effective’ number of times the alleles are observed, instead of the raw counts, can be used. this approach proved to be very useful in snptools  <cit> .

the allele sampling bias is represented by one parameter, λ, defined as the odds of sampling the reference allele from a diploid, heterozygous genotype. even though in some cases it could be estimated from the data, svgem requires λ to be passed as a parameter, in order to save degrees of freedom. otherwise, it would be impossible to get accurate estimates of extreme allele frequencies in the presence of errors. plus, because svgem is not designed to discover variants, but to analyse already known variants, it is fairly easy to estimate λ. there are two different situations. first, if the exact sequences of both structural alleles are completely known, the alleles can be distinguished by the single reads mapping specifically to one of them. all possible reads from the informative regions of both alleles can be extracted, as if they came from a heterozygous sample, and mapped back to the reference genome and to the alternative allele. then, λ would be estimated as the ratio between the number of reference reads that map uniquely to the reference allele, and the number of alternative reads that map uniquely to the alternative allele.

second, if the exact sequences of the structural alleles are not known , they must be distinguished by the pattern of paired-end mappings: concordant for the reference, and discordant for the alternative . still, the most likely version of the alternative allele could be composed, and used to extract paired end reads from it. in this case, the complete extraction of all possible paired-end reads is not feasible, but extensive simulations can be done with available programs, such as wgsim <cit> , or art <cit> . if the same coverage is simulated in both alleles, λ can be estimated as the ratio of the number of reference paired ends that map concordantly to the number of alternative paired ends that map discordantly. to overcome the imprecision of the breakpoints, several alternative alleles could be simulated and averaged. alternatively, if a subset of individuals are known to be heterozygous by other means , the ratio between their pooled numbers of reference and alternative reads can also be used as an estimate of λ. inaccurate estimates of λ have a mild impact on genotype likelihoods, and they are always preferred to the default value of λ= <dig>  as long as they are closer to the true value of the allele sampling bias .

implementation of the expectation-maximization algorithm
following the notation in  <cit>  , we refer to a genotype by its number of reference alleles, g ∈ { <dig>  1 … m}, where m is the ploidy, usually  <dig>  we assume that variants are biallelic, so that m - g is the number of alternative alleles in the genotype. table  <dig> shows the likelihoods of the three diploid genotypes. the main difference with respect to li’s equation  <dig>  <cit>  is the heterozygous genotype, the likelihood of which depends here on the allele sampling bias. if λ =  <dig>  and allowing for all the observations of the same allele to have the same quality, the difference vanishes . the likelihoods of the hemizygous genotypes alt/ <dig> and ref/ <dig> are the same as those of the respective homozygous genotypes.

ε
r
ε
a
treating the genotypes as missing values, we implement an expectation-maximization  method to estimate either the alternative allele frequency, ψ, under the assumption of hardy-weinberg equilibrium, or the genotype frequencies ψ
g
  or ϕ
g
 , and eventually the proportions of errors among reference  and alternative  counts. note that ψ
g
 is the frequency of genotype g among diploids, and ϕ
g
 is the frequency of genotype g among hemizygous individuals. the em algorithm is an iterative estimation of the parameters that gets closer to the maximum likelihood estimates in every iteration. additional file  <dig> gives a summary of how the standard formulation of the em algorithm is used to derive the next values of these parameters, namely: 

 ψ=2d0+d1+h02+d1+d0)+h0+h1ψg=dgdϕg=hghεa=a2a0+a <dig> ifλ=1εr=r0r0+r <dig> ifλ= <dig> 

in the equations above, dg is the t
th
 estimate of the total number of diploid individuals with genotype g, and hg is the t
th
 estimate of the total number of hemizygous individuals with genotype g. that is, they are the summations of the posterior probabilities of genotype g over the respective kind of individuals. d and h are the total number of diploid and hemizygous individuals, respectively, where d + h = n. ag is the t
th
 estimate of the total number of alternative counts coming from hemizygous and homozygous individuals for either the alternative  or the reference  allele. finally, rg is the t
th
 estimate of the total number of reference counts that come from hemizygous and homozygous individuals for either the alternative  or the reference  allele.

when there is sampling bias in heterozygous individuals, λ≠ <dig>  and the next values of the proportions of errors among reference  and alternative  counts are the results of two quadratic equations . in practice, it is assumed that the erroneous counts are a minority, and the program halts when ε
r
 ≥  <dig>  or ε
a
 ≥  <dig> . this can prevent the correct estimation of extreme allele frequencies in the presence of erroneous counts, as should be expected.

output and applications
the output includes: maximum likelihood estimates of the parameters mentioned above, the likelihood of such estimates, the genotype likelihoods of all individuals, and the posterior probabilities of the genotypes of all individuals. the main purpose of svgem is to obtain unbiased estimates of allele and genotype frequencies, which are fundamental parameters in population genetics. from these estimates, several other population parameters can be estimated. the maximum likelihood estimate of the frequency of the heterozygous genotype , estimated without assuming hardy-weinberg equilibrium, is a direct estimate of heterozygosity. an estimate of the inbreeding coefficient follows from comparing ψ^ <dig> with the expected frequency of heterozygous individuals under hardy-weinberg equilibrium: f^=1-ψ^1/) . the fixation index, fst, which measures genetic differentiation among populations, is also readily estimated from allele frequencies  <cit> . a test for hardy-weinberg equilibrium  can be performed by running svgem with and without the equilibrium assumption, and comparing the log-likelihoods of the estimated frequencies. twice the difference between the log-likelihoods must be compared with a χ <dig> distribution with  <dig> degree of freedom, if all individuals are diploid, or with  <dig> degrees of freedom if the frequencies of hemizygous genotypes are also being estimated.

some analyses that used to require accurate knowledge of individual genotypes can be performed now using only genotype likelihoods. for example, it is possible to estimate the linkage disequilibrium between pairs of variants using genotype likelihoods, instead of individual genotypes  <cit> . at the end of the next section, we show how to estimate the linkage disequilibrium between a structural variant and the snps around it, without the biases typically associated with genotype imputation.

it is also possible to run genetic association tests from genotype likelihoods, without knowing the exact genotype of the individuals  <cit> . associations between phenotypes and genetic variants are a significant difference in allele frequency between two samples , and they are routinely searched along the human genome to infer the causal variants of diseases. to compare the allele frequency of a variant between two samples, svgem must be run three times: once in each sample separately, and once in the joint dataset. lets call ℓ
a
 and ℓ
b
 the log-likelihoods of the two independent estimates for samples a and b. the total log-likelihood of the hypothesis of two different frequencies is just the sum of the log-likelihoods of the two samples: ℓ1 = ℓ
a
 + ℓ
b
. the log-likelihood of the hypothesis of one common allele frequency, ℓ <dig>  is obtained from the run on the joint data set. because the two hypotheses are nested, the application of a likelihood ratio test is justified. thus, if the null hypothesis of a common allele frequency is true, the statistic  <dig> is expected to follow a χ <dig> distribution with as many degrees of freedom as additional parameters the most complex model has, which is  <dig> in this case .

for other analyses, that may require knowledge of individual genotypes, we recommend using the genotype with the highest posterior probability, which is more accurate than the most likely genotype, because posterior probabilities take into account the information of the genotype frequency in the population . svgem uses the maximum likelihood estimates of allele  or genotype  frequencies, and the genotype likelihoods ) to calculate the genotype posterior probabilities, p: 

 p=ℒp∑g=0mpℒif hwe is assumedℒψ^g∑g=0mψ^gℒif it is not 

performance
although svgem is designed to analyse one variant at a time, more than one variant can easily be analysed in multiple parallel runs. for the purpose of detailed population genetic analyses of specific variants of interest, svgem performs well, since its typical run time is always a tiny fraction of the time usually needed to obtain the allele counts. in absolute terms, it can analyse > <dig> individuals in, at most, a few seconds, in a standard pc. however, the run time is variable, just as in any expectation-maximization algorithm, and convergence may take longer if the information content of the input data set is limited.

RESULTS
estimates of 
λ
 from real structural variants
in order to assess the expected range of values of the λ parameter, we downloaded the breakdb database  <cit> , last accessed on january 26th  <dig>  and built a library with the known sequences of both alleles of  <dig> structural variants . then, we simulated the exhaustive sequencing of both alleles with single-end, 100-bp reads. next, we mapped the sequenced reads first to the library built with the sequences of the reference and the alternative alleles, and afterwards to the whole reference genome , in order to discard any non-specific read. for this purpose, we used the pipeline breakseq  <cit> , with minor modifications. we removed from breakseq a filter that required the reads to map on the breakpoints, in order to be able to use the inserted or deleted sequences as evidence of the presence or the absence of an insertion or a deletion. finally, we counted how many reads mapped specifically on the reference or on the alternative allele, and estimated λ as the ratio of the two counts.

the observed, finite values of λ ranged between  <dig>  and  <dig> . figure  <dig> shows that the length of the insertions and deletions greatly contributes to the value of λ, as expected. because the inserted or deleted sequence is known, and used as evidence of the presence of the longest allele , longer insertions or deletions produce more unbalanced allele observations, favouring the reference allele in a deletion  or the alternative one in an insertion . the local sequence around and within the variant, and the method used to detect the alleles  must also influence the exact value of λ. however, the linear regressions between the logarithm of λ and the logarithm of the size of the insertion or deletion  allow for a rough, first approximation to λ, at least when detecting insertions or deletions with single-end sequenced reads: log = - <dig>  +  <dig>  log for deletions with respect to the reference allele , and log =  <dig>  -  <dig>  log for insertions . in the case of inversions, a λ =  <dig> is a fair assumption, in the absence of additional information. this approximations are not expected to hold when detecting structural variants flanked by segmental duplications or other repeats.

analysis of simulated data
we run some simulations to test svgem. in the artificial datasets, genotypes followed hardy-weinberg equilibrium, with allele frequencies between  <dig>  and  <dig> , and the allele counts were sampled with a simulated error rate of  <dig> . coverage was poisson-distributed, in order to introduce variation in coverage among individuals, although the exact distribution is irrelevant for the calculation of genotype likelihoods. in all,  <dig> simulations were run with the same parameter values.

first, we checked that svgem is able to get unbiased estimates of the allele frequency with low coverage data, in the absence of any allele sampling bias . figure  <dig> shows how estimates based on a sample of  <dig> individuals are accurate and as precise as they can be with mean coverages ranging from  <dig>  to  <dig>  the only biased estimates correspond to alternative allele frequencies lower than  <dig>  , targeted with sequencing coverages lower than  <dig> . not surprisingly, as the number of parameters to estimate increases, the precision and the accuracy drop. the frequencies of the three genotypes can still be estimated without bias in most cases, if the mean coverage is higher than  <dig> . when comparing the true genotypes of all individuals simulated with the most likely and with the most probable genotypes , two results become aparent: 1) the benefit of using posterior probabilities, instead of just likelihoods , is higher when the coverage and the minor allele frequency are lower; and 2) applications that require accurate genotypes should use coverages higher than  <dig>  unless the minor allele frequency is always very low. the very high levels of genotype errors observed when the minor allele frequency is high and the coverage is low are an instrinsic problem of the limited amount of data available to infer the genotype. even if the allele frequency and the allele sampling bias were known with accuracy, up to 50% of the genotypes predicted by maximum posterior probability are expected to be wrong when the coverage is  <dig> and the minor allele frequency is  <dig>  . the fact that allele and genotype frequencies can be estimated accurately under rampant uncertainty of individual genotypes strongly encourages the use and further development of genotype-free methods, that take full advantage of low-coverage sequencing data.

next, we checked svgem performance with different sample sizes from  <dig> to  <dig> and a fixed sv frequency of  <dig> , which is the one with higher sampling variance. figure s <dig> in additional file  <dig> shows that smaller samples, with a mean coverage of  <dig>  also yield unbiased estimates with a precision comparable to the expected under accurate knowledge of genotypes.

finally, we prove that arbitrarily high reference bias does not deviate the estimates from the true values, if svgem is informed of the bias. figure  <dig> represents the accuracy and the biases of the estimates of the allele frequency for several combinations of the true  and the estimated  values of the allele sampling bias. the estimates are always unbiased if λ^=λ, as expected. interestingly, the estimates are also unbiased when λ is very low  or very high , and λ^ is even lower, or even higher, respectively. this implies that extreme values of λ can be effectively approximated by a wide range of values. the reason of this nice property is that at low coverage, the outcome of an extreme λ is always the same: none of a few observations gets to sample the disfavoured allele from a heterozyous sample. it is also worth noticing that rough approximations to λ, in the range between λ /  <dig> and 2λ produce only minor biases in allele estimates. moreover, any estimated λ^ closer to the real value of λ than the default λ =  <dig> will improve the allele frequency estimates.

it is also important to mention that the frequency of erroneous reference or alternative allele counts, ε
r
 and ε
a
, need to be either known or co-estimated from the data to get accurate estimates of allele or genotype frequencies. an erroneous count is a false observation of an allele, which should not contribute to the estimate of allele frequency. they are assumed to be less frequent than true counts. in practice, the accurate estimation of both the allele  frequency and the frequency of erroneous counts is only feasible if there is enough information in the data. as a rule of thumb, when coverage is below  <dig>  or the number of individuals is below  <dig>  a priori estimates of ε
r
 and ε
a
 are highly recommended. they can be obtained from simulations, or estimated from a subset of individuals with high coverage, or empirically determined in a subset of homozygous individuals.

analysis of real data
to test the performance of the algorithm on real data, we used as a model a previously unknown human inversion with simple breakpoints. analysis of this inversion was part of a larger study to characterize and validate polymorphic inversions in human populations. in particular, the inversion selected  is a  <dig> bp inversion in the chr5q <dig>  region, supported by paired-end mapping data of fosmids  <cit>  or small dna fragments  <cit> . by comparison of the hg <dig> human genome reference assembly  <cit>  with the alternative human assemblies of celera  <cit>  and huref  <cit> , it was found that the inverted allele includes two small deletions flanking the inversion and it was possible to locate the breakpoints  to hg <dig> position chr5:147533233- <dig>  and chr5:147534809- <dig> , which correspond to the sequences deleted in the inverted chromosomes  <cit> . from there, we extracted  <dig> nucleotides-long in silico probes, in which the sequence change between the two orientations is located exactly in the middle . then, we mapped the reads from  <dig> individuals from the  <dig> genomes project  <cit>  on these probes, using the program breakseq <cit> , and counted how many matched specifically the reference or the alternative breakpoints. in order to quantify the allele sampling bias, λ, we extracted all possibly informative reads from the  <dig> nucleotides probes , with the same length range as the real reads used , and used breakseq again to count how many of them mapped uniquely to either the reference or the alternative breakpoints. a negligible bias  was found. erroneous counts were experimentally determined to be also negligible , and their frequencies were set to  <dig> ×10- <dig>  although several orders of magnitude of variation in this parameter did not alter the results significantly. from the allele counts and from these parameter values, svgem estimates a global alternative allele frequency of  <dig> , and population-specific frequencies ranging from  <dig>  to more than  <dig>  . among related individuals, only the oldest parents of a family were retained for the estimation of population parameters. using a likelihood ratio test, we prove that asian and native american populations have a significantly lower frequency of the alternative conformation than african and european populations .

to genotype experimentally the inversion, we used different pairs of primers specific for the reference orientation  or the inverted orientation  and carried out duplicate pcrs of each individual, both in simplex and multiplex format. in total, the  <dig> individuals of the phase ii of the hapmap project were analyzed, including  <dig> yoruba ,  <dig> from european origin ,  <dig> chinese  and  <dig> japanase , and the pcr results can be accessed in the invfest database  <cit> . table s <dig> shows the observed genotypes and the genotype posterior probabilities calculated with svgem for the  <dig> individuals that were both genotyped by pcr and analysed with breakseq and svgem. the alternative allele frequencies determined experimentally or estimated with svgem in this subsample were, respectively,  <dig>  , and  <dig> . the most probable genotype determined by svgem matched the true genotype in  <dig>  individuals, with only  <dig> error  when the coverage is higher than  <dig>  from the allele counts of homozygous individuals, it can be seen that the opposite allele is never observed, confirming that the rate of erroneous counts is negligible.

once having accurate genotype likelihoods of this short inversion, it is possible to calculate its linkage disequilibrium with nearby snps, without having to know the true genotypes, neither of the inversion, nor of the snps. this allows the study of the association between structural variants and snps without having to rely on imputed genotypes, and without having to exclude snps with arbitrary coverage thresholds. the method to calculate the pairwise linkage disequilibrium statistic r <dig> from genotype likelihoods is implemented in bcftools <cit> , and requires an input vcf file with genotype likelihoods. we downloaded from the  <dig> genomes project database a vcf file spanning  <dig> kb around the inversion, and manually combined it with the inversion itself, represented by two punctual variants at the positions of its breakpoints. figure  <dig> shows how the two breakpoints are correctly determined to be in perfect linkage disequilibrium between them, and how the patterns of linkage among the inversion and the snps around it differ between european and asian populations. note that linkage disequilibrium estimates, let alone their comparison between populations, would be biased if imputed genotypes had been used, because imputation already assumes some linkage disequilibrium, not always measured in the population of interest.

CONCLUSIONS
the development of methods to discover structural variants in individual genomes is giving way to population-level analyses. the most recently developed discovery tools, such as gasvpro  <cit>  or cloudbreak  <cit> , call the genotypes of the individuals analysed, instead of just reporting the variants discovered . however, these individual-based methods require high coverage, and they are oblivious to the information present at the population level. while these methods are still useful in some applications, there is a current demand for efficient ways to analyse low-coverage population genomics data. most studies still insist in genotyping the individuals, despite of the loss of data caused by arbitrary quality thresholds, and despite the circularity and biases associated with genotype imputation  <cit> . the alternative of using likelihood or bayesian approaches, which take genotype uncertainty into account, is an optimal strategy to explore genetic diversity, since it does not require high coverage per individual, and allows the sequencing of more individuals at the same cost  <cit> . not surprisingly, a new method to genotype indels from sequence data in polyploid genomes uses the same approach of likelihood calculation, frequency estimation through an expectation-maximization algorithm, and reporting of posterior probabilities  <cit> . however, this method does not consider any allele sampling bias, because it targets indels shorter than the reads used to distinguish the alleles. by including allele sampling bias in the genotype likelihood calculation, our program extends the applicability of these methods to the analysis of large structural variation. furthermore, for the first time nucleotide and structural variation can be analysed in the same statistical framework, without having to rely on the accuracy of the genotypes.

two of the key features of svgem are its simplicity and its few assumptions about the data, which make the program useful for a wide variety of data types. any bi-allelic structural variant detected by sequenced paired-ends or split reads, including inversions, mobile element insertions, duplications, and deletions, can be analysed by svgem. using simulations, we have shown that estimates of allele or genotype frequencies are accurate, even in the face of rampant allele sampling bias, that usually accompanies the detection of structural alleles. finally, using data from the  <dig> genomes project and pcr experiments, we prove its applicability to real data.

availability and requirements
project name: svgem.

project home page:http://grupsderecerca.uab.cat/cacereslab/content/resources.

operating system: platform independent.

programming language: c++.

other requirements: none.

license: gnu general public license.

any restrictions to use by non-academics: none.

abbreviations
em: expectation-maximization; kb: kilobase pairs; pc: personal computer; hwe: hardy-weinberg equilibrium; pcr: polymerase chain reaction; snp: single-nucleotide polymorphism; maf: minor allele frequency.

competing interests
the authors declare that they have no competing interests.

authors’ contributions
jill wrote the program, run it on the simulated and real data, and coordinated the writing of the manuscript. dv retrieved the allele counts from the  <dig> genomes project database. ca designed and oversaw the pcr experiments. mc designed the study and supervised all steps. all authors contributed to the writing. all authors read and approved the final manuscript.

supplementary material
additional file 1
this is a plain text file containing the source code of 
svgem
, in c++.

click here for file

 additional file 2
additional text including 
svgem
’s manual and some details on how the expectation-maximization algorithm is implemented.

click here for file

 additional file 3
tables s <dig> and s <dig>  table s <dig> in silico probes and pcr primers. in silico probes including the two breakpoints, in both the reference and the inverted conformations, and primers used for pcr validations. table s <dig>  experimental validation. allele counts, genotype posterior probabilities obtained with svgem, and true genotypes determined by pcr, for inversion hsinv <dig> in  <dig> individuals from the  <dig> genomes project.

click here for file

 acknowledgements
we thank david izquierdo for help with the experimental genotyping of the inversion, and xavier estivill and marta morell for help with the ceu population lymphoblastoid cell cultures. this work was supported by the european research council  under the european union seventh research framework programme ; and by the commission for universities and research of the ministry of innovation, universities and enterprise of the autonomous government of catalonia and the cofund programme of the marie curie actions of the fp <dig> .
