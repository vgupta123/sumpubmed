BACKGROUND
computational motif discovery for transcription factor binding sites is a challenging research problem that has been studied for many years, but we are still missing approaches that can ensure generally good performance. for transcription factors with known binding motifs, scanning sequences for matches to motif models can identify potential binding sites, but the performance is often strongly degraded by a high content of false positive predictions; predicted sites that do not correspond to actual transcription factor binding events  <cit> . de novo motif discovery, i.e. discovery of potentially novel motifs from a set of dna sequences, can work well for input sequences with high motif content, like from chip-seq experiments. however, it is often less successful on more general sequence sets, based for example on regulatory regions for co-regulated genes  <cit> .

it is a commonly used approach to not rely on predictions of just a single method, but to run several motif discovery methods on the same dataset and compare the results. the motivation is, of course, that although one individual method might be mistaken in a single case, any motif predicted by several different methods is probably more likely to be correct. tools such as melina  <cit>  and tmod  <cit>  provide users the opportunity of running and comparing results for several methods within a unified interface, and ensemble methods, like emd  <cit>  and motifvoter  <cit> , can take predictions from multiple methods as input and automatically derive a consensus. still, the reason why motif discovery is so difficult in the first place is that binding motifs are often rather short and can vary substantially between binding sites. this makes them hard to discover with de novo motif discovery methods since the signal-to-noise ratio can be quite low when searching for motifs embedded in long background sequences. however, transcription factors seldom operate alone but work in concert with other transcription factors and co-factors in order to achieve the required regulatory control. hence, groups of motifs for co-operating factors will often occur in close proximity to each other in the dna sequence, and such “composite motifs”, or cis-regulatory modules , can provide a stronger signal than individual motifs. several module discovery methods have therefore been proposed to search for such motif groups  <cit> .

a fundamental limitation with the traditional motif and module discovery approaches is that they only rely on information in the dna sequence itself, but the mere presence of a binding motif does not necessarily imply that it is a functional binding site. other conditions, such as for instance chromatin accessibility, dna-methylation or even the distance to the transcription start site, can also influence the ability of transcription factors to bind and exert their regulatory function. many binding sites may also function in a cell- or tissue-dependent manner, and a site which is active in one cell-type might well be inactive in others.

recent advances in high-throughput experimental methods and large-scale genome annotation efforts, such as the encode project  <cit> , have led to an avalanche of data which is now available to researchers. chip-seq data, for instance, can provide evidence that a specific transcription factor has bound to a region , and information about dnase hypersensitivity and epigenetic marks can indicate which regions of the dna are generally accessible and also give clues as to their regulatory roles in different cell-types.

newer motif/module discovery methods, including for example chromia  <cit> , centipede  <cit> , probtf  <cit> , completemotifs  <cit> , combinatorial crm decoder  <cit>  and i-cistarget  <cit> , try to take advantage of such additional information in order to improve their predictions. some of these tools rely on a fixed set of features which are utilized in a predefined manner. this makes them very convenient and easy to use, but it also means that they are unable to incorporate new data unless their original creators update the underlying databases. other methods are more general and can work with arbitrary data, but require that the users themselves obtain all the relevant data for the sequences they want to analyse and also convert this data into a format the tool can handle. this might not always be a trivial task, and it can sometimes even require that the users are skilled in programming. hence, the threshold for making use of additional data in the analysis can often be high.

in this paper we present a tool called motiflab which is designed to be a general workbench for analysing regulatory sequences and predicting binding sites for individual transcription factors and modules of co-operating factors. the main purpose of motiflab is to provide a flexible framework which allows users to easily incorporate different kinds of additional information into the motif discovery process. as a motif discovery workbench it has drawn inspiration from other related tools, primarily toucan  <cit> , but it also shares similarities with e.g. mochiview  <cit> , seqvista  <cit>  and rsat  <cit> . motiflab is written in java and will run locally as a stand-alone application.

implementation
software description
at its core, motiflab functions as a repository of data objects that can be manipulated and analysed using a number of available operations. the results can be visualized and examined interactively within the system or be output to standard text based formats  for further processing by other programs. motiflab is not backed up by a central dedicated database server, but data can be retrieved automatically from various internet resources, such as the ucsc genome browser  <cit>  or das servers  <cit> , or alternatively be imported from local files. new data objects can also be derived from already existing objects or created manually from scratch.

motiflab distinguishes between several types of data for different purposes. one of the fundamental data types in motiflab is the sequence, which represents a segment of a genome, such as the promoter region associated with a specific gene. users can create new sequence objects by specifying their chromosomal coordinates or by providing motiflab with a list of gene identifiers and selecting a region to analyse around the genes’ transcription start or end sites. the sequence objects merely function as references to genomic locations, and besides the coordinates, genome build and strand orientation of the sequences, they hold little additional information by themselves. however, sequences can be further annotated with feature datasets, which come in three different types: dna sequence datasets, numeric datasets and region datasets. dna sequence datasets contain a single base letter for each position within a sequence. usually, they just hold the original dna sequences for the genomic segments being investigated, but it is fully possible to have multiple dna sequence datasets associated with the same sequences. these additional datasets can then contain masked versions of the original dna sequence or randomly scrambled sequences to be used for statistical comparisons. numeric datasets, on the other hand, have a numeric value for each position in the sequences, and this data type can represent information such as phylogenetic conservation level, dna stacking energy, melting temperature or basically any other signal that can vary in intensity along the sequence. the final feature data type, region datasets, associates each sequence with a set of regions. a region here refers to a subsegment of a sequence which has distinct properties that sets it apart from the rest of the sequence. regions can represent features such as genes, cpg-islands, repeat regions or transcription factor binding sites. different regions within the same sequence may overlap each other, and regions can also be assigned values for various attributes, including a type designation, score value and strand orientation.

motiflab’s graphical user interface offers a sophisticated sequence browser with powerful capabilities for visualizing sequences and associated feature data tracks, as shown in figure  <dig>  all the sequences are displayed simultaneously beneath each other in the same window so that features for different sequences can be compared visually. the browser is highly interactive and customizable, and it supports fast zooming to any scale and panning to show different parts of a sequence. the appearance of each track, including its colour, size and orientation, can be easily modified, and the order of the tracks and sequences can be rearranged or sorted according to different criteria. individual sequences, tracks and even individual regions within region datasets can also be hidden from view to display only what the user wants to focus on at any time.

besides sequences, another fundamental data type is the motif, which is used to model binding motifs for transcription factors. the binding motifs themselves are typically represented as either position weight matrices or iupac consensus sequences, but motif objects can be annotated with a lot of additional information as well, such as the names of different transcription factors that bind to the motif, names of organisms and tissues these factors are expressed in, references to other motifs representing known interaction partners for these factors and references to alternative models for the same motif. new motif objects are automatically added when performing motif discovery, but they can also be created manually by entering a matrix, iupac consensus or a set of aligned binding sequences. motiflab includes several predefined motif models from databases such as transfac  <cit> , jaspar  <cit>  and scertf  <cit> .

it is often useful to be able to refer to subsets of sequences and motifs, for instance to divide a set of sequences into groups according to gene expression or to limit the search for binding motifs to transcription factors that are actually present in the cell-types being investigated. in motiflab this can be accomplished with the help of collection objects. users can create new collections by selecting data objects from a table or by supplying a list of objects to include. collections can also be based on various statistics. for example, it is possible to create a sequence collection containing sequences with less than 40% gc-content or a motif collection with motifs that appear in at least 80% of the sequences. somewhat related to collections are partitions which allow all data objects of a specific type to be divided into non-overlapping clusters. the numeric map data type associates each sequence or motif with an individual numeric value. numeric maps can be used to hold data such as gene expression values for sequences or expected occurrence frequencies for motifs. general text variables, on the other hand, can hold any kind of structured or unstructured text which will be interpreted depending on the context.

operations and protocol scripts
motiflab provides more than  <dig> data-processing operations to create, transform, combine, analyse and output data objects, including special operations to perform motif and module discovery. some of these operations, like “output” and “copy”, can be applied to any object, while others may be specific to a single type of data. the “mask” operation, for instance, can replace parts of a dna sequence with other letters, such as x or n, or it can even replace the whole sequence with random bases sampled from a background distribution to create an entirely new artificial sequence. numeric data objects can be transformed with arithmetic operations or other mathematical functions such as logarithms, range normalizations etc., and sliding windows can be applied to numeric features to smooth the data or to detect peaks, valleys and edges within the track. other operations can change the size of regions by extending them in either direction or merge regions that overlap with each other. one of the simplest operations, but also one of the most useful, is the “filter” operation, since it can be employed to remove selected regions from a dataset, particularly binding sites that are suspected to represent false predictions.

operations that target feature datasets can be limited to selected parts of sequences by specifying conditions that are evaluated for each individual base position or region in the dataset. these conditions can be based on the contents of the target track itself or involve information compared across several tracks. for example, a simple way to perform phylogenetic footprinting without having explicit access to orthologous sequences would be to first predict a set of binding sites in the normal way and then filter out those predictions where the average value of a conservation track within the binding sites is less than some threshold. likewise, the process of “repeat masking”, which is often performed prior to motif discovery, can easily be accomplished by limiting the “mask” operation to bases that lie within regions in a track containing known repeats. conditions offer an easy way of integrating information from several features, and they can be made arbitrary complex by combining multiple individual conditions with boolean operators.

analysis of regulatory sequences usually involves multiple steps and requires several operations to obtain and pre-process data, discover motifs and binding sites and post-process and analyse the results. to keep track of what is being done, motiflab provides functionality that allows users to automatically record every step they perform in a protocol. the protocol is written in a structured format and includes information about which operations have been executed, as well as details about their parameters, conditions and constraints. the protocol can thus serve as a form of documentation of the analysis process, but more importantly, it also makes motiflab able to automatically apply the same workflow to other datasets as well, or to restore a previous session. protocols can alternatively be written and edited manually, either in external text editor programs or in motiflab’s own internal protocol editor. by supplying a protocol script describing the full analysis workflow, it is possible to run motiflab in “batch mode” from a command line without starting up the graphical user interface. this also allows motiflab to be incorporated as a component in larger analysis pipelines.

motiflab’s graphical user interface promotes interactive data exploration, and multi-level undo/redo-functionality provides users the opportunity to experiment with various operations and try out different parameter settings for these without having to worry about making irreversible changes to the data. unlike some other workbench systems, motiflab does not maintain an explicit history record which keeps track of all changes made to data and provides access to earlier states. however, when data is updated through the use of operations, the results can always be stored in a new data object under a different name rather than replacing the original object. this way, the original data can be kept intact and used for other purposes as well. it is also possible to save the entire state of motiflab to a single “session file” to continue working on an analysis at a later time.

motif discovery
discovering motifs and searching for transcription factor binding sites within sequences are some of the primary functions of motiflab. however, motiflab is not actually capable of performing motif discovery by itself but relies on external programs installed on the user’s computer to accomplish such tasks. this makes motiflab flexible with respect to local software preferences or novel tools. in order for motiflab to communicate with external programs, they must conform to standard data formats for input and output and their interfaces must be described in xml-based configuration files. motiflab already supports several popular motif discovery tools, including alignace  <cit> , bioprospector  <cit> , mdscan  <cit> , meme  <cit> , motifsampler  <cit>  and weeder  <cit> , and more tools will continuously be added . many of the supported programs have also been gathered in a central repository so they can be downloaded and installed from within motiflab.

motiflab has separate operations for performing motif scanning, where external programs are provided with a collection of predefined motifs and should return a region dataset containing predicted binding sites for these motifs, and de novo motif discovery, where the programs should discover both the binding sites and the motifs themselves. in addition, a third operation offers support for ensemble methods which can take predictions from other methods as input and combine these into potentially more reliable predictions.

tracks with predicted binding sites are called motif tracks, and they have a special status in motiflab because of the connection between the binding site regions and the motif objects associated with these sites. this enables the sequence browser to visualize binding sites with motif logos superimposed on the regions , and clicking on a binding site will bring up additional information about the motif.

using positional priors to guide motif discovery
motif discovery is a challenging problem since it involves searching for short and often degenerate patterns embedded in potentially long sequences. however, some parts of the sequences are more likely to contain functional binding sites than others, such as regions where the chromatin has an open conformation or sites that have been conserved throughout evolution. some motif discovery programs allow users to limit the search space by masking out parts of sequences and thereby excluding them completely from further consideration. however, this approach might be considered too strict, since the excluded regions could, in fact, contain functional binding sites that will inevitably be destroyed by the masking procedure. a more flexible alternative is to construct a positional priors track wherein each sequence position is assigned a score or probability value reflecting a prior belief that the position could be part of a binding site. such a track can be used to guide motif discovery programs by biasing the search towards regions with higher probability of containing true sites. many types of information can be represented using positional priors, for instance phylogenetic conservation  <cit> , nucleosome occupancy  <cit> , properties of the dna-helix  <cit>  and epigenetic marks  <cit> , and information from many different sources can be combined into a single priors track  <cit> . positional priors are currently only supported directly by a few motif discovery and scanning programs, including priority  <cit> , meme  <cit> , fimo  <cit> , chipmunk  <cit>  and grisotto  <cit> , but they can also be used indirectly in combination with other programs, for instance by employing positional priors to filter out likely false predictions in a post-processing step.

although tracks related to e.g. conservation, dnase hypersensitivity and chip-seq experiments do not actually contain probability values in a strict statistical sense, such tracks can often be used directly as positional priors  since higher values in these tracks correlate well with occurrences of functional binding sites. for other types of features the relationship might not be so direct, and more advanced processing will be required to generate positional priors based on such features. motiflab is an extension of an earlier program called priorseditor  <cit> , which was developed specifically for creating and using positional priors tracks for motif discovery. many of the operations provided by motiflab are therefore related to transforming and combining features to facilitate manual construction of positional priors tracks, for instance to make weighted combinations of several tracks. creating positional priors tracks manually can be beneficial if you want to utilize specific biological knowledge or want to set up a track with clearly defined focus. for example, if you have a set of known binding sites for a single transcription factor and want to look for potential interaction partners for this factor, you can create a track which focuses the search to the vicinity of these sites, possibly adjusting the track further, for instance by assigning increased weight to conserved regions.

compared to priorseditor, motiflab offers several new functions to work with positional priors, including an operation to convert a regular priors track into a discriminative prior  and analyses to evaluate the potential merit of priors tracks. the most important new addition, however, is the introduction of “priors generators” that can be used to generate positional priors automatically based on information from various features. a priors generator is basically just a machine learning classifier that can be trained to predict whether or not a position in a sequence would be expected to lie within a transcription factor binding site depending on the values of relevant features at that position. motiflab provides a simple “wizard” to guide users through the steps required to configure a new priors generator, such as selecting the target and input features, setting up a training dataset and finally training the classifier and saving the result. once a priors generator has been created, it can be used to generate positional priors for any sequence as long as the required input features are available. although priors generators were introduced primarily for the prediction of transcription factor binding sites, they can just as well be trained to predict other region-based features in the same manner, provided that a reasonable correlation between the target feature and the input features can be expected.

module discovery
co-occurrence of motifs in modules represents a higher level of cis-regulatory organization that can be exploited to improve motif prediction, as binding sites for interacting factors which appear in close proximity to each other are less likely to represent spurious motif occurrences. motiflab allows motifs to be annotated with information about known interaction partners, and one way to utilize this information is simply to filter out predicted binding sites that do not have sites for potential partners within some given distance.

regulatory modules can also be modelled explicitly in motiflab with their own data type analogous to single motifs. a module is made up of multiple constituent motifs along with optional constraints on their order, their orientations relative to each other and the distances between them. because public motif databases often contain several alternative motif models for the same transcription factors, motiflab permits each constituent motif in a module to be represented by collections of motifs in order to achieve greater sensitivity when performing module scanning.

as for single motif discovery, motiflab provides separate operations to scan sequences for matches to predefined modules and to search sets of sequences to identify groups of motifs that might represent novel modules. again, both of these operations rely on external module discovery programs to do the actual work.

statistical analyses
the analyze operation is a versatile operation that can be employed to perform a number of different statistical analyses ranging from simple data comparisons to more elaborate analyses like motif overrepresentation studies. it will often be used to produce the final reports for an analysis session, but it is also useful for providing rapid answers to simple questions that might arise when working with datasets, such as “what is the gc-content of these dna sequences”, “do these two collections share a significant overlap”, “is property x correlated with property y” or “is the value of this numeric track higher within some regions than outside”.

the results from the analyses can be output either as html-documents, with nicely formatted tables and images, or in a “raw text” format suitable for parsing by other programs. individual results can also be extracted from analysis objects and turned into other types of objects for use elsewhere. for example, if you have performed an analysis to determine the number of times each motif occurs in a sequence set , you can extract these counts as a numeric map, or you can make a motif collection containing the motifs that were significantly overrepresented in the sequences and use this in another analysis.

some analyses, like the previously mentioned “count motif occurrences”, will generate individual results for each motif, module or sequence, and these results are presented in interactive tables that are linked to the corresponding data items. this makes it possible to e.g. highlight entries in the tables that are members of different collection objects, or to highlight corresponding elements in the sequence browser based on selections made in the tables. for example, when examining the results from a motif overrepresentation analysis, users can select the top most significant motifs from the table and then choose “show only these motifs” from a context menu to visualize only the binding sites for these motifs in the sequence browser. the tables are therefore not merely static presentations of the results, but can be used as a starting point for further exploration of the data. if the tables contain motifs, the motif logos will always be included in a separate column. this is very useful, since rather than just listing numerous motif identifiers or names of transcription factors the user may or may not be familiar with, the logos enable users to immediately identify properties of the corresponding motifs and see similarities between them.

results from multiple analyses can be collated into “meta-analyses” by extracting selected columns from individual analyses and combining them into larger tables. information from different types of analyses can be combined in this way to produce more comprehensive reports, or results from the same analysis run multiple times with different parameter settings can be juxtaposed to assess the impact of varying these parameters.

interactive tools
in addition to the data manipulation and analysis capabilities provided by operations, motiflab also includes a few tools aimed at interactive exploration of data. unlike operations, these tools cannot be controlled by protocol scripts, and they are only available through the graphical user interface. many of the tools are intended to aid visual inspection of motif tracks, for instance by highlighting binding sites with selected properties in the sequence browser.

the motif browser and module browser are two convenient tools for managing your motif and module libraries. these browsers will show an overview of all motifs or modules currently known to the system. the entries are displayed in a table with three columns containing the name of the motif/module, a graphical logo representation, and a third property that can be chosen by the user . a filter box enables users to search for entries with specific properties, for instance motifs associated with a given transcription factor, motifs for factors expressed in specific organisms or tissues, motifs containing a given consensus sequence, or modules containing a specific constituent motif. the search filter can also be coupled to the sequence browser so that only binding sites for motifs or modules matching the selected filtering criteria will be shown in the tracks.

the motif score filter tool is basically just a slider bar which is used to dynamically adjust a cut-off threshold. any binding site region whose score-property falls below the selected threshold will be hidden from view in the sequence browser. this tool can thus be used to highlight sites with increasingly higher scores. besides the standard score-property, other values associated with binding sites can be used for filtering as well, for instance the average score of a numeric data track within the binding site.

as previously mentioned, motiflab allows motifs to be annotated with known interaction partners, and this information can be utilized by the interactions viewer to visualize potential interaction networks directly within motif tracks. when a user clicks on a binding site region, any binding sites within a chosen distance that are associated with known interaction partners of the target motif will be highlighted . the network can also be expanded to show several levels of interactions in different colours. this tool is especially useful if you already have a verified binding site that can be used as a starting point to implicate additional predictions that might be likely to represent functional binding sites.

finally, the positional distribution viewer will draw a histogram based on the locations of all currently visible regions in a selected track across all sequences . the histogram will be dynamically updated in response to events that change the visibility of regions, making it very useful in conjunction with other tools such as the motif browser or motif score filter.

RESULTS
this section presents three examples of practical applications using motiflab, which also illustrate some benefits of incorporating additional information when analysing regulatory sequences. complete protocol scripts for these examples are available from the motiflab web site.

example 1: improving motif discovery with automatically generated positional priors
we have previously published a suite of benchmark datasets for single motif discovery  where we made sure that it would be at least theoretically possible to discriminate the target motifs from the background sequence. nevertheless, when we tested the performance of the motif discovery program meme on these benchmark sets, the results were not particularly encouraging  <cit> . in this example we use an updated version of the datasets  to demonstrate how information about various sequence-related features can be integrated into a positional priors track and used to guide meme towards the target motifs. the features chosen as a basis for the priors track were: conservation, conserved peaks, dnase hypersensitive sites, general regions bound by transcription factors according to chip-seq data, cpg-islands, gene regions, coding regions, repeat regions and regions with histone marks h3k4me <dig> and h3k4me <dig>  since not all organisms are annotated with these features at the present time, we restricted the benchmark datasets to only consist of sequences from human and mouse genomes. the updated benchmark suite comprised  <dig> datasets, each containing binding motifs for a particular transcription factor and consisting of at least five sequences. we used a cross-validation approach where a priors generator based on a neural network classifier was trained on  <dig> of the  <dig> datasets and then used to generate a positional priors track for the dataset that was held out. the priors tracks were provided as input to meme along with the dna sequences, and meme was instructed to identify a single motif with size between  <dig> and  <dig> bp in each dataset. for comparison we also ran meme with a uniform priors track  and a priors track based solely on conservation.

the results, combined over all datasets, are shown in figure  <dig>  detailed results for individual datasets are provided in additional file  <dig>  as can be seen from the bar chart, the performance of meme when not relying on any additional information was rather low, with an average cc score of  <dig> . however, the performance increased about 3- to 4-fold for most metrics when the automatically generated positional priors were used to guide the search. many of the target binding sites in the benchmark were located in conserved regions, and conservation was the most informative single feature with respect to binding site prediction. conservation also contributed most to the specificity of the combined priors, while the other features primarily helped to elevate the basal prior probability slightly within some broader parts of the sequences. figure  <dig> illustrates the ability of the individual features to discriminate between binding sites and the background sequence.

even when positional priors were used, the results were far from perfect. there are several reasons for this: 1) for about half of the datasets meme failed to predict the correct target motif as its top candidate, 2) in some datasets where meme did identify the correct motif, alternative binding sites for the motif were selected instead of the annotated targets in a few sequences, and 3) even if meme predicted the basic motif and binding sites correctly it did not always predict the correct size of the motif, which could have significant impact on the nucleotide-level statistics. a closer look at the predicted sites and motifs revealed that meme found the target motif  in  <dig> out of the  <dig> datasets with the uniform priors. this number increased to  <dig> when conservation was used to guide the search, and with the auto-generated priors meme found the target motif in about  <dig> to  <dig> datasets .

example 2: module discovery
in a second benchmark study we evaluated the performance of eight published module discovery methods on a novel benchmark suite  <cit> . the suite consisted of  <dig> datasets with pairs of motifs appearing together in multiple sequences and two additional datasets with larger heterogeneous modules involved in regulation in liver and muscle tissue respectively. most of the methods we tested relied on a first step to scan sequences with a provided motif collection to find a set of candidate binding sites, and then they proceeded to search through these candidates in order to identify potential modules. the results showed, not surprisingly, that the task of identifying the target modules became harder as more candidate motifs were considered. in this example we demonstrate how the performance of a module discovery tool can be improved by utilizing additional information to reduce the number of candidate sites in a pre-processing step.

to generate the candidate datasets we first scanned the benchmark sequences with  <dig> motifs from transfac pro using a rather sensitive threshold  to ensure that all the target binding sites were recovered. then we filtered the predicted sites according to various criteria to produce different candidate sets. as filtering criteria we used increasing levels of average conservation within the sites  or required that each site should be located nearby a site for a known interaction partner . for the “liver” and “muscle” datasets we also filtered sites for transcription factors that were not known to be expressed in the respective tissues. in addition we tried several combinations of these criteria. the remaining binding site predictions for each dataset were provided as input to the module discovery tool modulesearcher  <cit> .

results for two of the datasets are shown in figure  <dig>  and the remaining results are included in additional file  <dig>  for all  <dig> datasets there was some form of additional information that would lead to better performance when used to filter candidate sites. however, in some cases, there were filtering criteria that would actually result in lower performance. this was especially true for the datasets “cebp-nfkb” and “irf-nfkb” . these two datasets were the easiest in the original benchmark, and modulesearcher did a good job of discovering the target modules even without filtering the candidate sites. however, since only about half of the binding sites comprising these modules were conserved, using a strict conservation criterion made it impossible to correctly discover the target modules.

as an additional control we also tried to filter the candidate datasets completely at random to verify that any increase in performance was not simply due to a general reduction in the number of candidate sites. filtering sites at random would in fact lead to better results in many cases, most notably for datasets where the baseline performance was poor. this is perhaps not so surprising, since the vast majority of the candidate sites would be considered to be false positives anyway according to the benchmark datasets. however, the increase in performance was usually not as great as when more sensible filtering criteria were employed.

example 3: identifying tfs regulating genes after forskolin treatment
forskolin is a diterpene which is known to raise the level of camp  within cells  <cit> , and this will in turn trigger many different responses, including activation of various transcription factors. hek <dig> cells were treated with forskolin and the effect on gene expression was measured at different time points using microarray technology. genes that were significantly differentially expressed compared to untreated cells were identified and sorted according to their peak time point. of the  <dig> genes in total whose transcript levels were changed by the forskolin treatment,  <dig> had a peak differential expression after  <dig> hours . we obtained promoter sequences for these  <dig> genes spanning  <dig> bp upstream to  <dig> bp downstream of the transcription start site and performed motif scanning with  <dig> vertebrate motifs from transfac pro.

the standard procedure for identifying transcription factors that might be involved in regulating a set of genes is to identify motifs that are significantly overrepresented in the dataset relative to a realistic background frequency. to estimate an expected frequency of each motif, we used a 3rd-order background model based on human promoter sequences to create a set of artificial control sequences and performed motif scanning in those sequences using the same parameter settings as before. we then derived the frequencies of the motifs from these control sequences and stored the results in a numeric map. finally, we counted the number of times each motif occurred in the target dataset and used the expected motif frequencies to calculate p-values for overrepresentation with a binomial test.  <dig> motifs were found to be overrepresented at a significance threshold of  <dig>  . many of the motifs with lowest p-values were gc-rich, which might stem from the fact that the sequences in the target dataset had a slightly higher gc-content than the control sequences used for comparison. the transcription factor creb, which is a well-known camp-responsive factor but does not have a particularly gc-rich motif, was only ranked as number  <dig> according to p-value.

an alternative to overrepresentation is to look for motifs whose sites share similar properties across several sequences, for instance motifs that tend to appear at the same distance from the transcription start site, or motifs that are consistently conserved in many sequences. we therefore ran two additional analyses where we first calculated the average conservation level for each motif across all its binding sites and then analysed the positional distribution of the sites, using kurtosis as a simple measure of clustering.

not surprisingly, the motifs that scored highest on average conservation were those that only occurred once or twice and their binding sites just happened to lie within conserved regions. these motifs are not interesting for the dataset as a whole, however, since they are at best involved in regulating only a few genes. the most interesting motifs would be those that score high on conservation and kurtosis but still occur often enough to have a significant overrepresentation p-value, so we combined these three properties into a single measure using rank sum.

according to this combined measure, creb  was ranked on top, followed by the ubiquitous factor sp <dig> which binds to the gc-box. another significant transcription factor found was nf-y which binds to the ccaat-box. this motif scored particularly high on kurtosis, and it is known that functional binding sites for nf-y tend to be located between  <dig> to  <dig> bp upstream of the tss  <cit> . nf-y is also known to cooperate with sp <dig> to regulate some genes in response to camp  <cit> . the two factors nrf- <dig> and nrf- <dig>  bind to different motifs, but both are ranked high and both have previously been implicated together with creb in responses to raised levels of camp  <cit> . interestingly, many of the sites for these two factors coincided with narrow peaks in the conservation track whose size matched exactly the width of the motifs. the fact that these sites were conserved while the flanking sequence around the sites was not is a strong indication that the sites might be functional.

discussion
the examples given above, as well as previous publications by other groups, have shown that making use of additional information might boost the performance of motif and module discovery methods and help steer them towards regulatory elements that are more likely to be functional in a given context. however, relying on the “wrong” data, or even using data in the wrong context, can sometimes also have adverse effects. for example, filtering predicted sites based on phylogenetic conservation can lead to a higher proportion of true sites among the remaining predictions, but this will inevitably also remove any functional sites that are species-specific, and therefore not conserved. even “gold standard” data, like dnase hypersensitive sites, should be used with some caution, especially when applied across different cell-types and conditions. to help users decide on which types of data might be useful to consider, motiflab includes several analyses to evaluate the merit of different types of information and to benchmark the performance of motif and module discovery methods. in fact, all the performance evaluations in the previous examples were performed within motiflab, and the bar chart figures and roc-curves included in this paper were produced directly from the analyses using the “output” operation.

although many recent motif discovery tools can make use of additional data, they are often limited in what kind of data they can use and what they do with it, typically using information about known repeats to mask sequences or conservation to filter predicted binding sites. motiflab allows users to incorporate many different types of data and use it in any way they like. no kind of information is treated as special compared to others by motiflab, and information is represented with a few general data types. this means that it should be easy to also incorporate new kinds of data that might be available in the future.

the ability of motiflab to process data in arbitrary ways using operations also sets this tool apart from most other motif discovery workbenches. the program has been designed so that users with some background in the field of regulatory sequence analysis should be able to rapidly learn how to perform standard tasks such as obtaining promoter sequences, annotating them with feature data and performing motif discovery or scanning. but it should also be relatively easy to perform more sophisticated pre- and post-processing tasks which would otherwise often require writing custom scripts. for the use case examples described in this paper, all the data processing steps involved in the analyses were performed within motiflab itself.

motiflab keeps all data objects in memory at all times rather than relying on external storage solutions. in addition, all operations are performed locally so most processing tasks will execute relatively fast. visualization in the sequence browser is also very fast and responsive since the system does not have to wait for individual data segments to load from a server. this means that the tool has not been designed primarily to handle extremely large datasets , although it is possible to apply it for genome-wide binding site predictions if sufficient memory is available. however, motiflab is ideal for in-depth analysis of small to moderate datasets ranging from a single sequence to a few hundred  sequences, such as promoter sequences from groups of co-expressed genes. it is also very well suited for interactive, visual exploration of datasets and for rapid hypothesis testing.

CONCLUSIONS
although vast amounts of genomic annotation data are now available to researchers who study transcriptional regulation, it is not necessarily trivial to make good use of this data for people who are not skilled in bioinformatics programming. the motiflab workbench presented in this paper was designed to make it simple for users to obtain relevant data for sequences they want to study and to use this information in combination with existing motif discovery tools in many different ways. the utility and versatility of motiflab was demonstrated through three practical analysis cases.

availability and requirements
project name: motiflab

project home page:http://www.motiflab.org

operating system: motiflab itself is os-independent, but some external tools used by motiflab for motif discovery etc. might only be available for some operating systems.

programming language: java  <dig> 

other requirements: none

license: none

any restrictions to use by non-academics: none

abbreviations
acc: accuracy; asp: average site performance; auc: area under the curve; bp: base pair; cc: matthews correlation coefficient; f: f-measure; fp: false positive; pc: performance coefficient; ppv: positive predictive value; roc: receiver operating characteristic; sn: sensitivity ; ssn: sensitivity ; sp: specificity; tf: transcription factor; tp: true positive; tss: transcription start site.

competing interests
the authors declare that they have no competing interests.

author’s contributions
kk designed and implemented the motiflab software and drafted the manuscript. fd supervised the project. both authors participated in the design and analysis of the examples presented in the paper, and both authors revised and approved the final manuscript.

supplementary material
additional file 1
supplementary methods and additional results. this supplementary file contains detailed descriptions of the procedure to generate and analyse the datasets used in examples  <dig> and  <dig>  as well as results for individual datasets from those examples.

click here for file

 acknowledgements
kjetil klepper and finn drabløs were supported by the national programme for research in functional genomics in norway  and the norwegian infrastructure for bioinformatics elixir.no, both in the research council of norway. the forskolin response data were provided by kristine misund, liv thommesen and astrid lægreid.
