BACKGROUND
metagenomics is a new field of research on natural microbial communities strongly enhanced by the new high-throughput sequencing  technologies like roche's 454-sequencing, abi's solid or illumina's genome analyzer. in traditional genomics, the sequencing of new microbial genomes was limited to those microbes that can be cultivated in a monoculture, which constitute less than  <dig> percent of all microbes. to explore the other  <dig> percent, metagenomics makes it possible to retrieve information about the functional and taxonomic composition of the community they originate from  <cit> .

with decreasing sequencing costs, shotgun metagenomics, i.e. sequencing of random genomic dna fragments from natural microbial communities, has become feasible  <cit> . comparing such metagenomic sequences with sequences of known function makes it possible to analyse the biological diversity and the underlying metabolic pathways in microbial communities.

to infer the taxonomic origin of metagenomic reads, two kinds of methods, composition-based and comparison-based, can be distinguished. the composition-based methods extract sequence features, like gc content or k-mer frequencies, and compare them with features of reference sequences with known taxonomic classifications  <cit> . in detail, different techniques, like the calculation of correlation coefficients between oligonucleotide patterns  <cit> , self-organizing maps   <cit> , or support vector machines   <cit>  can be used to classify the metagenomic fragments. the comparison-based methods rely on homology information obtained by database searches, e.g. using search tools like blast <cit> . an additional challenge is the fact that the new sequencing techniques produce short  and ultra-short  reads. new bioinformatic tools have to be developed that can cope with both, the huge amount of data and the short read lengths. especially the short read lengths have been considered the main bottleneck for the usage of ultra-short reads in metagenomics  <cit> .

in  <dig>  we developed carma  <cit> , a new software pipeline for the characterisation of species composition and the genetic potential of microbial samples using short reads. in contrast to the traditional 16s-rrna approach for taxonomical classification  <cit> , carma uses reads that encode for known proteins. by assigning the taxonomic origins to each read, a profile is constructed which characterises the taxonomic composition of the corresponding community. krause et al.  <cit>  showed on a synthetic metagenome that even with reads as short as around  <dig> bp, high accuracy predictions with an average false positive rate of  <dig>  to  <dig>  percent are possible. the carma pipeline has already been successfully applied to 454-sequenced communities including the characterisation of a plasmid sample isolated from a wastewater treatment plant and other communities  <cit> .

here we introduce webcarma, a refined version of carma available as a web application for the taxonomic and functional classification of unassembled short reads from metagenomic communities. the web application is freely available at http://webcarma.cebitec.uni-bielefeld.de. furthermore, we examined the applicability of carma for simulated ultra-short reads  by comparing the results with earlier ones obtained by short reads  using samples from a biogas plant  <cit> .

implementation
webcarma is based on a new carma version  <dig>  with some improvements over the last published version  <dig>   <cit> . we first review the basic concepts behind carma, before we present our new webcarma.

carma
next-generation sequencing technologies in metagenomics produce millions of dna reads, from which carma detects those that encode for known proteins. these reads are called environmental gene tags   <cit> . in a second step they are assigned to taxa from six taxonomical ranks: superkingdom, phylum, class, order, genus and species. the set of classified egts provides a taxonomical profile for the microbial community.

in detail, blastx  <cit>  is used to search within the set of reads for candidate egts that encode for protein sequences contained in the pfam database  <cit> . a rather relaxed e-value of  <dig> and frameshift option -w  <dig> are used. each read that has a match to a protein family member is translated according to blastx reading frame and frameshift predictions. the final determination of egts is done by matching the candidate egts against their matching protein families with the corresponding pfam hidden markov models  <cit> . for this purpose mmpfam from the hmmer package  <cit>  is used. only candidate egts with an hmmpfam e-value match of  <dig>  or lower are accepted as egts.

after the egts are identified, they are taxonomically classified. therefore, each egt is aligned against the multiple alignment of its family with hmmalign . from this new alignment, the pairwise sequence distance is computed for all pairs of sequences, based on the fraction of identical amino acids. this produces a pairwise distance matrix which then is used to compute a phylogenetic tree with the neighbour-joining clustering method  <cit> . the egt is then classified depending on its position within this tree. if the egt is localised within a subtree of family members all sharing the same taxon, then the egt is classified with the same taxon. for example, if the egt is localised in a subtree with the three members bacteria cyanobacteria synechococcales prochlorococcus, bacteria cyanobacteria chroococcales synechococcus and bacteria cyanobacteria nostocales nostoc, the egt is classified as bacteria cyanobacteria. for a more formal definition and further details see  <cit> .

webcarma
we have reimplemented large parts of carma, including a faster construction of the phylogenetic trees by caching the pairwise distances between pfam family members. the carma results now include for each egt the corresponding hmmpfam e-values and a list of go-ids   <cit>  associated with the corresponding pfam family. the gene ontology provides a controlled vocabulary for gene products, distinguishing between their associated biological processes, cellular components and molecular functions, and can therefore be used to create a functional profile of the metagenome. a major modification of carma is the usage of the ncbi taxonomy database  <cit>  instead of the pfam nomenclature. the ncbi taxonomy database currently indexes over  <dig>  species  <cit> , which are classified in a hierarchical tree structure. each taxon from the taxonomy is represented as a node in the tree with a unique identifier  and its taxonomic rank ranging from superkingdom to subspecies. for compatibility with other applications and databases, the output files of carma contain, along with the prettyprint taxa classifications, the corresponding tax_id.

the webcarma website is built upon an apache web server using perl and cgi. the carma pipeline is executed on the compute cluster of the bielefeld university bioinformatics resource facility at the center for biotechnology  using sun grid engine http://gridengine.sunsource.net/. in order to use webcarma and to upload metagenomic sequences, the users have to register with their e-mail address. after the uploads are finished, carma starts with the search for egts and the taxonomical classification. by the time the jobs are completed, the user receives an e-mail with a download address pointing to the results.

we provide several pre-computed data formats that allow the user to explore the results in different ways:

• the translated egts, with additional information about the name of the original metagenomic sequence, reading frame, pfam id, hmmer e-value and a list of go-ids associated with that corresponding pfam id.

• a go-term profile in two variants, as a text data file and visualised as a histogram in pdf format.

• the taxonomical classification results as a text data file.

• a taxonomic profile, once as a text data file and once visualised by histograms for each taxonomic rank in pdf format.

the profile data files as well as the classification results are provided in tsv-format , which makes it easy to import the data into other programs  for different visualisation types or any other further processing.

we provide perl scripts for download that can easily be used as templates for own data processing pipelines. a manual with further explanations can be found on the webcarma site.

RESULTS
the webcarma web application
a local installation of carma  <cit>  requires the pfam mysql database and several bioinformatics tools, like blastx, the hmmer package, the phylip package  <cit>  and several perl packages. most strikingly, it has high computational demands which make the usage of a high-performance grid inevitable. therefore, we introduce webcarma, our new platform-independent web application which makes carma easily accessible to the scientific community .

webcarma produces functional  and taxonomic profiles  of metagenomic sequences, available in text format and as histograms.

an example of a functional profile of a complete metagenomic  <dig> data set  produced with webcarma is depicted in figure  <dig>  examples of comparative taxonomic profiles are discussed in the use case study.

to classify a metagenomic data set as used in the use case study below  takes about  <dig>  <dig> cpu hours  on our compute cluster. because the neighbour-joining algorithm has quadratic runtime, cluster jobs which process bigger pfam families will take much more time to compute than other. therefore, using  <dig> cpus, it takes for this data set about  <dig> hours until the last job has finished.

comparison of full-length  <dig> and simulated ultra-short reads
in order to evaluate the applicability of short and ultra-short reads in metagenomics, we used a real-world data set and several realistic simulated data sets. the real-world data set consisted of  <dig>  <dig> reads with an average read length of  <dig> bp of a microbial community from an agricultural biogas reactor  <cit> , sequenced with the  <dig> genome sequencer flx system . instead of using real ultra-short reads, we decided to simulate ultra-short reads by clipping off suffixes of the 454-reads to get the desired read lengths. we generated nine data sets, each consisting of reads of one of the lengths  <dig> bp,  <dig> bp,  <dig> bp,  <dig> bp,  <dig> bp,  <dig> bp,  <dig> bp,  <dig> bp, and  <dig> bp, respectively.

it is known that some sequencing techniques exhibit correlations between read coverage and gc content  <cit> . by using simulated reads instead of real ultra-short reads we can be sure that any differences we see in the classification results between the data sets are only due to the different read lengths. if there is a bias in the  <dig> data, then we also have the same bias in the simulated data sets and our comparison should not be much affected by this.

first, we analyse the number and lengths of the egts obtained for each data set, then we compare the taxonomic classification results for the different read lengths.

as shown in table  <dig>  the number of reads in each data set decreases with increasing read length. this is because the  <dig> data set contains reads of different lengths and some of the reads are already too short to serve as a template for all simulated data sets. the relative amount of egts that is found in each data set increases with increasing read length.

number of reads and egt yield for each data set. some metagenomic reads have matches to more than one pfam family and therefore are translated into more than one egt. the column "unique" denotes the total number of egts where egts from the same read are counted only once. the column "yield" denotes the fraction of  egts that could be obtained from the corresponding data set.

in rare cases, it happens that an egt is one amino acid longer than its read length divided by three. for example, in the set of egts produced from the  <dig> bp-reads data set, the longest egts are  <dig> amino acids long. this can occur when blastx predicts two frameshifts in one read.

for our analysis of the applicability of ultra-short reads with carma, we considered seven different taxonomic ranks: superkingdom, phylum, class, order, family, genus and species. a first relative abundance for each taxon is obtained by dividing the absolute number of egts that predict this taxon by the total number of egts at the same taxonomic rank. the latter do not include egts which predict nothing . we consider taxa with a relative abundance below the threshold  <dig>  in all data sets, to be false positives. therefore they are classified as "other".

after applying the threshold we recompute the relative abundances for each taxon, this time subtracting both, "unknown" and "other" from the total number of egts at the same taxonomic rank.

with this, we have normalised the relative abundances for the taxa such that they sum up to  <dig> and therefore ensured comparability between the data sets.

for scaling reasons, the fractions of "unknown" and "other" egts are not shown in the histograms . this data is given in tables  <dig> and  <dig> 

"other" are egt's with a relative abundance below the threshold  <dig>  and are not shown in the histograms. here we show the rates of "other" egts relative to the total number of classified egts for each taxonomic rank and data set.

even though the taxonomic predictions on lower taxonomic ranks  are known to be imprecise, we included them in our experiment in order to study the effect of using short reads compared to longer ones at all taxonomic ranks.

figures  <dig>   <dig> and  <dig> show the results for superkingdom, order and species. the complete set of figures for the evaluation at all taxonomic ranks can be found in additional files  <dig>   <dig>   <dig>   <dig>   <dig>   <dig> and  <dig> 

the results show that carma predicts for all data sets and all taxonomic ranks the same taxa. for higher taxonomic ranks, even the relative abundance levels are similar between the different data sets. deviations of  <dig> bp-reads for example can be seen on the level of order, where significantly more of thermotogales and haemosporida, and less of thermoanaerobacterales are predicted. the  <dig> bp data set does not show these differences. even more deviations can be found on lower taxonomic ranks, for example species.

furthermore, as expected, the rate of egts which are not classified increases for lower taxonomic ranks for all data sets . interestingly, the rate of unclassified egts is smaller for shorter reads than for longer reads. this might be due to the circumstance that shorter egts need to have more sequence similarity to the pfam families than longer egts, in order to achieve the same e-value threshold.

CONCLUSIONS
carma is a software pipeline for the characterisation of species composition and the genetic potential of microbial samples using short reads that encode for known proteins. the species composition can be described by classifying the reads into taxonomic groups of organisms they most likely stem from. carma has been successfully evaluated on a synthetic metagenome  <cit>  and has already been used for the analysis of several microbial communities  <cit> .

here we have presented our new web application webcarma, which makes metagenomic analyses with carma easily accessible. webcarma provides functional and taxonomic classifications in common data formats as well as basic visualisations of the profiles.

previous metagenomic analysis relied on reads of length  <dig> bp or longer. we have shown that ultra-short reads as short as  <dig> bp can be used for the taxonomic classification of a metagenome. the biogas data set we have used in the analysis is a low complexity data set with only a few prevalent species. therefore, our results do not necessarily apply to data sets of higher complexity. still, we think we have shown that ultra-short reads can indeed, in principle, be used for reliable taxonomic classification of a microbial community if the coverage is high enough. we have found most differences between the different data sets in the taxa of higher order, e.g. at the species level, and in general for species with very low abundance.

metagenomics with carma still leaves some room for improvements. proper statistics to assess the significance of functional and taxonomic predictions based on short reads  are still missing. the abundance levels of the classification results have to be read with care. species with larger genomes or more genes than other species will be overrepresented in the taxonomic profiles because more egts can be found. therefore, more accurate results might be achieved by weighting egts using additional information like the genome size of the closest known relative.

availability and requirements
• project name: webcarma

• project home page: http://webcarma.cebitec.uni-bielefeld.de

• operating system: platform independent ; unix/linux 

• programming language: perl

• other requirements: none

• license: gnu gpl

• any restrictions to use by non-academics: none

• upload restriction: maximum  <dig> mb of fasta per month

authors' contributions
the new version of carma was implemented by wg. sj and ft contributed to the webcarma web application. ag and js supervised the development of the initial system design and gave important suggestions to the manuscript. all authors have read and approved the manuscript.

additional files
this is the complete set of figures for the evaluation from the use case study. only those taxa are visualized, where in at least one of both data sets the predicted relative frequency was  <dig>  or higher. taxa that are not visualised contribute to "other".

supplementary material
additional file 1
taxonomic results on the level of superkingdom. only taxa with an abundance of  <dig>  or higher are shown.

click here for file

 additional file 2
taxonomic results on the level of phylum. only taxa with an abundance of  <dig>  or higher are shown.

click here for file

 additional file 3
taxonomic results on the level of class. only taxa with an abundance of  <dig>  or higher are shown.

click here for file

 additional file 4
taxonomic results on the level of order. only taxa with an abundance of  <dig>  or higher are shown.

click here for file

 additional file 5
taxonomic results on the level of family. only taxa with an abundance of  <dig>  or higher are shown.

click here for file

 additional file 6
taxonomic results on the level of genus. only taxa with an abundance of  <dig>  or higher are shown.

click here for file

 additional file 7
taxonomic results on the level of species. only taxa with an abundance of  <dig>  or higher are shown.

click here for file

 acknowledgements
wg was supported by the dfg graduiertenkolleg  <dig> bioinformatik, sj by the bmbf pathogeno-mik plus network project 0313801n and ft by the bmbf era-net pathogenomics project 0313939a.
