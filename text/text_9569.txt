BACKGROUND
this study explores attentional modulation within the 'what'-stream of the auditory modality during phoneme processing. knowledge of speech sound representation in the auditory domain is still sparse. however, parallels to the extensively studied visual modality and also to the somatosensory domain are becoming evident. for example, columnar mapping of several stimulus properties  has been revealed in human and animal research: acoustic parameters like spectral bandwidth, periodicity, stimulus intensity  <cit>  or – for human speech sounds – distance between spectral peaks  <cit>  appear to be mapped perpendicularly to the main cochleotopic gradient. recently, a segregation of a ventral 'what' and a dorsal 'where' stream – as long established in the visual system  <cit>  – has also been proposed for the auditory system. this conclusion was based on neuroanatomical and functional studies in macaques  <cit>  and has been substantiated in humans  <cit> .

given these parallels between sensory domains and the increasing preference for complex stimuli along the auditory central pathway, more complex topologies such as language-specific maps in auditory cortex are also plausible, and evidence for individually ordered mapping of speech sounds is growing  <cit>  . more specifically, data from our lab imply map dimensions along phonological features which build the basic components of speech sounds: in obleser et al.  <cit> , responses to dorsal vowels  were located more posterior in auditory association cortex than responses to coronal vowels , and a topographical shift between these classes of vowels even when embedded in non-words has been reported  <cit> .

research has long been tackling the question of attention and attentional top-down modulation that may tune cortical neurons and with it functional maps in a context-specific manner: in the visual domain, a top-down influence on receptive fields of areas as basic as vi has been shown  <cit> , and in the somatosensory domain ergenzinger and colleagues reported that drastic changes in functional maps can be experimentally induced even on a thalamic level  <cit> . the thalamic homuncular representation of a monkey's hand becomes blurred and distorted when top-down modulation from somatosensory cortex is blocked neurochemically within the cortex. these results emphasize the possibility of attention-dependent modulation of maps, a topic exemplified in a somatosensory meg mapping study by braun and colleagues  <cit> : in a somatosensory stimulation with small brushes moving back and forth across the digit tips, subjects either attended the movement of single brushes on single digits and reported the movement direction or they attended and reported the global direction of all brushes on all five digits. magnetic source imaging of the somatosensory evoked field revealed a typical homuncular representation of the single digits spread along the post central gyrus only in the condition where the focus of attention was on single digits rather than on the hand as a whole. in the latter condition, top-down attentional demands temporarily seemed to blur the single digit mapping.

for the developing field of speech sound mapping, top-down influences of attentional demands on functional organization at the different stages in the processing streams have not been sufficiently studied. nevertheless, it becomes a central issue when the functional architecture of the effortless and robust perception of speech shall be understood. it is common to study speech perception either in passive oddball paradigms  <cit>  where the subject's attention is deliberately forced to a movie or to reading a book, or in passive listening conditions where no attentional control is experimentally induced , or in active target detection tasks where the attention is commonly focused on the phonological content of the speech material  <cit> .

we analyzed the magnetic n <dig>  response to two vowels  and , both produced by a male and a female speaker. subject's attention was either on the vowel or on the speaker difference, in a counterbalanced order. how would a controlled shift of attention from specific phonological features of speech to features of speaker identity affect the speech sound mapping in timing and topography of the brain response? two concurrent outcomes are conceivable here: first, from the numerous parallels between the auditory and other sensory domains, one might expect a blurring of differences of the phonological map in auditory cortex when features such as the speaker identity rather than phonological differences are attended over minutes. second, phonological processing could be the default process needed in all speech-listening situations and should therefore activate phonological feature maps irrespectively of attentional demands. we would then expect that the separate mapping of dorsal and coronal vowels described previously  <cit>  is unaffected by an attentional focus on speaker identity. however, a shift of activational patterns as an entity would reveal more about the staging of parallel processing in the flow of the 'what' stream.

RESULTS
in  <dig> of  <dig> subjects, a clear waveform deflection around  <dig> ms post vowel onset was observed  in all conditions over both hemispheres and sensor space parameters peak latency and amplitude were obtained. satisfying and physiologically plausible dipole fits  in both hemispheres could be obtained in  <dig> subjects and were subjected to statistical analysis.

n100m latency, amplitude and source strength
analysis of the n100m root mean square  peak latency revealed foremost a main effect of vowel , whereby the dorsal vowel  consistently elicited n100m peaks  <dig> ms later than the coronal vowel . in sensor space, an enhancement of rms peak amplitude for the  vowel by  <dig> ft  almost attained significance . however, the effect was significant in source space that is not influenced by varying head-to-sensor positions: the  dipole source strength, an estimate for the amount of massed neuronal activity, was larger for the  vowel than for the  by  <dig> % or  <dig> nam . no hemispheric differences in signal power between vowel categories or tasks were apparent.

n100m source location and orientation
in agreement with previous findings with a more comprehensive set of vowels  <cit> , the vowel categories  and  elicited statistically different centers of activity along the anterior-posterior axis , that is, the auditory processing in the dorsal vowel  was reflected by a more posterior ecd location . a difference in source configuration was also evident from a more superior position of the  source , a more vertical orientation  than the  source, and from an angular difference between the two vowel categories in the sagittal plane  and in the axial plane . none of these effects showed an interaction with hemisphere, but data gained further validity as the right-hemispheric sources were all located more posterior , more inferior  and were tilted more vertically  than their left-hemispheric counterpart. such a difference is to be expected from previously reported n <dig> asymmetries between cerebral hemispheres  <cit> .

the relative mapping of phonological features of the speech signal  <cit>  was not affected by the task-induced shifts of attention. however, shifts of subjects' attentional focus from phonological categorization to identification of the speaker's voice shifted vowel sources as a whole to more posterior and superior locations within the supratemporal plane. statistically, the speaker categorization task produced more superior  and marginally more posterior  ecd locations, which was also evident by an angular displacement in the sagittal plane . the effect seemed to be driven by changes in the left hemisphere but the task × hemisphere interaction never attained significance .

when brain responses were analyzed separately for stimuli spoken by male and female speaker, which yielded satisfying dipole solutions only in  <dig> subjects, the most striking finding was a consistent speaker × task interaction of the dipole location in both the sagittal plane  and the axial plane . that is, subjects' attentional focus slightly affected the relative displacement of male and female voice-evoked brain responses: in both the sagittal plane and the axial plane, a significant 4° difference emerged in the phonological categorization task , which vanished in the speaker categorization task. in contrast, as reported above, no such task influence was evident in the relative position of vowel-evoked brain responses.

performance
overall target detection rate was  <dig>  %, false alarms occurred in  <dig> % of all trials. responses of the  <dig> subjects whose brain responses were subjected to magnetic source imaging were analyzed in detail: the phonological categorization task  and the speaker categorization task  did not differ significantly .

discussion
this study was set up to explore potential influences of the attentional focus on the mapping of speech sounds within the auditory cortex. with subject's attention either on the phonological differences or on the speaker difference between vowel stimuli, we mapped the auditory evoked n100m and localized its sources that fitted well with a single dipole per hemisphere. all responses were located in the perisylvian region. furthermore, the relative distribution of sources indicated an interesting pattern. as hypothesized and expected from previous studies, the fundamental location difference between the sources of the dorsal vowel  source and the coronal vowel   <cit>  could be replicated under both attentional conditions. in contrast, the corresponding difference between speaker-dependent sources was subject to task influences.

that is, a shift of subjects' attention to a non-phonological acoustic feature, the speaker identity, did not blur the spatial segregation within the speech sound map. in contrast, the  and  generators were slightly displaced towards more posterior and more superior locations when subjects focused on speaker identity.

in most situations, a listener may automatically extract the phonological invariants from the speech signal in order to access lexical information, for example the meaning of the information inherent in speech. speaker-dependent features such as pitch and periodicity should not play a crucial role in this phonological decoding process. this is what we mimicked by asking our subjects to detect a certain vowel in a stream of varying speech sounds. however, in cocktail-party-like situations there is the additional demand to attend acoustic properties of certain speech streams or speakers, and we implemented it by asking our subjects to detect a certain voice in a stream of varying speakers. speaker identification comprises an important but not necessarily orthogonal process to phonological decoding in speech perception: areas in the upper bank of the superior temporal sulcus  have been identified previously  <cit>  to be voice-selective , and in many situations the selective tracking of one voice amongst others is a prerequisite for decoding the phonological content of this speaker's utterances. the displacement of dipolar sources seen here may mirror the involvement of additional cortical areas, such as the voice-specialized part in the sts  <cit>  or pitch-specialized areas in the primary auditory cortex. an additional sts activation would most likely elicit an inferior shift of the dipole sources during speaker categorization. however, a shift into the opposite direction was obtained. this might indicate that the contribution of the voice-specialized part of the sts around  <dig> ms post-stimulus onset is small compared to other additional cortical areas, such as pitch-specialized areas in the primary auditory cortex. it is now well-established that a finegrained analysis of the speech signal takes place mainly in anterior parts of the supratemporal gyrus  <cit> , thereby anterior of primary auditory areas. consequently, the activity shift towards more posterior sites we observed in the speaker categorization task strongly argues for an additional involvement of these primary auditory areas. unfortunately, we cannot dissociate speaker identification processes from pitch processing in the current study. however, pitch differences are among the primary cues dissociating male and female voices, and a clear involvement of auditory core areas in pitch processing has been shown in a recent meg study focusing on pitch detection mechanisms  <cit> .

CONCLUSIONS
data presented here suggest that the systematic mapping of speech sounds within the auditory cortex is robust under changing attentional demands and not tied to phonological awareness. however, the general shift of activity when a non-phonological speaker categorization must be accomplished shows that speech sound representations are modulated in their locations in a context-dependent manner. situational demands obviously influence the differential but time-synchronous involvement of specialized neuronal assemblies that contribute to speech sound decoding in a top-down fashion. hence, the spectrally high-resolving analysis of the incoming speech stream is performed at the same time but in different locations, i.e. in a different mix of cell assemblies than the analysis of speaker-dependent features .

further spatially high-resolution brain imaging studies are needed to quantify as to which extent voice-selective areas in the upper bank of the sts  <cit>  become involved when speaker categorization is accomplished. for the time being, this study increases our understanding of speech sound processing, as it replicates previous findings of an orderly mapping of phonological vowel features and as it shows that changing attentional foci affect the absolute but not the relative distribution of vowel-evoked activity within the auditory cortex.

