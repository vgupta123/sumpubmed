BACKGROUND
alternative splicing is a ubiquitous phenomenon among eukaryotic organisms. based on the most recent studies, more than 74% of the human genes with multiple exons undergo this process  <cit> . alternative splicing plays an important role in the function of eukaryote organisms. it is a versatile process that can be integrated with other regulatory mechanisms to generate protein diversity, to modulate cellular responses, and to regulate biochemical pathways  <cit> . changes in splicing are often associated with genetic disease and cancer  <cit> . thus being able to measure and compare transcript variant abundance is critical for understanding the function of a gene.

many studies have been taken to perform genome-wide analysis of alternative splicing using microarrays. most current approaches, however, focus mainly on qualitatively detecting splicing events  <cit>  by examining the presence or absence of known variant-specific exons or junctions. presence or absence of a variant is then inferred based on the transcript annotation.

on the other hand, quantitatively measuring gene-level expression has been a key task in microarray analysis . most current methods, however, impose a simple identifiability constraint on probe responsiveness  for each probe set . accordingly, none of these algorithms can reconstruct all variant abundances  on the same scale; though perhaps not a problem when comparing the estimates across experiments, it causes insurmountable difficulty when attempting to compare among different variants. further, even concentrating on a single family of variants, the mathematical linkage between intensity and the multiplicative model allows for ambiguous reconstruction. the aim of this paper is to find a generic method to estimate variant abundances consistently for all variant structures.

we first review the mathematical model and prove necessary and sufficient conditions to detect and resolve ill-posed instances of the model.

in a previous work, wang et al.  <cit>  have implemented a model-based method to estimate the relative concentrations of known splice variants by incorporating gene structure into a probe intensity model  <cit> , where the probe intensity is modeled by probe responsiveness and probe abundance, plus an error term. the gene structure specifies the relationship between known transcript variants, genomic features and probes, where genomic features can be either exons or junctions. this linkage enables them to use a probe intensity model to estimate the relative abundance of variants. maximum likelihood estimation  is used to obtain the estimates for variant concentrations and probe affnities.

this method often leads to unresolved ambiguities in reconstruction. we have observed the algorithm can not produce a unique solution for many gene structures  <cit> . the mle gives multiple solutions, each one attaining the  optimal function value. a simple example is the so-called "two-variant subset" gene structure, where the feature composition of one variant is a subset of the other one. biologically, if the two variants of a gene use different promoters or 3' utrs, the gene structure will display the "subset" property. figure 1b shows the simulation output for such a gene structure given in figure 1a. the algorithm generates different estimates for probe responsiveness and variant concentration in different runs even though the residual-sum-of-squares  are the same.  we have also observed that the same issue widely exists in more complex gene structures.

this is an example of an "ill-posed" problem, where additional constraints must be added to overcome the singularity, otherwise the ambiguity will seriously limit the usage of the above method. more recently, shai et al.  <cit>  developed a probability model using unsupervised bayesian learning to estimate variant concentrations. some constraints are obtained in a "semi-supervised" fashion by minimizing the root mean squared error between the final predictions and the rt-pcr results. unfortunately, their model will encounter the same nonuniqueness problem in general. however, as a special case, for their cassette exon example with only two variants and the correspondingly simple gene structure , there is no ill-posed issue and the solution is unique.

the aim of this paper is to find a generic method to estimate variant abundances consistently for all variant structures. we first review the mathematical model and prove necessary and sufficient conditions to detect and resolve ill-posed instances of the model. the natural source of information contained in probe sequences is used to construct additional constraints in the deconvolution. due to the great difficulty of predicting probe effects via sequence composition, this probe sequence based model does not produce mathematically perfect constraints. we therefore incorporate a probe responsiveness model into a supervised bayesian framework, which can accommodate imperfect or imprecise constraints. a useful side effect is that this model allows for reconstructing all variant abundances on the same scale between exons, and further, if the probe affinity model can be improved to produce sufficiently accurate predictions, reconstruct abundances on the same scale between genes. we demonstrate the potential efficacy of this method through simulation as well as experimental data. although the overall success in recovering comparable signal values across genes is not yet great, our model succeeds in uniquely resolving alternative splicing data even given the loose constraints from an imprecise model.

RESULTS
we first demonstrate the effectiveness of our dulmage-mendelsohn decomposition based grouping procedure on some simulation data. then the performance of our bayesian method is shown on two real biological datasets. as we shall see, although the overall fitness on t is not yet good enough, we do succeed in recovering important quantities none of the other methods can. r and matlab  <cit>  were used.

simulation data
in this subsection, we use simulation data with no sequence information to demonstrate the effectiveness of the grouping procedure in removing the non-uniqueness during transcript deconvolution. deriving the grouping procedure and building probe responsiveness models, though related to each other in the framework, are two independent tasks. by using simulation data, we can skip the errors in a probe responsiveness model built on probe sequences. this follows the case in which we have perfect knowledge of the response of each probe . we have tried large amount of data with varying sizes and different gene structures. one such example is presented as follows.

in this simulation dataset, there are  <dig> probesets, each one containing  <dig> probes,  <dig> variants, and  <dig> experiments. so the probe intensities y is a 10-by- <dig> matrix. for space reasons, we only list the gene structure matrix g here:

  

in addition to the gaussian noise ~ n added to the true signal , we appended a significant background signal uniformly drawn from  <cit>  to increase the deconvolution difficulty. this background signal is completely unknown in the estimation. our task is to reconstruct both t and a from y with f and g known.

with no grouping and no additional constraints, the solutions are not unique  and each one is a global minimum of the log-likelihood but not the truth. see the upper panel of figure  <dig> for an illustration. although it is relatively easy to get a globally optimal solution, there is no appropriate criterion to tell which estimate is correct or gives the best approximation.

applying the grouping procedure described in the methods section below to this data, we obtain four probe groups, which suggests a high deconvolution singularity. group constraints are then constructed from the true a or t to help fit the model. we use alternative optimization with group-rescaling to solve the model. the lower panel of figure  <dig> shows that after adding the group constraints in the fitting procedure, the prediction matches perfectly with the true answer, even with some substantial unknown background signal.

biological data
in this subsection, we demonstrate the power of our general framework with two biological datasets â€“ hg-sv and hg-ls.

data description
two data sets are used in this paper to train the sequence model and estimate the concentrations.

 <dig>  human gene latin-square  data. the data can be found at affymetrix's web site at . this latin square design consists of  <dig> spiked-in gene groups in  <dig> experimental groups. the concentrations of the  <dig> gene groups in the first experiment are  <dig>   <dig> ,  <dig> , <dig> , <dig> , <dig>  and  <dig> pm. each subsequent experiment rotates the spike-in concentrations by one group, i.e., experiment  <dig> begins with  <dig>  pm and ends at  <dig> pm, on up to experiment  <dig>  which begins with  <dig> pm and ends with  <dig> pm. each experiment contains  <dig> replicates. there are  <dig> probe sets and  <dig> pm/mm probe pairs in total.

 <dig>  human gene splice variants  data. the data was generated using a custom designed array. please refer to  <cit>  for details of array design and experimental design. four genes  with two clone variants were spiked in with varying concentrations. we first mixed targets derived from two variants  with differing concentrations: the first variant ranged from  <dig> to  <dig> pm and the second variant ranged from  <dig> pm to  <dig> pm with the total concentration held constant at  <dig> pm. by diluting the whole set  <dig> and  <dig> times, we obtained further results for titration sets with total concentrations of  <dig> pm and  <dig> pm respectively. there are  <dig> exon and exon/exon junction probesets and  <dig> pm/mm probe pairs in total. the sequences of these  <dig> variant clones are all known.

hg-sv data
the hg-sv data described previously have two known transcript variants in their gene structure. in this experiment, we took genes mylk and tpm <dig> as training data , cd <dig> as validation data , and mapt  as test data. the unknown t is of size 2-by- <dig>  with  <dig> variants and  <dig> experiments. on this relatively small data set, the estimate is, inevitably, not perfect, with the median absolute error  given by  <dig> , and the mean ae  <dig> . however, all the t-entries are estimated on the same scale and we do observe that our reconstruction is good in comparing the concentrations between the two variants. as demonstrated in figure  <dig>  our estimated concentration differences roughly follow the right trend for the  <dig> experiments. in particular, the obtained zero-crossings are approximately correct. for comparison purpose, we ran the space algorithm and got much larger errors; the median and mean ae are  <dig>  and  <dig>  respectively. the space estimates are much worse especially for the last  <dig> experiments, as clearly shown in figure  <dig> 

hg-ls data
genes in hg-ls data set only have one transcript. our framework is general enough to be applied to such data as well, corresponding to a special case where g = i. our goal here is to compare transcript abundance level between genes. since the g matrix is an identity matrix, the number of additional constraints required for estimating all transcript concentrations on the original scale is equal to the number of transcripts. they can be constructed via probe responsiveness predicted by the sequence model . to evaluate the performance of the algorithm on this dataset, we used  <dig> transcripts for training,  <dig> for validation, and the remaining  <dig> for testing purposes.

our method allows us  to estimate the whole concentration matrix t with no ambiguity. the bayesian method including the standard error information of the predicted responsiveness can handle a poor probe sequence model and is efficient. it is not yet satisfactory enough to recover every concentration precisely, with the mean ae given by  <dig>  and the median  <dig> . this is not so surprising considering the poor fit of current probe sequence-based models and the small sample size  of the data. we also ran the sapce algorithm  <cit>  which yields larger errors; the mean and median ae are  <dig>  and  <dig>  respectively.

on the other hand, it is interesting and encouraging to note that the between-experiment and between-variant information has been restored to a large extent using our method. to clearly show this, we compare the following three types of ratios, where t and t are used to denote the i-th row  and the j-th column  of t, respectively, and diag, adiag to denote the diagonal and anti-diagonal of t, and 'med' represents the median operator.

a. across-experiment accuracy.

for each variant i, compare /med) to t/med).

b. across-variant accuracy.

for each experiment j, compare /med) to t/med).

c. across-variant-and-experiment accuracy.

compare diag()/med) to diag/med), and compare adiag()/med) to adiag/med).

the results are plotted in figure  <dig>  figure  <dig>  and figure  <dig>  the space estimates are poor and not plotted in these figures. to get an overall intuition, see figure  <dig> for a summarized ratio-comparison of our method and the space algorithm. one may find that our results make much more sense and are much closer to the truth especially for moderate ratios. by contrast, space is not able to resolve all deconvolution ambiguities; its t-estimate gives very misleading between-entry ratios. in all of the figures, we clearly see that our method is capable of restoring the ratios between the entries in t to some extent  except for very large ones. the lower predicted concentrations are likely due to experimental error where the variants were spiked in a lower concentration than specified , as was noted in wang et al.  <cit> . our complete recovery of t is superior to single row recovery as most other methods are trying to solve. in particular, the across-row information can be very useful for comparing between different transcripts.

discussion
the singularity problem arising in deconvolution is common, both at the variant level and at the transcript level, if we want to recover from probe intensities all concentrations on the same scale. our mathematical analysis and the grouping procedure in this paper apply to any complex gene structures in both situations. furthermore, we built a bayesian framework that adapts to any probe responsiveness model and probe intensity model . it reduces the risk of using poorly predicted probe responsiveness based on current probe sequence models. experimental results are positive and encouraging: our approach is able to reconstruct all variant abundances on the same scale, and thus for the first time allows for quantitatively comparing the estimated abundances between different transcripts. this is an advantage over most other methods which explicitly or implicitly impose an identifiability constraint on probe affinities for each probe set and are thus only meaningful for comparing the abundances across experiments.

in the experiments, our model cannot yet provide an adequate fit for the microarray data to reconstruct all concentrations precisely. a careful study shows that this is largely due to the poor fitness of existing probe sequence models  and the small number of probes of these datasets. we expect to develop a more accurate biophysics model to characterize the probe responsiveness and try our method on some larger microarrays as well. moreover, since it is usually true that many probes might behave badly, further study is needed to investigate multiplicative probe intensity models and to design an appropriate robust fitting criterion in our bayesian deconvolution framework.

CONCLUSIONS
the matrix analysis of constraints provides a tool for detecting real-world instances in which additional constraints may be necessary to resolve splice variants. while purely mathematical constraints can be stated without error, real-world constraints may themselves be poorly resolved. our bayesian framework provides a generic solution to the problem of uniquely estimating transcript abundances given additional constraints that themselves may be uncertain, such as regression fit to probe sequence models. we demonstrate the efficacy of it by extensive simulations as well as various biological data.

