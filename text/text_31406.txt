BACKGROUND
microarrays and other new high-throughput technologies are changing the way molecular biology is practiced. however microarray platforms and protocols are still under development, and the causes of common errors and artifacts are still not completely understood or controlled. over time and replications, many types of errors seem almost random. others, however, affect many gene expression measures at once, introducing systematic biases into the data. most statistical methods are designed to deal with measures corrupted by random noise; methods to deal with systematic biases are not so well developed.

spotted arrays
over the extent of a single spotted microarray, factors such as temperature, liquid flow rate or rna diffusion rate may differ among different regions on the array. often, washing is less thorough near the edges of a slide, contributing to higher local off-spot background near the edges. high local background usually pushes up the spot measures, although not always predictably. to detect such technical artifacts, it is now standard practice to examine images of slides for pronounced irregularities and high backgrounds. such examination can identify many types of faults, but even a skilled technician may miss regions of higher than average intensity in affymetrix arrays or moderate biases in the ratios calculated for spotted arrays, since the vast majority of spots appear dim in images calibrated for the dynamic range of the brightest spots. at the moment there is no way of quantifying regional biases, and a lot is left to the technician's judgment.

affymetrix arrays
to address such issues, affymetrix has gone to great lengths to standardize their procedure. however, uniform results are rarely achieved in practice. often a bubble remains after filling an affymetrix cassette. this bubble will not travel uniformly over the chip during hybridization mixing and may get stuck or move in an irregular circuit. scratches and other manufacturing imperfections can make a difference. scratches are sometimes visible with the aid of software such as dchip  <cit>  or rma  <cit> . although a skilled technician can identify some of the grosser faults by examining the images of hybridized affymetrix chips, he or she has no current standard for measuring how serious the problems are or for knowing whether other sorts of systematic problems are evading scrutiny.

current practice in quality assessment for spotted arrays considers individual spot measures, such as area and signal/noise ratio  <cit> . current quality metrics for affymetrix arrays consider 3'/5' ratios for selected genes and spike-in ratios. these quality metrics don't take variation within a slide or chip into account. we show here that such bias, which is currently ignored, can be a significant problem.

methods
all computation was done within the r programming environment  <cit> , and the affymetrix analysis used the affy package  <cit> .

detection of regional bias on spotted arrays
an effective way to present information about regional biases is through plots or maps of the ratios or signals over the chip surface. for two-color arrays it is natural to plot ratios as a function of position. because all ratios are represented at the same brightness, such a plot makes it much easier to see patterns of regional bias than does inspection of the raw image file. such a plot is shown in figure 1a. similar plots are available through arraymagic  <cit> . however we still face the problem that many different ratios  are juxtaposed on the slide, making it difficult to see subtle but consistent biases.

many two-color microarray experiments focus on a single tissue but use a common reference rna not specific to the tissue. in such a design, two neighboring probes will often show consistently different red/green ratios across all slides, reflecting the typical abundance of the probes' mrna targets in the samples relative to the common reference. we would like to compare each slide's probe ratios with a standard ratio profile, reflecting the typical abundance of all mrna species in the tissue under study relative to the reference. we approximate such a common standard by computing, for each probe, the 20%-trimmed mean of the probe's log ratios, across all slides. in doing so, we are assuming that the biological variation due to sample and the regional biases on each slide will tend to balance out over the whole experimental set.

for each slide we then compute the difference between the log ratio of each spot and the spot's average log ratio over all of the pertinent arrays:

 di,j = log <dig> – mi; mi = trim),

where d is the difference, i indexes the spot, j indexes the particular slide, k indexes all slides, and trim refers to the 20% trimmed mean of a set; ri,j and gi,j are the red and green channel intensities of spot i on chip j. when these differences di,j are represented as colors over the area of the chip, then often the high and low ratio values are clearly concentrated in some sub-regions. an example is shown in figure 1b. more examples are in the supplementary material. because the probes for most co-regulated sets of genes are distributed widely throughout the chip, we don't expect that a biological process would generate such a pattern. hence, such regional inhomogeneity of ratios must be a technical artifact.

affymetrix arrays
affymetrix raw data are considerably denser  than spotted array data, so a deeper investigation is possible. we present several types of plots here showing different aspects of bias. the first  shows how the raw intensity data look if we present brightness on a logarithmic scale. ref  <cit>  shows a similar plot. because of the log transformation, this plot brings out detail in the low range . typically, this low range contains more than half the probes on a chip. such a plot often shows striations because probes of similar sequence are placed in rows.

even more than with spotted array ratios, it is difficult to see subtle spatial patterns on an affymetrix chip image because neighboring probes show such a wide range of different intensities next to one another. to make biases visible we would ideally like to compare individual slides with a standard that represents a good, uniform hybridization. ideally, we would like to have many replicate slides of at least one representative sample and to use their average as a standard. in practice we rarely have such replicates. hence, in the approach to be presented here, we construct a reference for the affymetrix chips  by taking a trimmed mean of each probe across all chips  in the experimental series. in the calculations here, we use a 20% trim, which seems to work satisfactorily. this standard chip ideally represents the probe intensities for a 'typical' sample in the experimental series – a virtual sample of the same tissue type with expression values intermediate among those of all samples in the experimental series. we then plot the differences between log values on each chip and the standard chip:

 di,j = log <dig> – trim),

where i indexes the probe, j indexes the chip, and k indexes all chips; inti,j is the intensity of probe i on chip j. a plot of dij is shown in figure  <dig> at upper right. we note that the differences {di,j} reflect discrepancies from an average, and cannot detect regions on a slide which consistently show the same bias.

using the greater density of probes on an affymetrix chip we can investigate in more detail how the log differences in equation   between the sample chip and standard chip) differ from one region to another. to estimate the log difference in local background of a region, we adopt a heuristic procedure, first selecting those probes with intensities in the lowest one-fifth of probe intensities for the chip as a whole. then we compute the 20%-trimmed mean of differences between the log2-intensities of the selected probes on the chip and the corresponding probes on the standard:

 pj = trim

 bg = trim -pj) | pj < qp, <dig> ).

here, trim represents the 20%-trimmed mean of the variable x restricted to the set s, and inti,j represents the intensity of probe j on chip i, pj represents the log2-intensity of probe j on the standard, and qp,a represents the a-th quantile of probe intensities on the standard chip.

to compute the log <dig> scale factor, s, we use the 20%-trimmed mean among the highest 20% of probe intensities in the region:

 s = trim – pj | pj > qp, <dig> ).

we then construct heat maps of the log <dig> background factor  and log <dig> scale factor  over the chip. when these plots are placed side by side , we see regions in which the background is raised but the scale factor is unaffected, and vice versa. further examples are in the supplementary material. the code for making such plots for affymetrix chips is available on our website .

quantitation of regional bias
it is important to have some scale on which to measure the distortions introduced by spatial effects, and to have some idea how much difference these distortions make to the final estimates of gene expression. the simplest estimate is correlation between each probe intensity or ratio and the average of its four neighbors. for spotted arrays the measure of correlation is

 r = < rlm, / <dig> >,

where l indexes rows, m indexes columns, and rl,m is the log <dig> red-green ratio at a spot indexed by l and m. in the case where all slides use a common reference, then the difference between the log <dig> ratio of the spot and the average signal from that spot may be used, as described earlier. the notation <x,y> refers to the pearson correlation between variables x and y over all values of l and m in the array. for an array with no regional bias, r would equal 0; for one with regional bias, r >  <dig>  for affymetrix arrays we computed r using the difference between the log <dig> ratio of each probe and the average signal from that probe, and we used only neighbors within rows, because neighbors within a column include the corresponding mismatch probes, which should be highly correlated with the perfect match probe.

measuring effect of regional biases on estimates
to test how much biases affect the expression estimates, we selected several very clean-looking chips from several different studies and systematically distorted their cel file data by multiplying regions of various sizes by factors of  <dig>  and  <dig>  corresponding to log <dig> changes of  <dig>  and  <dig> . the distortion patterns were selected to mimic patterns that we observe in real chips. we then estimated the gene abundances using the mas <dig> and rma algorithms in the affy package of bioconductor. the results did not depend much on the exact shape of the region distorted, and results were comparable using different chip types .

RESULTS
we investigated several hundred spotted microarrays and affymetrix chips, from over a dozen different studies, finding noticeable bias in almost all slides and in most chips. many of the studies included some slides or chips whose regional biases were severe enough to compromise at least part of the study.

spotted arrays
using our methods we find both sharply defined, high-contrast artifacts, and diffuse regional biases. the most common sort of regional bias on spotted arrays is associated with high backgrounds of one color over a region. it is usually supposed that background subtraction removes such biases. we find, however, that the standard method of subtracting the off-spot local background from each channel does not effectively correct regional biases  and sometimes introduces them . the implicit model underlying background subtraction is that the amount of non-specific dna binding to the substrate around a spot is equal to that within the spot and additive to the target-specific binding within the spot. there are several different mechanisms that cause fluorescent signal outside of the spots – such as direct binding of dye or labeled cdna to substrate, reflection from substrate, and binding of labeled target to smeared probe – and only some of them will contribute additively to the measured signal on spots. we think that the issue of adjustment for background needs more thought than is usually given it.

affymetrix chips
we find three major types of spatial artifact on affymetrix arrays:

1) obvious, distinct artifacts with sharp boundaries; most of those defects cover less than 5% of chip area.

2) regional shifts in non-specific signal background: in wide areas of the chip the tenth percentile may be as much as 50% higher than the corresponding quantile over the remainder of the chip

3) regional shifts in scale factor: in wide areas, the highest values of both pm and mm appear to be up to 50% lower than corresponding values in other areas; the scale factor appears very uneven, and shows a characteristic turbulent appearance.

we suspect that artifacts of type 2) and 3) are also present on spotted arrays, but we do not detect them as readily because the density of features is lower.

by looking in such detail, we find many irregularities in even the best affymetrix chips. since probes for each gene are distributed across the chip, however, a modest area  of affected probes is not a serious problem. a robust statistical method, such as mas <dig>  dchip, rma, or the plier method, will down-weight those values, as described later. the problems become more serious when large  regions of the chip are higher in intensity than other regions by a factor of  <dig>  or more. if we use a linear algorithm without outlier removal, then the values for some probes may be changed more than  <dig> -fold, and the few high-intensity probes may dominate estimates for genes by these methods. if one used a linear algorithm on the log-scale then the distortion over the chip should roughly average out for each probe set. however, it is difficult to predict the effect on estimates made by a robust algorithm such as mas <dig> or a linear model, such as li-wong, rma or plier, because such methods remove outliers, and these may be found preferentially in one region of the chip. below, we investigate empirically the effects of regional biases on gene expression estimates from robust algorithms.

typical measured biases
on spotted arrays we find typical correlations r between raw ratios of  <dig>  to  <dig>  and typical correlations using log ratios relative to the average of  <dig>  to  <dig> . some slides show correlations as high as  <dig>  in log ratios relative to the average.

on affymetrix chips we find, as did workman, only slight correlation using intensities. the correlations are much stronger for ratios of individual probes to their typical values, as instantiated in the 'standard' virtual chip. a good chip will typically show correlations in ratio relative to standard between nearest neighbors of  <dig>  to  <dig> . we observe the highest correlations along horizontal straight lines in the most recent generation of chips. that is so because probes with similar sequence motifs are often printed on lines , and sequence similarity may predict similar responses to many variations in conditions.

effect of regional biases on affymetrix estimates
entries for rma and mas <dig> in the table are fractions of probe set abundance estimates  changed by more than  <dig>  on a log <dig> scale as a consequence of the bias introduced. the rows labeled r report values of the local correlation, r.

as expected, both mas <dig> and rma are fairly robust to small distortions but, as would be expected, both methods do worse as more distortion is added to the chip images. rma is notably more robust than mas <dig> to the moderate distortions commonly found in affymetrix chips. however, rma does worse than mas <dig> when the perturbation is most serious. a little thought makes the reason clear: rma aims to fit the majority of the intensities on each chip well; it down-weights probes that appear too high or too low relative to the majority of others in the probe set, according to the pattern on other chips. when half of the chip is raised in intensity values relative to the other half, then roughly half the probes for each gene lie in each region. rma fits one half well and discounts the other half.

discussion
consequences for data analysis
as described above, chips with significant regional distortions can be expected to yield gene expression estimates that differ significantly from the true values. other, less distorted chips in a group will show expression values more indicative of the biology. several studies that have come to the first author from leading core facilities include chips with very large spatial distortions that went undetected by the  qc at the facility. good intuition leads the data analyst to suspect certain outliers and to include others. however, data analysts prefer to have some objective criterion to reject outliers. in our experience, most chips that are outliers relative to their experimental groups show large regional distortions.

rather than rely on intuition to discard outliers, we can use a systematic chip qc process to put outlier detection on a firm footing. we recommend that users note the r statistic, as defined in equation  <dig>  we find that the r statistic is a useful guide to the degree of distortion in expression measures as summarized in table  <dig>  users can decide how much distortion they are willing to live with, and select slides with r statistics accordingly. our standard practice is to run the bias detection program in batch on a new set of chips, and to discard chips with r values exceeding  <dig> . for chips with r values between  <dig>  and  <dig> , we scrutinize the images provided by our program, and decide whether the flaw is large and concentrated , or moderate and pervasive, in which case more probe sets will be notably affected.

the discovery of systematic bias leads a statistician to try to compensate. our qc visualization method is based on ratios, and ratios to a standard are a natural choice for normalization. smoothing is an approach to spatial variation favored by many statisticians, and several authors have proposed compensations for microarray spatial biases using smoothed fits to bias  <cit> . however, those methods have not met with unqualified success  <cit> .

we are not sanguine about the prospects for normalization by smoothing. our observation is that the biases represented in the ratio plots show abrupt transitions from one region within a slide to another and also occur in complex filigree patterns. often regions within the same print-tip group on a spotted microarray slide show apparent regional biases as large as do regions at greater distances on a slide . sometimes there is a repeating pattern of biases in all print-tip groups. smyth  <cit>  has suggested that such repeating patterns derive from different quality 96-well plates used for printing the arrays. he proposes a print-order normalization, but many arrays show non-repeating, non-random patterns of bias, which can't be compensated in that way.

a reasonable question is whether regional biases in affymetrix chips can be eliminated by comparing pm with mm. in fact, we find that a plot of log  – log  values for a chip, relative to the same quantities for the average chip, shows much less regional bias than does a plot of log probe intensities relative to their averages. that observation suggests that, in practice, the mas <dig>  pm correction reduces regional biases in scale factor, whereas the rma procedure does not. in the same way, the mas <dig>  background correction reduces regional biases in background, whereas the rma procedure does not. however our results in synthetically distorted chips suggest this advantage of the mas <dig>  procedure is telling only in the presence of strong regional bias .

CONCLUSIONS
we have shown that regional biases are common on microarrays, and that in some cases they may be responsible for apparent large differences in gene expression. we have presented methods for visualizing and quantifying the levels of regional bias . in our judgment the most practical way to use information about regional biases on microarrays is in the quality assessment step, rather than in an attempt to compensate for it. we hope that others will use the tools we have provided at  to visualize and quantify these biases on their microarrays.

supplementary material is online at 

authors' contributions
mr conceived of the study, wrote the code, analyzed the results and drafted the manuscript. jnw suggested the perturbation study, and provided extensive and detailed comments on the manuscript. all authors read and approved the final manuscript.
