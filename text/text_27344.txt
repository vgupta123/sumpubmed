BACKGROUND
advances in sequencing technologies have revolutionized the life sciences. for example, ecology and evolution can now be examined across the tree of life  <cit> , and at resolutions ranging from broad analyses  to focused investigation of population structure within particular species  <cit> . these analyses, however, center on genomes as the unit of interest and represent a “bottom-up approach” to exploring the diversity of life  <cit> .

concurrently, metagenomics provides a “top-down approach” for studying complex microbial assemblages in nature  <cit> . recent reviews cover next generation sequencing applications  <cit> , but rarely acknowledge the factors that generate quantitative data needed for metagenomics. for example, sequence quality evaluated across benchtop systems did not consider library preparation  <cit> , and recommendations of amplification-free protocols that require >2 μg of dna to minimize biases  <cit>  are not meaningful for dna-limited applications. there are also numerous sequencing platform options, though microbial metagenomes generated across commonly-used sequencing platforms only minimally differ in taxonomic distributions or contig assembly quality  <cit> .

some fields, such as viral ecology or microbial ecology of permafrost soils or the atmosphere, are routinely dna-limited  and thus require optimization and quantitation assessment at each step in the metagenomic sample-to-sequence pipeline  <cit> . towards this end, empirical data are now available to guide researchers in concentrating and purifying viruses  <cit>  prior to dna extraction. once dna is extracted, small yields require amplification to obtain enough material for sequencing. while whole genome amplification was an attractive option, it is now documented to result in non-quantitative metagenomes due to both stochastic  <cit>  and systematic biases  <cit> . in contrast, linker-amplification-based libraries  <cit>  provide a nearly quantitative alternative, even from sub-nanogram amounts of dna  <cit> . together these advances allowed the compilation of the first large-scale, systematically prepared comparative metagenomic dataset for quantitative viral ecology  <cit>  with new tools and analytical platforms now emerging to handle such datasets  <cit> . beyond viral ecology, these studies provide a roadmap for generating quantitative metagenomic datasets from any low  input dna samples.

here we expand upon these efforts to focus on the final steps in viral metagenomic sequencing . the first experiment evaluates co-varied input dna and amplification cycle amounts, as well as sequencing platform choice on the resulting metagenomes. these data were derived from dna extracted from a  <dig> l biosphere  <dig> ocean viral concentrate and included small-insert metagenomes prepared from varied low-input dna amounts  and amplification conditions for commonly used sequencing platforms . additionally, these low-input samples were complemented by standard input dna small-insert metagenomes to compare three sequencing platforms  and limited large-insert clone library sanger end-sequencing . the second experiment focuses on illumina sequencing only. here, viral dna derived from two separate ocean samples  was used to examine the effect of amplification conditions  and input dna amount independently, as well as compare standard illumina libraries to transposon-based nextera libraries  <cit> .

starting dna refers to the amount of pre-size selection dna used in library construction; library amplification abbreviations are la = linker amplification and n = nextera; raw quality scores reported are phred scores; raw length ‘pe’ denotes paired end reads. * denotes the successful 10ng library and one of the 100 ng libraries had an additional 40% of qc-passed reads that were lost due to removal of truseq adaptor sequence contaminants.

RESULTS
experiment 1: the impact of input dna, amplification, and sequencing platform on metagenomes
library success varies by sequencing protocol
as expected, the fosmid library and all  <dig> libraries made from ≥ <dig>  ng dna were successful in generating sufficient dna for sequencing regardless of sequencing platform . additionally, low dna input libraries for  <dig>  were all successful, with highest read yields per ng of input dna of any method .

in contrast, experiment  <dig> illumina libraries constructed from low starting dna amounts were less successful . specifically,  <dig> of  <dig> libraries, one 10ng and both 1ng libraries, failed library construction, even with the addition of carrier dna and adaptor concentration adjustment to increase ligation efficiencies. two of the remaining  <dig> low input dna libraries, one 10ng and two 100ng, were sequenced, but yielded fewer and more variable numbers of reads and abundant adaptor sequence .

%g + c content variation within treatments is minimal
the replicates’ read %g + c distributions were correlated using the pearson product–moment correlation coefficient . there is little variation in %g + c across replicate libraries from any  <dig>  illumina, or ion torrent sequencing data – replicates have pairwise correlation values from  <dig>  to  <dig> and cluster together >94% of the time . this indicates that, at least for the range of %g + c in this b2o sample, intra-replicate variation is minimal and therefore there is high power to detect statistically significant differences across treatments.

input dna amount, decision to amplify impact %g + c content
hierarchical clustering of sample %g + c distribution correlations shows consistent differences. first, all ≥ <dig>  ng metagenomes cluster together 100% of the time . of the treatments tested, input dna most strongly impacts the resulting metagenomes, with ≥ <dig>  ng next-generation metagenomes clearly separated from the rest. among these ≥ <dig>  ng samples, illumina metagenomes have higher %g + c than  <dig> and ion torrent metagenomes , but differences between sequencing platforms are much less than differences between dna inputs, with upgma branch length distances of  <dig>  and  <dig> , respectively . while of limited sampling, the largest shift towards higher %g + c sequences  was in the fosmid library relative to the unamplified libraries .

among the < <dig> ng metagenomes, there are minimal differences between platforms and the only supported relationship, with bootstraps greater than the intra-replicate 94% value, was the clustering of illumina 100ng samples with illumina 10 ng samples . this implies that, among amplified metagenomes, the degree of amplification and sequencing platform choice only minimally impact the resulting metagenomes. the fact that these diversely prepared metagenomes were nearly indistinguishable by %g + c distribution metrics  is promising for comparability of amplified metagenomes across sequencing platforms.

duplicate reads uncorrelated with any single variable
duplicates in metagenomes are derived from either naturally occurring duplicates in genomes and communities, or artificial duplicates generated during 454’s empcr step or at some unknown point in illumina preparations that is inconsistent across replicate libraries  <cit> .

here, hierarchical clustering of duplicate frequencies  and raw duplicate distributions, normalized to metagenome size , suggest a pattern of three duplication groups. the first, composed of unamplified  <dig> and 10ng illumina metagenomes, contains intermediate levels of duplication  and few high-frequency  duplicate reads . the second cluster, composed of most illumina metagenomes, has an intermediate level of duplication , but also an excess of highly duplicated reads . the third includes the amplified  <dig> metagenomes, both ion torrent metagenomes, and the poorly amplified 100ng illumina library, all of which have few duplicate reads  and very few high-frequency duplicate reads  . however, these deep internal nodes lacked support, with bootstraps less than the intra-replicate 90% value, and duplication frequencies do not obviously correlate to any single metagenome category .

some duplicate sequences may be real. for example, one 100bp sequence is overrepresented in multiple libraries including  <dig> ng illumina , ion torrent , and unamplified  <dig>  libraries. artificial duplicate frequency correlations  match overall duplicate frequencies for all treatments except a single 10ng, poorly-amplified, adapter-containing illumina library , where 40% of the reads were predominantly artificial, high frequency duplicates .

gene function and read assembly parallel %g + c findings
to evaluate variations in gene function, metagenomic reads were compared to an expansive database of marine virus protein sequences . as is common for viral metagenomes  only 3—7% of the reads mapped to protein clusters without self-clustering. however, the resulting gene frequency patterns were well-supported and mirror patterns observed in the above %g + c analyses . replicate metagenomes were most similar , while the biggest difference was between metagenomes prepared from ≥ <dig>  ng of starting dna and those prepared from 100ng or less . within these two large clusters, sequencing technology choice contributed additional, but minor, divergences . notably, these protein cluster pairwise r-values are lower than those for either %g + c or duplicate frequency. this likely reflects increased analytical resolution, as  <dig>  protein clusters correlated per metagenome in the function analysis, while only  <dig> or  <dig> bins were resolved in the %g + c and duplicate analyses, respectively.

finally, assembly experiments  revealed that total assembly size positively correlated to the number of reads used in assembly. in turn, the maximum and n <dig> contig sizes were relatively insensitive to increased read numbers in the larger datasets. this was true for both k-mer and overlap-based assembly algorithms .

experiment 2: the independent effects of input dna and library amplification on illumina-sequenced metagenomes
low input dna library success improved with optimization
in contrast to experiment  <dig>  all  <dig> experiment  <dig> illumina libraries  were successful. replicate libraries did not cluster together consistently, but this reflected the extremely minimal variance across the replicates rather than poor replication .

transposon-based library preparation slightly impacts %g + c
in both tara oceans station  <dig> and  <dig> datasets, the amount of input dna  and amplification  resulted in less variation than was observed in replicate library preparations . the only exception was transposon-based libraries, which diverged from the relatively invariant standard illumina libraries. for all samples, duplicate frequencies varied as much between as within treatments  and much less duplication was observed in experiment  <dig> than  <dig>  the dendrogram topology observed in pairwise %g + c analyses was recovered in analyses of function , but not assembly , where the transposon-based treatment for the station  <dig> sample produced many fewer reads than other metagenomes.

discussion
replication is fundamental to rigorous experimental design  <cit> , but it is only now becoming financially possible for metagenomic studies  <cit> . here we examined replicate metagenomes across varied dna input amounts, library preparation procedures, and sequencing platforms.

low input dna library success depends on adaptor ligation
while all ≥ <dig>  ng dna libraries were successful, environmental samples, particularly for viruses, routinely yield <1ng of dna  <cit> . libraries constructed from ≤100 ng dna were successful using the linker-amplification protocol for  <dig>  <cit> , but illumina libraries failed or were low-quality for experiment  <dig>  but not experiment  <dig>  two separate protocols were used – both optimized for recovery from column purification steps  <cit> , but employed different template:adaptor ratios in ligation  <cit> . specifically, experiment  <dig> used 170: <dig>  while experiment  <dig> used 22: <dig> for 10ng starting dna. thus low dna libraries require adjusted adaptor:template ratios during ligation .

presence of library amplification drives bias
two amplification reactions are common in metagenomic sample preparations. the first, library amplification, increases input dna to balance library preparation losses from purification, size selection, and quality titrations  <cit> . this adaptor-mediated amplification step is used for limiting dna for  <dig> , but is routinely employed in ion torrent  and illumina  to enrich for correctly ligated adaptors. this step can alter overall library %g + c  <cit> . the second amplification step is specific to the sequencing technology  and used for improving signal detection. this step should not alter overall library %g + c, but can artificially over-represent sequences  <cit> .

in this study, two libraries received no library amplification: unamplified  <dig> and fosmid libraries. fosmids had elevated %g + c, which is ascribed to a cloning bias  <cit> . among the remaining libraries, we expected a low %g + c shift due to the adaptor-mediated amplification step, commonly attributed to inhibitory effects of high %g + c dna secondary structures, either during library amplification  <cit>  or downstream empcr  <cit> . however, these trends were not observed: in experiment  <dig>  the  <dig> unamplified and amplified illumina  <dig>  ng libraries correlate well with one another , but poorly  with the amplified  10ng illumina libraries. this difference appears to be driven by reduced low %g + c reads relative to the ≥ <dig>  ng libra ries, which may implicate low input dna libraries as more sensitive to loss of low %g + c reads either during gel extraction heat steps  <cit>  or preferential fragmentation through heating  <cit> . a possible improvement over gel extraction is sage science’s pippin prep , which avoids heating. heat during fragmentation is avoidable with covaris acoustic shearing. both techniques also minimize contamination, which is crucial for dna-limited libraries.

while amplified ≤100 ng metagenomes displayed different %g + c distributions from ≥ <dig>  ng metagenomes, the amount of amplification only minimally impacts the resulting metagenomes. this was true in experiment  <dig>  where starting dna amount and amplification cycling co-varied, as well as experiment  <dig>  where these parameters were independent. fragment competition resulting from cycling conditions is thought to select for higher %g + c and shorter fragments, thus linker-mediated amplification protocols employ tight sizing conditions and %g + c optimized pcr conditions  <cit> . such careful library construction can produce minimally biased  viral metagenomes from sub-nanogram amounts of dna  <cit> . the %g + c patterns observed in the current larger-scale study were also paralleled in functional analyses  and assembly performance. this suggests that systematically prepared linker-amplified metagenomes derived from variable input dna amounts are quantitatively comparable.

some caution is warranted for high-throughput transposon-based library preparation options like nextera. specifically, experiment  <dig> revealed that standard libraries prepared from limiting dna and under varied conditions were relatively invariant, whereas the transposon-based protocol led to divergent %g + c and protein cluster profiles for metagenomes from both stations. while these deviations were statistically significant , they were minor in magnitude relative to other treatment effects observed here. such a %g + c bias in nextera library preps is not entirely surprising as previous work demonstrated reduced coverage in both high and low %g + c regions of virus genomes  <cit> , presumably due to non-random transposition. evaluation of new transposition methods should be considered if their eventual products require strictly unbiased representation of input dna.

finally, while not investigated here, polymerases used in amplification can alter metagenomes. phi <dig> polymerase, for example, leads to stochastic and systematic biases that can impact resulting coverage  <cit> , while some high-fidelity polymerases  enrich for rare sequences and others  do not  <cit> . in experiment  <dig>  the ≥ <dig>  ng libraries only minimally differed from each other despite the fact that they employ different polymerases across sequencing platforms. these polymerase-specific effects would depend on protocol particulars   <cit>  and the underlying %g + c distribution  of the dna to be amplified. future work to determine the impact of polymerase choice empirically on metagenomes derived from a wider range of %g + c than those employed here would be informative.

duplicates vary by input dna, amplification, technology
duplicated reads are problematic in quantitative applications as they can be real or artificial  <cit> . here, experiment 1’s true distribution of duplicates is presumably represented by the first cluster , except the artificial duplicates discussed below. by comparison, metagenomes from the second cluster contained highly duplicated artificial reads that reduced library complexity during amplification. the last cluster, which included amplified  <dig>  as well as one illumina and two ion torrent metagenomes, had low levels of duplication. for the  <dig> libraries, this could be due to the diversifying effects of the linker amplification process  <cit> , but it is harder to explain this trend in the ion torrent metagenomes or find a process that ties low library amplification in the 100ng illumina metagenome to lower duplication levels. artificial duplicates in illumina libraries were only an issue in the problematic 10ng library, where 40% of the reads were high-frequency, predominantly artificial duplicates. further study is required to determine mechanisms that generate artificial duplicates in illumina data.

sequencing technologies produce comparable output
while the metagenomes here were derived from three very different ocean viral communities, the range of %g + c was not extreme. given that, sequencing technology is not a major factor impacting ocean viral metagenomes, which is consistent with previous microbial metagenomic studies  <cit> . however, read length can influence many downstream applications, from assembly efforts to functional identification of genes  <cit> . of widely used next-generation technologies,  <dig> currently has the longest read length of 800bp, with paired-end illumina capable of 250 + bp  <cit> . however, emerging nanopore technologies are likely to be truly transformative  <cit> . details are not yet public, but these technologies promise longer reads, direct observation of fragment sequences, and minimal library preparation enabling low input dna applications.

CONCLUSIONS
as we strive for systematic and quantitative analyses of complex environments, a thorough understanding of empirically-documented biases in methods is critical. here we demonstrate that while sequencing platform choice and degree of amplification have little impact on resulting metagenomes, presence of amplification and starting dna amounts do influence library success and composition. our findings are critical both for the interpretation of systematic comparisons of dna-limited community metagenomes, as well as for novel methods of studying virus-host interactions  <cit>  that generate small amounts of dna. notably, however, high replicability observed here might have been aided by diluting the initial concentrated dna sample, and potential inhibitors, to obtain ‘low input dna’ samples. consideration should be made of the impact of inhibitors on low input dna samples, particularly when amplification steps are needed for sample preparation.

given current findings, unamplified libraries are best when dna is not limiting   <cit>  while sequencing platform choice minimally impacts quantitative representation in the resulting metagenomes. when dna is limiting, as in viral community samples or microbial communities of permafrost soils or air samples, specific recommendations for quantitative metagenomics are as follows. low input dna  libraries can utilize either a linker-amplified protocol  <cit>  optimized for the appropriate sequencing technology of choice  <cit>  or, for illumina sequencing, standard library preparations where adaptor:template ratios are carefully controlled. for samples with ultra-low dna yields , it is best not to risk failure in standard library preparations and to use instead a sequencing technology optimized linker-amplified protocol. future research directions include developing a mechanistic understanding of the non-intuitive, but replicable differences in linker-amplified metagenomes, as well as improving understanding of polymerase impacts and developing empirical datasets for a broader range of %g + c samples.

