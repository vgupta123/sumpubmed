BACKGROUND
recent years have seen intense interest in representing complex biological systems as networks, and a new research discipline, network biology, has arisen. in particular, markov networks and bayesian networks have been applied in many domains  <cit> . the former are based on undirected graphs, and the latter on dags . a key challenge in deriving such networks from the high-dimensional data typical of the genomics era is computational efficiency: model selection algorithms that perform well for small or moderate dimensions may be intractable for high dimensions. the approach of chow and liu  <cit> , which predates much of the development of probabilistic graphical models, is particularly efficient, being quadratic in the number of variables.

the chow-liu algorithm
suppose that we have a dataset with n observations of p discrete random variables x = v∈Δ. we call the possible values a discrete variable may take its levels, and label these  <dig> ...|xv|, so that |xv| is the number of levels of xv. we write a generic observation  as x = , and the set of possible cells as χ. we assume that the observations are independent and are interested in modelling the probabilities p = pr for x ∈ χ.

suppose also that the cell probabilities factorize according to a tree, that is, a connected acyclic graph, written  =  where x is the vertex set and e the set of edges. that is to say, the cell probabilities can be written p = ∏e∈ege for functions ge that only depend on the variables in e. so when e = , ge is a function of xu and xv only. chow and liu  <cit>  showed that the cell probabilities take the form   

where dv is the degree of v, that is, the number of edges incident to v. hence up to a constant the maximized log-likelihood is ∑∈eiu, v, where iu, v is given by  

n being the number of observations with xu = xu and xv = xv. the quantity iu, v is called the mutual information. it follows that if we use the iu, v as edge weights on the complete graph with vertex set x, and apply a maximum spanning tree algorithm, we obtain the maximum likelihood tree.

in statistical terms, iu, v is one half of the usual likelihood ratio test statistic for marginal independence of xu and xv, that is g <dig> = - <dig> ln q = 2iu, v, calculated using the table of counts {n} formed by cross-tabulating xu and xv. under marginal independence g <dig> has an asymptotic  distribution, where k = . the degrees of freedom k is the number of additional free parameters required under the alternative hypothesis, compared with the null hypothesis.

a very similar exposition can be given for multivariate gaussian data: here the sample mutual information is  

where  is the sample correlation between xu and xv. as before the likelihood ratio test statistic g <dig> = - <dig> ln q = 2iu, v. under marginal independence g <dig> has a  distribution.

algorithms to find the maximum weight spanning tree of a arbitrary undirected connected graph  with positive edge weights have been studied thoroughly. the following simple and efficient algorithm is due to kruskal  <cit> . starting with the null graph, repeat this step: among the edges not yet chosen, add the edge with the largest weight that does not form a cycle with the ones already chosen. when p -  <dig> edges have been added, the maximum weight spanning tree of  has been found. the algorithm can be implemented to run in o time.

as mentioned above,  is here taken to be the complete graph on x with edge weights given by {iu, v}u, v∈x. in practice the task of calculating these p/ <dig> edge weights dominates the time usage, so the complexity of the chow-liu algorithm may be taken to be o. methods to improve computational efficiency have been described  <cit> .

chow and liu's approach has been extended to more general classes of graphs than trees: to thin junction trees  <cit> ; to polytrees  <cit> ; to bounded tree-width networks  <cit> , and to mixtures of trees  <cit> . the approach has also been extended to tree-based models for gaussian processes  <cit>  and discrete-valued time series  <cit> . the consistency of the algorithm has been shown  <cit> .

RESULTS
extension to minimal aic/bic forests
a disadvantage with selecting a tree based on maximum likelihood is that it will always include the maximum number of edges, irrespective of whether the data support this or not. it is desirable to take account of the number of model parameters in some fashion. in the machine learning literature it is customary to penalize the likelihood using the minimum description length principle  <cit> , whereas in the statistical literature the use of information criteria is well-established, particularly aic  and bic . the former is defined as - <dig> ln l + 2r, where l is the maximized likelihood under the model and r is the number of parameters in the model, and the latter as - <dig> ln l + lnr. discussions of the relative merits of these criteria are available  <cit>  and need not be repeated here.

first, suppose that kruskal's algorithm is applied using penalized mutual information quantities  = iu, v - ku, v or  = iu, v - lnku, v/ <dig>  where ku, v is the degrees of freedom associated with iu, v, as described above. then it is easily seen that the tree with the minimum aic or bic is obtained. note that for gaussian data this will be identical to the maximum likelihood tree, since all edges have the same degrees of freedom. for discrete data with varying numbers of levels, the maximum likelihood tree and the minimal aic/bic tree will generally differ.

second, given a graph  =  with both positive and negative edge weights, consider the problem of finding the maximum weight forest, that is, the acyclic subgraph on vertex set v with maximum weight. let  be the graph derived from  by omitting all edges with negative weights. for any forest with vertex set v, removing all edges with negative weights would increase the total weight and not introduce any cycles. it follows that we can construct the maximum weight forest by finding the maximum weight spanning tree for each connected component of . we can do this simply by applying kruskal's algorithm to : it is not necessary to find the connected components explicitly.

so it is easy to find the minimal aic or bic forest by using penalized mutual information quantities as weights. this approach is attractive with high-dimensional data, since if the selected forest does consist of multiple connected components these may then be analyzed separately -- allowing a dimension reduction. we show below that the connected components of the minimal aic/bic forest are also connected components of the minimal aic/bic decomposable model, providing further justification for this procedure.

that using penalized likelihood with the chow-liu algorithm leads to forests rather than trees appears to be known in the machine learning literature  <cit> ; also,  <cit>  finds the bayesian map tree/forest in a similar way, but we have found no published references in the computational biology or statistics research literatures. we believe that it is a useful method that deserves to be far more widely known.

a numerical illustration
here we compare application of the algorithms to some simulated data involving three discrete random variables, xa, xb and xc with  <dig>   <dig>  and  <dig> levels respectively, and whose joint distribution is given by  

where pr = ',  and either   or  .

note that xa and xb are strongly associated but there is weak or no association between xa and xc.

in case , the ml tree algorithm incorrectly identifies  about 17% of time; otherwise it correctly identifies . penalizing with aic or bic increases the success frequencies to almost 100%. in case  the true model  is a forest rather than a tree, so the ml tree algorithm cannot select it. note that it almost always selects : since 2ib, c~  and 2ia, c ~ , the former is almost always greater than the latter. penalizing using aic and bic increases the success frequencies to 90% and 100%, respectively. for insight into the relative performance of aic and bic in this example, see  <cit> .

extension to mixed discrete and gaussian data
the second extension we consider is to data with both discrete and gaussian variables. our approach uses the class of undirected mixed graphical models  <cit> . consider a data set with n observations of p discrete random variables x = , and q continuous random variables y = . the models are based on the conditional gaussian distribution, that is to say, the conditional distribution of y given x = x is multivariate gaussian with mean, and possibly also variance, depending on x. models in which the variance depends on x are termed heterogenous, otherwise, they are called homogeneous.

tree  dependence models can be defined as mixed graphical models whose independence graphs are trees . but since their likelihood functions do not in general factorize according to  the theory does not carry through directly. to obtain the analogous factorization, we restrict attention to those models that have explicit maximum likelihood estimates, the so-called strongly decomposable models  <cit> . these are easily characterized. a mixed graphical model is strongly decomposable if and only if it is triangulated  and contains no forbidden paths  <cit> . see figure  <dig> 

a forbidden path is a path between two non-adjacent discrete vertices passing through continuous vertices. since trees and forests are acyclic, they are triangulated, and since they contain at most one path between any two vertices, we can simplify the criterion as follows: a tree or forest dependence model is strongly decomposable if and only if it contains no path between discrete vertices passing through continuous vertices. we call such a tree  an sd-tree . in an sd-tree the discrete vertices induce a connected subgraph.

to apply the algorithm we need to derive the mutual information between a discrete variable xu and a continuous variable yv. the marginal model is a simple anova model . let s <dig> = ∑k - )2/n, and write the sample cell counts, means and variances as . in the homogeneous case, the mutual information is iu, v = n ln/ <dig>  where . there are k = |xu| -  <dig> degrees of freedom. in the heterogeneous case, the mutual information is iu, v = n ln/ <dig> - , with k =  <dig> degrees of freedom. the expressions given here assume that all parameters are estimable: when this is not so, they need to be modified slightly, but we omit the details.

we also need to modify kruskal's algorithm. as before an undirected graph  with positive weights is given. starting with the null graph, we repeatedly add the edge with the largest weight that does not form a cycle or a forbidden path. it is shown below that this returns the maximum weight sd-forest.

about the forbidden path restriction
we describe here a perspective on the forbidden path restriction that gives useful insight. graphical models encode sets of conditional independence relations, and if two graphical models encode the same set of conditional independence relations they are termed markov equivalent  <cit> . for example, each graph in figure  <dig> represents the conditional independence of xa and xc given xb. sample data from the joint distribution of xa, xb and xc supply information on which conditional independence relations hold and which do not, but cannot distinguish between the four graphs. to do this would require intervention in the system, for example by perturbing xa to see whether the distribution of xb is altered. for this reason algorithms to identify bayesian networks from sample data  <cit>  can only do this up to markov equivalence.

the dags that are markov equivalent to a given tree comprise a markov equivalence class. as illustrated in figure  <dig>  they are easily found. labelling a node  as a root and orienting all edges away from the root, induces a single-parent dag, that is, one in which all nodes have at most one parent. any node can be chosen as root. under such a dag, the joint distribution factorizes into  

where pa denotes the parents  of xu in the dag. models corresponding to the dag are constructed by specifying a marginal distribution pr and a series of conditional models for pr).

first consider the pure case, that is, when all variables are either discrete or continuous. in the discrete case, we can construct a model for the dag by specifying a multinomial distribution for xr and arrays of transition probabilities for the conditional models. in the continuous case, xr is gaussian and the conditional models are simple linear regressions. when xu and xv are both discrete or both continuous, the mutual information iu, v is symmetric, and is consistent with the conditional models for both pr and pr. it follows that a dag model in the markov equivalence class is essentially a reparametrization of the tree model, and so has the same maximized likelihood and penalized likelihood scores. so in the pure case the algorithm identifies a markov equivalence class of dags, just like other bayesian network selection algorithms. note that the search space is restricted to single-parent dags.

in the mixed case, however, the mutual information between a discrete xu and a continuous xv is asymmetric, and corresponds to an anova-type conditional model for pr but not for pr. so a dag model in the markov equivalence class is a reparametrization of the tree model only if the dag contains no edges pointing from continuous to discrete nodes. if the tree has a forbidden path, no such dag will exist: see for example figure  <dig>  if the tree has no forbidden paths, then a dag generated in the above way will have this property if and only if its root is discrete. so in the mixed case the algorithm identifies a subset of a markov equivalence class of dags, those generated using discrete roots. that only a subset is identified is due to a limitation of the model apparatus, not to any evidence in the data. the limitation is unproblematic provided that the discrete variables are prior to the continuous variables.

all this has two broad implications. the first is that, when interpreted causally, the tree and forest models allow at most one determinant of each variable. the second is that the approach implicitly assumes that discrete variables are prior to continuous ones.

a marginality property
in some cases the global optimality of the selected model holds under marginalization. the following result is shown below in the methods section. suppose that  is the maximum likelihood tree  for a variable set v and let the connected components of  be c <dig> ... ck, say. then   is the maximum likelihood tree  for the variable set a provided that  is connected, for each component ci.

for example, consider a genetics of gene expression study involving a set of discrete dna markers Δ and a set of continuous gene expression variables Γ. a central tenet is that dna can affect gene expression but not vice versa. suppose that the minimal aic/bic forest for v =  is . the forbidden path restriction implies that for each connected component ci of ,  is connected. hence  is the minimal aic/bic forest for the discrete data alone. it follows that  can be regarded as a chain graph model  <cit>  with two blocks, Δ and Γ, with Δ prior to Γ, consistent with the tenet.

some applications of the algorithm
we show the results of applying the algorithm to three datasets.

study of leucine-responsive protein  in e. coli
the first dataset stems from a previously reported gene expression study  <cit> . the stated purpose of this was to identify the network of genes that are differentially regulated by the global e. coli transcription factor, leucine-responsive regulatory protein , during steady state growth in a glucose supplemented minimal salts medium. lrp has been reported to affect the expression of approximately  <dig> genes  <cit> . gene expression in two e. coli bacteria strains, labelled lrp+ and lrp-, were compared using eight affymetrix ecoli chips. the lrp+ strain is the control or wild type, and the lrp- strain is the experimental type, with the lrp gene knocked-out. four chips were hybridized with rna from the lrp+ strain, and four chips with rna from the lrp- strain. the raw data were preprocessed using standard methods and the algorithm applied to the derived data. the dataset had n =  <dig> observations and  <dig> variables, comprising  <dig> continuous variables  and one discrete variable, strain.

our implementation of the algorithm  took about  <dig> minutes on a laptop running windows xp to find the minimal bic forest. this is too large to display here, so instead we examine an interesting subgraph.

the regulatory system of e. coli has been well-studied, and it is interesting to note that other studies confirm that sera and gltd are targets of lrp  <cit> . indeed, lrp has many targets:  <dig> lrp-binding sites have been identified  <cit> , so it is certainly not true that lrp only targets sera and gltd. we have not been able to find other reports that the five distant genes -- ndk, pnt, ptsg, nupg and atpg -- should be directly or indirectly regulated by lrp.

the minimal bic forest provides a provisional causal model for the effect of lrp, and in this sense more directly addresses the stated goal of the study than a conventional analysis of differential expression. however, given the small number of observations in the study, it is clear that the network identification and any interpretations based on this are highly uncertain.

gene expression profiling in breast cancer patients
the second dataset comes from another gene expression study  <cit> , whose purpose was to compare the gene expression profiles in tumours taken from two groups of breast cancer patient, those with and those without a mutation in the p <dig> tumour suppression gene. a dataset containing a subset of the study data is supplied along with the r library grbase. the dataset has n =  <dig> observations and  <dig> variables, comprising  <dig> continuous variables  and the class variable. there are  <dig> cases  and  <dig> controls . the gene expression variables were filtered from a larger set, and all exhibit differential expression between the two groups. they have been standardized to zero mean and unit variance, but since the mixed graphical models used here are location and scale invariant, this does not affect the analysis.

the algorithm took about  <dig> seconds to find the minimal bic forest. figure  <dig> shows the radius seven neighbourhood of the class variable. the graph suggests that the effect of the p <dig> mutation on the gene expression profile is mediated by its effect on the expression of a gene with column number  <dig>  this gene is cdc <dig>  a gene involved in cell division. to examine this hypothesis more critically we could apply a richer class of models to this neighbourhood of genes, but that would take us outside the scope of this paper. figure  <dig> also shows some apparent hub nodes, including  <dig> ,  <dig> ,  <dig> ,  <dig>  and  <dig> , that appear to play a key role in the system. see table  <dig> of  <cit>  for further information on p <dig> - associated genes.

genetics of gene expression using hapmap data
the third dataset comes from a large multinational project to study human genetic variation, the hapmap project http://www.hapmap.org/. the dataset concerns a sample of  <dig> utah residents with northern and western european ancestry, the so-called ceu population, and contains information on genetic variants and gene expression values for this sample. the subjects are not unrelated , but the analysis ignores this. the genetic variants are snps . datasets containing both genomic and gene expression data enable study of the the genetic basis for differences in gene expression. this dataset is supplied along with the r library ggtools.

for illustrative purposes, the first  <dig> polymorphic snps and  <dig> gene expression values are here used in the analysis. if non-polymorphic snps were included, they would appear as isolated vertices in the sd-forest, but it is more efficient to exclude them beforehand. as may be characteristic for snp data, there are many ties in the mutual information quantities, so there may be multiple sd-forests with minimal bic. the algorithm took about  <dig> seconds to find the one shown in figure  <dig> below.

the main component of the sd-forest consists of a large connected block of snps, attached to most of the gene expression nodes via snp number  <dig> at the bottom of the figure. there are also  <dig> or so gene expression nodes adjacent to the snps as singletons, and a component of nine gene expression variables connected to snp number  <dig> in the centre of the graph. snp number  <dig> is possibly a gene expression hotspot and there are several potential hub nodes among the gene expression values.

the sd-forest does not allow study of the joint effect of snps on gene expression values since, as we have seen, in trees and forests variables may have most one determinant. the minimal bic forest obtained can be regarded as a special case of a chain graph model with two blocks, with the snp data in the first block and transcript abundance data in the second block, as mentioned above. this framework would be well-suited for further analysis of the data, allowing study of the joint action of snps on gene expression values.

discussion
deriving networks from high-dimensional data is a key challenge in many disciplines, and many different approaches have been proposed: for example, using approximation techniques  <cit>  or low-order conditional independence tests  <cit> . one broad approach is to consider restricted classes of graphs, for example triangulated graphs  <cit> , interval graphs  <cit>  and others mentioned above, for which faster algorithms can be applied. the chow-liu algorithm falls into this class. its utility is due to its remarkable computational efficiency, which reflects the simplicity of the graphs used. at the other end of the spectrum, it has been shown that selecting general bayesian networks by maximizing a score function is np-hard  <cit> .

in this paper we have described some simple extensions to chow and liu's method that enable forests with minimal aic or bic to be found, and allow datasets with both discrete and gaussian variables to be handled. in the previous section we demonstrated that useful insights into various high-dimensional datasets may be obtained by this method.

trees and forests are too simple to be realistic models of complex biological systems. nevertheless we believe that they can give a preliminary understanding of the overall dependence structure, and can be put to a number of practical uses.

firstly, we can use the selected model as a start model in a search algorithm based on richer, but more computationally demanding, model classes. since trees are triangulated, the class of  decomposable models is a natural choice for high-dimensional data. as described above, trees and forests represent markov equivalence classes of dags, so the minimal aic/bic forest can also be used as start model in bayesian network search procedures.

secondly, we can regard properties of the selected model as proxies for corresponding properties of the true, underlying network. properties that can be used in this way include connectivity, path length and degree. provided we can assume that the data are generated by a joint undirected model, we can model the connected components of the selected forest separately. this may allow substantial dimension reduction. it is natural to use the selected forest to identify neighborhoods of interesting variables for more detailed analysis: in effect, this uses path length in the forest as a proxy for minimum path length in the unknown true network. similarly, we can identify interesting features such as hub nodes -- nodes of high degree -- that may play a special role in the true network.

recently there has been interest in network motifs -- patterns of interconnections between small numbers of nodes that occur significantly more often than could be expected by chance  <cit> . for a review of motif discovery algorithms, see  <cit> . many of these motifs, such as the feed-forward or bi-parallel motifs, will not appear in trees due to the single-parent restriction discussed above. for this reason trees and forests appear to be too restrictive for motif discovery.

as pointed out by a referee, there are some similarities between the chow-liu algorithm and the aracne algorithm  <cit> . like the chow-liu algorithm, this algorithm initially computes the mutual information quantities iu, v for all node pairs . it forms an initial graph  by including all edges for which the iu, v exceeds a given threshold. the data-processing inequality states that if xu and xw are conditionally independent given xv, then iu, w < min. this is used to prune all complete triplets in , that is, all triplets xu, xv, xw with all three edges present in , by removing the edge with the least mutual information. since the condition given in the data-processing inequality is sufficient but not necessary, that the inequality holds does not imply that the condition is true, and the authors acknowledge that the process may incorrectly remove edges.

nevertheless the heuristic is reported to perform well when the true graph is a tree or is tree-like  <cit> .

although mixed graphical models have been studied for some time  <cit> , their adoption by the machine learning community seems to have been limited. as illustrated above, some natural application areas include comparative microarray studies, to model the effect of an intervention or class variable on gene expression, and genetics of gene expression studies, involving both discrete dna markers  and continuous responses . in both cases the discrete variables are clearly prior to the continuous variables. the conditional gaussian assumption is a distributional assumption that is not necessarily fulfilled for all continuous variables; but log-transformed gene expression values have been found to be approximately gaussian, and this assumption provides the basis for conventional analyses of differential expression.

an attractive aspect of the algorithm is that it allows different measures of mutual information to be used -- for example, measures based on specific genetic models. however, we consider it a key advantage of the models described here that they are embedded in a broader class of models for more general dependence structures, which provides an inferential framework for systematic model diagnostics and development.

CONCLUSIONS
the approach is generally useful as a preliminary step towards understanding the overall dependence structure of high-dimensional discrete and/or continuous data. trees and forests are unrealistically simple models for biological systems, but can nevertheless provide useful insights. in microarray studies the method supplements lists of differentially regulated genes, by suggesting a possible network of interrelationsships between these. other uses include the following: identification of distinct connected components, which can be analysed separately ; identification of neighbourhoods for more detailed analyses; as initial models for search algorithms with a larger search space, for example decomposable models or bayesian networks; and identification of interesting features, such as hub nodes.

