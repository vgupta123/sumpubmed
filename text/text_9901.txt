BACKGROUND
the development of high-throughput sequencing technologies in recent years  <cit>  has led to a massive increase in genomic data represented by counts. these count data are distinct from those acquired using bead and array technologies in that they are fundamentally discrete, rather than continuous, in nature. rather than measurements of intensity, we acquire counts of the number of times a particular sequence is observed in a library, whether the source is genomic dna, dna fragments produced by immunoprecipitation, mrna or small rnas. analyses of such sequence data are often concerned with detecting differential representation, that is, the discovery of data which are differentially represented between sets of biological replicates, particularly, but not exclusively, in analyses of transcriptomic data. these analyses are often challenging due to the small sample sizes available as a consequence of the relatively high cost of sequencing experiments.

this type of data first emerged from the serial analysis of gene expression   <cit> , and a number of approaches were put forward for its analysis. most of the early methods did not properly allow for replication or, when they did, could only be used to compare two groups. baggerly et al  <cit>  and lu et al  <cit>  introduced modelling approaches based on the overdispersed logistic and overdispersed log-linear distributions respectively that are able to handle both replicate data and multiple comparisons between groups. robinson and smyth derived an 'exact test' method based on the negative binomial distribution  <cit> , and further developed this approach using a moderated test statistic sharing information across genomic locations to stabilize dispersion estimation in small samples  <cit> . this approach showed improvements in accuracy compared with the overdispersed logistic and log-linear approaches, but the methods are limited to pairwise comparisons. a recently developed method, degseq <cit>  takes an alternative approach, assuming normality of the log-ratios of the data from different biological samples conditional on the log geometric mean of the data. another recent method deseq <cit>  also makes the assumption of a negative binomial distribution, but adds the assumption of a locally linear relationship between over-dispersion and mean expression levels of the data. these later methods have not yet been fully described, but again appear strictly limited to pairwise comparisons.

we develop here an empirical bayesian approach that is able to increase the accuracy of predictions by borrowing information across the dataset, but which removes the restriction of only considering pairwise comparisons and allows us to analyse more complex experimental designs. we are able to show that our method gives equivalent or improved performance in both simulated and biological data when compared to existing methods for the discovery of differential expression in pairwise comparisons, and offers improvements in performance for more complex designs.

in order to address the problem of more complex experimental designs involving multiple groups of samples, we develop our method in a very general form by first establishing a framework for describing diverse patterns of differential expression within a dataset. using this framework to define a set of models, we seek to establish posterior probabilities of each model. finally, we demonstrate the applicability of our method to these experimental designs on simulated data, and are able to show substantial improvements in performance using our method.

methods
we adopt and adapt the nomenclature of robinson and smyth  <cit>  to describe sage data as this seems generally applicable to the data from high-throughput sequencing technologies. a set of data acquired by sequencing a cdna library contains a number of sequence tags. since in sage data, there is only one tag per mrna molecule, robinson and smyth  <cit>  examine methods for detecting differentially expressed tags between samples. however, in a number of applications made possible by high-throughput sequencing, we may wish to group multiple tags together and acquire a single count for that grouping. for example, with whole transcriptome mrna or small rna data, we may wish to consider the total number of counts for all tags coming from a defined locus. in either case, for each distinct tag or grouping of tags, we have an ordered list, or tuple, of discrete counts with the sample order the same in each tuple. in the work that follows, we therefore refer simply to tuples, without needing to specify whether these are counts of individually sequenced tags or aggregated counts of multiple tags. the library size is a measure of the total number of counts in a given library, or some surrogate measure of library size as discussed by bullard et al  <cit> , and is used as a scaling factor for the observed data.

approach
we take an empirical bayesian approach to estimate the posterior probabilities of each of a set of models that define patterns of differential expression for each tuple. this approach begins by defining each of our models in terms of similarity and difference between samples. for a given model, we seek to define which samples behave similarly to each other, and for which sets of samples there are identifiable differences. in order to assess the posterior probabilities of each model for each tuple, we consider a distribution for the tuple defined by a set of underlying parameters for which some prior distribution exists. samples behaving similarly to each other should possess the same prior distribution on the underlying parameters of the tuple, while samples behaving differently should possess different prior distributions. we develop our method based on the negative binomial distribution for the tuple data, and derive an empirical distribution on the set of underlying parameters from the whole of the data set.

an important advantage of our method is that the evaluation of posterior probability for multiple models is simply achieved. for this reason, the techniques described are developed in a very general form.

model definitions
in forming a set of models for the data, we consider which patterns are biologically likely. in the simplest case of a pairwise comparison, we have count data from some samples from both condition a and condition b. if we suppose that we have two biological replicates for each condition, then there are four libraries, a <dig>  a <dig>  b <dig>  b <dig>  where a <dig>  a <dig> and b <dig>  b <dig> are the replicates. in most cases, it is reasonable to suppose that at least some of the tuples may be unaffected by our experimental conditions a and b. the count data for each sample in these tuples will then share the same underlying parameters. however, some of the tuples may be influenced by the different experimental conditions a and b. for such a tuple, the data from samples a <dig> and a <dig> will share the same set of underlying parameters, the data from samples b <dig> and b <dig> will share the same set of underlying parameters, but, crucially, these sets of parameters will not be identical. we can thus treat our models as non-overlapping sets of samples. our first model, of no differential expression, is thus defined by the set of samples {a <dig>  a <dig>  b <dig>  b2}. our second model, of differential expression between condition a and condition b is defined by the sets {a <dig>  a2} and {b <dig>  b2}.

more complex models
in the simple example described, only two models are plausible, and this framework may seem overly complex. however, in experimental designs involving multiple sample groups, many more models are possible. as an example, we consider the next most complex experimental design, involving samples from three distinct conditions a, b and c. in this case, for a given tuple, either the data are equivalently distributed across all samples, or they are equivalently distributed under two conditions but not under the third, or they are differently distributed in all three conditions. there are thus five models which we need to consider.

in the first of these, all samples are equivalently distributed, and so the model is defined by the set {a <dig>  a <dig>  ..., b <dig>  b <dig>  ..., c <dig>  c <dig>  ...}. we then need to consider the three models under which there is equivalent distribution under two conditions but not the third. the first of these models can be described by the sets {a <dig>  a <dig>  ..., b <dig>  b <dig>  ...}, {c <dig>  c <dig>  ...}, in which the data from condition a and condition b are distributed equivalently, and the data from condition c are differently distributed. similarly, we need to consider the other two models in which a single condition differs from the other two, {a <dig>  a <dig>  ..., c <dig>  c <dig>  ...}, {b <dig>  b <dig>  ...} and {b <dig>  b <dig>  ..., c <dig>  c <dig>  ...}, {a <dig>  a <dig>  ...}. finally, we need to consider the model defined by the sets {a <dig>  a <dig>  ... }, {c <dig>  c <dig>  ... }, {a <dig>  b <dig>  ...}, in which the data from all three conditions are differently distributed.

it is clear from considering even this relatively simple example that the number of potential models rises rapidly as the number of different experimental conditions increases. we should also note, however, that in many cases we will be able to exclude particular models based on biological knowledge , and so the complexity of the system need not grow too rapidly. our task is now to determine the posterior probability of each of our models, given the data, for each tuple. this will allow us to form ranked lists of the tuples, ordered by the posterior probabilities of a particular model .

one interesting advantage of determining posterior probabilities, rather than significance values  for each comparison, is that, since we acquire posterior probabilities for each model and each tuple, and since these models are mutually exclusive, it is trivial to combine models of interest by summing the posterior probabilities. for example, if we are interested not in any specific type of differential expression, but simply in whether or not differential expression of any type exists in our data, we can acquire the probability of differential expression of any type by summing the posterior probabilities of all  models that describe differential expression. we can then rank the tuples on these probabilities as well as on the probabilities of individual models.

equivalence of distributions
suppose we have the count data from a set of n samples a= {a <dig>  ..., an}, such that the observed data for a particular tuple, c, is given by  where uic is the count for a particular tuple c for sample i. for each sample ai, we also have the library size scaling factor li. for each tuple, then, we can consider the data to be

 dc={,} 

now we consider some model m on these data defined by the sets {e <dig>  ..., em}. if, in this model, the samples ai and aj are in the same set eq, then we know that they have the same parameters of underlying distribution θq. we can define a set k = {θ <dig>  ..., θm}. for notational simplicity, we will also define the data associated with the set eq as dqc = {, } given a model m for the data, then the quantity of interest for each tuple c is the posterior probability of the model m given the data dc, that is

  ℙ=ℙℙℙ 

we can then attempt to calculate ℙ by considering the marginal likelihood

  ℙ=∫ℙℙdk 

negative binomially distributed data
there are a number of possible distributions which could be used for dc|k, m and k|m. one approach that seems natural is to assume that the data are poisson distributed and the parameters gamma distributed, thus modelling the rarity of any individual molecule being sequenced and allowing a form of the poisson-gamma conjugacy to be used in calculating ℙ. however, as robinson and smyth  <cit>  point out, this model fails to take into account the extra variability introduced by biological replication. an assumption that the data are negative binomially  distributed may be used to account for this variability. robinson and smyth  <cit>  showed the existance of over-dispersion in real data, and we are also able to see this in the data set we introduce below. furthermore, lu et al  <cit>  show in simulated data that an assumption of a negative binomial distribution can be robust even if the data are not truly negative binomially distributed.

in the case of equal library sizes, it is possible under an assumption of a negative binomial distribution to develop an exact test for the likelihood of observing the data given non-differential expression. the problem of unequal library sizes can be approached by generating 'pseudodata' that is approximately identically distributed to the real data but has a common library size. this is the approach taken by robinson and smyth  <cit> . as an alternative to this approach, we use numerical methods in an empirical bayesian approach that allows us to retain the real data, using library size as a scaling factor. we consider a sample ai belonging to the set eq with library size li. we now assume that the count in this sample at tuple c, uic is distributed negative binomially, with mean μqli and dispersion ϕq, where θq = . then one parametrization can be defined as

 ℙ=ΓΓuic!ϕq−1uic 

there is unfortunately no obvious conjugacy that can be applied as in the poisson-gamma case. however, if we can define an empirical distribution on k then we can estimate ℙ numerically. we assume first that the θq ∈ k are independent with respect to q. then

 ℙ = ∫ℙℙdk       = ∏q∫ℙℙdθq 

this assumption reduces the dimensionality of the integral and thus improves the accuracy of the numerical approximation to the integral.

next we suppose that for each θq ∈ k we have a set of values Θq that are sampled from the distribution of θq. then we can derive the approximation  <cit> 

  ℙ≈∏q1|Θq|  ∑Θq   

the task that then remains is to derive the set Θq from the data.

empirically derived distributions on k
we can derive an empirical distribution on k by examining the whole dataset. for each set of samples eq, we would like to find some estimate of the mean and dispersion of the distribution underlying the data from a single tuple, dqc. by similarly finding estimates of the mean and dispersion for a large number of tuples, we would have our sampling Θq. the chief difficulty here lies in properly estimating the dispersion. for example, suppose that the data from a given tuple shows genuine differential expression. if the model that we are testing assumes that there is no differential expression, then the dispersion will be substantially over-estimated for this tuple. since we do not know in advance which tuples are genuinely differentially expressed and which are not, we need to consider the replicate structure of the data in order to properly estimate the dispersions. we define the replicate structure by considering the sets {f <dig>  ... fs} where i, j ∈ fr if and only if sample aj is a replicate of ai.

given this structure for the data, we can estimate the dispersion of the data in a tuple dc by quasi-likelihood methods  <cit> . quasi-likelihood methods have been shown to give good estimations of the dispersion of a single tuple in this setting  <cit> . we first define μ∧rc=〈{uicli:i∈fr}〉, and then choose ϕc such that

  2 ∑r∑i∈fr{uiclog−log} =   n− <dig> 

taking this value for ϕc we can then re-estimate the values μ^ic by maximum likelihood methods, choosing the values for μ∧ic that maximise the likelihoods

 ℙ=∏i∈fr  ΓΓuic!ϕc−1uic 

for each r.

we then iterate on our estimations of ϕc and μ^ic until we achieve convergence.

this gives us a value for ϕc. we then need to estimate the mean of the distribution underlying the data dqc, that is, for the set of samples in eq, which we can easily do by fixing the value acquired for ϕc and estimating the mean μqc by maximum likelihood methods, choosing the value for μqc that maximises the likelihood

 ℙ=∏{i:ai∈eq}ΓΓuic!  ϕc−1uic 

for each q.

we can then form the set Θq = {} by repeating this process for multiple h, and are then able to calculate ℙ from eqn  <dig> 

this method of estimating the dispersion assumes that the dispersion of a tuple is constant across different sets of samples. in most cases, where the number of samples is low, this is likely to be the best approach. where there is some expectation that the dispersion will be substantially different between sets of replicates, there may be advantages to estimating the dispersions individually for each of the different sets of samples in each model, while still considering the replicate structure within these sets. this is easily done by restricting the data  to dqc when estimating the dispersion in eqn  <dig>  we found no substantial differences between these approaches in simulation studies  and so show only the results acquired when the dispersion of each tuple is assumed constant.

estimation of prior probabilities of each model
a number of options are available when considering the prior probabilities of each model ℙ required in eqn  <dig>  if we are able to estimate these from other sources, this may provide the optimum solution. however, in many cases we may not be able to provide a reasonable estimate of prior probabilities. we propose that the methods suggested by smyth  <cit>  for estimating proportions of differentially expressed genes in analysis of microarray experiments may reasonably be adapted to estimate these priors. we begin by choosing  some value p to use as the prior probability for the model m in order to estimate the posterior probability ℙ for the cth tuple. but then we can derive a new estimate

 p′ = 〈ℙ〉c 

for the prior probability of model m. by iterating until convergence, we acquire estimates of the prior probabilities for each model. in practice, we find that the initial choice of the ps has no substantial effect on the values to which they finally converge. this method is straightforward to implement, but potentially allows for positive feedback and hence over-estimation of the prior probability of a model .

an alternative to this approach would be to establish some distribution on the prior probabilities of our models and find the marginal posterior probability of the data based on this distribution. one approach to this might be to use the distribution of posterior probabilities as an approximation to a distribution on the priors. we could then use a numerical integration method to re-estimate the posterior probabilities, and iterate as before. however, in practice this method is extremely computationally intensive and offers little improvement in the accuracy of the predictions made .

the scaling factor ℙ
finally, we need to consider the scaling factor ℙ in eqn.  <dig>  since the number of possible models on m on a is finite, though potentially large, the scaling factor ℙ can be determined by summing over all possible m, given appropriate priors ℙ. in practice, the number of models may be limited by only considering those that are biologically plausible, or by imposing some distribution on the number of sets in m in a similar manner to lönnstedt et al's approach  <cit>  for analysis of variance in microarray data.

RESULTS
we use both simulated and real data to compare the method we have developed to the previously developed methods of robinson and smyth  <cit>  as implemented in the edger  <cit>   bioconductor  <cit>  package, the overdispersed log-linear model of lu et al  <cit> , the overdispersed logistic model of baggerly et al  <cit> , and the recently released methods degseq <cit>   and deseq <cit>  . we compare these methods to our empirical bayes approach as implemented in the r package bayseq , with the default settings used for the bayseq and edger packages. overall, we found that the default settings of the edger package seem to give good performance. alterations to the default settings, in particular to the 'moderation' parameter, caused some small improvements in performance for some simulations but degraded it slightly in others. we have, therefore, used the default settings here as in real-world applications it will be difficult to determine how to alter these settings to optimise performance. the recommended method of operation for the deseq package is to infer library sizes from the data. however, we observed that this gave extremely poor performance in simulations in which a large proportion of the data are differentially expressed in a single direction. we therefore use the known library sizes in the implementation of the deseq method, as we also do for all other methods, with the exception of degseq, which does not accept library size as a parameter. the degseq package has multiple modes of operation; we found that the ma plot-based method with random sampling  performed best on simulated data  and have therefore used this approach  in the comparison studies.

comparison of methods for pairwise comparisons: simulated data
we begin by applying the methods being evaluated to the simulation studies described in robinson and smyth  <cit> . we choose to replicate these simulation studies, and the manner in which the results are presented, in order to allow direct comparisons between our method and previous approaches to this problem. the purpose of these simulations is to establish the ability of the methods to rank the tuples in order of differential expression and evaluate the number of true and false positives for the top n tuples.

random dispersion simulations
robinson and smyth  <cit>  suggest one possible simulation for high-throughput sequencing count data. the library sizes, li, are sampled from a uniform distribution between  <dig> and  <dig>  these library sizes are considerably smaller than those available from the current generation of sequencing technologies. however, increasing the library size to better reflect current levels does not significantly alter the conclusions drawn, because the 'library size' is, in effect, a scaling factor. all tuples are simulated from a negative binomial distribution, and we simulate differential expression by varying the means of the distribution from which they are sampled.

for a non-differentially expressed tuple c, we simulate the data with means λcli where the λc are sampled randomly from a a set of values empirically estimated by the edger method from a sage dataset consisting of both normal and cancerous cells  <cit> .

ten percent of the ten thousand simulated tuples are differentially expressed. in order to produce both over and under-expression in our simulated data, we simulate the differentially expressed data in one of two ways, where the alternatives are chosen at random for each tuple. we can simulate the data for the first n <dig> samples with means λcli/b while the data from the remaining n <dig> samples are simulated with mean λclib alternatively, we can simulate the data for the first n <dig> samples with mean λclib while the data from the remaining n <dig> samples are simulated with mean λcli/b.

small  and moderate  numbers of libraries are compared, with large  and moderate  differential expression. dispersions are randomly sampled from a gamma distribution with shape =  <dig>  and scale =  <dig> .

for the bayseq method, posterior probabilities were calculated for each tuple for each of two models, one defining differential expression between the first n <dig> libraries and the second n <dig> libraries and one defining no differential expression between any library. figure  <dig> shows the estimated posterior probability of differential expression plotted against the estimated log fold change for a single simulation with b =  <dig> and n <dig> = n <dig> =  <dig>  we see a 'wine glass' shaped plot, characteristic of this analysis.

the 'stem' of the goblet is made up of tuples with low fold change and reasonably high levels of expression. with these tuples, it is relatively easy to identify them as non-differentially expressed, and so these tuples have low posterior probability of differential expression. however, some tuples with low fold change also have very low absolute values. with low absolute values in a tuple, it becomes harder to determine whether or not the tuple is genuinely differentially expressed or not, and so these values tend to have slightly higher posterior probabilities of differential expression than tuples with high absolute values but low fold change. the top of the stem, with a posterior probability of differential expression of around  <dig> , is thus composed of tuples that have only one or two counts observed in any sample. for these very low expression tuples, changes of only one or two counts in a sample can lead to a relatively large fold change difference. however, these small changes do not substantially affect the posterior probability and so, although we see a spread in the fold change at the top of the stem, the posterior probability of differential expression remains low for these tuples. we tend not to see a similar spread for the tuples near the base of the stem as these tuples tend to have a high expression. for a tuple with a high expression to show a high fold change, but nevertheless have a low posterior probability of differential expression, there must be a very high dispersion associated with such a tuple, which will not often occur.

in the arms of the wine glass, we see that as the fold change increases, the posterior probability of differential expression also increases, although there is a wide range of posterior probabilities for  a fold change of  <dig>  we see this range of posterior probabilities of differential expression for a given fold change as the posterior probability also depends heavily on both the dispersion observed within the data, and the level of expression of the tuple, since, as before, it is easier to tell whether or not a highly expressed tuple is genuinely differentially expressed or not. for high posterior probabilities of differential expression, we see an increased density of tuples, predominately consisting of truly differentially expressed tuples.

as in robinson and smyth  <cit> , false discovery rate  curves are used to assess the ability of the methods to successfully rank the tuples. false discovery rates for these data are calculated by  <cit>  on the basis of one simulation. for increased robustness, we estimate mean false discovery rates for the top n tuples over  <dig> simulations . for the bayseq method, the tuples were ordered by the posterior probability of differential expression and true and false positive rates were calculated on the basis of this ordering. for the edger, the overdispersed log-linear, overdispersed logistic, deseq and degseq methods, the tuples were ordered on the basis of the p-values estimated by each method.

in these simulations, the bayseq method appears to perform as well or better than the existing methods. the performance of the bayseq approach is virtually identical to that of edger for small numbers of libraries . for larger numbers of libraries, bayseq appears to offer an improvement in performance over edger. for small b, the overdispersed log-linear approach seems to show comparable performance to edger and bayseq. for larger b, however, particularly for higher numbers of selected tuples, the edger and bayseq methods perform considerably better than the log-linear approach. the log logistic, deseq and degseq methods always perform poorly compared with both the edger method and the bayseq approach.

to establish whether this difference in performance for these methods is meaningful in a practical sense, we estimate from these analyses that if we were to validate the top  <dig> tuples identified by edger, bayseq, and the overdispersed log-linear model fit, for n <dig> = n <dig> =  <dig>  b =  <dig> we would expect  <dig>  false positives for the bayseq method,  <dig>  from edger and  <dig>  for the overdispersed log-linear approach. for n <dig> = n <dig> =  <dig>  b =  <dig>  we would expect  <dig> ,  <dig> , and  <dig>  false positives from bayseq, edger and the overdispersed log-linear approaches respectively. however, for the higher numbers of libraries, where n <dig> = n <dig> =  <dig>  for b =  <dig> we expect  <dig> ,  <dig>  and  <dig>  false positives, while for b =  <dig> we expect  <dig> ,  <dig>  and  <dig>  false positives from the bayseq method, edger and the overdispersed log-linear approach respectively. for higher numbers of libraries, therefore, we achieve a practically meaningful improvement by using the bayseq method.

fixed dispersion simulations
for completeness of comparison with previous methods, we also consider a less realistic simulation first developed by lu et al  <cit> . we simulate ten library sizes as before. the tuples are again simulated from a negative binomial distribution but now with a fixed dispersion ϕ of either  <dig> ,  <dig>  or  <dig> .  <dig> non-differentially expressed tuples are simulated with mean λli, and  <dig> tuples are chosen to be differentially expressed; those from libraries 1- <dig> are again simulated with mean λli while those from libraries 6- <dig> are simulated with mean bλli, and so we see only over-expression of libraries 6- <dig> in the data. these simulations are applied with λ =  <dig>  and b =  <dig> 

as in robinson and smyth  <cit> , we examine the results by considering receiver-operating characteristic  curves for all analyses . the performance of the degseq methods is strikingly poor. further investigation showed that this loss of performance is associated with the large proportion of tuples that are differentially expressed in the same direction, that is, all up-regulated in libraries 6- <dig>  if either the proportion of differentially expressed tuples is reduced sufficiently, or if similar proportions of up-regulation and down-regulation exist in the data, then the performance the degseq method improves substantially. this poor performance occurs becuase of the assumption by the degseq method that the mean of the log-ratios between samples is approximately zero. in this case, because the differential expression always occurs in the same direction, this assumption fails. this may be a problem in real-life applications if large numbers of genomic features are all affected similarly.

of the remaining methods, we see that as the dispersion increases, the performance of all the methods decreases; however, the bayseq approach appears to outperform all existing methods for all values of ϕ, in that, for low false positive rates, the bayseq method has higher true positive rates. this effect is particularly noticeable for simulations involving higher dispersion. the overdispersed logistic model in general performs worse than the overdispersed log-linear method. in turn, the overdispersed log-linear approach is outperformed by the deseq method, which is outperformed by the edger method. this roughly corresponds to the relative performance of these methods on the more realistic simulations.

comparison of methods for pairwise comparisons: biological data
we next apply the methods to a set of data acquired by illumina sequencing small rnas  from leaf samples of arabidopsis thaliana . the experimental data are taken from two wild-type samples and two rdr <dig>  knockout samples. it is known that rdr <dig> is required for production of tasrnas   <cit> . we would therefore expect to see differential expression of tasrnas in a comparison between the wild-type and the mutant samples; specifically, under-expression of tasrna associated small rna sequences in the rdr <dig> knockouts.

we consider only those sequence reads that perfectly matched the arabidopsis genome as defined by the arabidopsis information resource   <cit>  . sequences were matched using the patman algorithm  <cit> . a total of  <dig> unique small rna sequences matching the genome were observed in the data, and the total number of genome matching reads, used to define the library sizes, were  <dig>   <dig>   <dig> and  <dig> for the two wildtype and two rdr <dig> mutant knockout samples respectively. we examined this data for overdispersion by performing likelihood-ratio tests on the reads acquired for each sequence by fitting both a poisson model and an alternative negative binomial model, allowing for both differences in library size and between the two sample types. although many sequences showed no significant variation from the poisson model, a substantial number showed very significant variation . this effect is noticeable particularly in those sequences which have a high average count, presumably because it is for these sequences that overdispersion can reasonably be detected.

we identified  <dig> different small rna sequences that perfectly matched the tasrna loci  and matched nowhere else in the genome.  <dig> of these small rna sequences showed higher expression in the rdr <dig> mutant than in the wild-type samples and these were excluded, leaving  <dig> potential true positives. we applied the methods to the count data for each small rna sequence, seeking differential expression between the wild-type samples and the rdr <dig> knockout samples. we then ranked the sequences by the extent to which they are reported as differentially expressed by each method. we would expect a sizeable fraction of our  <dig> potential true positives to appear near the top of the list.

multi-group experimental designs
we next illustrate the application of our method to a more complex experimental design involving multiple experimental conditions. we return to the example discussed in the methods section, in which we have sequence data from three conditions; condition a, condition b and condition c, with n libraries from each condition. there are five different models for these data; one in which there is no differential expression of any kind, three models in which one of the conditions shows differential expression compared to the other two conditions, and one model in which data from all three conditions are different from each other.

we investigate the ability of our method to detect such patterns of differential expression by adapting the more realistic simulations proposed by robinson and smyth  <cit> . in total, data from 3n libraries are simulated, of which two thousand tuples are in some manner differentially expressed. the library sizes, and dispersions of each tuple are simulated as before, as are tuples with no true differential expression.

five hundred tuples are simulated to have equivalently distributed data between condition a and condition b, with data from condition c differently distributed. in order to simulate both over and under-expression in the data, we simulate the data in one of two ways, where the alternatives are chosen at random for each tuple. we can simulate the data from condition a and condition b from a distribution with mean λcli/b and the data from condition c from a distribution with mean λclib. alternatively, we simulate the data from condition a and condition b from a distribution with mean λclib and the data from condition c from a distribution with mean λcli/b.

another five hundred tuples are simulated similarly such that tuples have equivalently distributed data in conditions a and c, but differently distributed data in condition b, while a third five hundred tuples are simulated such that tuples have equivalently distributed data in conditions b and c, but differently distributed data in condition a.

a further five hundred tuples are simulated in such a way that the data from all three conditions are differently distributed. for a given tuple, we simulate data from condition x <dig> from a distribution with mean λcli. for condition x <dig>  we simulate from a distribution with mean λcli2b, and for condition x <dig> we simulate from a distribution with mean λcli2b conditions a, b and c are randomly allocated to be conditions x <dig> x <dig>  x <dig> for each tuple, and so we see various patterns of differential expression between these samples.

we again evaluate the methods by looking at the false discovery rates. in this analysis, we are interested in the ability of our method to accurately identify each of the different types of differential expression by simultaneously considering all possible models for the data. we can also consider the ability of our method to detect differential expression of any kind by taking the sum, for each tuple, of the posterior probabilities of all five models describing differential expression. we can thus consider four fdr curves for each type of differential expression present in the data, and an additional fdr curve for data showing differential expression of any kind.

for the pre-existing methods, in the overdispersed log-linear and the overdispersed logistic approaches, we are able to form linear models that describe all possible patterns of differential expression present in the data. for the edger, degseq and deseq methods, we are only able to carry out pairwise comparisons and so we carry out three analyses on each dataset, one for each pattern of differential expression in which a single experimental condition is differentially expressed when compared to the other two. we are unable to consider directly, by the method of pairwise comparisons, the pattern of differential expression in which all three experimental conditions are differentially expressed, and so we do not use the edger, degseq or deseq methods for the identification of tuples of this type.

we present the data  for b =  <dig> and n =  <dig> or n =  <dig>  again, for increased robustness, we estimate mean false discovery rates for the top n tuples over  <dig> simulations for all models. as would be expected, for all methods the false discovery rates are almost identical for the three models in which a single experimental condition is differentially expressed when compared to the other two conditions. we therefore show only the results for differential expression of conditions a and b compared with condition c, together with the results for the case where all three experimental conditions are differentially expressed. in this more complex experimental design, bayseq outperforms all existing methods, particularly as the number of libraries available increases. perhaps surprisingly, the edger method does better than either the overdispersed log-linear or overdispersed logistic method in discovery of differential expression that can be expressed in terms of a pairwise comparison, as, to a lesser extent, does the deseq method. the degseq method, however, does not perform as well as any of the alternatives in these comparisons.

CONCLUSIONS
we present an empirical bayes method, bayseq, that can simultaneously establish posterior probabilities of multiple models of differential expression and performs as well as or better than any existing techniques for identifying pairwise differential expression in count data. more significantly, this method enables the analysis of experimental designs involving multiple sample groups while using the whole data set to establish parameters on the level of dispersion present. this allows considerably greater accuracy in the analysis of more complex experimental designs than has previously been possible, and is hence a significant step forward in the analysis of the data being produced by high-throughput sequencing technologies. that the method produces posterior probabilities of models of differential expression, rather than significance values, offers a number of advantages in downstream analysis; for example, it becomes a simple matter to find an expected number of differentially expressed tuples, or to combine posterior probabilities of multiple models.

in developing this method, we have established a well-defined framework for describing diverse patterns of differential expression between samples. we then take an empirical bayes approach in order to establish posterior probabilities of each model for each tuple. we achieve this by assuming that the data for each tuple is negative binomially distributed. this assumption is supported by the presence of over-dispersion in true data  and the work by lu et al  <cit>  showing that an assumption of a negative binomial distribution can be robust even if the data are not truly negative binomially distributed. we then estimate empirical prior distributions for the parameters of these negative binomial distributions. this is a very natural approach as high-throughput sequencing provides a large set of data from which to estimate prior distributions. an interesting feature of this approach is the flexibility we gain in choosing how to estimate the parameters of the negative binomial distributions. we have chosen to use quasi-likelihood methods here as they seem to give better performance than maximum-likelihood approaches . however, other methods of estimating these parameters  might be adapted to further improve the performance of our method. we can also deal easily with the problem of different library sizes, as this parameter can be built directly into the assumptions about the distribution of the data.

our method is relatively computationally intensive, but has been implemented to take advantage of parallel processing, such that an analysis of pairwise differential expression of ten thousand tuples coming from ten samples takes approximately  <dig>  minutes running on a machine with eight  <dig> ghz processors. we compare bayseq to the method implemented in the edger package, because this has been reported to outperform other existing approaches for pairwise comparisons  <cit> , and is the most commonly used method for analysis of count data . we also include comparisons to two recently developed methods for pairwise comparisons, deseq and degseq, and to the older overdispersed logistic and overdispersed log-linear methods as these latter approaches allow for analysis of more complex experimental designs.

comparisons of the methods on pairwise data are made on the basis of previously developed simulation studies  <cit> , as well as on real biological data, and the bayseq method developed here performs comparably to, and in some cases better than any existing approach. we also see that one of the recently developed methods, degseq, shows extremely poor performance when there is a high proportion of unidirectional differential expression, although it is comparable to both edger and bayseq in other circumstances. when the dispersion of data is constant, the proportion of differentially expressed tuples is high, and the differential expression is unidirectional, there appears to be a clear improvement in performance by bayseq compared to all other methods using their default parameters .

for analyses of data with random dispersions , bayseq performs almost identically to edger for small numbers of libraries, but show a marked improvement in performance for larger numbers of libraries. the overdispersed log-linear method performs almost identically to bayseq for low levels of differential expression, but shows substantially worse performance for higher levels of differential expression. the deseq and degseq methods show noticably worse performance compared to bayseq as both the level of differential expression and the number of libraries increases, with degseq performing particularly poorly. the overdispersed logistic method is always amongst the worst performers.

analysis of real biological data again suggests that our method performs at least as well, and potentially better, than edger, while both methods appear to substantially outperform the overdispersed log-linear and logistic methods. the deseq method again appears to perform poorly compared to bayseq. however, in these data degseq shows performance comparable to bayseq.

the chief advantage of the empirical bayes method developed here, however, is its ready applicability to more complex experimental designs, although at present these methods remain limited to comparisons involving multiple groups, and are not able to account for, for example, paired samples. one possible extension to this work is thus the generalisation of the methods to some form of generalised linear model approach. however, our method is able to simultaneously identify multiple types of differential expression from a single experiment. in comparisons of the methods using simulations of an experimental design involving multiple groups , the bayseq method appears to offer substantial improvements over existing methods. figure  <dig>  which compares the performance of the bayseq method in identifying different patterns of differential expression, suggests that we should expect some loss of performance for the bayseq method for more complex patterns of differential expression. however, we can also see that combining models to acquire, for example, posterior probabilities of differential expression of any kind, is a valuable approach.

our method thus provides performance as good as or better than previous methods whilst enabling experimenters to simultaneously consider many diverse sample types in a single sequencing experiment. we believe that this is a valuable approach representing an important step forward for the analysis of count data from sequencing experiments.

availability and requirements
the empirical bayes method developed in this paper are implemented in the software package bayseq <cit>  for the cross-platform computing environment r  <cit>  . bayseq is released under the gpl- <dig> licence as part of the bioconductor project  <cit>  at http://www.bioconductor.org/packages/ <dig> /bioc/html/bayseq.html

authors' contributions
tjh designed and implemented the bayseq package and drafted the manuscript. kak drafted the manuscript. all authors read and approved the final manuscript.

