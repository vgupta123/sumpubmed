BACKGROUND
the engineering of ontologies is still a new research field. there does not yet exist a well-defined theory and technology for ontology construction. this means that many of the ontology design steps remain manual and a kind of “art” and intuition  <cit> . there exists a variety of different ontologies, constructed for different purposes and projects.

as far as the biomedical ontologies are concerned, during the last years there have been major efforts in the biological community for organizing biological concepts in the form of controlled terminologies or ontologies  <cit> . a key difference between terminologies and ontologies is that the former lack the semantic depth of the latter. however, when it comes to design, terminologies can serve as basis for ontologies and vice-versa. an example where a terminology can serve for ontology is that of the gene ontology  <cit> , which provides a controlled vocabulary to describe gene and gene products in any organism. on the other side, the gene ontology next generation  project  <cit>  aims at the migration of current bio-ontologies to a richer and more rigorous status, using formal representation languages like owl. examples of true ontologies are the galen project  <cit>  and the systematized nomenclature of medicine   <cit>  which are based on description logic for concept representation and the foundational model of anatomy   <cit>  which is based on frames representing information about anatomical classes, designed so that content can be maintained as a dynamic resource and can be used as terminologies.

there have also been developed systems to provide interoperability among different ontologies, such as the unified medical language system  <cit>  in order to provide a common frame of reference among the different research communities. the open biomedical ontologies  foundry  <cit>  hosts over  <dig> open source ontologies associated with phenotypic and biomedical information, such as the mouse anatomy   <cit>  and the cell ontology   <cit> . bodenreider and stevens  <cit> , blake and bult  <cit>  and baker et al.  <cit>  give overview on biomedical ontologies, the consortia involved, formalisms as well as semantic web technologies and representation tools.

semantic meta-information provided in the form of ontologies has proven useful in order to search  <cit>  or index large collections of documents . meta-information found for text documents is often general  or still too complex for an automated evaluation . finding terms of controlled vocabularies in text overcomes this shortage, while relations between terms provide the necessary navigation structures.

ontological background knowledge can serve to answer questions with knowledge-based search engines, by easing the task of finding relevant documents through the term automatic annotation  <cit> . in the domain of lipoprotein metabolism, for example, a search for “analphalipoproteinemia” will retrieve articles for tangier's disease, which is actually a synonym. in case of a syndrome, such as the “metabolic syndrome”, in a properly designed ontology the articles retrieved will contain symptoms and other characteristics for it . researchers explore literature on different parameters that can affect the lipoprotein metabolism, such as the phenotype, genotype and age of the patients/animals tested, environmental factors and lifestyle, specific lipoprotein and enzyme concentrations and others. questions like ‘what is the activity of cholesterol ester transfer protein in diabetes’, ‘which cells/tissues is apoe expressed in’, ‘what is the impact of a fish oil diet on metabolic syndrome individuals’, ‘which genes/proteins/metabolites are hypertension-specific’ can be answered with the use of a well designed ontology on lipoprotein metabolism, containing terminology found in literature with semantically interconnected terms.

the gopubmed search engine  <cit>  allows users to explore pubmed search results with the gene ontology   <cit>  and medical subject headings   <cit> . gopubmed retrieves pubmed abstracts for a search query, detects terms from the go and mesh in the abstracts, displays the subset of go and mesh relevant to the keywords and allows for browsing the ontologies and displaying only articles containing specific go and mesh terms. the search engine is developed in a way that any ontology  can be easily integrated and used for a domain-specific literature search. one of the benefits of such an ontology-based literature search is the categorization of abstracts according to a specific ontology, allowing users to quickly navigate through the abstracts by category and providing an overview of the literature. it can also automatically show general ontology terms related to the original query, which often do not even appear directly in the abstract.

in this paper, we introduce design principles for ontologies used for text mining, based on our personal experience with the manual development of a lipoprotein metabolism ontology. a key problem in this context is the generation of terms, which is corroborated by castro et al.  <cit> , who compared different ontology design methods and tools all of which lacked automated term recognition. the paper is organized as follows. we first introduce the design principles followed when designing the lipid metabolism ontology and turn to the question how to automate the generation of terms. we introduce two methods to identify terms and evaluate them together with two existing tools for this task.

methods
ontology design principles
the open biomedical ontologies  foundry provides ontology design principles concerning the syntax, unique identifiers, content and documentation of ontologies to be added or edited, as a common agreement between users/editors. obo principles that are not discussed later  refer mainly to the use of a common shared syntax , the insertion of a unique identifier per term, the relations included in the obo relation ontology and the clearly delineated content . the success of the obo representation format is attributed to its informal expressivity, combined with the ability of conversion into owl and vice-versa.

the only obo principles we did not follow were the free availability and collaboration with other obo foundry members, due to corporate reasons. however, we present the knowledge acquired and the problems faced during the ontology design. the following guidelines, as well as the decisions, compromises and problems described later derive from our experience during the manual development of the lipoprotein metabolism ontology.

some basic steps that should be followed during the design of any ontology include identifying the range of intended users, deciding on the purpose and main research area of the ontology and defining/predicting further possible applications . important points to start from are literature scanning for deciding on the basic concepts as well as the insertion of a textual definition for each term. formulation of questions is also crucial  <cit> . examples of questions that researchers from unilever needed to answer were: “what is the activity of cholesterol ester transfer protein  in diabetes?”, “which tissues is apoe expressed in?”, “what is the impact of fish oil diet in metabolic syndrome patients?”, etc, indicating that terms such as ‘cetp’, ‘diabetes’, ‘apoe’, ‘diet’, ‘fish oil diet’, ‘metabolic syndrome’ and ‘patient’ should be included in the ontology. reusing existing ontologies that may cover to some extent the ontology under design or could be inserted as a separate branch of the ontology is also a possibility. in the case of the lipoprotein metabolism ontology , we needed to include information on diet. for this purpose, we included the nutrition ontology from the nci cancer nutrition ontology project  <cit>  as a separate part under diet. deciding on a label for each concept is one of the most crucial steps during the structuring of the ontology. this task is difficult for humans as it requires good knowledge of the domain of interest so as to group concepts on the hierarchy in a semantically meaningful way. it is even more difficult for machines to do this automatically. there has been previous work on automatic labeling of document clusters  <cit>  by using the most frequent and most predictive words in clusters of documents, but there is still work to be done on that. one must firstly concentrate on the semantics of a term, decide what is really needed to be expressed with that term and then choose the appropriate name. last, but not least, and perhaps one of the very first steps of the designing procedure is the selection of a suitable ontology editor. we used the protégé owl plug-in  <cit>  for building the ontology and cmaptools  <cit>  for visualization. ontology visualization is crucial when the knowledge engineer and the domain expert are two different persons and need to agree on the different versions of the ontology.

with go we experienced some limitations for text-mining. for example, it is unlikely that a descriptive label such as ‘cell wall ’ will literally appear in text. a comprehensive overview of such problems is provided by smith et al.  <cit> . there often exist ontology terms that are unlikely to appear as such in text but are rather of a structuring nature. for example, the terms ‘hydrolase activity, acting on ester bonds’  or ‘hydrolase activity, acting on carbon-nitrogen  bonds’  include several different types of information: activity , type of bond affected  and exception  . these should be  <dig> different branches of the tree, combined with relations, therefore structuring ‘logical formulas’. for example, in the case of the second term , the exception could be expressed as a certain condition: the protein has a hydrolase activity and is acting on carbon nitrogen bonds, but not in all bonds . aranguren et al.  <cit>  provide a simple and indicative example of the problem: a person is a man or a woman, a man has testis, a woman has no testis, but what happens in the case of a eunuch ? there is a need for distinguishing between relations that are strict “always” rules and “normally” or “usually” relations that can also allow for exceptions. biomedical terms are usually connected with “usually” relations between them. another example is the definition of mammals: a simple definition  <cit>  can be ‘warm-blooded vertebrate animals belonging to the class mammalia, including all that possess hair and suckle their young’. therefore, one can say that all mammals give birth to and suckle their young. but there exists the exception of the monotremes, which are mammals that lay eggs instead of bearing live young. the definition here would be “mammals are animals that normally bear live young and suckle them” and the exception “monotremes are mammals that lay eggs”. another example is given by hoehndorf et al.  <cit>  , where “every instance of a human body has as part an appendix”, corresponding to an idealized  “normal” human. however, an individual human body may lack an appendix as a part, demonstrating that canonical ontologies do not always represent default knowledge and should include exceptions. hoehndorf et al. developed a methodology for representing canonical domain ontologies within the obo foundry by adding an extension to the semantics for relationships in the biomedical ontologies that allows for treating canonical information as default. rector  <cit>  explored some of the alternatives in owl and related languages for dealing with issues such as exceptions  and limited expressivity. rector's analysis is divided in four cases, which can be resolved with owl, more precise logical formulation , more explicit context and generalized common information and other more complicated methods.

compositional structure of terms is a major bottleneck for ontology design, especially when it comes to text mining, as the relations between terms must be as simple as possible. ogren et al.  <cit>  have performed an analysis of the term names in the go to investigate substring relations between terms and revealed that  <dig> % of all go terms contain another go term as a proper substring. these terms can be categorized into two groups: go terms that contain other go terms as proper substrings  and ‘hydrolase activity’ ) and go terms that contain strings that seem to recur frequently .

text-mining ontologies can be extensions of annotation ontologies which enrich annotation ontologies with synonyms suitable for text-mining. some decisions and compromises have to be made on the relationships and on the labels defined during the concept hierarchy design.

decisions that need to be made during the ontology design
keep or dismiss a term: when using the ontology for text-mining over a specific biomedical domain, it is important to include terms specific enough to define the domain and also general enough to cover it entirely. for example, including information on ‘kinetics’ during the design of the lipoprotein metabolism ontology is crucial. but ‘kinetics’ is too general as a term, as the distinction between different kinds of kinetics is important . on the other hand, the term ‘lipoprotein kinetics’ is too specific and documents mentioning it do not cover all essentials known in lipoprotein kinetics. searches for “lipoprotein kinetics”, “lipoprotein” and “kinetics” and retrieval of relevant articles  lead to the decision that the best term to use for ‘lipoprotein kinetics’ is the exact term. there already exist previous efforts on automatic labeling of document clusters and identification of ontology components, based on natural language processing techniques or hierarchical and suffix-tree clustering  <cit> .

decide on ontology design/relations: the ontology must be a subsumption ontology. it can be either a structured vocabulary/terminology containing only child-parent relationships  between concepts or an ontology of different complexity that could be easily translated into a simple hierarchy. it should also be rich in synonyms and textual definitions , that would be useful for disambiguation. for the lipoprotein metabolism ontology we used the protégé owl plug-in, with concepts being the term labels  and instances the term synonyms/variants .

decide on synonyms: researchers do not have strict and formal ontologies or nomenclatures in their minds when composing a scientific article and therefore use terminology of differing granularity. they often use parent terms to refer to a child term, or vice-versa ’ is child of ‘cardiovascular disease’, but in many cases authors are treating them the same). again literature scanning, for both child and parent term, will help to clarify how researchers refer to different terms. another problematic case is that of the different lipoprotein subclasses  where there do not exist clear limits between them. depending on the way of measurement and the difference in surface lipid content, they can be expressed in different ways. for example, in the case of ldl, there are  <dig> different subclasses based on particle size , but there are also references such as ‘small dense ldl’ or ‘buoyant ldl’ that are very often found in text but could contain a mixture of different subclasses. since we need to keep only a simple hierarchy with parent-child relationships, we do not incorporate any “definitional” information . in these cases, we put the synonyms according to the authors’ use, for example ‘small dense ldl’ as a synonym for ldl iii and ‘buoyant ldl’ or ‘large ldl’ as synonyms for ldl i  <cit> . a similar example from the go is that of ‘transporters and carriers’. in every day language ‘transporter and carrier’ is the same as ‘transporters or carriers’, but logically they are different.

handle term variation: terms like ‘tangier disease’, ‘tangier's disease’ or ‘tangiers disease’ are variants of the same term. terms like ‘ldl i’, ‘ldl-i’, ‘ldl-1’, ‘ldl 1’, ‘ldl1’ and ‘ldli’ are also variants of the same term. the process of manually inserting such lexical variants  in the ontology is tedious and time-consuming. there exist programs that handle such variations by producing the normalized form of a term, such as the umls lexical variant generation program  <cit> . for the lipoprotein metabolism ontology we did not use such a variant generation program. we included only term variants we could find in literature.

compromises that need to be made, problems, inconsistencies
there must be made some compromises to retain a correct ontology  and still get the best possible results from text-mining:

ambiguity resulting either from identical abbreviations for different terms , or ambiguous term labels  is always a problem. abbreviations and acronyms should be included in the ontology, but conservatively or with an appropriate algorithm that could handle them. word sense disambiguation is a salient point here; knowledge sources like long-form/short-form combinations, domain  and collocations  can be exploited to provide the correct sense of the term  <cit> . for the case of incomplete term labels, let us consider the following example: we are only interested in experiments performed in human patients and need to distinguish between human- and animal- referring articles. one option is to insert into the ontology only human-specific terms, such as ‘experimentee’, ‘patient’, ‘man’, ‘boy’, etc. ‘male’ cannot be in the ontology, since it could also be referring to animals. another option is to maintain a list of human- and animal- specific words or expressions and then transform the algorithm in a way that one could make a boolean selection  in the query and finally include or exclude the results for the specific selections.

try to avoid any possible inconsistencies. to illustrate the implication of inconsistencies on reasoning, let us describe the following example: a researcher is interested in the different lipoprotein levels in patients of different race and geographical location, since there has been evidence that these two factors affect lipoprotein metabolism. combination of geographical information as well as racial information in one part of the ontology is, therefore, needed. many articles refer to “african-americans” as “blacks”, so the term must be included under ‘ethnic group’. then the following must be valid: define ‘caucasian’, ‘african’ and ‘asian’ as ‘ethnic group’, ‘american’ is a ‘caucasian’, ‘african-american’ is a ‘african’, ‘african-american’ is a ‘american’, ‘african-american’ is ‘black’ , ‘caucasian’ is white  but ‘african-american’ cannot be ‘caucasian’ or ‘white’ . this is similar to the case of mammals that lay eggs or the ‘man, woman, eunuch’ example described earlier; people very often formulate rules such as “normally is-a”, as there are always exceptions. for the lmo we excluded the ‘american’ concept and added ‘african-american’ as child of ‘african’ and ‘hispanic-american’ as child of ‘caucasian’.

RESULTS
the lipoprotein metabolism ontology  was manually built in collaboration with domain experts from unilever for the purpose of document retrieval. it consists of  <dig> concepts and  <dig> additional synonyms, with an average term length of  <dig> . a concept as used here consists of a concept label and optional synonymous terms. a term can be any word or phrase of relevance to the studied domain. together with the nutrition ontology from the nci cancer nutrition ontology project  <cit> , the lmo contains in total  <dig> concepts and  <dig> additional synonyms, with an average term length of  <dig> . concerning the relations between the concepts, the mean number of parents is  <dig>  and the mean number of siblings is  <dig> . we did not include the nutrition ontology terms in the experiment, as we only wanted to compare the terminology created manually by us with the automatically derived terminologies from the different term extraction methods. for automatic term recognition , a ‘lipoprotein metabolism’-specific corpus was created, consisting of  <dig> abstracts collected from pubmed with the query “lipoprotein metabolism” . these  <dig> abstracts were the maximal number of articles where all methods delivered results. five different atr methods were tested on that corpus, namely text2onto, ontolearn, termine  <cit>  and two methods developed in-house, one considering the relative frequency  of a term in the corpus and the other  additionally using the document frequency derived from all phrases contained in ncbi's pubmed database. termine  <cit>  considers several statistical characteristics of the candidate term, such as the total frequency of occurrence in the corpus, the frequence of the term as part of other longer candidate terms  and the length of the candidate term . text2onto  <cit>  is based on algorithms calculating the relative term frequency and tfidf, as well as entropy and the c-value/nc-value used by termine in order to extract the concepts. it further exploits the hypernym structure of wordnet  <cit> , matches hearst patterns  <cit>  and others in the corpus in order to get the relations , but at this point we only examined the terminology extraction precision. ontolearn  <cit>  uses a linguistic processor and a syntactic parser in order to extract a list of syntactically plausible terminological noun phrases. for filtering “true” terminology, ontolearn is based on two measures, namely domain relevance and domain consensus, which calculate the specificity of a candidate term with respect to the target domain via comparative analysis across different domains as well as the distributed use of a term in a domain. ontolearn was excluded from further analysis, as it only generated a few terms so that a meaningful comparison would be possible, see table  <dig>  text2onto was only included in the analysis for  <dig> abstracts as it was not possible to process all  <dig> review article abstracts for “lipoprotein metabolism” listed in pubmed. we performed a bipartite analysis. we tried to automatically reconstruct the manually created lmo terminology, compared the terms predicted by the four methods to the current lmo terms and also evaluated manually the top  <dig> retrieved terms. all automatic comparisons between candidate terms and lmo were not case sensitive.

 listing of the top  <dig> predictions for tfidf, relfreq, termine, text2onto and ontolearn. terms relevant to the lipoprotein metabolism domain are marked with x.

reconstruction of lmo terminology
consider table  <dig>  which shows the percentage of terms that can be generated by the four methods. the first table lists the results for lmo alone, the second for lmo and terms considered relevant after manual inspection. furthermore, we distinguish precision and average precision. the latter takes the ranking of terms into account:

 average precision=∑r=1n×rel)number of retrieved terms, with

 rel=−2n2+2n

 the key finding is that among the top  <dig> predictions there are up to 51% terms, which are in the lmo or considered good terms by expert, implying that automated term recognition can play an important role in semi-automated ontology design.

where r is the rank of retrieval and p is the precision at a cut-off rank. for each of the four methods we list the percentage of relevant terms for the top  <dig>  top  <dig>  and top  <dig> predictions. the results show that the precision for the top  <dig> predictions for lmo ranges from 17-35% and 4-8% for the top  <dig> predictions. using lmo and the expert terms leads to better results of up to 75% for the top  <dig> predictions and up to 29% for the top  <dig>  considering the average precision and thus the ranking of terms, results for the top  <dig> predictions go up to 89% and for the top  <dig> up to 51%. generally, termine which favours long terms performs well for the top  <dig>  because long terms are a good indicator of a relevant term. however, there are many short terms, which are relevant, too. the tfidf and relfreq methods can pick up these terms, as they include background knowledge, i.e. frequencies of terms in pubmed. by and large, text2onto does not perform so well as it neither includes domain-specific background knowledge  nor the ranking pursued by termine, which is biased towards longer frequent terms. text2onto suggested short and very general terms, like ‘use’, ‘effect’, ‘study’, ‘event’, etc. although we explicitly deactivated the relation extraction part for this experiment, it is not clear why text2onto persisted in ranking these terms in the top of the list. overall, the results are encouraging, as they indicate that a large part of the terminology can be generated automatically.

concerning recall, consider table  <dig>   <dig> documents contain only 53% of the lmo terms literally. tfidf manages to predict up 39%, which is an encouraging result. increasing the document base to  <dig>  only 71% of the lmo terms are included indicating a possible upper limit. figure  <dig> provides an overview of the results we acquired from these comparisons. figures  <dig> and  <dig> provide zoom-ins of figure  <dig>  describing the performance of each method in the top  <dig> predicted terms.

 the table sets the upper limit of terms that can be found with text-mining: even a large text base with  <dig>  documents contains only 71% of lmo terms. tfidf can predict up to 38% of lmo terms.

                              lmo terminology predicted by tfidf
                              lmo terminology literally contained
discussion
the low coverage of the lmo in the data sets calls in question the document set selected and the suitability of the manually built lmo itself. the straightforward approach to select relevant documents from pubmed  did not return enough documents to cover all of the lmo.

the lmo terms that were absent from the  <dig>  pubmed abstracts were grouped in five categories: rarely occurring terms, rarely occurring variants of terms, very long terms, combinations of terms/variants and, finally, terms that should normally be easily found. terms such as ‘experimentee’  , ‘obesive’ , ‘test person’  and ‘central fatness’  are lmo terms, but rarely used by authors and, therefore, rarely appearing in pubmed. the second group contains variants of terms that appear rarely in pubmed, such as ‘apo-f’ , ‘apolipoprotein c-3’ , ‘idl i’ , ‘vldl chol’ , ‘diabetis’ , ‘free chol’ , ‘hypolipoproteinaemia’ , ‘insuline resistant’ , ‘slo syndrome’  and ‘sphingomyelinase deficiency disease’. however, we decided to include such terms in the lmo for completeness. the third category contains terms that are too long and, therefore, unlikely to appear as such in text: ‘receptor-mediated extra-hepatic cellular uptake’ , ‘macrophague cellular uptake’ , ‘predominance of large low-density lipoprotein particles’  and ‘apob <dig> containing particles’ . however, given the initial purpose of the lmo for document retrieval, these terms were included to be recognized by the ontology-based text-mining methods  <cit> . the fourth group is a combination of the previous two, i.e. lmo terms that are long terms and contain rare variants of lmo terms, such as ‘elevated plasma-tg level’ , ‘increased total chol’ , ‘long-lived test person’ , ‘apoprotein b <dig> kinetics’ , ‘elevated plasma tg concentrations’ , and ‘decreased hdl-chol’ . the last group contains lmo terms that appear often in pubmed and should normally be identified, but are probably absent from the document set, due to its size or specificity. such terms are ‘diabetes type i’ , ‘acetyl-coa c-acyltransferase’ , ‘apolipoprotein-c’ , ‘type-ii diabetic’ , ‘long-lived population’ , ‘middle-aged adult’ , ‘human body composition’ , and ‘lipid poor hdl’ .

the third and fourth groups of terms belong to the same category as the hydrolase activity example described earlier. composite terms like ‘receptor-mediated extra-hepatic cellular uptake’ and ‘predominance of large low-density lipoprotein particles’ could be easily broken into several semantic parts  and handled by an algorithm that could later compose them and still keep their semantics.

the terms that were predicted by most of the methods but were not in the lmo were further examined and grouped. these were either wrongly predicted ones, meaning phrases frequently occurring in the corpus, but not relevant to lmo,   or vocabulary that could extend the current ontology . this would include disease-specific terms such as ‘atherosclerosis’, ‘cardiovascular risk’ and ‘atherogenic dyslipidemia’, drugs or other chemicals such as ‘statins’, ‘ezetimibe’ and ‘torcetrapib’, or even method and therapy related terms like ‘dose’ and ‘lipid lowering therapy’.

availability
the tfidf term recognition is available as web service, described at 

CONCLUSIONS
as pointed out in  <cit> , automated term recognition is missing from many ontology design methologies. in this paper, we manually created an ontology for lipid metabolism with  <dig> concepts and  <dig> additional synonyms , we derived design principles and systematically evaluated four methods for automated term recognition.

automated predictions of up to  <dig> terms generate in the order of 40-50% useful terms. considering only the top  <dig> terms, the results improve up to 89% average precision for lmo + domain expert . this suggests that automatic term recognition  methods can aid and speed up the process of ontology design by providing lists of useful domain-specific terms, but that they cannot  replace the manually designed term lists. the key problem to further improve these results are composite terms which do not appear literally in text, like go's ‘hydrolase activity, acting on ester bonds’ or lmo's ‘receptor-mediated extra-hepatic cellular uptake’.

overall, our results show that ontology development can be performed in a semi-automatic way. the domain expert must have as initial input the output from an automatic term recognition method and proceed with enriching the ontology. the experiment as described aims at providing restrictions as well as decision points for including, excluding and reforming ontology terms. once the domain expert acquires the list of candidate terms, he/she needs to decide on the relations between them. formulation of questions is one of the most important steps in the ontology design process, helping to step from a list to an ontology.

we discussed principles for development of an ontology with text-mining as intended use, based on our personal experience from the manual development of the lipoprotein metabolism ontology and gopubmed. we related these principles to the performance of four different atr methods and their agreement with the manually built lmo. open problems relate to the choice of suitable text bodies for term recognition as well as generation of composite terms from basic ones.

list of abbreviations used
lmo – lipoprotein metabolism ontology

atr – automatic term recognition

obo foundry – open biomedical ontologies foundry

mesh – medical subject headings

go – gene ontology

owl – web ontology language

owl-dl – web ontology language-description logic

pmid – pubmed identifier

tfidf – term frequency inverse document frequency

relfreq – relative frequency

ncbi – national center for biotechnology information

nci – national cancer institute

ldl – low density lipoprotein

idl – intermediate density lipoprotein

hdl – high density lipoprotein

vldl chol – very low density lipoprotein cholesterol

apof – apolipoprotein f

competing interests
the authors declare that they have no competing interests.

authors' contributions
da and lp developed the lmo, da conceived the design principles and did the manual evaluation. tw implemented the tfidf and relfreq methods and automated the data collection and analysis. ms and ce supervised and coordinated the project. all authors have read and accepted the final manuscript.

