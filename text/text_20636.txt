BACKGROUND
given the large volume of data generated by microarray technology and the many sources of variation involved, including not only biologically relevant variation, but also technical variation that results from sample preparation and labeling, hybridization, and other processing steps  <cit> , methods for analyzing and interpreting the results are very important. an important component of these technologies is redundancy. for example, the affiymetrix® genechip® platform, employs many features  to interrogate each gene . these redundant probes are called a "probe set" and summarizing each probe set to arrive at a robust value representing the abundance of the associated transcript is one of the first steps in any analysis  <cit> . another important step is normalization to remove systematic array to array variation such as differential hybridization and scanning artifacts. some popular processing methods for these steps are the mas  <dig>  algorithm  <cit>  developed by affymetrix®, the robust multichip average  method developed by irizarry et al.  <cit> , and the dchip® method developed by li et al.  <cit> . each of these include normalization methods: mas  <dig>  uses a simple global scaling factor  <cit> , rma uses quantile normalization  <cit> , and dchip®  uses a rank-invariant set based method  <cit> . by definition, the global scaling method of mas  <dig>  cannot handle non-linear artifacts. furthermore, it may not even produce the optimal linear scaling factor as suggested by lu  <cit> . still, the mas  <dig>  method is commonly used and even preferred by some researchers for some applications  <cit> . rma has a number of advantages over mas  <dig>  including quantile normalization, which is a mathematically elegant solution for setting the intensity distributions equal for all arrays in the dataset  <cit> . however this is not always appropriate and may cause problems when the assumption of equal distributions is not met, for example when more probe sets are up-regulated than down-regulated as discussed by freudenberg et al.  <cit> . dchip® uses a rank-invariant set based normalization method on probe level data, however the dchip® approach selects one reference sample and compares all other samples to it, selecting a different rank-invariant set to normalize each sample. using our proposed method based on a global rank-invariant set to create a robust average reference, which we refer to as global rank-invariant set normalization  and applying it to the summarized probe set data from dchip®, we see a further reduction in specific types of systematic array to array variation.

for the purpose of this discussion, we will classify the variation of microarray data into three categories: biological, random, and systematic. biological variation is of interest to the researcher and may contain many different components. the random and systematic categories are both forms of technical variation. random variation has no biological relevance and is the result of uncharacterizable measurement errors. systematic variation also has no biological relevance, but is characterizable as a function of expression value. we are interested in systematic variation because it can be "modeled" and removed. for example, if any of the microarray processing steps  are non-linear functions of transcript abundance, and the conditions affecting these non-linear functions change from array to array or with biologic condition due to unbalanced gene expression, then systematic variation will be introduced between arrays and/or conditions. the goal of this work is to graphically show and mathematically remove this type of variation, which we refer to as "non-linear artifacts" or "skew". we use rank-invariant transcripts as reference points to detect and remove these non-linear artifacts. this is not a new concept, for example, li and wong  <cit>  use rank-invariant probes for normalization in their dchip software. however, we have extended this idea by selecting a global set of endogenous, rank-invariant, transcripts to generate average reference points used to normalize all samples in a dataset. we also apply our normalization as an additional step after using existing methods for summarizing probe sets. the efficacy of additional normalization at the "probe set level" has been advocated by others  <cit> . using a global rank-invariant set  reduces the risk of introducing noise into the dataset. applying our method as a post probe set summary method allows us the flexibility of using our favorite probe set summary method. in addition, the summarized probe set values should give the best estimate of true gene expression, so it makes sense to use these values when selecting the rank-invariant set. with the use of optimized probe set definitions as described by sandberg and larson  <cit> , this may become even more beneficial.

in our experience with microarray datasets, both from human cancer studies and animal models, it is common to have unbalanced up or down regulation of gene expression between two sample populations. when using the standard data processing methods discussed above, we often see an intensity-dependent skew when comparing conditions in such data. this skew, in turn, introduces errors in further statistical analysis and in the calculation of fold change. these errors will bias the results of gene selection based on statistics and fold change and can lead to the detection of "statistically significant" genes that are not in fact differentially expressed. grsn is a simple, yet robust, method for reducing this type of distortion, and minimizing the chances of obtaining misleading analysis results. we use simulated data to show that grsn reliably reduces non-linear skew even when actual gene expression is highly unbalanced. grsn does not introduce bias into the dataset by trying to balance the number or magnitude of up and down regulated genes. as a result, grsn performs well on a wide range of datasets, including datasets with as few as two samples.

RESULTS
visualizing non-linear technical variation in microarray data
in microarray datasets, we expect only a small fraction of the transcripts interrogated by an array to be differentially expressed. therefore, when utilizing a scatter plot to compare pairs of samples, we expect to see most transcripts centered along the diagonal line. when this is not the case, further normalization may be required. we have examined over  <dig> publicly available datasets, and found many to contain samples with systematic non-linear distortions apparent in their scatter plots. in this report, we will consider a variety of datasets demonstrating various degrees of non-linear distortions, and the effect of grsn correction. an example of non-linear distortions between microarray samples within a dataset is shown in fig. 1a. this graph compares two normal samples from a study of the inherited disease, fanconi anemia  using patient bone marrow samples run on the affymetrix® hg-u133a genechip®. there is a distinctive curve to the data in the scatter plot  when the mas  <dig>  method is used to process the data. this "frown" is even more evident when the data is plotted using a standard m vs. a plot . the m vs. a plot  <cit>  provides an optimal visualization of the ratio of two samples as a function of expression level. in fig. 1a, columns  <dig> and  <dig>  although not as pronounced, we also see a systematic skewing of the data when the rma or dchip methods are used to process this data . similar distortions can be seen in other samples in this dataset and additional examples from this and other datasets are shown in subsequent figures. we have developed a method called global rank-invariant set normalization  in an effort to reduce this type of non-linear technical variation.

global rank-invariant set normalization
grsn is based on the general idea of rank-invariant genes presented by li and wong  <cit> . we extend this idea to select a single, globally rank-invariant set of endogenous genes to be used to normalize all samples in a dataset. these are genes believed to be consistently expressed in all samples within a given dataset and should appear in roughly the same rank order in each sample when sorted by expression level. importantly, this ordering, or rank, should not be affected by the types of non-linear artifacts that this normalization method is designed to correct.

an overview of the grsn method is shown in figure 1b. briefly, all transcripts  are ranked in each sample of a dataset based on expression . the variance of the rank order for each transcript is then calculated across all of the samples. transcripts with the highest rank variance are discarded. the remaining transcripts are again ranked and the process is repeated in an iterative fashion. this iteration cycle is important because, for datasets with unbalanced numbers of up and down regulated transcripts, there can be a global shift of transcript rank order caused by the most differentially regulated transcripts. this global shift of the rank order will disappear as the most differentially regulated transcripts  are discarded during the first few iteration cycles. note that if we require the global rank-invariant set to have rank variance of zero for all transcripts, we will not typically have enough transcripts for an effective calibration curve, i.e. the set of transcripts with exactly the same rank order in all samples is too small. therefore, the iteration cycle is terminated when a reasonable number of approximately rank-invariant transcripts remain . these probe sets are considered the "global rank-invariant set" .

a single virtual reference sample is then created by taking the trimmed mean  expression value  for each summarized probe set , and m vs. a plots are generated comparing each sample to this virtual reference. this provides a visualization of the effect of applying grsn. fig.  <dig>  column  <dig> shows the m vs. a plots comparing sample  to the virtual reference of the gb dataset after the data is summarized using mas  <dig>  , rma , or dchip . we then generate a m vs. a plot of the identified gris transcripts only, comparing expression values from a given sample to expression values from the virtual reference sample . we use lowess  <cit>  to fit a smooth curve through these points . this smoothed curve is used as the calibration curve for this sample. we then calculate an intensity-dependent adjustment for transcripts in each sample which, when applied, will center the sample's gris on the horizontal line of the m vs. a plot . fig.  <dig>  column  <dig>  also shows the gris after calibration of this sample . fig.  <dig>  column  <dig>  then shows all transcripts after calibration of the sample compared to the virtual reference sample . this process is repeated for each sample, with a different calibration curve generated each time . using the trimmed mean values of the gris as the reference for normalization provides a robust average across all samples so that the linearity of the normalized data is not affected by a few samples with anomalous non-linear artifacts. note that these intensity-dependent adjustments are applied additively to the log scaled data and that this is equivalent to an intensity-dependent scaling of the original, non-log scaled data.

determining global rank-invariant set size
when selecting the gris, we aim to minimize the rank order variation among transcripts in the set. we do not attempt to select a set with no rank variation because this would normally result in too few transcripts to define a smooth calibration curve. therefore, when choosing the size of the global rank-invariant set, we must balance the desire for rank-invariant transcripts with the need for a sufficient number of calibration points. the effect of selecting too few transcripts is demonstrated in fig. 3a. here, multiple calibration curves  are graphed for a single sample. the five red curves represent calibration curves generated using gris sizes of  <dig>   <dig>   <dig>   <dig>  and  <dig>  at this size range, the curves are erratic and segmented. the five green curves represent sizes of  <dig>   <dig>   <dig>   <dig>  and  <dig> . at this size range, the calibration curves smooth out and become more consistent. we conclude that gris sizes in the range of  <dig> to  <dig> are insufficient, but that sizes in the range of  <dig> to  <dig>  appear to be adequate.

next, we look at the effect of different gris sizes on the detection of statistically significant genes. for each candidate rank-invariant set size, we apply the grsn method followed by a statistical analysis to identify lists of up and down regulated genes. we used the ebayes and toptable functions from the limma  <cit>  package in bioconductor with a fc cutoff of  <dig>  and a false discovery rate  cutoff of  <dig>   to select statistically significant genes. the fdr method  <cit>  applies to multiple hypothesis testing. it uses calculated p-values to control the rate of false positives expected from a set of statistical tests. to compare two candidate sizes for the gris, we compare these lists of genes. for the two up regulated lists, we count the number of genes that are in one or the other list, but not both. we do the same for the down regulated lists and add the results. this gives us the number of genes affected by the change in the rank-invariant set size. in fig. 3b, we use a bar graph to report the numbers of affected genes when different rank-invariant set sizes are compared. as a reference point, we compare grsn with a gris size of  <dig>  to no grsn normalization . this serves to quantify the effect of the grsn method itself. to quantify the "stability" at reasonably sized rank-invariant sets, we compare  <dig> k to  <dig> k,  <dig> k to  <dig> k and  <dig> k to  <dig> k . the effect of applying grsn  is large while the effect of changing the rank-invariant set size above  <dig> k  is small. in summary, the size of the rank-invariant set does not seem to be critical. any value in the range of  <dig> k to  <dig> k should work equally well on the current high-density arrays. however, given that we want to minimize rank variance in our selected gris, we use a default size of  <dig> k  for high density arrays with greater than  <dig>  probe sets.

the choice of the smoother span supplied to the lowess function  can also effect the calibration curves. we have evaluated a range of values for this parameter  and have chosen  <dig>  as the default for grsn. however, in a few cases, this default value may not be optimal. for example, some datasets  produce a gris that is not evenly distributed along the full transcript expression range. in these cases, a larger smoother span may be needed to produce a smooth calibration curve. in the case of the simulation study described below, we chose  <dig>  for the smoother span . the tradeoff is that increasing the smoother span can lead to calibration curves that do not properly track the gris at the extreme ends of the transcript expression range. we recommend starting with the default value of  <dig> , but checking the calibration curves plotted by the grsn method for continuity with the gris .

grsn improves statistical performance in simulated data
when evaluating the performance of grsn on a given microarray dataset, we are confronted with the typical problem of not knowing a priori which transcripts are truly regulated and by how much. therefore, we have created simulated datasets where we have artificially introduced differential gene expression so that we do know a priori which genes are regulated and to what degree. we then introduce simulated, systematic, non-linear artifacts  typical of what are seen in real world datasets. this data allows us to evaluate the ability of standard statistical methods to identify the correct up and down regulated genes before the simulated artifacts are introduced, after they are introduced, and after applying grsn to correct the simulated artifacts. thus, the performance of grsn can be evaluated with respect to reducing unwanted variance and improving statistical gene selection performance.

to create a relatively realistic simulated dataset, we used a dataset from a cell culture model with  <dig> biological control replicates  to obtain typical background variance   <cit> . in the first stage of the simulation we randomly partitioned the samples in this dataset into two equal subsets, a and b. we then randomly selected unique subsets of genes and introduced simulated fold changes  in the b samples.  <dig> genes were set with a fc of  <dig>  up,  <dig>  <dig> fold up,  <dig>  <dig> fold up,  <dig>  <dig> fold up; and then  <dig> were set down  <dig>  fold,  <dig> down  <dig> fold, and  <dig> down  <dig> fold. this gives a total of  <dig> up regulated genes with fc in the range of  <dig>  to  <dig> compared to only  <dig> down regulated genes with fc in the range of - <dig>  to - <dig> so that both the number and degree of up and down regulation is heavily biased in the up direction. in the second stage of the simulation we added random non-linear skew to each sample. the third and final stage of the simulation was to apply grsn to correct the skew just added. we have repeated this complete simulation, starting with the random partitioning of the original  <dig> control samples,  <dig> times . figure 4a shows m vs. a plots demonstrating typical skews introduced in a selected sample in two of the  <dig> different simulations. this figure shows a selected sample compared to the virtual reference sample both before and after the introduction of a simulated skew, and then shows the effect of applying grsn to correct the simulated skew .

at each stage of each simulation , the standard deviation  within replicates and the average fc between a and b sample subsets is calculated for each gene. a goal of grsn is to reduce the sd among replicates. as shown in table  <dig>  the average sd among replicates is highest in the data with simulated skew and is substantially reduced when grsn correction is applied. the sd after grsn correction is almost identical to the sd for the original data before simulated skew is introduced . in addition to removing unwanted technical variation, it is important to preserve biologically relevant variation. in this simulation, the biologically relevant variation is the simulated fc introduced in sample set b. here we calculate the average for all simulated fc ranges up or down across all simulations. in our study, the average fc value stays relatively constant  at each stage of the simulation , demonstrating that grsn does not adversely affect the relevant variation .

average standard deviation  among replicates and average fold change  are reported for each stage of our simulated data study . sd values for each gene are calculated separately for sample set a and sample set b and then averaged across both sample sets and all  <dig> simulations. fc values are calculated for each gene by taking the average for sample set b and dividing by the average for sample set a then averaging over all  <dig> simulations. the values reported in each column are  1) the average sd for all genes, 2) the average sd for the up and down regulated genes, 3) the average fc for up regulated genes, and 4) the average fc for down regulated genes. values reported in the top row are for data with simulated fc only. values in the middle row are for data with simulated skew added. the bottom row reports values after grsn correction of the simulated skew.

next we evaluated the effects of the introduced skews and grsn correction on statistical gene selection performance in our simulated datasets. statistically significant genes were selected with ebayes using a fc cutoff of  <dig>  and a fdr cutoff of  <dig> . we evaluated the numbers of true positive  , false positive , and false negative  genes found at each stage of the data simulation for each of the  <dig> simulations run. figure 4b shows the results using box plots showing the range of gene selection results across all  <dig> simulations. the statistical results from the data with simulated artifacts, but no grsn correction, vary widely from simulation to simulation, resulting in a substantial reduction in identified true positives , and an abundance of false negatives and false positives . false negatives are more common than false positives due to the random nature of the introduced skew. however, grsn corrects these issues and the results both before the simulated artifacts and after the simulated artifacts have been corrected with grsn are very stable .

we also evaluated the ability of grsn to preserve the fold change  values introduced in the above simulation. we tabulated the average fc for each range over all  <dig> simulations. this tabulation was done for each stage of the simulation: after simulated fc, after simulated skew, and after grsn correction. box plots were used to summarize the results for each fc range and each stage. as seen in fig. 4c, the variation in fc for each simulated fc range is increased substantially by the simulated skew, but the application of grsn restores both the mean fc and the variation in fc to values very close to the pre-skew values.

grsn corrects non-linear distortions in representative microarray datasets
we have investigated the application of grsn on a wide variety of microarray datasets including clinical sample datasets, cell culture datasets with various treatment modalities, and genetic mouse model datasets  <cit>  . two examples are shown in figure 5a with rma pre-processing. 1) a mouse model  of carcinogenesis in cultured clonal keratinocytes  <cit> . samples were run on the affymetrix® moe430a genechip®. this dataset represents cell culture based experiments with minimal biological variance between replicate samples. 2) a study of limb development in a mouse model  courtesy of dr. scott stadler at ohsu  <cit> . samples were run on the affymetrix® moe430a genechip®. this study compares mutant vs. wild type mice with three female and three male replicates for each condition. in both cases we see a reduction in the systematic intensity-dependent artifacts observed in these samples with application of grsn .

when datasets are analyzed for fold change between two experimental conditions where each gene's average fc between conditions is plotted versus its average expression for both conditions on m vs. a plots, we also often see non-linear skewing in the data even after averaging replicate samples and regardless of the pre-processing method. this is again likely resulting from the systematic, intensity-dependent artifacts which have no biological significance and it appears at least in some cases to be exacerbated in datasets containing unbalanced numbers of up or down regulated genes. for example, fig. 5b shows m vs. a plots of the gb dataset comparing  <dig> fanconi anemia samples to  <dig> normal bone marrow samples before and after applying grsn. in this example, non-linear distortions are seen without grsn correction when mas  <dig>  pre-processing is used , as well as when rma pre-processing , and dchip pre-processing  are used. however, applying grsn substantially reduces this skew in all cases . thus, in some datasets, fc assessments can be affected by non-linear artifacts even when averaging multiple, replicate samples and regardless of the probe set summary method used. for each summary method shown, grsn effectively reduces this skew. the same results are seen with additional datasets .

reduction of systematic variation by grsn
the goal of grsn is to reduce systematic non-linear variation in microarray datasets. grsn is very successful at this task as demonstrated with simulated data. however, there is also random variation in any microarray dataset and this random variation tends to be larger than the systematic variation addressed by grsn. as a result, applying grsn will not reduce the variation of all genes and the variation of some genes will actually increase due to the random nature of the non-systematic variation. still, in most cases, grsn will reduce the average variation among replicates as shown in fig.  <dig>  the main benefit seen from this reduction in average variance is in the genes with relatively small random and biological variations. these genes are at the largest risk of becoming false positives due to systematic non-linear artifacts. an example of this is seen in the ss dataset .

implications of grsn for gene discovery
an important goal of many microarray-based studies is the identification of genes with statistically significant differential expression between experimental conditions. as seen with the simulated data study and as shown in real data sets in fig. 5b, the non-linear skew seen in some datasets is likely to significantly impact standard statistical methods for selecting differentially regulated genes. to analyze this we compared statistical results before and after applying grsn normalization to a number of datasets. we selected significant up and down regulated transcripts that pass a fold change threshold of  <dig>  and a false discovery rate threshold of  <dig>  . in fig. 7a, we use the same m vs. a plots as in fig. 5b, but add color coding to visualize genes selected as statistically up or down regulated between two sample classes. the "s" shaped skew in the data effects both the calculation of statistical significance and the calculation of fold change. in fig. 7a, genes from the gb dataset summarized with rma are color coded based on meeting both a statistical and a fold change cutoff. transcripts found significant only when grsn is not applied are indicated in blue, transcripts found significant only when grsn is applied are indicated in red, and transcripts found significant in both cases are indicated in yellow. the blue horizontal lines indicate the fc threshold applied to select the blue transcripts  and the red horizontal lines indicate the fc threshold applied to select the red transcripts . in this case, it can be seen that the skew is pushing large groups of genes in or out of the selected fold change range. in fig. 7b–d the color coding is modified to show the blue genes only on the left and red genes only on the right and in fig. 7b there are more blue genes lost with the application of grsn than there are red genes gained. this result is misleading, because the median p-value for the yellow genes  has decreased  from  <dig>  to  <dig>  with the application of grsn. the reason less genes are found after applying grsn is due to the fdr adjustment. the p-value required to meet the  <dig>  fdr threshold before application of grsn was  <dig>  while the required p-value after grsn application was  <dig> . therefore, the p-value threshold associated with the given fdr value became more stringent after applying grsn. this is most likely due to the distribution of p-values for genes that did not make the fc cutoff. the cause of this is well illustrated in fig. 7c with the ss dataset. here, statistics alone, with the fdr threshold reduced to  <dig>  and with no fold change cutoff, are used to select genes. in this case, it appears that there are large groups of genes that are detected as statistically significant due solely to the effect of the "s" shaped skew in the data. in fact, applying grsn in this case reduces the total number of genes selected from approximately  <dig>  to only  <dig> genes significantly up regulated and  <dig> genes significantly down regulated . these large numbers of false positive results will cause overly optimistic fdr calculations for all genes and removing these false positive results with the use of grsn results in fewer genes passing the fdr cutoff even when the actual p-values have improved. in fig. 7d there are a significant number of red genes added when grsn is applied and no blue genes lost. in this case, the median p-value for the yellow genes improved significantly from  <dig>  to  <dig>  while the p-value required to meet the fdr threshold changed from  <dig>  to  <dig> . in this case, the fdr threshold became less stringent with the application of grsn. presumably the benefit from a decrease in variance among replicates out weighed any bias in the fdr calculation introduced by the removal of false positives . in summary, systematic distortions in microarray datasets are likely to adversely impact statistical calculations leading to unreliable gene selection results.

grsn improves downstream pathway analysis using gene set enrichment analysis 
in addition to examining the effects of grsn on variance and statistical gene selection we have used the gsea tool  <cit>  to further analyze the effects of grsn on downstream microarray data analysis. gsea looks for the enrichment of known pathways  in the "gene signature" of a particular experiment. part of the power of gsea is that it considers the rank and significance of all genes in the gene signature. therefore, gsea will benefit both from an increase in true positives and in a decrease in false positive gene selection results with the use of grsn. we have applied gsea to both the rs and the ss datasets . the ability of gsea to detect pathways shown to be relevant in each of these datasets is evaluated both with and without the use of grsn. as shown in table  <dig>  both the normalized enrichment score  and the false discovery rate  for these relevant pathways are consistently improved and in some cases, pathways are only detected when grsn is used. in particular, vegf is identified as an important player in the ss study  <cit>  but the associated "vegfpathway" is only identified by gsea when the data is normalized with grsn. also, the rs study involves expression of the c-myc oncoprotein, which is known to induce cell cycle, cell proliferation, cell growth, dna damage, cell death, and htert . gsea identifies all of these pathways to be enriched with c-myc expression compared to control and as shown in table  <dig> all of these pathways are detected at a higher nes and much more significant fdr value when grsn is used.

gsea is applied to the ss and rs datasets. pathways known to be active in these datasets are shown and referenced. for each selected pathway, the normalized enrichment score  and the false discovery rate , as reported by gsea, are shown. nes and fdr values are shown both for data processed with rma alone  and for data processed with rma followed by grsn  as indicated.

discussion
with any data manipulation there is a risk of adding noise. this is a classic problem with background subtraction where subtracting one noisy signal from another noisy signal can actually double the noise. the goal of grsn is to remove intensity-dependent, technical variation in the data, but we need to make sure that we do not increase the random noise at the same time. grsn minimizes this risk in a number of ways. first, by using a global rank-invariant set, we ensure that any noise associated with the selection of the rank-invariant set is applied equally to all samples. this both reduces the risk of adding random variance among replicate samples and reduces the risk of adding bias between sample groups. second, the iterative method used to select the rank-invariant set ensures that the set is not biased by unbalanced numbers of up or down regulated genes or by unequal degrees of up or down regulation. third, a single robust virtual reference sample is generated by taking the trimmed mean value  of each gene in the global rank-invariant set. this ensures that the linearity of the normalized data is not affected by a few abnormal samples, but is a robust reflection of the dataset as a whole. forth, the actual intensity-dependent calibration applied to each sample is calculated using a robust lowess smoothing algorithm through many points. therefore, each sample is compared to the same "representative" virtual reference and the actual calibration is calculated using a rigorous averaging of many reference and comparison data points.

an important distinction between grsn and other normalization methods is simply when it is applied. we are applying it to the probe set level data after it has been processed and summarized by other methods. this has the advantage that the expression value for a given transcript should more accurately reflect its actual value than will the individual probe values. other authors have also advocated the application of additional normalization at the probe set level  <cit> . while we have not investigated applying grsn to probe level data, we have tried applying the rma type of quantile normalization to probe set level data. interestingly, compared to the standard method of applying quantile normalization at the probe level, this yields results more similar to grsn. we have also investigated substituting lowess normalization for the quantile normalization step in the rma method  and found it to lead to increased non-linear skew. when grsn is applied, this increased skew is significantly reduced . this suggests that the quantile normalization step is not the cause of the skew and neither is a simple substitution of lowess the solution to the skew.

it is important to note that the typical degree of skewing seen in datasets processed with the rma method is relatively small in terms of absolute fold change. therefore, a typical fold change cutoff threshold of  <dig>  or  <dig>  will mask most of this effect and avoid most false positives. for example, if a fold change cutoff of  <dig>  is applied to the data shown in fig. 7c, all but one of the false positive results reported will be masked, although this is not true for the data in fig. 7a. however, even when the false positives are masked, they are still affecting the false discovery rate calculation for all genes, leading to overly optimistic values. this is probably more of a problem than the errors in the fold change values for the selected genes.

CONCLUSIONS
when microarray data from the affymetrix® platform is processed using the mas  <dig>  algorithm , it is crucial to check for non-linear artifacts. a simple way to do this is to look at log scale scatter plots comparing pairs of samples. if the trend for any of the scatter plots deviates from the diagonal, additional steps should be taken to normalize the data  <cit> . the global, rank-invariant set based method  presented here is a robust method to address this need. a less obvious and more profound finding is that even when using methods such as rma or dchip® , it is still important to check for non-linear artifacts. in particular, datasets with unbalanced numbers of up and down regulated genes often have an expression level dependent skew when comparing conditions. grsn is able to correct this skew without introducing bias. in other words, grsn does not try to balance up and down gene expression. this skew is not always obvious on a standard log scale scatter plot but can be seen on an m vs. a plot and can adversely impact the calculation of fold change and statistical significance and in some cases can lead to false negative and/or false positive results. using simulated data where we controlled gene expression and non-linear skew, we have demonstrated how this type of skew can lead to both false negative and false positive gene selection results, and we have shown that grsn can effectively reduce these artifacts, resulting in much more accurate gene selection performance similar to what was obtained when no skew was present. we also show that grsn correction of the introduced skew reduces standard deviation among replicates while preserving the magnitude of introduced fold-change. moreover, we have shown that application of grsn to real datasets reduces variance among replicates and improves gene pathway enrichment scores for known pathways in datasets.

in summary, grsn is a robust post-processing normalization step that can correct non-linear systematic distortions in microarray datasets resulting in improved statistical performance, more accurate gene discovery, and enhanced pathway enrichment analysis. grsn is freely available for non-commercial use . this report focuses on data from the affymetrix® platform, but grsn should apply equally well to high-density data from other microarray platforms.

availability and requirements
this tool is available for free for non-commercial use . any commercial use requires prior written permission from the author and oregon health and science university and may require licensing fees. an implementation based on the "r" statistical computing language is provided with source code included. the scripts have been developed and tested using windows xp®, but should work on other operating systems which are supported by the "r" statistical platform, including macos and linux. multiple "r" versions have been tested, including version  <dig> . <dig>  future updates and additional information will be provided at: sears lab when available.

