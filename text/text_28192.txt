BACKGROUND
the system-level approach to data analysis known as enrichment analysis  is now commonplace. moreover, the number of available software tools to perform such analysis is large . the preferred way to formalize the enrichment problem is by means of a contingency table, often  <dig> ×  <dig> 

the mathematical problem is conceptually generic, being applied to diverse types of data, such as genomics, transcriptomis or proteomics datasets; diverse types of analysis, including multiple and/or ordered outcomes; and diverse types of gene classification schemes, such as gene ontology , kegg or organism-specific ones. for a given ontology term t defining the set of genes gt and its complementary set gtc
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwghbwrdaqhaawcbagaemidaqhabagaem4yamgaaaaa@30b0@, the general enrichment analysis contingency table is:

 gtgtcoutcome1x <dig> x <dig> outcome2x <dig> x <dig> ⋯⋯⋯outcomekxk,1xk,2
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaafaqabeqbdqaaeeaaaeaacqwghbwrdawgaawcbagaemidaqhabeaaaoqaaiabdeeahnaadaaaleaacqwg0badaeaacqwgjbwyaaaakeaacqwgvbwbcqwg1bqdcqwg0badcqwgjbwycqwgvbwbcqwgtbqbcqwglbqzdawgaawcbagaegymaedabeaaaoqaaiabdifaynaabaaaleaacqaixaqmcqggsaalcqaixaqmaeqaaagcbagaemiwag1aasbaasqaaiabigdaxiabcycasiabikdayaqabaaakeaacqwgvbwbcqwg1bqdcqwg0badcqwgjbwycqwgvbwbcqwgtbqbcqwglbqzdawgaawcbagaegomaidabeaaaoqaaiabdifaynaabaaaleaacqaiyagmcqggsaalcqaixaqmaeqaaagcbagaemiwag1aasbaasqaaiabikdayiabcycasiabikdayaqabaaakeaacqwivlctaeaacqwivlctaeaacqwivlctaeaacqwgvbwbcqwg1bqdcqwg0badcqwgjbwycqwgvbwbcqwgtbqbcqwglbqzdawgaawcbagaem4aasgabeaaaoqaaiabdifaynaabaaaleaacqwgrbwacqggsaalcqaixaqmaeqaaagcbagaemiwag1aasbaasqaaiabdugarjabcycasiabikdayaqabaaaaaaa@7469@ 

besides measuring the statistical significance of the null hypothesis that the rows and columns are independent, as yielded by fisher's exact test  <cit>  and fisher-like methods  <cit> , it is also possible to measure statistical association between a table's rows and columns  <cit>  .

most of the attention in the enrichment analysis problem has focused on issues such as the search for the best multiple-test correction or the implementation of better user-friendly software interfaces to facilitate biologist's exploratory work  <cit> . however, one of the limitations that the available approaches still share is that they assume, explicitly or implicitly, that one is able to construct the contingency table exactly, without uncertainty in populating its cells. some efforts to consider ranked lists of genes, ranked by their reliability, were proposed to ameliorate the aforementioned limitations  <cit> , however they do not work on the categorical data framework and incorpore the probabilitic information in a heuristic fashion  <cit> .

recently, the computational biology community has been witnessing an increasing interest in probabilistic approaches to gene annotation, particularly in the gene ontology  context, as a realization of the limitations imposed by the traditional deterministic and context-independent gene annotation schemes  <cit> . these efforts are motivated by: the necessity to assess the error propagation in automatic gene annotation  <cit> ; desire to include different types of evidence sources such as protein-protein interaction  <cit>  or phylogenomics  <cit>  and annotation extrapolation from model organisms to others  <cit> . meanwhile, the probabilistic nature of data obtained by high-throughput measurement techniques is well recognized and a number of attempts to model it were proposed over the past decade in various experimental contexts  <cit> . however, these efforts are not integrally taken into account when usual enrichment analysis is performed.

we describe a computational solution that is able to deal with the uncertainty introduced in enrichment analysis due to:  the stochastic nature of the results obtained with such high-throughput experimental techniques or  probabilistic gene annotation.

implementation
probcd is an open-source software designed to perform probabilistic categorical data analysis. probcd is written in r  <cit>  with a level of modularity that makes it suitable to be incorporated by existing development efforts of integrative tools  <cit> . to facilitate the usage by researchers with no knowledge of r, we implemented a user-friendly web-based interface for the software, which is not limited to any particular organism. the on-line interface and the source-code are available on the project's website  <cit> .

the idea behind probcd's implementation is to formally represent the intuitive process of building a contingency table in a probabilistic manner. informally speaking, each element to be placed in the contingency table is not considered to be indivisible, but instead is "shared", according to probabilistic rules, among the contingency table's cells in a manner that is conceptually similar to fuzzy membership. the theoretical and computational implementation aspects are described in detail below.

without loss of generality, the following descriptions are applied considering one particular ontology term t that is associated with a set of genes, named simply as gt. it should be noted that gt is not restricted to the gene ontology categorization and can be any kind of classification or annotation.

the vector q contains a probabilistic annotation for all g of the organism's genes: qj = ℙ  for j ∈ { <dig> ⋯, g}. this probabilistic annotation is assumed to be given, typically obtained from some analysis process. the deterministic scenario corresponds simply to ℙ  ∈ { <dig>  1}, and hence is a special case.

the matrix p contains a probabilistic description for all k possible outcomes of the property being studied. therefore, p is a k × g matrix with elements pi, j = ℙ  for j ∈ { <dig> ⋯, g} and i ∈ { <dig> ⋯, k}. this probabilistic description of the data uncertainty is assumed to be given.

to motivate the general probabilistic model, it is useful to examine an arbitrary  <dig> ×  <dig> example in the deterministic scenario:

 ggchx <dig> x <dig> hcx <dig> x <dig> 
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaafaqabewadqabbaaabagaem4raceabagaem4rac0aawbaasqabeaacqwgjbwyaaaakeaacqwgibasaeaacqwg4baedawgaawcbagaegymaejaeiilawiaegymaedabeaaaoqaaiabdiha4naabaaaleaacqaixaqmcqggsaalcqaiyagmaeqaaagcbagaemisag0aawbaasqabeaacqwgjbwyaaaakeaacqwg4baedawgaawcbagaegomaijaeiilawiaegymaedabeaaaoqaaiabdiha4naabaaaleaacqaiyagmcqggsaalcqaiyagmaeqaaaaaaaa@45f1@ 

where all x's are the counts of a regular contingency table over the gene sets g and h. in its matrix representation:

 =
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaadaqadaqaauaabeqaciaaaeaacqwg4baedawgaawcbagaegymaejaeiilawiaegymaedabeaaaoqaaiabdiha4naabaaaleaacqaixaqmcqggsaalcqaiyagmaeqaaagcbagaemieag3aasbaasqaaiabikdayiabcycasiabigdaxaqabaaakeaacqwg4baedawgaawcbagaegomaijaeiilawiaegomaidabeaaaaaakiaawicacaglpaaacqgh9aqpdaqadaqaauaabeqaciaaaeaadaaeqaqaagqabiab=fdaxmaabaaaleaacqgg7bwecqwgnbwzcqwglbqzcqwgubgbcqwglbqzdawgaaadbagaemoaaogabeaaliabgigiolabdieaijabc2ha9bqabagccqwfxaqmdawgaawcbagaei4easnaem4zacmaemyzaumaemoba4maemyzau2aasbaawqaaiabdqgaqbqabawccqghiiizcqwghbwrcqgg9bqfaeqaaaqaaiabdqgaqbqab0gaeyyeiuoaaoqaamaaqababagae8xmaezaasbaasqaaiabcuha7jabdeganjabdwgaljabd6gaujabdwgalnaabaaameaacqwgqbgaaeqaasgaeyici4saemisagkaeiyfa0habeaakiab=fdaxmaabaaaleaacqgg7bwecqwgnbwzcqwglbqzcqwgubgbcqwglbqzdawgaaadbagaemoaaogabeaaliabgigiolabdeeahnaacaaameqabagaem4yamgaasgaeiyfa0habeaaaeaacqwgqbgaaeqaniabgghildaakeaadaaeqaqaaiab=fdaxmaabaaaleaacqgg7bwecqwgnbwzcqwglbqzcqwgubgbcqwglbqzdawgaaadbagaemoaaogabeaaliabgigiolabdieainaacaaameqabagaem4yamgaasgaeiyfa0habeaakiab=fdaxmaabaaaleaacqgg7bwecqwgnbwzcqwglbqzcqwgubgbcqwglbqzdawgaaadbagaemoaaogabeaaliabgigiolabdeeahjabc2ha9bqabaaabagaemoaaogabeqdcqghris5aagcbawaaabeaeaacqwfxaqmdawgaawcbagaei4easnaem4zacmaemyzaumaemoba4maemyzau2aasbaawqaaiabdqgaqbqabawccqghiiizcqwgibasdaahaaadbeqaaiabdogajbaaliabc2ha9bqabagccqwfxaqmdawgaawcbagaei4easnaem4zacmaemyzaumaemoba4maemyzau2aasbaawqaaiabdqgaqbqabawccqghiiizcqwghbwrdaahaaadbeqaaiabdogajbaaliabc2ha9bqabaaabagaemoaaogabeqdcqghris5aaaaaogaayjkaiaawmcaaaaa@c326@ 

where 1{} is the indicator function.

inspired by this representation, it is easy to see that the "hard" indicator functions may be substituted by bernoulli random variables in order to account for the categorization uncertainty. since all sets are finite, the indicator functions can be represented as vectors in { <dig>  1}g and the sums over all genes as dot products. in a generic scenario, with given non-deterministic p and q, the contingency table represented by x|p, q is a random matrix that is difficult to describe in closed form. it is also not compatible with the statistical formalism supporting fisher's exact test or other well-known fisher-like approaches, as these are not applicable to random tables.

the contingency table is defined in terms of bernoulli schemes  <cit>  which is the generalization of the bernoulli process to more than two possible outcomes. the notation z ~be represents the distribution:

 z={with probability p1;with probability p2;with probability p3;⋯with probability pn.p1+⋯+pn=1
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwg6bgecqgh9aqpdagabeqaauaabaqagiaaaaqaaiabcicaoiabigdaxiabcycasiabicdawiabcycasiabicdawiabcycasiabl+uimjabcycasiabicdawiabcmcapaqaaiabbeha3jabbmgapjabbsha0jabbigaojabbccagiabbchawjabbkhayjabb+gavjabbkgaijabbggahjabbkgaijabbmgapjabbygasjabbmgapjabbsha0jabbmha5jabbccagiabdchawnaabaaaleaacqaixaqmaeqaaogaei4oasdabagaeiikagiaegimaajaeiilawiaegymaejaeiilawiaegimaajaeiilawiaes47iwkaeiilawiaegimaajaeiykakcabagaee4dacnaeeyaakmaeeidaqnaeeiaagmaeeiiaaiaeeicaanaeeocainaee4ba8maeeoyaimaeeyyaemaeeoyaimaeeyaakmaeeibawmaeeyaakmaeeidaqnaeeyeaknaeeiiaaiaemicaa3aasbaasqaaiabikdayaqabagccqgg7awoaeaacqggoaakcqaiwaamcqggsaalcqaiwaamcqggsaalcqaixaqmcqggsaalcqwivlctcqggsaalcqaiwaamcqggpaqkaeaacqqg3bwdcqqgpbqacqqg0badcqqgobaacqqggaaicqqgwbaccqqgybgccqqgvbwbcqqgibgycqqghbqycqqgibgycqqgpbqacqqgsbabcqqgpbqacqqg0badcqqg5bqecqqggaaicqwgwbacdawgaawcbagaeg4mamdabeaakiabcuda7aqaaiabl+uimbqaaaqaaiabcicaoiabicdawiabcycasiabicdawiabcycasiabicdawiabcycasiabl+uimjabcycasiabigdaxiabcmcapaqaaiabbeha3jabbmgapjabbsha0jabbigaojabbccagiabbchawjabbkhayjabb+gavjabbkgaijabbggahjabbkgaijabbmgapjabbygasjabbmgapjabbsha0jabbmha5jabbccagiabdchawnaabaaaleaacqwgubgbaeqaaogaeiola4cabagaemicaa3aasbaasqaaiabigdaxaqabagccqghrawkcqwivlctcqghrawkcqwgwbacdawgaawcbagaemoba4gabeaakiabg2da9iabigdaxaqaaaaaaiaawuhaaaaa@d04f@ 

the random variable x is a matrix representation of a k ×  <dig> contingency table:

 =
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaadaqadaqaauaabeqadiaaaeaacqwgybawdawgaawcbagaegymaejaeiilawiaegymaedabeaaaoqaaiabdifaynaabaaaleaacqaixaqmcqggsaalcqaiyagmaeqaaagcbagaes47iweabagaes47iweabagaemiwag1aasbaasqaaiabdugarjabcycasiabigdaxaqabaaakeaacqwgybawdawgaawcbagaem4aasmaeiilawiaegomaidabeaaaaaakiaawicacaglpaaacqgh9aqpdaqadaqaauaabeqadiaaaeaaiewacqwfkbazdawgaawcbagaegymaedabeaakiabgwsixlab=fgahnaabaaaleaacqaixaqmaeqaaagcbagae8hzaq2aasbaasqaaiabigdaxaqabagccqghfly1cqwfhbqydawgaawcbagaegomaidabeaaaoqaaiabl+uimbqaaiabl+uimbqaaiab=rgaknaabaaaleaacqwgrbwaaeqaaogaeyyxictae8xyae2aasbaasqaaiabigdaxaqabaaakeaacqwfkbazdawgaawcbagaem4aasgabeaakiabgwsixlab=fgahnaabaaaleaacqaiyagmaeqaaaaaaogaayjkaiaawmcaaaaa@67d6@ 

where·is the usual dot-product, ai =  is a row-vector of a  <dig> × g binary matrix a such that |qj ~be and di =  is a row-vector of a k × g binary matrix d such that | ~be.

it is very easy to extend this framework for completely generic k × m tables , but this would be outside the scope of the ontology enrichment problem.

to measure statistical association between rows and columns in contingency tables, analogously to correlations for non-categorical data, we recall the pivotal works by l.a. goodman and w.h. kruskal  <cit> . depending on the problem under consideration, an appropriate association measure function ρ can be chosen. probcd calculates the statistical association accounting for the stochastic nature of the table's categorization, reporting ρ = ρ , where e
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaatuudjxwak1uy0hmmaehbfv3yslgzg0uy0hgiud3bagabaiab=ri8fbaa@388c@ is the expectation operator. if the categorical data is represented by a regular  <dig> ×  <dig> matrix, then yule's q can be used as the statistical association function ρ ≡ q : ℝ <dig> → . if one is dealing with ordered contingency tables, then goodman-kruskal's gamma, ρ ≡ γ : ℝ2k → , can be used since it is the generalization of yule's q. considering non-ordered categories, there is no analogy with the usual correlations in  and in this case, as suggested by  <cit> , cramer's t is used with ρ ≡ t : ℝ2k →  <cit> .

all the association measures implemented can be calculated for e
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaatuudjxwak1uy0hmmaehbfv3yslgzg0uy0hgiud3bagabaiab=ri8fbaa@388c@  ∈ ℝ2k, while  <dig> ×  <dig> fisher's exact test p-value cannot, since it is a function in ℕ <dig> →  <cit> . moreover, a p-value is related to the significance only, containing no information about the actual association level.

the dichotomous case, which is the simplest one, gives a more intuitive illustration on how the association is calculated in practice for the particular implementation: e
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaatuudjxwak1uy0hmmaehbfv3yslgzg0uy0hgiud3bagabaiab=ri8fbaa@388c@  = e <dig>   <dig> = p <dig>   <dig> q <dig> + ⋯ + p <dig>  g qg, e
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaatuudjxwak1uy0hmmaehbfv3yslgzg0uy0hgiud3bagabaiab=ri8fbaa@388c@  = e <dig>   <dig> =  q <dig> + ⋯ +  qg, e
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaatuudjxwak1uy0hmmaehbfv3yslgzg0uy0hgiud3bagabaiab=ri8fbaa@388c@  = e <dig>   <dig> = p <dig>   <dig> + ⋯ + p <dig>  g , e
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaatuudjxwak1uy0hmmaehbfv3yslgzg0uy0hgiud3bagabaiab=ri8fbaa@388c@  = e <dig>   <dig> =   + ⋯ +   and ρ = /, which corresponds to yule's q.

to measure the statistical significance of the estimated association, probcd uses a randomization approach. the null distribution for the association measure, ρ*, is proposed to be estimated from several permutation rounds. in each round a gene j receives randomly its probabilities  from one of the g possible columns of p and an association value is calculated. the significance of the statistical association between rows and columns in the contingency table is calculated as p = ℙ . a term t is significantly over-represented  depending on user-defined thresholds for significance and/or association.

RESULTS
the following examples illustrate the potential utility of considering probabilistic annotations and/or data uncertainty assessment in the enrichment analysis using probcd on artificial datasets and a published yeast dataset.

the point of the following illustration is to show that even ontology terms annotated with modest probabilities can be considered to be over-represented if the list of genes obtained behave in a supportive pattern. consider a hypothetical organism with  <dig> genes annotated in several go terms, as described in the additional files. the genes gene <dig> to gene <dig> are deterministically annotated to the ontology term t = a. in other words, assume that it is well known that these  <dig> genes have some given functionality a. the experiment, for example from a hypothetical proteomics dataset, yielded a deterministic list of differentially expressed  genes ranging from gene <dig> to gene <dig>  the contingency table for this problem is, therefore:

 gagacde100dec1080
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaafaqaaewadqabbaaabagaem4rac0aasbaasqaaiabdggahbqabaaakeaacqwghbwrdaqhaawcbagaemyyaegabagaem4yamgaaagcbagaemiraqkaemyraueabagaegymaejaegimaadabagaegimaadabagaemiraqkaemyrau0aawbaasqabeaacqwgjbwyaaaakeaacqaixaqmcqaiwaamaeaacqai4aaocqaiwaamaaaaaa@3fae@ 

in this case, the de gene list is clearly enriched for a within any meaningful significance cutoff. consider now a second ontology term b obtained from a probability-based source with ℙ  = 40%, i ∈ { <dig> ⋯, 20}. a probability of only 40% generally would not be sufficient evidence to warrant the inclusion of those  <dig> genes in gb considering a usual deterministic framework and, therefore, would not be analyzed by deterministic-based methods, such as the fisher's exact test. however, probcd is able to incorporate this information and yields: ρ =  <dig>  and p < 10- <dig> in  <dig> permutation rounds, a significant enrichment for b. one can easily imagine, for example, genes that have a main function a but also have a different function b in, say, 40% of documented conditions.

the point of the following illustration is to show that the incorporation of probabilistic annotation information does not always translate to addition of terms into the enrichment result, as in the example above, but it can also mean the exclusion of non-relevant terms. consider a hypothetical organism with  <dig> genes. let the genes gene <dig> to gene <dig> be grouped together in a cluster h after some genomic sequence analysis. let the term a be annotated deterministically  yielding the contingency table:

 gagach1000hc100900
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaafaqabewadqabbaaabagaem4rac0aasbaasqaaiabdggahbqabaaakeaacqwghbwrdaqhaawcbagaemyyaegabagaem4yamgaaagcbagaemisageabagaegymaejaegimaajaegimaadabagaegimaadabagaemisag0aawbaasqabeaacqwgjbwyaaaakeaacqaixaqmcqaiwaamcqaiwaamaeaacqai5aqocqaiwaamcqaiwaamaaaaaa@4065@ 

in this situation, h is clearly enriched for a within any meaningful significance cutoff. now let the same annotation incorporate some evidence levels by defining: ℙ  = 99% for i ∈ { <dig> ⋯, 10} and ℙ  = 1% for i ∈ { <dig> ⋯, 100}. intuitively, this means that only  <dig> out of  <dig> genes clustered in h are, in fact, confidently annotated with the ontology term a. the incorporation of this information results in non-significant enrichment of h for a since: ρ =  <dig>  and p =  <dig>  in  <dig> permutation rounds. therefore, it can be useful to incorporate uncertainty information into the enrichment analysis to also down-rank potentially spurious enrichment results.

the following illustration shows that the use of ordered categories  can produce useful results when additional information, regarding the order, is added. consider a hypothetical organism with  <dig> genes. in a hypothetical network analysis, let the genes be categorized, for simplicity and without loss of generality, in a deterministic fashion in a natural order: hubs , regular nodes  and leaves . let the term a be annotated deterministically  yielding the contingency table:

 gagach152n5378l1803420
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaafaqabeabdqaaeeaaaeaacqwghbwrdawgaawcbagaemyyaegabeaaaoqaaiabdeeahnaadaaaleaacqwghbqyaeaacqwgjbwyaaaakeaacqwgibasaeaacqaixaqmcqai1aqnaeaacqaiyagmaeaacqwgobgtaeaacqai1aqnaeaacqaizawmcqai3awncqai4aaoaeaacqwgmbataeaacqaixaqmcqai4aaocqaiwaamaeaacqaizawmcqai0aancqaiyagmcqaiwaamaaaaaa@4414@ 

if one cannot express the difference between hubs and regular nodes in the enrichment analysis, the contingency table is forced to be described as:

 gagach+n20380l1803420
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaafaqabewadqabbaaabagaem4rac0aasbaasqaaiabdggahbqabaaakeaacqwghbwrdaqhaawcbagaemyyaegabagaem4yamgaaagcbagaemisagkaey4kasiaemota4eabagaegomaijaegimaadabagaeg4mamjaegioagjaegimaadabagaemitaweabagaegymaejaegioagjaegimaadabagaeg4mamjaeginaqjaegomaijaegimaadaaaaa@42f2@ 

the most connected nodes in the network are not enriched for a considering the consolidated table above using either the fisher's exact test  or probcd . however, using the original categorization order, probcd suggests a significant enrichment for a with ρ =  <dig>  and p < 10- <dig>  the conclusion that the property a must be related to gene connectivity seems subjectively reasonable considering the numbers in the first contingency table. the rationale used for the hypothetical network analysis could be useful in other scenarios where there is a natural order that can provide extra information such as: highly expressed, expressed, and not expressed or up-regulated differentially expressed, not differentially expressed, and down-regulated differentially expressed.

the next illustration demonstrates the impact of considering the uncertainty in lists of genes, rather than in the annotations, on the enrichment analysis. in this example, the aim is to find which go terms, annotating the yeast saccharomyces cerevisiae, are statistically associated with periodic expression levels, measured by microarray technology  <cit> . andersson and colleagues  <cit>  devised an elaborate bayesian model which produces the probability that a gene is periodically expressed during the cell-cycle. since the final probability values are sufficient for our objectives in this work, we refer the interested reader to the original work by andersson and colleagues  <cit>  for more details. in this example, the annotation is considered to be deterministic and was downloaded from the go project page   <cit> .

to perform the usual enrichment analysis one needs to define a probability cutoff value in order to split the gene list in two: the periodic genes and the non-periodic genes. consider initially the reasonable cutoff ℙ  ≥ 70% and focus on a single go term go: <dig> , defined as "a cell cycle process that modulates the frequency, rate or extent of the progression through the s phase of mitotic cell cycle". although this go term is clearly associated with periodic gene expression, performing a usual enrichment analysis results in the conclusion that the periodic genes are not significantly enriched for go: <dig> within usual significance cutoffs .

suspecting that this non-intuitive result could be due to the probability threshold chosen to select periodic genes, illustrated in the figure  <dig>  one could repeat the same analysis above building the contingency table considering the cutoffs ℙ  ≥ 50%, 95%, 99% or  <dig> %. the result of this repeated analysis is also non-intuitive since the p-values are:  <dig> ,  <dig> ,  <dig>  and  <dig>  for 50%, 95%, 99% and  <dig> % cutoffs, respectively, meaning that increasing the stringency to define a gene as periodic only decreases the significance of the enrichment for go: <dig> 

using probcd, one can consider the actual probability of being periodic  in the enrichment analysis instead of using the deterministic approximation . this results in a relatively high statistical association between periodicity and the term "regulation of s phase of mitotic cell cycle"  with high significance . judging subjectively by the definition of go: <dig>  probcd returned a meaningful result.

other similar cases can be easily identified. for example, the go term go: <dig>  exhibits erratic behavior depending on the chosen cutoff for the probability of being periodic: p-value of  <dig> ,  <dig> ,  <dig> ,  <dig>  and  <dig>  for 50%, 75%, 95%, 99% and  <dig> % cutoffs, respectively. the probability stringency used to build the contingency table and the subsequent significance test are not necessarily correlated. probcd yielded a significant  moderate association  for go: <dig>  other examples include go: <dig> , defined as "any process that activates or increases the frequency, rate or extent of progression through the cell cycle", which would be called significant using the regular enrichment method only if the right probability cutoff ℙ  ≥ 95% is guessed initially: p-value of  <dig> ,  <dig> ,  <dig> ,  <dig>  and  <dig>  for 50%, 75%, 95%, 99% and  <dig> %, respectively.

the above analysis process is repeated for all go terms, with the results available as additional files and summarized in figure  <dig>  this figure suggests that there is a large variability in the possible final outcome of an enrichment analysis depending on the probability cutoff used to build the associated contingency table. this variability is avoided by probcd because it directly takes into account the uncertainty in the data instead of introducing a discretization step .

discussion and 
CONCLUSIONS
the usual enrichment analysis is a particular case in this probabilistic framework and can be obtained by probcd ignoring the difference between evidence sources in gene annotation and defining fixed gene lists, which would correspond to the deterministic setting: qj = ℙ  =  <dig> or  <dig> and pi, j = ℙ  =  <dig> or  <dig> 

even if a probabilistic annotation is not readily available for a given organism, it could be interesting to perform enrichment analysis taking into account some form of weighting on available annotations according to their reliability. for a concrete example, the go consortium  <cit>  provides annotations accompanied with evidence codes related to the kind/level of evidence available for a given go annotation  <cit> , such as iea: inferred from electronic annotation, imp: inferred from mutant phenotype, rca: inferred from reviewed computational analysis or ida: inferred from direct assay. it is known that some evidence sources are more reliable than others and this knowledge can be used, in a bayesian sense, as subjective probabilities.

once an annotation is considered in a probabilistic framework, it could reflect a dependence on the context. one can consider cases in which ℙ  ≫ ℙ , defining context-dependent gene annotations derived, for instance, from automatic literature mining  <cit> .

our intention is to complement existing approaches, rather than substitute them. toward this aim, we built probcd to be as modular as possible in order to be incorporated into existent software or pipelines  <cit> , composed of ontology pre-processing  <cit>  or powerful visualization capabilities  <cit> .

it is important to note that probcd is also applicable to other categorical data analysis contexts in which the construction of contingency tables is subject to uncertainty, a recurrent theme in science.

availability and requirements
• project name: probcd

• project home page: 

• operating systems: platform independent

• programming languages: r

• license: gnu lesser general public license  <dig> 

authors' contributions
rznv implemented the project. is supervised the project. all authors read and approved the final manuscript.

supplementary material
additional file 1
probcd source-code and examples. source-code used to build the probcd package. future upgrades will be available at the project website  <cit> . dataset and results for the three examples presented in the results section.

click here for file

 acknowledgements
we thank drs. john boyle, vesteinn thorsson, nathan price and other isb colleagues for insightful discussions. we also thank dr. carlos a. de b. pereira  for introducing us to the works of l.a. goodman and w.h. kruskal. this work is partially supported by nih grants u54-ai <dig>  u19-ai <dig> and p50-gmo- <dig> 
