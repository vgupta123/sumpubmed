BACKGROUND
transcriptome analysis is an important tool for characterization and understanding of the molecular basis of phenotypic variation in biology, including diseases. during the past decades microarrays have been the most important and widely used approach for such analyses, but recently high-throughput sequencing of cdna  has emerged as a powerful alternative  <cit>  and it has already found numerous applications  <cit> . rna-seq uses next-generation sequencing  methods to sequence cdna that has been derived from an rna sample, and hence produces millions of short reads. these reads are then typically mapped to a reference genome and the number of reads mapping within a genomic feature of interest  is used as a measure of the abundance of the feature in the analyzed sample  <cit> .

arguably the most common use of transcriptome profiling is in the search for differentially expressed  genes, that is, genes that show differences in expression level between conditions or in other ways are associated with given predictors or responses. rna-seq offers several advantages over microarrays for differential expression analysis, such as an increased dynamic range and a lower background level, and the ability to detect and quantify the expression of previously unknown transcripts and isoforms  <cit> . the analysis of rna-seq data is, however, not without difficulties. some of these difficulties are inherent to next-generation sequencing procedures. for example, the variation in nucleotide composition between genomic regions implies that the read coverage may not be uniform along the genome. further, more reads will map to longer genes than to shorter ones with the same expression level. in differential expression analysis, where the genes are tested individually for expression differences between conditions, such ‘within-sample’ biases are usually ignored since they are assumed to affect all samples similarly  <cit> .

other types of non-uniformities are seen between samples in an rna-seq experiment. first, the sequencing depths or library sizes  are typically different for different samples, which means that the observed counts are not directly comparable between samples. indeed, even in the absence of any true differential expression, if one sample is sequenced to twice the depth of another we expect all the genes to obtain twice as high count in the first sample compared to the second, and we do not want to confuse such effects with true differential expression. the most straightforward way of approaching the different library sizes is to simply rescale or resample the read counts to obtain equal library sizes for all samples. however, such a normalization is generally not enough. the reason is that even if the library sizes are indeed identical, rna-seq counts inherently represent relative abundances of the genes. a few highly expressed genes may contribute a very large part of the sequenced reads in an experiment, leaving only few reads to be distributed among the remaining genes  <cit> . the presence of the few highly expressed genes thus represses the counts for all other genes, and in comparison to a sample where the reads are more evenly distributed, the latter group of genes may, perhaps incorrectly, seem to have a lower expression which can lead to a lot of genes being falsely called differentially expressed. to account for this difficulty and attempt to make the counts comparable across samples, more complex normalization schemes have been proposed  <cit> . in addition to the library sizes, these procedures also include the estimation of sample-specific normalization factors that are used to rescale the observed counts. using these normalization methods, the sum of the normalized counts across all genes are therefore not necessarily equal between samples , but the goal is instead to make the normalized counts for non-differentially expressed genes similar between the samples. in this study, we use the tmm normalization  and the normalization provided in the deseq package  <cit> . a comprehensive evaluation of seven different normalization methods was recently performed  <cit> , in which these two methods were shown to perform similarly, and they were also the only ones providing satisfactory results with respect to all metrics used in that evaluation. still, it is important to keep in mind that even these methods are based on an assumption that most genes are equivalently expressed in the samples, and that the differentially expressed genes are divided more or less equally between up- and downregulation  <cit> .

microarrays have been used routinely for differential expression analysis for over a decade, and there are well-established methods available for this purpose . these methods are not immediately transferable to analysis of rna-seq data  <cit> , since these are somewhat different from the data obtained from microarrays. the intensities recorded from microarrays are treated as continuous measurements, commonly assumed to follow a log-normal distribution, while the counts from an rna-seq experiment are non-negative integers and thus inherently follow a discrete distribution. in the methods explicitly developed for differential expression analysis of this type of count data, the poisson distribution and the negative binomial  distribution are the two most commonly used models  <cit> . other distributions, such as the beta-binomial  <cit> , have also been proposed. the poisson distribution has the advantage of simplicity and has only one parameter, but it constrains the variance of the modeled variable to be equal to the mean. the negative binomial distribution has two parameters, encoding the mean and the dispersion, and hence allows modeling of more general mean-variance relationships. for rna-seq, it has been suggested that the poisson distribution is well suited for analysis of technical replicates, whereas the higher variability between biological replicates necessitates a distribution incorporating overdispersion, such as the negative binomial  <cit> . instead of using integer counts directly, some software packages represent rna-seq data by transformed quantities such as rpkm   <cit>  or the related fpkm   <cit> . the goal of such transformations is to normalize the counts with respect to the differing library sizes and with respect to the length of the transcripts, since a long transcript is expected to obtain more reads than a short transcript with the same expression level. other normalization strategies can be employed to handle other biases, arising for example from the variable gc content of the reads. after transformations such as these, the resulting values are no longer integer counts, which means that they should not be plugged into count-based methods for differential expression analysis. among the methods evaluated in this study, only the non-parametric ones would thus be suitable also for rpkm values. other software, such as cufflinks/cuffdiff  <cit> , provide an integrated analysis pipeline from the aligned reads to the differential expression results, where the inference is based on fpkm values.

the field of differential expression analysis of rna-seq data is still in its infancy and new methods are continuously being presented. so far, there is no general consensus regarding which method performs best in a given situation and few extensive comparisons between the proposed methods have been published. in a recent paper  <cit> , four parametric methods were compared in terms of their ability to discriminate between truly differentially expressed  and truly non-de genes, under different simulation conditions. the authors also compared the overlap between the sets of de genes found by the different methods in a real data set. another recent study  <cit>  evaluated the impact of increasing sequencing depth on the ability to detect de genes and contrasted this with the benefits of increasing the sample size, and the latter were found to be considerably larger. in  <cit> , the authors presented a case study on saccharomyces cerevisiae, comparing the results obtained by several differential expression analysis methods for rna-seq with each other and with results obtained from microarrays, and reported a generally good agreement between the different methods.

in the present paper we conduct a comparison of eleven methods, developed for differential expression analysis of rna-seq data, under different experimental conditions. among the eleven methods, nine model the count data directly, while the remaining two transform the counts before applying a traditional method for differential expression analysis of microarray data. the study is confined to methods that are implemented and available within the r framework  <cit>  and that are applicable to count matrices . several methods for obtaining such a matrix from the raw sequence data exist, but a comprehensive evaluation of these are outside the scope of the present study. we further focus on finding genes that are differentially expressed between two conditions only, since this is arguably the most commonly encountered application. moreover, it is supported by all evaluated methods, although most methods allow also more complex experimental designs .

RESULTS
eleven methods for differential expression analysis of rna-seq data were evaluated in this study. nine of them work on the count data directly: deseq  <cit> , edger  <cit> , nbpseq  <cit> , tspm  <cit> , bayseq  <cit> , ebseq  <cit> , noiseq  <cit> , samseq  <cit>  and shrinkseq  <cit> . the remaining two combine a data transformation with limma  <cit>  for differential expression analysis, and we will refer to them as voom  <cit>  and vst  <cit> . more detailed descriptions of the methods can be found in the materials and methods section and in the respective original publications.

the methods were evaluated mainly based on synthetic data, where we could control the settings and the true differential expression status of each gene. details regarding the different simulation studies can be found in the materials and methods section. as the baseline , we simulated all counts using negative binomial distributions, with mean and dispersion parameters estimated from real data. in these simulations, the dispersions in both conditions were assumed to be identical. note that this does not imply that the variances are the same in the two conditions, since the variance depends also on the mean. we also evaluated the robustness of the methods against variations in the distribution of the input data, by instead imposing a poisson distribution for the counts for some of the genes , or including outliers with abnormally high counts . the outliers were introduced in two different ways. for the ‘single’ outlier simulation studies , we selected 10% of the genes, and for each of these genes we selected a single sample for which we multiplied the observed count with a randomly generated factor between  <dig> and  <dig>  for the ‘random’ outlier simulation studies , we considered each observed count independently, and with probability  <dig>  we multiplied it with a randomly generated factor between  <dig> and  <dig> 

the total number of genes in each simulated data set was  <dig> , and the number of differentially expressed  genes was set to either  <dig>   <dig>  or  <dig> . we also varied the composition of the de genes, that is, the fraction of de genes that were up- and downregulated, respectively, in one condition compared to the other. finally, we evaluated the effect of varying the sample size, from  <dig> to  <dig> or  <dig> samples per condition. these sample sizes were chosen to reflect a wide range of experimental settings. since, however, most current rna-seq experiments exhibit small sample sizes and the choice in the experimental design is often between two or three samples per condition, we also performed some comparisons with  <dig> samples per condition. these comparisons, contrasted with the results from  <dig> and  <dig> samples per condition, are given in the supplementary material . in the supplementary material we also present some results obtained for data sets where the dispersion parameters were different between the two conditions.

in addition to the simulated data, we compared the methods based on their performance for three real rna-seq data set. the results from one of these data sets are shown in the main article, and the remaining two are discussed in the supplementary material .

using the synthetic data, we studied the following aspects of the methods under different experimental conditions:

•the ability to rank truly de genes ahead of non-de genes. this was evaluated in terms of the area under a receiver operating characteristic  curve , as well as in terms of false discovery curves, depicting the number of false detections encountered while going through the list of genes ranked according to the evidence for differential expression.

•the ability to control type i error rate and false discovery rate at an imposed level. this was evaluated by computing the observed type i error and the true false discovery rate, respectively, among the genes called differentially expressed at given significance levels.

•the computational time requirement for running the differential expression analysis. these results are given in the supplementary material .

for the real rna-seq data we compared the collections of genes called de by the different methods, both in terms of their individual cardinalities and in terms of their overlaps. we also studied the concordance of the gene rankings obtained by the different methods.

discrimination between de and non-de genes
we first evaluated to what extent the eleven considered methods were able to discriminate between truly de genes and truly non-de ones. we computed a score for each gene and each method, which allowed us to rank the genes in order of significance or evidence for differential expression between the two conditions. for the six methods providing nominal p-values , we defined the score as  <dig> - pnom. for samseq we used the absolute value of the averaged wilcoxon statistic as the ranking score, and for bayseq, ebseq and shrinkseq we used the estimated posterior probability of differential expression or, equivalently in terms of ranking,  <dig> - bfdr, where bfdr denotes the estimated bayesian false discovery rate  <cit>  . for noiseq, we used the statistic qnoiseq . all these scores are two-sided, that is, they are not affected by the direction of differential expression between the two conditions. given a threshold value for such a score, we may thus choose to call all genes with scores exceeding the threshold de, and correspondingly all genes with scores below the threshold are called non-de. considering the genes that were simulated to be de as the true positive group and the remaining genes as the true negative group, we computed the false positive rate and the true positive rate for all possible score thresholds and constructed a roc  curve for each method. the area under the roc curve  was used as a measure of the overall discriminative performance of a method, that is, the overall ability to rank truly de genes ahead of truly non-de ones.

under baseline conditions, and when only 10% of the genes were simulated to be de , the composition of the set of de genes  had only a minor impact on the gene ranking accuracy for most methods . when almost one third of the genes were de , the effect of the composition of the set of de genes became more dramatic. now, the performances of all methods were considerably worse when all de genes were upregulated in s <dig> compared to s <dig> than when some genes were upregulated and some were downregulated . a possible explanation for this effect is that the normalization factors, which are designed to account for this type of varying count distributions, are not able to estimate the effect to a full extent which leads to a lot of false positive results, mixed with the true positives. notably, samseq, which uses a resampling strategy to equalize library sizes and thus implicitly assumes that all normalization factors are equal, showed the best performance in simulation study b <dig>  where all the  <dig>  de genes were upregulated in condition s <dig> compared to condition s <dig> .

for the largest sample sizes  and when there were both up- and downregulated genes, all methods performed similarly in terms of the auc. all methods performed better for large sample sizes. tspm and ebseq showed the strongest sample size dependencies among the methods, followed by samseq and bayseq. for the smallest sample size , the best results were generally obtained by deseq, edger, nbpseq, voom+limma and vst+limma.

when all de genes were upregulated in condition s <dig> compared to condition s <dig> , we saw a high variability in the results obtained by bayseq. this variability was reduced when the de genes were regulated in different directions .

we chose to evaluate the effect of introducing non-overdispersed genes or outliers under the settings of simulation study b <dig> . when the fraction of genes following a poisson distribution was increased from  <dig> to 50%  the auc increased, especially for the smallest sample size . outliers with abnormally high counts reduced the auc slightly for all methods, but less for the transformation-based methods  and samseq than for the other methods .

while the auc provides an overall measure of the ability to rank truly de genes ahead of truly non-de genes, it does not immediately tell us if the deviation from a perfect discrimination is mainly due to false positives or false negatives. we therefore also constructed false discovery curves, depicting the number of false discoveries encountered as the total number of discoveries increased . figure  <dig> shows representative false discovery curves for the same simulation studies that were considered in figure  <dig>  with  <dig> samples per condition. in the supplementary material  we show corresponding curves for  <dig> and  <dig> samples per condition, respectively . given that we are most interested in the genes showing the strongest evidence of differential expression, we confined the analysis to the  <dig>  top-ranked genes for each method. we noted that although nbpseq was among the best methods in terms of the overall ranking , it had problems with false discoveries among the very top-ranked genes under many simulation settings. indeed, while the total number of false discoveries among the  <dig>  top-ranked genes were in parity with many other methods, there were often some false discoveries ranked very near the top by nbpseq. tspm and noiseq also tended to rank some truly non-de genes in the very top. for simulation study p <dig>  where half of the genes were generated according to a poisson distribution, the performance of tspm was improved and fewer non-de genes were ranked near the top . overall, the best performance, in terms of ranking mainly true positives in the very top, was obtained with the transformation-based methods  and shrinkseq. samseq also performed well, but returned the same  score for many genes, both truly de and truly non-de.

larger sample sizes led to considerably fewer false positives found among the top-ranked genes . actually, as seen by comparing additional file 1: figure s <dig> to additional file 1: figures s <dig> and  <dig>  already increasing the number of samples per condition from  <dig> to  <dig> provided a tangible improvement.

control of type i error rate
next, we evaluated the six methods returning nominal p-values  in terms of their ability to control the type i error at a pre-specified level in the absence of any truly de genes. under baseline conditions  and using a nominal p-value cutoff of  <dig> , all six methods performed quite well and in many cases called around 5% of the genes differentially expressed . nbpseq and tspm found the highest number of false positives and deseq was the most conservative among the six methods. this is concordant with the findings in a previous study  <cit>  where the type i error rate control of edger, deseq and nbpseq were compared. the strongest dependence on sample size was seen for tspm, which performed poorly for the smallest sample size , but in parity with the other methods for the larger sample sizes. a slight reduction in type i error rate with increasing sample size was seen also for edger and deseq while the performance of the transformation-based approaches and nbpseq were less sample-size dependent.

the results stayed largely similar when we let the counts for half of the genes be poisson distributed , but for the smallest sample size we noted a reduction of the type i error rate for tspm and an increase of the type i error rate for the transformation-based methods and nbpseq. introducing ‘single’ outliers  had a considerable effect on the type i error of the three methods that are explicitly modeling the counts using a negative binomial distribution . under these conditions, the type i error rates of nbpseq and edger increased substantially, while deseq instead became even more conservative . the type i error rates of the transformation-based methods and the tspm were less affected, but tended to decrease rather than increase following the introduction of outliers. similar effects, but even more pronounced, were noted when we instead introduced ‘random’ outliers  figure 3d, see the materials and methods section for a more extensive explanation of the different types of outliers). if these outliers were instead introduced by dividing the counts by a random factor between  <dig> and  <dig> , the results were largely similar to those from the baseline study , except for a slight reduction of the type i error rate for nbpseq and edger . in additional file  <dig> , we show representative p-value distributions under the different simulation settings. in these figures, we note that even when all null hypotheses are true, the p-values are not always uniformly distributed. specifically, some methods  exhibit an excess of large p-values. this has been observed also in previous studies and has been attributed to the use of exact tests based on discrete probability distributions  <cit> . since the total number of reads mapping to the different genes is very different, the null distribution of p-values will be a mixture of a large number of different discrete distributions  <cit> .

control of the false discovery rate
next, we examined whether setting a significance threshold for the adjusted p-value  indeed controlled the false discovery rate at the desired level. we put the fdr threshold at  <dig> , and calculated the true false discovery rate as the fraction of the genes called significant at this level that were indeed false discoveries. since noiseq does not return a statistic that is recommended to use as an adjusted p-value or fdr estimate, it was excluded from this evaluation. for bayseq, ebseq and shrinkseq, we imposed the desired threshold on the bayesian fdr  <cit> .

as above, when only 10% of the genes were de, the direction of their regulation had little effect on the false discovery rate . the main difference between the two settings was seen for shrinkseq, whose fdr control was worse when all genes were regulated in the same direction. the high false discovery rate seen for shrinkseq can possibly be reduced by setting a non-zero value for the fold change threshold defining the null model. also the variability of the bayseq performance was considerably reduced when there were both up- and downregulated genes among the de ones. for the largest sample size , shrinkseq, nbpseq, ebseq, edger and tspm often found too many false positives. the remaining methods were essentially able to control the false discovery rate at the desired level under these conditions. a possible explanation for the high false discovery rates of nbpseq is that the dispersion parameters, and thereby also the variances, are understimated for many genes which implies that the significance of these genes are overestimated. when the sample size was decreased, all methods except shrinkseq performed considerably worse in terms of fdr control, and with only two samples per group, all methods were far from controlling the true false discovery rate at the desired level. tspm was most heavily affected by the decreasing sample size, in terms of increasing fdr, which is in agreement with previous observations  <cit> . with only  <dig> samples per condition, neither samseq nor the two transformation-based methods called any genes significantly de. as for the false discovery curves above, already an increase in sample size from  <dig> to  <dig> samples per condition improved the fdr for many of the methods, in particular deseq and bayseq, and both transformation-based methods were able to find differentially expressed genes  with  <dig> samples per condition  and s11).

when the de genes were regulated in different directions, increasing the number of de genes from  <dig>  to  <dig>  improved the ability to control the fdr . conversely, when all de genes were regulated in the same direction, increasing the number of de genes impaired the ability to control the fdr especially for the largest sample sizes . when outliers with extremely high counts were introduced . also the fdrs of samseq and tspm were largely unaffected by the inclusion of outliers.

in a practical situation, we are not only interested in keeping the rate of false discoveries low, but also to actually be able to find the true positives. therefore, we also computed the true positive rate  among the genes that were called significant at a fdr threshold of  <dig> . in general, deseq and bayseq tended to give the lowest number of true positives . this should be viewed in relation to figure  <dig>  where it was shown that these methods often also gave low fractions of false discoveries. the other two methods that are based on the nb model, edger and nbpseq, as well as shrinkseq, in which we used a zero-inflated nb model, returned more true positives but at the price of a higher false discovery rate. the non-parametric samseq method gave high true positive rates across all simulation settings, seemingly without an accompanying high false discovery rate. however, for the smallest sample sizes this method did not find any significantly differentially expressed genes at all which is not surprising due to its non-parametric nature and reliance on sample permutations. the true positive rate of ebseq was largely unaffected by the sample size, but the false discovery rate decreased as sample size increased.

as expected, increasing the expression difference between the two conditions  improved the ability to detect truly de genes and reduced the observed false discovery rate, in a concordant manner for all methods . when the dispersions in the two conditions were different, we observed an increased fdr for the majority of the methods , compare to figure 4b).

real rna-seq data from two mouse strains
in addition to the synthetic data set, we also analyzed an rna-seq data set from  <dig> mice,  <dig> of the c57bl/6j strain and  <dig> of the dba/2j strain  <cit> . after filtering out genes for which the total count across the  <dig> mice was less than  <dig>  the data set contained  <dig>  genes. we applied the eleven methods to find genes that showed differential expression between the two mouse strains. all genes found to be de at a fdr or bayesian fdr threshold of  <dig>  were considered significantly de. it is not clear how to set a threshold for the q-value returned by noiseq to be comparable with the fdr estimate or adjusted p-value from the other methods, and hence noiseq was excluded from most of the subsequent analysis.

first, we compared the number of de genes found by each method . the highest number of de genes was found by shrinkseq, while bayseq returned relatively few. as can be seen in figure 5a, tspm, edger, nbpseq and the two transformation-based methods found approximately the same number of de genes. next, we studied the overlap between the sets of genes called de by different methods. figure 5b shows the overlap between the sets of de genes found by edger, deseq, nbpseq and tspm . from this figure, we noted that the de genes found by deseq were to a large extent found also by edger, nbpseq and tspm . in contrast, both edger, nbpseq and tspm found a fair amount of ‘unique’ de genes, that were not shared with the other methods. figure 5c shows the corresponding comparison for bayseq, ebseq and the two transformation-based methods. the de genes found by voom+limma essentially formed a subset of the slightly larger set of de genes found by vst+limma. similarly, many of the de genes found by bayseq were also found by ebseq, and the de genes found by ebseq were to a large extent found also by the transformation-based methods. the set of de genes found by samseq and shrinkseq, finally, contained a large part of the genes found by all the other methods. table  <dig> shows the overlap between the collections of differentially expressed genes for each pair of methods. to characterize the sets of genes preferentially called de by the different methods, we marked the de genes in an ma-like plot . these results showed clearly that for all methods, a higher fold change was needed for significance for the genes with low average expression. bayseq seemed to require a higher fold change than the other methods across all expression levels, and did not call any highly expressed genes de. in contrast, samseq and shrinkseq required a lower fold change for calling highly expressed genes de, while the threshold for lowly expressed genes was similar to that from the other methods. the low fold change required for highly expressed genes may potentially compromise the biological significance of some of the findings from samseq and shrinkseq and may necessitate the inclusion of an additional fold change threshold.

the table contains the number of differentially expressed genes that are shared between each pair of methods, for the bottomly data set . the numbers on the diagonal, indicating the number of differentially expressed genes found by the respective methods, are highlighted in bold.

in additional file 1: figures s24-s <dig>  we show the normalized counts  across all samples for some of the genes found to be de by only a single method. deseq, edger, voom+limma, bayseq and ebseq did not find any unique de genes and hence there are no figures corresponding to these methods. from additional file 1: figures s24-s <dig>  we noted that the de genes found uniquely by shrinkseq, and to some extent for those found uniquely by samseq, tended to be reasonably highly expressed and consistently expressed across the samples from both conditions while for many of the other methods, the unique de genes exhibited highly inconsistent counts even within conditions. the two genes found exclusively by vst+limma both had very low counts in all samples, as was the case for most genes found uniquely by tspm.

in additional file 1: figure s <dig> we compare the gene ranking scores obtained by the different methods for the bottomly data set . from this figure, we noted that edger, deseq, voom+limma, vst+limma, tspm and samseq tended to rank the genes similarly, while the rankings obtained by nbpseq were less similar to these. the rankings obtained by bayseq and ebseq were considerably different from the other rankings.

to further evaluate the performance of the methods, we applied them to the data set consisting of only the mice from the c57bl/6j strain, within which we defined two arbitrary sample classes of  <dig> samples each. the analysis was repeated five times for different arbitrary divisions. under these conditions, we expect that no genes are truly de. nevertheless, most methods found differentially expressed genes in at least one instance. tspm found by far the largest number of de genes , which supports our previous observation that this method may be too liberal. by studying the genes called de in the five instances, we noted that the de genes found by edger often overlapped with the de genes found by nbpseq, while only few of the de genes called by tspm overlapped with those found by the other methods. also ebseq tended to call unique genes, that were not found by any of the other methods. the lack of consensus among the de genes found by the different methods may be a further indication that they are indeed false positives, and that the different methods tend to favor different types of patterns.

CONCLUSIONS
in this paper, we have evaluated and compared eleven methods for differential expression analysis of rna-seq data. table  <dig> summarizes the main findings and observations. no single method among those evaluated here is optimal under all circumstances, and hence the method of choice in a particular situation depends on the experimental conditions. among the methods evaluated in this paper, those based on a variance-stabilizing transformation combined with limma  performed well under many conditions, were relatively unaffected by outliers and were computationally fast, but they required at least  <dig> samples per condition to have sufficient power to detect any differentially expressed genes. as shown in the supplementary material , they also performed worse when the dispersion differed between the two conditions. the non-parametric samseq, which was among the top performing methods for data sets with large sample sizes, required at least 4- <dig> samples per condition to have sufficient power to find de genes. for highly expressed genes, the fold change required for statistical significance by samseq was lower than for many other methods, which can potentially compromise the biological significance of some of the statistically significantly de genes. the same was true for shrinkseq, which however has an option for imposing a fold change requirement in the inference procedure.

the table summarizes the present study by means of the main observations and characteristic features for each of the evaluted methods. we have grouped voom+limma and vst+limma together since they performed overall very similarly.

small sample sizes  imposed problems also for the methods that were indeed able to find differentially expressed genes, there leading to false discovery rates sometimes widely exceeding the desired threshold implied by the fdr cutoff. for the parametric methods this may be due to inaccuracies in the estimation of the mean and dispersion parameters. in our study, tspm stood out as the method being most affected by the sample size, potentially due to the use of asymptotic statistics. even though the development goes towards large sample sizes, and barcoding and multiplexing create opportunities to analyze more samples at a fixed cost, as of today rna-seq experiments are often too expensive to allow extensive replication. the results conveyed in this study strongly suggest that the differentially expressed genes found between small collections of samples need to be interpreted with caution and that the true fdr may be several times higher than the selected fdr threshold.

deseq, edger and nbpseq are based on similar principles and showed, overall, relatively similar accuracy with respect to gene ranking. however, the sets of significantly differentially expressed genes at a pre-specified fdr threshold varied considerably between the methods, due to the different ways of estimating the dispersion parameters. with default settings and for reasonably large sample sizes, deseq was often overly conservative, while edger and in particular nbpseq often were too liberal and called a larger number of false  de genes. in the supplementary material  we show that varying the parameters of edger and deseq can have large effects on the results of the differential expression analysis, both in terms of the ability to control type i error rates and false discovery rates and in terms of the ability to detect the truly de genes. these results also show that the recommended parameters  are indeed well chosen and often provide the best results.

ebseq, bayseq and shrinkseq use a different inferential approach, and estimate the posterior probability of being differentially expressed, for each gene. bayseq performed well under some conditions but the results were highly variable, especially when all de genes were upregulated in one condition compared to the other. in the presence of outliers, ebseq found a lower fraction of false positives than bayseq for large sample sizes, while the opposite was true for small sample sizes.

