BACKGROUND
traditional information retrieval  system should respond with a ranked list of retrieved documents or passages to users, according to their probabilities of relevance to the query. the model only concerns with the relevance between retrieved documents and user query, but does not take redundancy between retrieved documents into account. the retrieved documents with similar contents thus tend to appear over and over again. ideally, in order to provide a comprehensive picture of all interpretations to the query, it would be better for an information retrieval system to return a ranked list of retrieved documents or passages taking both relevance and diversity into account.

for genomics information retrieval, the problem is particularly prominent, on account of immense data and tremendous increase of genomics and biomedical relevant publications. the wealth of information has led to an increasing amount of interest in and need for applying information retrieval techniques to access the scientific literature in genomics and related biomedical disciplines. in many cases, the desired information of a question  asked by biologists is a list of a certain type of entities covering different aspects that are related to the question  <cit> , such as cells, genes, diseases, proteins, mutations, etc. hence, it is important of a biomedical ir system to be able to provide relevant and diverse answers to fulfill biologists' information needs. in recent years, the "aspect retrieval" was proposed in trec genomics tracks. the aim of the aspect retrieval task is to promote retrieval ranking diversity in the ranked list of retrieved passages. aspects of a retrieved passages could be a list of named entities or mesh terms  <cit> , representing answers that cover different portions of a full answer to the query. aspect mean average precision   <cit>  was defined in the genomics tracks. its purpose is to study how a biomedical retrieval system can support a user to gather information about different aspects of a query. biomedical retrieval system should return relevant information at the passage level; meanwhile, judges would comprehensively rate the retrieved passages by relevance as well as aspect diversity. relevant passages that do not contribute any new aspects will not be used to accumulate aspect map. therefore, aspect map is a measurement for both relevance and diversity of an ir ranked list.

our work is inspired by several recent papers that concerned with promoting ranking diversity in ir ranked list. the most representative method is maximum marginal relevance  proposed by carbonell et al. <cit> . the mmr method selects a document that has the highest combination of a similarity score with respect to a query and a dissimilarity score with respect to the documents selected at earlier ranks at each iteration. zhang et al. <cit>  presented four redundancy measures. they modeled relevance and redundancy separately. since they focused on redundant document filtering, experiments in their study were only conducted on a set of relevant documents. zhai et al. <cit>  proposed a sub-topic retrieval framework which models relevance and redundancy within the language modeling framework. in particular, they devised several methods based on the kullback-leibler divergence measure and a mixture model. the basic idea of above three methods is to penalize redundancy by lowering an item's rank if it is similar to the items already ranked. however, these methods often treat relevance ranking and diversity ranking separately, and sometimes with heuristic procedures. rianne kaptein et al. <cit>  employed a top down sliding window to diversify ranked list of retrieved documents. they kept the highest ranked result as is and chose from the next n documents the one that maximizes diversity according to some diversity indicators, such as the number of new terms or new links introduced by the next document. a recent study concerning on the genomics aspect retrieval was conducted by huang et al. <cit> . their experimental results demonstrated that the hidden property based re-ranking method can achieve promising and stable performance improvements. yin et al. <cit>  proposed a cost-based re-ranking method to promote ranking diversity. this method concerns with finding the passages that cover more different aspects of a query topic. a side effect of these three re-ranking strategies is that they favor long documents, as the long documents tend to contain more distinct terms. in biomedical retrieval domain, zhu et al. <cit>  proposed a clustering-based ranking algorithm called grasshopper to promote ranking diversity. grasshopper is an alternative to mmr and variants with a principled mathematical model and strong empirical performance on artificial data set. unfortunately, this re-ranking method would reduce their system's performance and decrease the aspect map of the original results for the genomics aspect retrieval  <cit> .

however, the previous work considers the aspects of user query and retrieved documents mainly on word level. in other words, one word or more co-occurrence words are used to identify a specific aspect. for instance, given two retrieval passages: the first one is related to some disease research, in which kidneys of white rats are used as experimental materials; the second one is relevant to subject of kidney transplantation. obviously, the aspect of kidney occurs in both passages. under this situation, re-ranking order of the second passage is likely to be reduced because kidney aspect has occurred in the first passage we have observed. however, the second passage is not redundant in fact. the above problems are due to two following reasons: firstly, one or more co-occurrence words in a passage are used to identify the aspect. however, it is common sense for us that a specific word can express more than one latent topics according to different contexts in a passage. in this above case, the word kidney can be used to express the experimental material as well as the object of organ transplant; secondly, words in a passage are considered as independent to each other. however, some potential relationships between words might exist. as shown in the above instance, the word kidney represents two different topics in the two passages, as it has distinctive contexts and relationships with other words. therefore, it is insufficient to identify aspect on word level.

in this paper, we aim at addressing both above problems simultaneously and assume that aspects should be identified by the topics of retrieved passages. we thus propose an approach which employs latent dirichlet allocation   <cit> , a topic generative model, to promote diversity and reduce redundancy in the ranked list for biomedical information retrieval. specifically, we discover topic distributions of retrieval passages and word distributions of each topic dimension using lda model, and then re-rank retrieved passages with topic distribution similarity between passages based on a "n-size slide window" strategy. experiments conducted on trec  <dig> genomics track collection and two very different ir baseline runs demonstrate the effectiveness of our approach. the evaluation results show that our approach can achieve 8% improvement over the highest aspect map reported in trec  <dig> genomics track. although the proposed method is not as good as the ones presented in  <cit>  and  <cit>  in terms of map performance, it is still promising because we do not employ other resources such as wikipedia, which is more efficient in data preprocessing. moreover, we can present aspect probability distributions for each topic.

methods
aspects from retrieved passages can not simply be identified on word level because a specific word can be used to represent more than one topic in different passage contexts. in this case, we assume that aspects should be identified by latent topics hidden in passages which are considered to be more abstract. in the rest of this paper, we use "topic" and "aspect" interchangeable. furthermore, words in one passage are not independent, which together construct passage topics. it can be also observed that two passages even with the same words can express different topics. we thus assume that latent topics can be identified by word distribution. in this section, we will expound how we use a particular generative model called lda to discover the topics covered by retrieved passage collection, and illustrate how these topics can be used to improve ranking diversity.

aspect discovery and transformation
aspect discovery using lda
discovering aspects covered by each retrieved passage is the first step for re-ranking. recently, a number of approaches  <cit>  to modeling document content are proposed and based on the principle that the probability distribution over words in a document can be expressed as a mixture of topics, where each topic is a probability distribution over words. lda  <cit>  is such a generative probabilistic model of document collection and has been used in many other applications such as computer vision  <cit> , image modeling  <cit> , social tagging system  <cit> , etc. we thus employ this model for aspect discovery. its basic idea is that documents are represented as random mixtures over latent topics, where each topic is characterized by a distribution over words.

the lda model is represented  as a probabilistic graphical model in figure  <dig>  it can be seen clearly from the figure that the lda representation has three levels and the generation of a document collection is modeled as a three-step process. first, for each document, a distribution over topics is sampled from a dirichlet distribution. second, for each word in the document, a single topic is chosen according to this distribution. finally, each word is sampled from a multinomial distribution over words specific to the sampled topic. in this model, ϕ denotes the matrix of topic distributions, with a multinomial distribution over n word items for each of t topics being drawn independently from a symmetric dirichlet prior. θ is the matrix of document-specific mixture weights for these t topics, each being drawn independently from a symmetric dirichlet prior. for each word, z denotes the topic responsible for generating that word, drawn from the θ distribution for that document, and w is the word itself, drawn from the topic distribution ϕ corresponding to z. nd stands for the number of words in the document. d stands for the size of document collection. estimating ϕ and θ provides information about the topics in a collection and the weights of those topics in each document. a host of algorithms have been used to estimate these parameters, ranging from mean field variational methods  <cit> , expectation propagation  <cit> , gibbs sampling  <cit> , collapsed variational inference  <cit>  to fast collapsed gibbs sampling  <cit> . under this unsupervised model, documents can be associated with multiple topics and we could automatically discover the topics covered by document collection.

aspect distribution transformation
we construct θ matrix of eq. in light of lda model discussed in above subsection, which is the matrix of passage-specific mixture weights for these t aspects discovered. θ provides the information about the aspects in the retrieved passage collection and the weights of those aspects in each retrieved passage. θi denotes the aspects distribution for each passage pi. aij stands for the weight of the aspect aj given the passage pi such that ∑j=1taij equals one.

  θ=t=a11⋯a1j⋯a1t⋯⋯⋯⋯⋯a1⋯aij⋯ait⋯⋯⋯⋯⋯ad1⋯adj⋯adt 

we have observed the following two interesting phenomena from the column of matrix θ. first, for some specific aspects, majority passages of the retrieved collection get large weight values; however, for some other specific aspects, a few passages get large weight values. this suggests that for each aspect the distribution of the retrieved passages is different. second, even the same weight value in different columns of θ matrix would have a different importance for different aspects. for instance, given two specific aspects am and an, there exist two weights apm and aqn for passage pp and pq respectively, which satisfies apm = aqn. if most of the passages have a smaller weight than apm for aspect am, and have a larger weight than aqn for aspect an, then we can easily have a conclusion that it is more important of apm for aspect am than aqn for aspect an. therefore, we tend to make transformation of θ matrix to represent the importance of each passage in each aspect.

given such a hypothesis that for each aspect, the importance of retrieved passages is a normal distribution, we can have t normal distributions, denoting by n = . given an normal distribution ni , mean μi and variance σi are referred to eqs. and  respectively.

  μi=∑j=1dajid 

  σi=∑j=1daji-μi2d 

where aji stands for the weight of the aspect ai for passage pj , and d denotes the number of retrieved passages. in addition, we get a new matrix Θ shown as eq. to measure the passages. importance for each aspect.

  Θ=Θ <dig> Θ2⋯,Θtt=n1⋯n1⋯n1⋯⋯⋯⋯⋯ni⋯nj⋯ni⋯⋯⋯⋯⋯nt⋯nt⋯nt 

where ni denotes the importance of passage pj for the aspect ai. Θi denotes the importance distribution of passage collection for the aspect ai.

re-ranking with n-size slide window
re-ranking problem is defined as this: given a query q and an initial ranking r produced for this query only with respect to relevance, we build a new ranking s taking account of both relevance and diversity. in terms of ranking r, our aim is that given a cut o position k of s, top k passages of s could deliver as many non-redundant aspects as possible. in this section, we introduce two re-ranking algorithms based on a slide window to promote ranking diversity. we set the slide window with size n, and put top n passages from r as candidate passages into the slide window when re-ranking. as we commonly set n with a small number, we suppose that there is no distinctive difference between passages in a slide window with respect to their query-relevance.

first, we choose a passage from the slide window as the first passage in ranking s, which contains the largest aspect coverage as show in eq..

  maxaspcoverg=arg maxq∈ <dig> n ∑t=1tnt 

where nt denotes the importance of passage pq for the aspect at and ∑t=1tnt stands for the aspect coverage of passage pq. after adding this passage into ranking s, we remove it from ranking r. for the rest of passages in r, if the number of passages in r is not less than n, we will put the top n passages in r into the slide window, or else we will put all the passages in r into slide window. then we choose a passage from the slide window, which contains the most distinctive aspects compared with the observed passages in ranking s, add it into s, and remove it from r. the working scheme of this ranking method based on n size slide window is described in algorithm  <dig>  named rank-nwin.

algorithm  <dig> rank-nwin algorithm
1: input: an initial passage ranking r produced for current user query only with respect to relevance, and the size n of the slide window

2: output: a reranked passage list s

3: process:

4: given top n passages in r, we find a passage pass <dig> containing the most aspect coverage value using eq.;

5: r ← r\{pass1};

6: s ← Ø∪{pass1};

7: while r:length ≠  <dig> do

8:   choose top n passages in r as candidate passages and if the length of rank r is less than n , take all passages in r as candidate passages;

9:   for each passage i of candidate passages do

10:    distance-ri = 0;

11:    for each passage j in s do

12:       distance-ri = distance-ri + distance;

13:    end for

14:    distance-ri = distance-ri /s.length;

15: end for

16: find the max distancer passage passrest in candidate passages;

17: r ← r\{passrest};

18: s ← s ∪{passrest};

19: end while

20: return s.

the advantage of the algorithm  <dig> is that it considers aspect distinctions between candidate passages in the slide window and observed passages ranked in s. however, considering original query-relevance ranking r, it is not appropriate for algorithm  <dig> to change in a wide range of r. therefore, another algorithm named rank-nwin-group is proposed to ensure that the new ranking s is just the original ranking r with slight adjustments. the key idea of this algorithm is described below. for the first passage in s, we still choose a passage containing the largest aspect coverage from the slide window, add it into s and remove it from r. different from rank-nwin algorithm, we first group rank r into several n size groups, and the size of last group may be less than n. we put each group into the slide window in turn, re-rank the passages in current group, and add them into s finally. the process of re-ranking in groups is similar to algorithm rank-nwin. algorithm  <dig> describes the process of re-ranking by using n-size slide window to group ranking r.

algorithm  <dig> rank-nwin-group algorithm
1: input: an initial passage ranking r produced for current user query only with respect to relevance, and the size n of the slide window

2: output: a reranked passage list s

3: process:

4: given top n passages in r, we find a passage pass <dig> containing the most aspect coverage value using eq.;

5: r ← r\{pass1};

6: s ← Ø∪ {pass1};

7: group passages in r into  groups;

8: for each group i do

9:    for each passage j in group i do

10:       distance-rj = 0;

11:       for each passage k in s do

12:          distance-rj = distance-rj + distance;

13:       end for

14:       distance-rj = distance-rj = s:length;

15:    end for

16:    rank passages in group i according to distancer in a descend order.

17:    r ← r\{pass in group i};

18:    s ← s ∪ {pass in group i};

19: end while

20: return s.

distance in algorithms rank-nwin and rank-nwin_group is the measurement of the aspect distinction between two passages. given two passages, the more different the aspects are, the larger value of distance will be. in our work, we use two slightly different ways to evaluate it. the first one can be seen as the original euclidean distance as shown in eq..

  distance=∑t=1t-nt) <dig> 

furthermore, we assume that the importance of each aspect is different, and μt as discussed in the last subsection denotes the mean distribution of the whole passage collection for the at aspect. we thus regard μt as the weight value and then get another equation for euclidean distance as shown in eq..

  distance*=∑t=1tμt-nt) <dig> 

RESULTS
dataset and evaluation metrics
in order to evaluate our proposed approach for promoting ranking diversity in biomedical information retrieval, we employ trec  <dig> genomics track collection as the test data set. it is a full-text biomedical collection consisting of  <dig>  documents from about  <dig> genomics-related journals indexed by medline  <cit> . these documents come from the highwire press  electronic distribution of journals and are in html format, which preserves the formatting, structure, table and figure legends, etc. there are  <dig> official topics for the track in  <dig>  which are in the form of questions asking for lists of specific entities that cover different portions of full answers. here "topic" means "query"  <cit> .

the followings are examples of queries from the  <dig> genomics track:

• query 200: what serum  change expression in association with high disease activity in lupus?

• query 221: which  are mediated by cd44?

• query 231: what  are found in zebrafish?

for trec  <dig> genomics track, there are three levels of retrieval performance measured: passage retrieval, aspect retrieval, and document retrieval. each of these provides insight into the overall performance for a user trying to answer the given questions. these three levels were measured by some variant of map. passage map, passage <dig> map, aspect map and document map, defined in  <cit>  and  <cit> , are four evaluation metrics corresponding to the three levels of retrieval performance. in this paper, we mainly focus on two evaluation metrics, aspect map and passage <dig> map, since our objective is to promote diversity in the ranked list of retrieved passages. furthermore, aspect retrieval and passage retrieval are also the major tasks in trec  <dig> genomics tracks.

genomics collections only contain a fraction of millions of biomedical literatures indexed by medline, but as far as we know, they are the largest and the only biomedical text collections with both manual relevance assessments and diversity evaluation available for biomedical text retrieval research.

retrieval baselines
we employ two retrieval baseline runs, nlminter  <cit>  and unine <dig>  <cit> . nlminter developed by u.s. national library of medicine achieved the best performance in trec  <dig> genomics track in terms of aspect map, passage <dig> map and document map. unine <dig> which is developed by university of neuchatel rue emile-argand combined different search strategies. this baseline run proposes a new approach to the generation of orthographic variants of search terms, and the generation of the ib <dig>  <cit>  with the article title included in each passage, or with both the article and orthographic variants. the performance of unine <dig> was above average among all results reported in trec  <dig> genomics track.

re-ranking performance
we preprocessed the retrieved passages of two baseline runs. for instance, any delimiting character, including hyphen, was used to separate words, and we deleted any words that occurred only once in one passage or belonged to the standard "stop" list  used in google retrieval engine.

re-ranking results of the proposed methods on trec  <dig> genomics collection are shown in table  <dig> and table  <dig>  the values in the parentheses are the relative rates of improvement over the original results. it can be seen from the table that our approaches can make improvements over both baseline runs. for the efficiency reason, we re-ranked only the top  <dig> passages. distinctive improvements over all baseline runs in terms of aspect map can be observed.

re-ranking performance is effected by the parameters chosen from lda model. comparison with nlminter baseline run, we only show the re-ranking results with parameters of β whose values are equal to  <dig>  in algorithm  <dig> and  <dig>  in algorithm  <dig>  respectively. for unine <dig> baseline run, we show re-ranking results with parameters of β whose values are equal to  <dig>  in algorithm  <dig> and  <dig>  in algorithm  <dig>  respectively. the choosing of the parameters in lda will be discussed in the next subsection.

discussion
impact of parameter β
the statistical model lda we have described is conditioned on three parameters, the dirichlet hyper-parameters α and β, and the number of topics t. the choice of α and β can have important implications for the results produced by the model. in particular, the value of β affects the granularity of the model. increasing β can be expected to decrease the number of topics used to describe retrieved passages. in other words, retrieved passages can be sensibly factorized into a set of topics at several different scales, and the particular scale of the topics assessed by the model will be set by β. a large value of β would lead the model to find a relatively small number of topics. since we focus on biomedical domain, we tend to employ smaller values of β, which will result in more topics that address specific fields.

we should choose the value of β for each specific user query. in order to improve experimental efficiency, we choose β according to the retrieval passages instead. as preprocess give us two word sets of  <dig>  words and  <dig>  words for retrieved passages by nlminter and unine <dig> baseline runs respectively, we give two different settings of β. for nlminter, we set the values of β ∈  in steps of  <dig> . however, for baseline unine <dig>  we set the values of β ∈  in steps of  <dig> . these values of β are relatively small and can be expected to give rise to a fine-grained decomposition of the collection into topics that address specific research fields.

impact of parameters α and t
given values of β, the problem of choosing appropriate values for α and t thus is a problem of model selection. we let αt = constant to keep constant the sum of the dirichlet hyper-parameters, which can be interpreted as the number of virtual samples contributing to the smoothing of θ  <cit> . moreover, because our strategy in this article is to fix αt = constant and β, and explore the consequences of varying t , for each fixed β value we set the values of t from  <dig> to  <dig> in steps of  <dig> consecutively. to evaluate the consequences of changing the number of topics t , we used the gibbs sampling algorithm  <cit>  to obtain samples from the posterior distribution over z at several choices of t.

next, we need to choose an appropriate value of t for each specific query. in our case, the data are the words in the retrieved passages, w, and the model is specified by the number of topics, t , thus we wish to compute the likelihood p. however, this requires to sum over all possible assignments of words to topics z. we can approximate p by the harmonic mean of a set of values of p when z is sampled from the posterior p  <cit> . in all cases, p increases at the beginning, and decreases after reaching a peak.

as mentioned above, the value of t depends on the choices of α and β, which will also be affected by specific decisions made in forming the dataset such as the use of stop-word list, etc. the distribution over topics illustrates how this statistical model can capture similarity in the semantic content of documents.

comparison of the two reranking strategies
the parameter β indicates the scale of topics for the retrieved passages. given different β, retrieved passages can be factorized into a series of topics at different scales. we propose two re-ranking algorithms and two distance metrics, and therefore have four re-ranking algorithms, whose re-raking performance can be also shown in figure  <dig>  as the aspect level retrieval and the passage level retrieval were two major tasks in the trec  <dig> genomics tracks, system performances at these two levels with different β are also shown in figure  <dig> 

figures  <dig> and  <dig> respectively show nlminter and unine <dig> system performances at aspect level with different β. it can be seen from figure  <dig> that when β's value is between  <dig>  and  <dig> , performance improvements on aspect level can be achieved for all re-ranking strategies. for ranking strategies rank-nwin and rank-nwin* , the aspect map increases with the increase of β, reaches at a peak for β =  <dig> , then decreases, and reaches at a local peak when β =  <dig> , and finally it plummets. for rank-nwin_group and rank-nwin_group*, the aspect map increases from β =  <dig> , reaches at a local peak when β =  <dig> , then drops down and jumps to a peak for β =  <dig> , and thereafter falls down. figure  <dig> shows that retrieval results at aspect level are better than the baseline runs with all βs for rank-nwin_group and rank-nwin group*. aspect map increases as β increases, reaches a local peak when β =  <dig> , and then decreases slightly, after that grows when β =  <dig> , reaches the maximum, and then drops down quickly. for rank-nwin and rank-nwin* , the performance improvements on aspect level are achieved when β =  <dig>  and  <dig> .

nlminter and unine <dig> system performances at passage level with different β are shown in figures  <dig> and  <dig>  comparing figures  <dig> and  <dig> with figures  <dig> and  <dig> respectively, we could observe that the trends of performances on aspect level and passage level are generally in agreement with rank-nwin-group and rank-nwin_group*. the observation illustrates that there are a clear correlation between aspect map and passage map. however, for rank-nwin and rank-nwin*, the trends of performances on aspect level is different from passage level. this could be caused by the reason that rank-nwin and rank-nwin* algorithms change original passage ranking within a large ranges. furthermore, we demonstrate that two different distance metrics, with or without weight, do not influence re-ranking performance significantly.

the comparison results shown in figure  <dig> indicate that both of the two proposed re-ranking methods are effective in promoting diversity for biomedical information retrieval, and rank-nwin-group outperforms rank-nwin in most cases.

CONCLUSIONS
in this paper, we propose an approach which employs lda, a topic generative model, to promoting ranking diversity for biomedical information retrieval. our contribution is three-fold. first, to the best of our knowledge, this is the first study of adopting topic model to biomedical ir. different from other approaches considering aspects on word level, our approach assumes that aspects should be identified by the topics of retrieved documents. we employ lda model to discover topic distribution of retrieval passages and word distribution of each topic dimension. second, since retrieved passages' distribution for each aspect is different, even the same weight value in different aspects would be of different importance, we made transformations with topic distribution. third, two re-ranking algorithms based on "n-size slide window" are proposed, which take both passage novelty and relevance into account. experiments conducted on trec  <dig> genomics track collection demonstrate the e effectiveness of our approach. the evaluation results show that our approach can achieve 8% improvement over the highest aspect map reported in trec  <dig> genomics track.

in future research, we intend to extend this work by exploring both more complex models and more sophisticated algorithms. we have shown the e effectiveness of our approach in biomedical information retrieval area, and this approach can be adopted to a variety of other domains. for example, we could apply our approach to other test collections, such as clueweb <dig> collection, to investigate whether the approach is still effective for improving ranking diversity in the web search. furthermore, ranking diversity plays an important role in a range of tasks or applications, such as information retrieval, social network analysis and recommendation system, etc. we thus plan to further improve our approach to solve the diversification in the above mentioned fields.

competing interests
the authors declare that they have no competing interests.

authors' contributions
yc proposed reranking strategies, carried on the experiments and drafted the manuscript. xy and jxh contributed in the study design and experiments. zl, xh and jxh supervised the study and revised the manuscript.

