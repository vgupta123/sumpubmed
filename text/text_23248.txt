BACKGROUND
complex biological pathways play a role in many common diseases, such as heart disease and cancer. genetic variants in the genes involved in these pathways may independently or in combination influence disease risk. the majority of genetic association studies, however, report results from sequentially testing marginal associations between each genetic variant and disease. while this approach has certainly had many successes, it is unlikely to capture many relationships among variables, such as gene-gene interactions  <cit> .

for applications with few candidate genetic variants, conventional multivariable regression modeling works well. here, the analyst uses a combination of model fitting and an understanding of biological context to build a model that may include confounding and interaction variables. when there are many variables, however, the analyst must turn towards automated variable selection algorithms, such as stepwise regression. these approaches often result in a single best model that ignores the uncertainty in the decisions made in building it.

bayesian approaches to variable selection address the uncertainty issue directly by using the posterior distribution of models rather than a single best model for inference  <cit> . when there are a small number of variables, exact computation can be accomplished by enumerating all possible models. with many variables this quickly becomes intractable and the posterior must be approximated with markov chain monte carlo  methods. recently, bayesian frameworks have been introduced for modeling complex interactions  <cit>  and risk scores for rare genetic variants  <cit> . these mcmc approaches, however, have been limited to applications with a relative small number of candidate variables because they do not efficiently sample the posterior distribution.

we introduce a framework called peak that improves the efficiency of mcmc by dividing a large set of variables into related groups using a rooted graph that resembles a mountain peak. our algorithm is flexible to different model specifications and takes advantage of parallel computing and existing biological databases when available. the framework will allow for comprehensive analyses of genetic association studies using modern bayesian modeling approaches.

methods
the peak framework is an implementation of bayesian variable selection for applications with many candidate variables . inference is based on the posterior distribution of models. the posterior probability for model m is given by

 p=pp∑m∈mpp 

where d is the observed data, p is the marginal likelihood for model m , p is the prior for the particular model , and the denominator is a constant found by summing over all models m. the marginal posterior probability for any variable of interest  is computed by summing the probabilities for each model containing the variable,

 p=∑m∈mpip∈m 

where ip∈m is an indicator if the variable p is in the model m. additionally, the bayes factor , the ratio of posterior to prior odds, is used to evaluate the extent the data supports a particular variable,

 bf=p/)p/) 

where a bayes factor of 1– <dig> is considered weak evidence, 3– <dig> positive evidence, 20– <dig> strong evidence, and greater than  <dig> very strong evidence  <cit> .

in many applications, an exhaustive search of m is intractable and the posterior distribution is approximated using mcmc methods. the peak framework is designed to efficiently sample from p using mcmc by using a graph to divide the set of candidate variables into groups.

model specification
the form of models considered by peak is flexible, and the model likelihood is specified by the user. in this implementation, we fit generalized linear models . the data d contain the outcome variable y and a matrix of p explanatory variables x . the expected value of yi, the outcome variable for individual i, depends on the linear predictors through the link function g such that,

 g=β0+∑ppβpxipip 

where μi=e,βp is the regression coefficient of variable p, and ip is a variable indicating if xp is included in the model m. the desired link function, the highest order interactions to consider in a model  and d are provided by the user.

graph-based metropolis-hastings
the peak framework implements a random-walk metropolis-hastings  algorithm  <cit>  with a custom proposal density. the proposal is customized through a vector of tuning probabilities ρ. if the tuning probabilities were equal for all variables, then the peak algorithm reduces to traditional m-h. peak customized the proposal using a graph to break the model search space down into local regions .

the p candidate variables are mapped to concepts, which are related through a directed acyclic graph . we specify a rooted dag g= consisting of a set of vertices v  and a set of directed edges e that connect pairs of concepts. concepts represent groups of variables . the edges may represent different relationships and can be either generic  or domain specific . g has a root vertex  in which all other vertices and edges are oriented, with vertices closer to the root being parents and those further away being children.

the algorithm begins by estimating the posterior probabilities for the set of variables mapped to the leaves of g. as concepts join in g, the algorithm estimates the posterior probabilities for a larger set of variables, returning to regions identified by local searches performed earlier by the tuning probabilities .

at the leaves of g, the tuning probabilities ρ are user defined. since we are interested in models with interactions, we set the default for these tuning probabilities so the proposed model m′, on average, involves two explanatory variables. for the internal vertices, ρ is weighted to ensure that the entire model space can be explored  or never  proposed in the new model m′). to accomplish this, we place a beta prior on the tuning probabilities to shrink the posterior probabilities computed at the end of algorithm  <dig> for vertex v’s children towards the default tuning probabilities for v.

algorithm  <dig> estimation of the posterior probabilities for all variables mapped to concept v in the directed acyclic graph g  

job management and parallel computing
the peak software queues algorithm  <dig> based on the graph using portable batch system . initially all the leaves of g are queued and executed in parallel up to the number of processors available. for internal vertices, a job is queued immediately after the completion of its children and executed when a processor becomes available. algorithm  <dig> is currently implemented in   <cit> .

simulations
we used data simulations to compare the performance of the peak algorithm, with different graphs and variable mappings, to the standard m-h algorithm. for the simulations, we assumed a binary outcome yi where yi∼bernoulli and a link function, g=logπi1-πi. each data replicate included j= <dig>  binary variables, which we refer to as genetic variants, and j2= <dig>  interaction variables. the outcome variable y was generated under additive and interaction true models, where variants x <dig> and x <dig> were involved: 

•scenario 1:g=β0+β7x <dig> i+β10x <dig> i with β <dig> and β10= log

•scenario 2:g=β0+β7x <dig> i+β10x <dig> i+βx7:x10x <dig> i:x <dig> i with no simulated main effects ) and an interaction effect between x <dig> and x <dig> )

for each scenario, we generated ten data replicates of  <dig>  individuals for analysis.

as input to the peak algorithm, we generated two different graphs. the first graph was obtained from the gene ontology database for the biological process “response to oxidative stress”. this six-level informative graph is denoted g <dig> and is presented in figure  <dig>  g <dig> was used in the analysis of the simulation datasets and a genome-wide study of childhood asthma. the second graph was not derived from a biological database. this graph  was symmetric with many concepts joining in three levels . the causal variants x <dig> and x <dig> were mapped in two different ways to these graphs. for the informative graph, these variants were mapped to the same concept  and then to separate concepts  sharing a common biological process . for the symmetric graph, the causal variants were mapped to the same concept and then concepts with a distant common ancestor . the non-causal variants were evenly mapped to the leaves of g.

the m-h and peak algorithms were configured to consider models with any number of variables, including pairwise interactions, and run on all the scenario  <dig> and  <dig> datasets. the m-h algorithm was run for u= <dig>  iterations. the peak algorithm was configured for g <dig> and g <dig> and the different variable mappings. algorithm  <dig> was run for u= <dig>  iterations for all vertices below the root and u= <dig>  iterations for the root. multiple chains with different initial values were used to evaluate convergence. for comparison to traditional approaches, the best model was chosen by bayesian information criterion  using forward stepwise logistic regression on each dataset.

RESULTS
statistical inference
the marginal posterior probabilities for each genetic variant were averaged over the data replicates. the top ten genetic variants obtained from the m-h algorithm were then compared to peak. while the posterior estimates varied by data set as expected, the distribution of posterior estimates were highly consistent across the m-h and peak algorithms . thus, under the configurations used in these analyses, inference using the peak algorithm was equivalent to the traditional m-h algorithm.

for the scenario  <dig> datasets, the simulated causal variants x <dig> and x <dig> were among the top variants. while some non-causal variants had elevated posterior probabilities in individual datasets , only x <dig> and x <dig> showed evidence across datasets. the maximum posterior probability for x <dig> was  <dig> , meaning that for this dataset, there was very strong evidence in favor of including this variable in the model . among the other scenario  <dig> datasets, there was positive evidence for including x <dig>  but with much lower posterior probabilities . the maximum posterior estimate for x <dig> was  <dig>  and had strong evidence of association . across datasets, there was positive evidence for including this variant in the model . no pairwise interactions had elevated posterior probabilities. this was expected given the data was simulated under an additive model. using forward stepwise regression on the scenario  <dig> datasets without considering interaction variables, x <dig> was included in the best model six times and x <dig> was included four times.

for the scenario  <dig> datasets, the simulated causal variants were again among the top variants. marginally, x <dig> showed evidence across the datasets , whereas x <dig> had a rather low posterior overall . this reflects that x <dig> was infrequently included without the interaction variable between x <dig> and x <dig>  this interaction had extremely strong evidence of association in one dataset , and positive evidence in the others . when analyzed these datasets using forward stepwise regression, x <dig> was included in the best model three times, and x <dig> was never included in the best model, indicating that x <dig> lacked a marginal effect in these datasets.

computational aspects
the peak algorithm selects variables to include in the proposed model based on a vector of tuning probabilities ρ. unlike the standard m-h algorithm, the probability of including each variable is dynamic and may change as a function of the evidence from lower levels in the graph. this can result in each variable having different probabilities of being included in the proposed model. the number of iterations  expected to propose the causal variant is proportional to the tuning probabilities, which are influenced by the graph and the way the variables are mapped to the graph. we defined speedup as the ratio of the custom tuning probabilities  used at the root of g to the uniform proposal probabilities used in the m-h algorithm. the tuning probabilities were summarized for the top genetic variants and compared to the m-h algorithm .

for the scenario  <dig> datasets, the tuning probabilities for the non-causal variants were close to the default of  <dig> , implying they were proposed with relatively low frequency. the causal variants had elevated tuning probabilities across the datasets . for example, with the informative graph g <dig>  the median probability for ρ <dig> was  <dig>  representing a speedup over the m-h algorithm of approximately  <dig>  and for the symmetric graph g <dig>  the median probability for ρ <dig> was  <dig>  with a speedup of  <dig>  this implies that the peak algorithm proposed the causal variants more often, and in expectation, greatly reduced the number of iterations  needed to propose the true model. for both causal variants, the tuning probabilities were higher for the symmetric graph than the informative graph . thus, having fewer variants mapped per leaf may have yielded a slight advantage to the symmetric graph. under an additive true model, the differences in variable mappings did not appear to significantly influence the tuning probabilities. there was a slight decrease in ρ <dig>  however, when the causal variants where mapped to distant concepts in the symmetric graph.

for the scenario  <dig> datasets, peak again improved the rate of convergence . with the true model containing an interaction, however, the performance was more dependent on the graph and where the causal variables were mapped to the graph. overall, the symmetric graph had higher values of ρ <dig> than the informative graph. the values of ρ <dig> were similar for the informative graph regardless to whether x <dig> shared the same concept or parents concepts with x <dig>  for the symmetric graph, when x <dig> was mapped far away from x <dig>  the values of ρ <dig> decreased, implying that both x <dig> and the interaction with x <dig> would be proposed less frequently in this case. the results show that for these data, the symmetric graph with the causal variables mapped to the same concept would be expected to converge the fastest.

the speedup from using parallel computing is highly dependent on the graph used. using  <dig> computing nodes for the processing of the symmetric graph, the speedup was  <dig> . for the informative graph using  <dig> computing nodes, the speedup was only  <dig> .

application to a genome-wide association study of childhood asthma
asthma is the most common chronic disease in children. there is evidence that cellular responses to oxidative stress are important in the development and progression of asthma  <cit> . variants in genes involved in this biological process may independently and jointly influence asthma risk. using data from a genome-wide association study  of childhood asthma and gene ontology, peak was used to find associations between  <dig>  variants in oxidative stress genes and childhood asthma.

the children’s health study  is an ongoing cohort study spanning  <dig> southern california communities investigating both genetic and environmental factors related to childhood asthma and lung function growth  <cit> . the chs gwas was a nested case-control sample selected from the chs cohorts genotyped for over  <dig>  single-nucleotide polymorphisms . after quality control screening, a total of  <dig>  subjects  were available for analysis. genotype imputation was performed using mach  <cit>  with the hapmap release  <dig> haplotypes as a reference. we extracted  <dig> genes associated with the concept “response to oxidative stress” in gene ontology . the ucsc hg <dig> start and stop position for each gene were extended by  <dig> kilobases and converted to compatible coordinates using liftover. for these regions,  <dig>  genotyped snps with an imputation quality of r2≥ <dig>  and minor allele frequency ≥ <dig>  were candidate variables. logistic regression models were considered, with imputation dosages of the minor allele being used for each snp, and including covariates to adjust for sex, chs cohort, self-identified ethnicity, and ancestry covariates obtained from the software structure  <cit> . over  <dig> million interaction variables were considered with no restriction on the size of the model. an extended version of the g <dig> graph was used with the  <dig> genes linked to the  <dig> gene ontology concepts. algorithm  <dig> was run for  <dig>  iterations for concepts below the root and one million iterations for the root. the root process took  <dig>  hours on an amd opteron  <dig>  ghz.

a summary of the top snps associated with childhood asthma are given in table  <dig>  the variant with the most evidence of association with asthma was rs <dig> in the erbb <dig> gene on chromosome  <dig> . other snps within erbb <dig> were associated with asthma included rs <dig> , rs <dig> , and rs <dig> . another region of interest was bcl <dig> on chromosome  <dig> flagged by rs <dig> , rs <dig> , and rs <dig> . both erbb <dig> and bcl <dig> were linked to response to hydrogen peroxide in go. the top interaction involved rs <dig> in bcl <dig> and rs <dig> in arnt on chromosome  <dig> . other interactions were found but with estimated posterior probabilities < <dig> , many of which included either bcl <dig> or erbb <dig> 

 <dig>  snps genotyped in a gwas of childhood asthma were extracted from  <dig> genes mapped to response to oxidative stress in gene ontology. the top estimated marginal posterior probabilities and bayes factors are reported.

discussion
the peak algorithms can be provided with different types of graphs. informative graphs group variables conceptually. these graphs can be created by the user or automatically extracted from existing databases, such as kyoto encyclopedia of genes and genomes  pathways  <cit>  or gene ontology. a hypothesized disease pathway, for example, can be captured by g with genetic variants or environmental factors being mapped to steps within the pathway. informative graphs allows inference on any user-defined functional unit that exists within the graph, for example genes or regions, steps in biological processes, or pathways within a larger network. these graphs may have an uneven distribution of variables mapped across concepts in the graph. if this unbalance is too extreme, there are too many variables with no information to customize the proposal. in this case, we recommend merging concepts or connecting additional concepts to widening the base of the graph.

there are applications where annotation does not exists or the knowledge captured is too sparse or vague to group variables in a meaningful way. in cases with no information, we recommend a symmetric graph with the set of variables divided into groups containing up to  <dig> variables. while the performance of our method is sensitive to graphs or variable mappings that do not accurately represent biological truth, there is still a benefit in dividing a large set of variables using a graph. in our simulations, we showed that a symmetric graph had better performance than the m-h algorithm because it allowed many small portions of the model space to be considered in parallel. the efficiency, however, may be dictated by the marginal effects of a variable, which may be small or non-detectable for certain types of interactions. for example, we had trouble finding the true interaction when the variants in scenario  <dig> were mapped to distant relatives in g <dig>  when variables involved in a true interaction are mapped to the same or closely related concept , they are discovered near the bottom of the graph and these findings are propagated up the graph.

the peak framework improves performance of the m-h algorithm by constructing a custom proposal density that can quickly explore the model space tagged by earlier searches. there is a tradeoff, however, between exploring the entire model space and discounting regions as uninteresting. the former converges to the same posterior distribution of models as direct computation , while the latter is necessary for the algorithm to complete in a reasonable amount of time. while not in a mcmc framework, other bayesian variable selection algorithms have summarized the posterior distribution of models for a subset of models defined using a search heuristic such as occam’s window  <cit>  or the leaps and bounds algorithm  <cit> . the peak algorithm approximates the posterior distribution of models of interest, but given enough iterations, as shown in our simulations, approximates the posterior distribution of all models. the peak algorithm is not a traditional adaptive algorithm because the proposal is customized by the metropolis-hastings algorithms that ran on child vertices of g. the target distribution is not biased since the tuning probabilities are set before the metropolis-hastings algorithm begins and the proposal is not adapting while the chain is executing.

the peak framework is capable of scaling to high-throughput genotyping and sequencing applications . although large applications would require considerable computing resources, cluster and cloud computing are becoming inexpensive and accessible. for smaller applications , peak could be run on a workstation with a multicore processor.

CONCLUSIONS
we have introduced a flexible analysis framework capable of efficiently performing bayesian variable selection in data with many candidate variables. the peak framework manages an extremely large model space by grouping variables on a graph and using many local searches to construct a custom proposal density for the metropolis-hastings algorithm. the peak algorithm can be provided with an informative graph, which can be advantageous when considering gene-gene interactions, as demonstrated in the asthma application. alternatively, peak may be provided with a symmetric graph, which simply divides the model space into manageable regions. the peak framework is compatible with various model forms by modifications to the proposal and model likelihood functions, allowing the algorithm to be configured for different study designs and applications, such as family-based studies and rare-variant analysis of sequencing data.

abbreviations
mcmc: markov chain monte carlo; glm: generalized linear model; m-h: metropolis-hastings; dag: directed acyclic graph; snp: single nucleotide polymorphism; go: gene ontology; chs: children’s health study.

competing interests
dr. baurley is co-founder and an employee of biorealm llc.

authors’ contributions
development of the method ; developing the software ; writing the manuscript . both authors read and approved the final manuscript.

