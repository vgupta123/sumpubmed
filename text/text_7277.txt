BACKGROUND
the metabolism of whole cells can be described as a network of metabolites and reactions interconverting these metabolites. to understand cellular systems, dynamic modeling of cellular processes has become an important task in systems biology  <cit> . dynamic models describe the whole system and the state of each reacting species therein in a time-dependent manner  <cit> . once such a model is constructed, several network properties can be derived, for instance stability, robustness, or the long-term behavior  <cit> . furthermore, a well developed model provides a basis for predictions under different perturbations or varied environmental circumstances and can be applied to enhance the yield of desired metabolic products like certain amino acids  <cit> .

to set up such models, appropriate rate laws have to be assigned to each reaction within the network. from these, a differential equation system that characterizes the rates of change of each reactant can be derived. however, setting up model equations is a difficult task. for many larger networks available in databases like kegg <cit>  or metacyc <cit>  the reaction mechanism remains unknown. in many cases, reliable rate equations for the reactions are not known because these actually have to be derived for each catalyzing enzyme individually  <cit> . it is therefore a common approach to apply approximative rate laws, which characterize the most important features of the reaction rate. many rate laws, which are either continuous or discrete, and either deterministic or stochastic  <cit> , have been proposed for this purpose. several examples of each group exist such as probabilistic  <cit> , phenomenological  <cit> , or semi-mechanistic approaches  <cit> .

a second problem arises whenever a dynamic model of biochemical systems is created, because any such model contains a certain number of parameters like the reaction rates, michaelis constants or the limiting rate as well as constants describing the influence of certain inhibitors  <cit>  or, in stochastic systems, the reaction propensity  <cit> . except for phenomenological models like power law approximations  <cit> , linlog  <cit> , or loglin kinetics  <cit> , the parameter values can often be measured. however, this procedure is time-consuming, expensive, and often impractical. online databases like the brunswick enzyme database   <cit>  provide measured parameter values for many enzymes, but variations in the experimental settings, under which these and the time series measurements for the system under study were obtained, limit the applicability of these values for modeling purposes. in addition, it was observed that there are differences between parameters measured in vivo and in vitro . the application of computational methods to optimize model parameters regarding the fit error has therefore become an important task in the model identification process  <cit> . in this connection, the optimizer tries to minimize the distance between measured values or values created in silico and the simulated time course for each reacting species by varying the model parameters. the smaller this distance is, the higher is the quality of a possible solution for one parameter set. this quality measure is often called the "fitness" of the parameter set. as an exhaustive search for the best solution is computationally not possible, heuristic optimization methods try to find the global optimum of the system. usually, metabolic systems are analytically hard or infeasible to solve. often those systems are non-convex or multimodal, i. e., contain numerous local optima, and the gradient cannot be computed easily. biologically inspired optimization procedures like evolutionary algorithms  are known to handle even highly nonlinear optimization problems  <cit> . many such optimization algorithms are freely available in several software packages  <cit>  or included in commercial toolboxes  <cit> .

during the last few decades, manifold derivatives of eas have been proposed. each of them has certain advantages and is therefore more or less appropriate for a special problem. their development was driven by analogies to natural phenomena such as darwinian evolution , hill climbing  <cit> , the formation of crystal structures in metallurgy , or the swarm intelligence idea . each one of these optimization procedures provides several settings that influence its performance; for instance, the temperature in simulated annealing, the crossover probability in genetic algorithms, or the population size in particle swarm optimization. for a detailled introduction to all heuristic optimization procedures used in this work .

in several studies, heuristic optimization procedures like eas have been applied successfully to biochemical systems after these have been translated into sets of differential equations  <cit> . most of the time standard settings for the optimization procedures are used. an analysis of these settings does, in fact, enable enhancement of the performance of the optimization process  <cit> . in many cases, a lack of time prevents researchers from systematically benchmarking these settings. in order to improve the model quality, however, this would be necessary. the resulting model systems, including the identified parameters, are often used to derive network properties like the long-term behavior or to perform steady-state analyses  <cit>  of the system, but only in few cases detailed and specially derived rate laws could be applied to deduce a model system  <cit> . many studies are available, in which a single type of approximative rate equation is applied to set up a model – in many cases without a comparison with alternative approaches. guthke et al. modeled the amino acid metabolism of primary human liver cells using a phenomenological approach  <cit>  whereas liu and wang used s-systems  <cit>  for their biochemical models  <cit> . magnus et al. applied linlog kinetics  <cit>  to model the valine and leucine metabolism in c. glutamicum  <cit> .

very few studies compare alternative modeling approaches to investigate their applicability for the specific problem  <cit> . while spieth et al. studied whether in silico time series data generated with certain model systems can be reproduced crosswise with other ones  <cit> , bulik et al. analyzed properties like stability when detailed kinetic equations within a system are replaced by approximative ones  <cit> .

an investigation of both, alternative modeling approaches together with a systematical benchmark of the settings of optimization procedures, was rarely done. the disposability of software tools, which assign rate equations more or less automatically  <cit> , requires the user to be especially aware of the properties of different modeling approaches and the possible quality that can be achieved with a certain type of kinetic models. since automatically created models have already been published  <cit> , and attempts have been made to scale up this modeling process to derive even genome-scale kinetic models automatically  <cit> , these properties are of paramount importance. summarizing, to construct a mathematical description of a biochemical reaction system the modeler has to consider at least two central questions:

 <dig>  which rate laws are the most appropriate ones for the specific purpose?

 <dig>  which optimization procedure performs best on the problem class of parameter inference?

once a model has been created, the choice of initial conditions represents a further important question for an appropriate simulation of the model. fundamentally, the system can be written as an initial value problem, sometimes referred to as a single-shoot approach  <cit> , or as a multiple-shooting problem  <cit> . here, a single-shoot strategy is employed using the steady-state concentrations of the participating metabolites as initial values.

this work addresses both questions and tries to identify an optimal model for a well-studied example network: the metabolism of l-valine  and l-leucine  in corynebacterium glutamicum, an aerobic gram-positive bacterium which is used to produce about two million tons of amino acids per year  <cit> . for this reaction network  we construct seven alternative systems of differential equations based on four rate laws. these are the generalized mass action rate law  <cit> , michaelis-menten equation, and convenience kinetics  <cit>  as well as the stochastic langevin equation  <cit> . to evaluate the influence of irreversible reactions, we construct two models for each deterministic rate law: one in which all reactions are considered reversible and a second one in which only two reactions are considered reversible. in a two-step benchmark we systematically examine eight optimization algorithms to estimate the parameters of all models. in a coarse-grained trial all algorithms are applied to all model systems with standard settings. in the fine-grained benchmark, alternative settings of the algorithms are evaluated to improve their optimization performance on the best models. we focus on nature-inspired heuristic optimization procedures , namely, hill climber , simulated annealing , genetic algorithm , evolution strategy , differential evolution , particle swarm optimization , and tribes. a random  optimization serves as a general reference algorithm.

the reactions in kegg are lumped together resulting in this reaction scheme which is in accordance with metacyc except for the question of irreversibility, and apart from r <dig> and r <dig>  which are reversible.

RESULTS
mathematical models
the reversibility of the reactions constitutes another important question to be solved before modeling. as transport through the cell wall removes both products from the cellular system, we assume that there is no reverse reaction  and, hence, consider both reactions irreversible. the two reactions r <dig> and r <dig> are reversible  <cit> . we let the optimization procedure "decide" if the remaining reactions should be modeled in a reversible or irreversible way. to this end, we construct one "reversible" and one "irreversible" alternative model for each rate law, keeping only the two known reactions r <dig> and r <dig> reversible.

in this way we derive the following seven models based on four approaches for the reaction velocity on this pathway. details and the formulas can be found in methods and .

gmakr pure generalized mass action kinetics, in which all reactions apart from r <dig> and r <dig> are modeled reversibly, with  <dig> parameters.

gmaki pure generalized mass action kinetics, in which only the two reactions r <dig> and r <dig> are considered reversible, with  <dig> parameters.

gmmr like gmakr but with three michaelis-menten equations for reactions r <dig>  r <dig> and r <dig>  this model contains  <dig> parameters. in the gmakr model the influences of all enzymes are neglected and hidden in the rate constants, which is an oversimplification of the biochemical process. the model comes closer to the biochemical process when inserting michaelis-menten equations for the three reactions r <dig>  r <dig>  and r <dig> 

gmmi like gmmr but with only two reversible reactions r <dig> and r <dig>  leading to  <dig> parameters.

ckmmr convenience kinetics with three michaelis-menten equations as in gmmr. all reactions apart from r <dig> and r <dig> are considered reversible leading to  <dig> parameters. the convenience rate law is also an approximation of the biochemical process. therefore, we do not construct a pure convenience kinetics model of the whole system but apply michaelis-menten kinetics whenever this is possible .

ckmmi convenience kinetics with three michaelis-menten equations as in model gmmi, in which only the two reactions r <dig> and r <dig> are considered reversible, with  <dig> parameters.

lang to demonstrate the possibility of large-scale parameter optimization, even for stochastic models, and to model the effects of random fluctuations in the metabolite concentrations, we consider a stochastic description as well. based on the langevin equation, this system contains  <dig> parameters.

in a glucose stimulus-response experiment  <dig> measurements are taken for  <dig> metabolites on this pathway . the parameters of all models are calibrated with regard to these data.

fine-tuned optimization algorithms and models
in the next step the parameters of all seven mathematical models have to be estimated. in this process the relative distance between simulated model data and experimental data serves as a quality measure  of an estimated parameter set. note that the error between the measurements and the model simulation is to be minimized, so the quality of the solutions increases with decreasing error values. a random optimization  of the models  yields relative differences between measurements and model systems that are at least three times higher than the difference between the measurements and uncoupled cubic approximation splines. therefore, we apply the nature-inspired heuristic optimization procedures hc, sa, ga, es, de, pso, and tribes to all seven models with standard settings . apart from only some minor exceptions for the two irreversible models, five algorithms turn out to be especially useful . these are the binary-valued genetic algorithm , evolution strategy with covariance matrix adaptation  <cit>   with elitism , pso, de, and tribes. the performance of the lattermost procedure cannot be further improved as this algorithm is a settings-free derivative of pso. hence, we study the influences of various settings on the capabilities of the other four procedures aiming to improve the fit of the model to the data for each deterministic model.

this overview lists the standard settings for the optimization procedures used to infer the parameters in the differential equation systems. the algorithms de and pso do not follow the general scheme of mutation and crossover. the tribes algorithm is not listed here as it was designed to be a settings-free derivative of pso. the cmaes is used with and without elitism . for details, see methods and .

for all deterministic models  the five absolute best algorithms and the five average best algorithms with standard deviations are listed.

due to the generally better performance of the three reversible models, we examine alternative settings for the optimization procedures only for these models and subsequently apply the best setting found to each alternative irreversible model. the most promising settings are used to optimize the stochastic model as well.

taking a closer look at the effects of alternative mutation and crossover operators on binga and es  reveals that the more detailed ckmmr model can be fitted to the data with almost any combination of both operators, whereas the other two reversible models show larger differences. binga especially provides good performance with almost every operator combination. the only two exceptions are no mutation combined with one- or n-point crossover. the influence of these operators on es is much stronger and more problem-specific. some settings improve the performance of es, but most result in significantly worse fitness values. in contrast to binga, for which the combination of adaptive mutation with one-point or bit-wise crossover or adaptive mutation without crossover provides an improved average performance, the plots in figure  <dig> through figure  <dig> do not show such a general trend for es. thus, we evaluate the influence of the mutation and crossover probabilities pm and pc on only binga to identify the best ratio. the plot of the resulting fitness landscape for the gmakr model was limited to a fitness of  <dig> ). hence, areas with a worse performance are shown in white. the best combination pm =  <dig>  with pc =  <dig>  is the starting point for investigating the influence of different population sizes. we vary the population sizes from  <dig> to  <dig>  ). the larger the population, the smaller is the variance within this population. however, if the population is too large, this variance increases again. although a larger population leads to smaller variances, statistically, it does not help to find a better total solution for the optimization problem.

due to the fact that cmaesplus leads to reasonable results on each model and also that there is no general trend for alternative combinations of other mutation and crossover operators, we pick the ckmmr model to examine the influence of population size . the value of μ represents the number of parents in the population from which, in each generation, λ offsprings are created. figure  <dig> depicts the resulting fitness landscape. combinations of μ and λ with μ > λ are left out and occur as a white area within the landscape. larger population sizes lead to better average fitness values. es achieves its best average and total performance for . the combination  leads to only a slightly worse average and total fitness. these two settings clearly outperform all other combinations. by varying the values for f, λ, and cr we test how to improve the performance of de on each reversible model. generally, the choice of f =  <dig>  leads to a better performance than f =  <dig>  . the influence of the remaining two parameters is less clear. hence, we pick the best setting for each model and evaluate the influence of different population sizes . a population with  <dig> individuals performs best on each model according to the median.

to hone the performance of pso we alter both strategy parameters ϕ <dig> and ϕ <dig> on the star topology and apply a grid  <dig> and linear  <dig> topology using the standard values for ϕ <dig> and ϕ <dig> . on the three reversible models the grid  <dig> topology performs slightly better than all other settings. hence, we test how an alternative population size influences its capacity. figure  <dig> depicts the results of this experiment where we vary the size of the population in the intervall from  <dig> to  <dig>  a larger size lowers the quality and a small population of  <dig> individuals is confirmed to be the best choice.

comparison of the performance of the optimization algorithms
an overview of the most successful optimization algorithms together with their best suited settings can be found in table  <dig>  tribes is not the very best optimization algorithm but yields meaningful results for all models. as a settings-free procedure, tribes is a good choice if there is no time to examine alternative adjustments. the standard pso algorithm yields the best median fitness for the ckmmr model with  <dig> . on the gmakr model, de with f =  <dig> , λ =  <dig> , and cr =  <dig> , and a population size of  <dig> gives the best median fitness of  <dig>  for this model. this is almost  <dig>  better than standard pso. de yields a median fitness of  <dig>  on the ckmmr model when set to f =  <dig> , λ =  <dig> , cr =  <dig> , and a population size of  <dig>  both algorithms also perform well on the gmmr and the langevin model . hence, they are an advisable choice when optimizing the parameters of various mathematical models of biological systems.

for each model the minimal fitness and the corresponding standard algorithm are listed. the algorithm that achives the best average fitness and the corresponding average fitness are written in the last two columns together with the standard deviation. on the langevin model, pso with star topology, ϕ <dig> = ϕ <dig> =  <dig>  and a population size of  <dig> is the most successfull algorithm with a fitness of  <dig> .

comparison of the modeling approaches
to evaluate which model is the most promising one we consider the following three criteria:

 <dig>  fit of the model to the data

 <dig>  number of model parameters

 <dig>  computational time for simulation 

each reversible deterministic model can be fitted to the data with a similar deviation from the measurements. the irreversible alternatives show a significantly higher deviation. only the irreversible ckmm model is able to fit the data almost as well as the reversible models. however, most curves resulting from all of the irreversible models tend to become straight lines through the measurements, and thus behave in a biologically implausible manner . this suggests that the irreversible models are unable to follow the dynamics of the system due to their fewer degrees of freedom. the rather abstract reversible models are able to tackle possible side effects of reactions not included in this reaction system and simulate them in terms of the reverse reaction. these models also consider the fact that, in biological systems, reaction products are normally not completely absent. their concentration may be low, but they still take part in the reaction, in some cases giving a kind of feedback to the reactants . therefore, the irreversible models are generally not competitive with respect to the data fit. from the three remaining reversible models, the ckmmr model achieves the best fit to the data, with  <dig> , followed by gmmr model at  <dig>  , and the gmakr model at  <dig>  . the difference in the best model fit between the ckmmr and the gmakr models is only  <dig> . hence, all three reversible models can be fitted to the data with a similarly small relative squared error . a comparison of the best model fit  <dig>   to the fitness of the independently computed splines  evinces a difference of only  <dig> . when considering the number of parameters , the gmakr model shows a clear advantage with its  <dig> parameters compared to the  <dig> of the gmmr model or even  <dig> of the ckmmr model.

when choosing the parameter values for the gmakr model completely randomly, this system can hardly be integrated without step size adaptation. therefore, it is necessary to identify meaningful ranges of kinetic parameters within brenda  <cit> . a low-value initialization is necessary to assure numerically stable initial populations for the optimization procedures. for the other models this happens only if the parameters are chosen from implausibly large ranges.

the last criterion, the computation time, also depends on the complexity of the model but not necessarily on the number of parameters. the gmakr model requires the smallest number of mathematical operations, followed by the gmmr model. the most complicated model is the ckmmr model. the average evaluation time over  <dig>  repeats with randomly chosen parameters is  <dig> ms for the gmakr model,  <dig> ms for the gmmr model and  <dig> ms for the ckmmr model. for hardware details see the hardware configuration section.

in order to take the effects of random fluctuations into account, one has to use stochastic models of the chemical reaction system. however, the most general approach, the chemical master equation  <cit> , can hardly be solved numerically for larger systems  <cit> . taking the number of parameters  and the computational costs  into account, the langevin model is the most suitable formalism to consider the effects of random fluctuations while still providing an acceptable performance. since the model can be stated in a way that allows it to be integrated with standard solvers for ordinary differential equations, the computational costs are of the same order of magnitude as the solution of the gmakr model. however, care must be taken with respect to justification of the underlying simplifying assumptions  <cit> . the stochastic model equations of the biological system under consideration show no qualitatively different behavior in comparison to the deterministic model. the main reasons for this observation are found in the rather large molecule populations and the absence of points of instability in the allowed phase-space region.

parameter space analysis
once a model has been optimized several times and locally optimal parameter sets for the model are available, an analysis of the space of potential solutions becomes possible. this allows deducing characteristics of the solution space aiming to reduce the model complexity and enhance the optimization performance. if, for instance, two parameters show a linear dependency or correlation to each other, one of these can be removed from the model. another interesting experiment would be to determine new ranges for each parameter. this can be done if a certain parameter varies only in a very small range compared to its maximal possible range.

for each of the three models, gmakr, gmmr, and ckmmr, we gather all parameter values from all optimization runs that lead to a fitness less than  <dig>  in this way, we obtain one parameter matrix for each model, in which each column corresponds to one optimization run and each row stands for one parameter. we conduct three analyses on the best parameters on each reversible model :

 <dig>  clustering to identify groups of similar ranges or almost constant values and to visualize the values of each parameter.

 <dig>  variance analysis to visualize the scattering of each parameter.

 <dig>  multiple correlation analysis aiming at finding highly correlated parameters, some of which can be eliminated.

for histograms showing the parameter distribution of the gmakr, gmmr, and ckmmr models .

clustering groups similar parameters and similar optimization runs together. first, all parameters are reordered so that within the parameter vector all parameters with similar values over all optimization runs are placed next to each other. in the second step, all parameter vectors from every optimization run are swapped so that similar parameter vectors are located next to each other. figure  <dig> graphically displays the results of the clustering approach . the heatmaps show all parameters on the y-axis and all optimization runs on the x-axis. the lighter the color, the lighter the value e of the parameter in the respective optimization run, with black representing values close to zero. as can be seen, there is a very flat hierarchy so there are no groups of parameters showing a similarity, but there are many parameters which are similar to their neighbor. a similar flat hierarchy can also be seen for the optimization runs. there is almost no relationship between the values of the parameters with respect to the experiments. this means that each parameter was optimized independently by the analyzed procedures. some parameters show stripes within the heatmap of figure  <dig>  stripes like these mean that the corresponding parameter barely varies in its value over all experiments. note that these more or less constant parameters do not occur within the same cluster. all parameters of this type can either be replaced by their median thus reducing the complexity of the system, or the ranges of these parameters can be set to more restrictive values. however, the experiments are broken into two groups in all three models: the first group shows homogeneously distributed parameter values whereas the second one contains more differences. the level of differences in the second group rises with the complexity of the model.

these results are confirmed by the variance analysis , whose results are shown in figure  <dig>  as can be seen, the higher the dimension of the optimization problem, i. e., the more complex the model is, the higher are the variances among the parameter set. this indicates that all parameters in the ckmmr model are allowed to vary within a rather large range. such behavior is often referred to as a multimodal optimization problem. in contrast, the less complex models, gmakr and gmmr, showed several dimensions of almost no variance. this corresponds to the observation made from the heatmaps that certain parameter values can vary only within a small range of values or even stay constant over multiple optimizations. thus, the probability of finding multiple local optima increases with the model complexity. particularly, all parameters which represent the impact of inhibitors exhibit noticeably large variances. the biological interpretation of this is that variations in strength and concrete mechanism of inhibition in one reaction can be balanced in terms of other reactions because this pathway contains four feedback inhibition mechanisms for this purpose .

in order to identify linear dependencies between model parameters, we perform a multiple correlation analysis . for maximum generality, each parameter is assumed to possibly correlate with all other parameters of the system. several highly correlated parameters are found in each model system. the correlation results are shown in figure  <dig>  all highly correlated parameters found exhibited significant variances as can be seen in table  <dig> and figure  <dig>  we select a subset of parameters to be replaced by a linear regression model of highly correlated parameters. in this way the number of parameters is reduced by seven in the gmakr model, by five in the gmmr model and by four in the ckmmr model. subsequently, each model is optimized with the reduced parameter set, using the linear regression model for the non-optimized parameters. for this optimization, pso is used because it is the the best-performing procedure in our benchmark. the results are shown in table  <dig>  the parameter reduction induced only a small loss of performance in each model, indicating that the original number of parameters does not reflect the true degrees of freedom of the system.

the table lists the parameters that are replaced by linear regression models with coefficients ai, bi, ci of other highly correlated model parameters.

CONCLUSIONS
the purpose of this study is to identify both the most suitable modeling approach and the best-performing optimization algorithm to calibrate the parameters contained in metabolic network models. to this end, we constructed one probabilistic and six deterministic mathematical descriptions of valine and leucine biosynthesis in c. glutamicum. the parameters of each model were optimized with respect to in vivo measurements for the reacting species within the system. in this way we compared eight optimization procedures. we systematically benchmarked both the algorithms and the alternative models to highlight their advantages and drawbacks. in the following paragraphs, we draw several conclusions from the comparison of these seven variants of a realistic reaction system, and we assume them to hold for similar systems. thus, if no prior knowledge about a comparable metabolic system is available, our results can serve as a starting point for model construction and calibration.

let us consider the capabilities of the modeling approaches in more detail, when taking into account the ability to approximate measured data, the hybrid model for the reversible system based on convenience rate laws and michaelis-menten equations  has the best performance. at the same time, this is the most complex model with respect to the number of parameters and computational costs for each simulation. the acceptable parameter values for this model, found by multiple optimization runs, varied over several orders of magnitude. this corresponds to the fact that the optimization problem shows a large number of local optima, which is often referred to as multimodal behavior. furthermore, this model is integrable with parameter values selected by chance from an almost arbitrarily wide range. this means that no preliminary data analysis in enzyme databases is required to obtain an integrable start population for the ckmmr model.

on the other hand, a simplified deterministic description of the reaction system based on the generalized mass action rate law  yields good performance as well. its advantage over the ckmmr model is its small number of parameters. its major disadvantage is the strong tendency to become non-integrable when selecting parameter values by chance from a larger range. a restriction of the parameter space is required to ensure numerical stability when integrating metabolic network models. some of the parameters showed almost no variance among the results of multiple optimization runs.

for models of biochemical systems with low metabolic concentrations or systems operating close to the point of instability, stochastic effects should be considered. generally, simulating large stochastic models is computationally not feasible. the langevin approach is a simplified stochastic description which facilitates taking these effects into account at acceptable computational costs. for the specific biochemical example network considered in this study, the stochastic effects are negligible as the behavior of the langevin model is similar to the gmakr model due to the rather large molecular populations. however, the benchmark showed that this approach is suitable for large-scale parameter optimization and model inference.

modeling certain reactions in a non-reversible way as was done in all remaining models leads to a significantly worse ability to fit the measured data. we conclude that possible side effects are compensated by means of the reverse reaction. when modeling multi-enzyme systems all reactions should be treated reversibly, unless there is significant biological evidence to introduce irreversible rate laws. if neither the kinetic equations nor meaningful ranges of the parameter space are known, the model should be constructed using convenience kinetics. if the parameter space can be restricted using prior knowledge and the number of parameters matters, a model based on generalized mass-action rate laws constitutes an appropriate choice.

the second aim of this study is to identify the best-performing optimization algorithm for parameter estimation. the ability to find good local optima for the parameter values is the first quality measure for the algorithms. all five evolutionary algorithms tested yielded reasonable performance. from a user perspective, these algorithms differ in the number of settings which influence their behavior and are therefore more or less easy to apply. hence, the effort to find a good configuration for an algorithm constitutes the second criterion of quality. the tribes algorithm was among the best-performing algorithms in our benchmarks. as a settings-free optimization procedure, it is the most user-friendly method. however, other algorithms are able to yield even better results after fine-tuning. particularly, de and pso provided the best performance while keeping the effort necessary for their fine-tuning within reasonable limits. es and binga are also able to identify valuable local optima for all systems but require examining a large number of well-established alternative operators for their crossover and mutation steps.

for first optimization attempts, the easy to use tribes algorithm is a good choice. with slightly more effort, the user can adjust the algorithms pso and de to yield even better results. combined with the convenience kinetics modeling approach, these algorithms provide a suitable choice to model unknown systems of metabolic reactions.

