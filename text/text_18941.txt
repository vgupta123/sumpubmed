BACKGROUND
technologies for the automation of biological data analysis
biological data is available in heterogeneous information systems that are distributed over the internet. in this situation, data integration is needed in order to achieve a better and wider view of available information, to automatically carry out analysis and/or searches involving more databases and software and to perform analysis involving large data sets. in this frame, the need is felt for a system that is able to improve the information accessibility by raising it at an automatic level.

among current ict technologies, workflow management systems , in connection with web services , seem to be the most promising ones. a recent paper presented a methodology for the automation of in-silico data analysis processes through workflow management systems that takes into account the synergic use of xml schema, xml data storage, data and task ontologies, web services, workflows systems and enactment portals  <cit> .

more specifically, reasons for the setting up of ws in bioinformatics have already been presented by many authors  <cit> . ws have already been implemented by many institutes and service centres in the biomedical field. partial lists of web services for bioinformatics are available at the mygrid wiki site  <cit>  and in the taverna web site  <cit> . also, web services can be retrieved and accessed through the moby central  <cit> , a ws archive based on biomoby  <cit> , an open source software that implements an architecture for the discovery and distribution of biological data through web services.

workflows are defined as “computerized facilitations or automations of a business process, in whole or part”   <cit> . their goal is the implementation of data analysis processes in standardized environments and their main advantages relate to effectiveness, reproducibility, reusability of procedures and of intermediate results and traceability.

some wms have also been proposed in bioinformatics  <cit> , the taverna workbench  <cit>  from the european bioinformatics institute  probably being the best known among open source applications developed by public research institutes. it is able to build complex analysis workflows, to access both remote and local processors of various kinds, to launch execution of workflows and to display different types of results, including text, web pages and various kinds of images and diagrams. processors that can be used through the taverna workbench include web services. one kind of web services that can be accessed by using taverna workbench, are those implemented by using soaplab  <cit> , a tool for the rapid deployment of web services developed at ebi by martin senger.

extending available contents
new information sources are often developed by taking into account above mentioned technologies. otherwise, many databases, developed during previous years, do not offer a programmatic access to them: this reduces the information that is available for automated analysis.

sequence retrieval system  is a well known indexing and search engine for biomedical databanks, developed by thure etzold at ebi and currently distributed by biowisdom ltd. srs is able to efficiently query a set of local databases. among its most original and useful features are the possibility of querying many databases together and of integrating data retrieval and data analysis in the same tool. srs is usually searched through its user interface, the cgi compliant software wgetz, that offers a rich set of alternatives ways to interact with srs and to compose queries in its query language. it is possible to interact with srs by creating ad hoc urls that either specify a query or request a specific output, such as the list of available databanks and the description of fields composing a library. examples of this are presented in table  <dig>  from its version  <dig>  srs is based on a new architecture where software components communicate among them by using web services. these do not follow agreed w3c standards, are proprietary and are not publicly available. for these reasons, they cannot be used in a open environment for integrating contents of srs libraries with other network data sources.

this table shows some of the many possibilities of interacting with srs version  <dig> by submitting arguments and options to wgetz through the url . this kind of interaction is the basis of perl scripts that are run by sws services.

srs used to be free for academic and no-profit institutes. through its many public sites, it offers access to more than  <dig>  databanks and about  <dig> analysis tools. the most important databank, like genbank, interpro, and gene ontology, can be included in many sites. this partial redundancy can be used to overcome possible sites' crashes and network faults that can occur at any time. although some srs libraries are subsets or subsections of other, this does not mean that they have less relevance and interest for researchers. for the sake of the srs system they effectively are different databases, each of them having its special interest. advantages of considering such libraries as real databases include, for subsets, improvement of performances, and, for subsections and views, simplified data management. the latter topic is especially important when considering automated analysis. unfortunately, srs libraries are not accessible through ws. so, a tool that would allow to interact with these databanks through web services would be extremely useful.

previous work for web services for srs libraries
to our knowledge, the only attempt to develop a system that is able to interact with srs through web services was made by the group of prof. douglas kell at the university of manchester  <cit> . they developed srs2acd, a set of java classes that are able to create ajax command definition   <cit>  files for accessing each databank that is available in an srs site, given its main url. these files can then be used for deploying web services by using the soaplab tool. each one of the resulting web services is then specially devoted to a unique implementation, i.e. to one database in one srs site. main limitations of this tool are that each implementation has a related web service, thus producing a high number of services, and that access to alternative, but equivalent, ws is not automatically managed.

the list of public srs sites
a list of srs public sites  <cit>  is maintained by biowisdom ltd  <cit> . this information is available as a simple, partially structured, html page. the list allows to identify all available copies of a given database and to compare them on the basis of their number of entries. it also provides the status of each site at a given date, although it is only updated once per day.

as previously said, the same library can be included in many srs sites. this duplication and partial overlap can support fault tolerance and help overcome sites' crashes and network faults. an analysis of the status of sites  over a period of  <dig> consecutive days showed that less than the 50% of sites was always active in that period.

transparent access to srs contents
a system for accessing srs contents, without the need of specifying which implementation should be queried, would be useful. this ‘transparent’ access to srs would allow researchers using workflow management systems to abstract their workflow from the connection details and would offer them a way for avoiding network problems. such system should be able to check which sites are available at the time of execution of the workflow and select the ‘best’ site, i.e. the site including the most up-to-date information, among active sites.

in this paper, we present a set of web services that makes information available in public srs sites accessible as a whole, not singularly, through a programmatic access. it enables wms to access all active srs sites and to query needed libraries. it also manages access to alternative, but equivalent implementations, by also selecting the most up-to-date among available systems.

RESULTS
a suite of web services
we have developed sws , a suite of ws allowing to query biological databases available in public srs sites, without specifying which one, and to return results in a simple text-only format. it allows to check sites, to query selected libraries and to retrieve essential information on sites, such as lists of included databases and tools, and on databases, such as sites where they are implemented and related sizes/versions.

sws can be invoked by specifying the name of the databank to be queried and the query terms. it then automatically choose the best site, performs the query and returns complete results. users can also specify the following information: the srs site to be queried, the fields where the information must be searched, the desired output fields.

available web services
sws currently includes five web services. the following three ws allow to retrieve information on available databases. getdbs retrieves acronyms of all libraries that are available in a specified site, or in all known sites, if none is specified. similarly, getsites retrieves acronyms of all srs sites that include a specified library, or of all sites if no library is specified. finally, getimplementations retrieves all implementations of a specified library. these ws are only available for informative reasons, they do not actually query any srs site. instead, results can be used to identify available libraries and to choose sites and libraries to be queried in following steps.

the fourth ws, querysws, allows to actually perform queries on a specified library. the query  is a mandatory parameter. the site, instead, can be omitted. in this case, sws identifies the best one by selecting, among those that are active, the site where that specific library has the greatest number of entries and, when more sites have the same number, the most recent version of srs . further parameters of this ws allow to determine which parts  of the library must be queried, and which parts of the entries  must be returned.

finally, the fifth ws, testsites, allows to check for the availability of a site at a given time. input parameters are the acronym of the site to be checked, the number of retries  and the time between retries. all these parameters are optional. when no site is specified, all sites are tested.

ws name, inputs and outputs are summarized in table  <dig> 

retries: the number of retries after an initial failure. default value: 1
site: the acronym of the site. default value: best site
query: the query . no default value.
in_fields: list of library's fields to be searched. default: alltext
this table lists sws services by specifying their name, function, input and output.

availability of the tool
sws is available on-line  <cit> . through this site, users and software agents can retrieve wsdl descriptions of web services included in sws. some wsdl compliant wms, such as taverna workbench, can directly interact with sws through this interface and execute the services.

a support site for sws is also available on-line  <cit> . in this site, a description of the software and usage information of single ws are provided, together with contacts data. we plan to allow, in the near future, downloading all files needed to implement a local version of sws, including data structure, scripts for retrieving information on available sites, acd definitions for a soaplab implementation of web services, scripts that actually implement the services and installation instructions. sws is being developed as an open source and it is under refinement and continuous development.

discussion
we believe automation of data analysis and retrieval processes will offer bioinformatics the possibility of implementing a really machine-oriented, distributed analysis environment. for this to happen, the development and implementation of ws that allow to make access to an exhaustive set of biomedical databases and analysis software is needed. only a few of the many biological data sources that are currently available on-line can be queried through standard programmatic interfaces. our tool sws contributes to overcoming this limitation by supporting programmatic access to known srs sites. contrary to other similar tools, sws offers a unique point of access for all sites because it leverages from a database of available sites, databanks and implementations that is derived by biowisdom's list of public srs sites and kept up-to-date by using own scripts. biowisdom's list is a useful reference enabling sws not to start from scratch. it is used both as a starting list and to check for new sites. an exhaustive list of public srs sites is very difficult to achieve, we hope that in the near future we can set up an alternative list and receive information on new sites. by querying this database, sws can determine which is the best site for each databank at any given time, and it therefore overcomes, at least partially, possible problems arising from sites' crashes and network faults. this is achieved b using the number of records included in the databank since, usually, this increases each time a new version of the databank is released. information regarding databases' version is not usually available and, thus, it can only rarely be used. sws also allows for the creation of workflows that are not dependent on one single site and can, therefore, work more consistently.

sws currently presents some limitations that we plan to overcome in the near future. it is currently not able to query sites using srs  <dig>  due to the difficulty in building queries through wgetz with this version. this limitation can be considered a minor one, since the vast majority of public srs sites is still based on srs  <dig>  we plan to overcome this limitation by collaborating with administrators of srs sites with specific expertise on this version. another limitation of sws is that it can presently only be efficiently used when the srs configuration of a databank is known. in this case, both searched and retrieved fields can be specified. this can be overcome by adding support for the retrieval of descriptions of databanks fields. another limitation refers to the scarce information that sws reports about the databanks and sites it used for a query. in fact, it's true that users are not informed about which data set was used. this problem is going to be faced by including detailed information on data provenance, mainly comprising date, time, site, database, db version, number of records. finally, access to tools  that are available in srs sites is not possible. we don't see this point as a limitation, because of the availability of alternative web services offering access to this software, like, e.g., emboss  <cit>  related ones.

CONCLUSIONS
web services are the most promising among ict tools, in view of the automation of network based data retrieval and analysis in biology. we developed sws, a suite of web services that support query and retrieve of data from databases included in public srs sites. these web services can increase the amount of data that currently is available for the setting up of complex workflows and can in fact improve automation of in-silico analysis by extending possible applications.

sws is available for interested researchers through their workflow management systems, provided they are soap compliant and can use wsdl descriptions. the tool will soon be available for downloading from the sws support site for local implementations.

sws is currently being further developed in the sphere of the laboratory of interdisciplinary technologies in bioinformatics – litbio  <cit> .

