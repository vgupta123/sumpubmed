BACKGROUND
commercial products of next generation sequencing  technologies such as roche/ <dig> flx, illumina genome analyzer/hiseq, applied biosystems solid™system and helicos heliscope™have enabled the sequencing of dna much faster and cheaper than before  <cit> . these have shifted the paradigm of biological sequence analysis to a new level. currently these are not only being used for the sequencing of whole genome, but also for sequencing of known exons and transcriptomes as well. the main motivations behind the technology of targeted resequencing  include the following among others. the actual coding regions or the exons of the human genome account only for ~1% of the total sequences, which consequently gives about  <dig> mb data compared to  <dig> gb data in wgs  <cit> . currently, getting higher coverage of targeted regions using ngs technologies is about six times  <cit>  cheaper and faster compared to achieving the same coverage of whole genome. on the other hand approximately 85% of disease causing mutations lie in the coding regions  <cit> . targeted resequencing has been mainly used in medical sequencing to find disease causing genetic variations . recent studies on tr and wes data have successfully detected cancer specific mutations  in breast cancer  <cit> , ovarian cancer  <cit>  and prostate cancer  <cit> . although, exome sequencing has been successfully used to find small variations in cancer genomes, its potential to find large structural variations such as cnv has not yet been fully explored.

cancer arises due to the acquisition of many somatic variations by the dna of cancer cells  <cit> . copy number alterations  play a major part in the progression of this deadly disease  <cit> . until recently, the most common method to detect cnv in cancer dna was to use micro array based technologies. however, during last  <dig> -  <dig> years many algorithms have been developed to identify cnv in cancerous data generated by whole genome sequencing  <cit> , making use of the vast amount of data produced by ngs technology. the higher resolution that can be achieved through ngs data has helped to detect new variations that were undetectable previously and include cnvs which are as small as  <dig> bp  <cit> . these methods use the number of reads mapped to a particular region in the genome, to find copy number varying regions in one genome compared to one or more other genomes. some of these methods have been adapted from the methods used in acgh. for example circular binary segmentation   <cit>  and hidden markov model   <cit> . however, methods in whole genome sequencing cannot be directly applied to whole exome sequencing data due to the small size and sparseness of these data  <cit> . on the other hand, the useful signal will be hindered by the intrinsic noise present in the exome sequencing data itself due to various biases introduced in target capturing and sequencing phases. to address these issues and to utilize the advantages provided by targeted resequencing, new algorithms have to be developed. since the end of  <dig>  very few bioinformatics methods for detecting copy number variations in targeted resequencing data have been published. the method in  <cit>  describes the use of tr data to detect cnv in cancer samples. however, the targeted regions in this method are larger in size , where as exons are much shorter . methods such as  <cit>  are developed to find cnv in non cancerous exome data, such as in population studies. contra  <cit>  is a recent method proposed to evaluate cancer tr data using a pooled or a matched normal sample. exomecnv  <cit>  and var scan  <dig>  <cit>  are specifically designed for whole exome sequencing of cancer samples. a limitation in these approaches is that they have a higher number of false positives which result in a very low precision .

in this work, we present convex, a method that evaluates exon level depth of coverage ratios to assess variation in copy number of whole exome capture data produced from cancer samples. we propose to use discrete wavelet transformation denoising to reduce the variability of coverage ratios and then use hmm to detect copy number variations. our method reduces the number of false positives by efficient pre-processing of the data, which results in a mean precision of more than 50%.

methods
data pre-processing
depth of coverage ratios at each targeted region
number of reads covering each base at a targeted region is calculated using bedtools  <cit> . then the exon level depth of coverage  is calculated as mean of the per base coverage of that particular exon. to control the quality, only the regions having more than  <dig> bp doc in the control sample are retained for further analysis. to correct for the differences in total number of reads in tumour and control samples, the exon level doc is divided by the mean of doc of all the exons in that sample. then the exon level doc ratio at region i is calculated as,

  ri=ntinci 

where nti and nciare the mean normalized doc of tumour and control respectively.

dwt smoothing of the data
the actual copy number of the exon regions can be masked by the noise present in the data itself. this would lead to lot of false positives. the raw signal of exon level ratios can be represented as below,

 ri=r¯i+ϵi 

here, r¯i is the true signal of copy number variation with additive noise, ϵi. this noise can be assumed to be iid with nwhere σ is the standard deviation of the distribution. we have used dwt smoothing  <cit>  on ri, to detect true signal r¯i to increases the ability of actual copy number prediction. the dwt smoothing procedure starts by first taking discrete wavelet transformation of ratios using "haar" wavelet. the fundamental assumption behind discrete wavelet transform is that, there is a correlation between the two neighbouring samples or data points. this is very much true in predicting cnvs as they span multiple successive exons. the selection of haar wavelet family was based on the fact that it computes the wavelet coefficients as the difference between two near by blocks of data points. this feature helps to retain the information regarding copy number aberration points. the shrinking of the dwt coefficients were done using soft thresholding function and the threshold value was calculated by stein's unbiased risk estimator  for each level of dwt. finally, the modified coefficients were used to reconstruct the de-noised signal at ithlocation of chromosome j, r¯ij, by taking the inverse transform.

cnv prediction using a hidden markov model
the copy number state for each targeted region is assigned using a hidden markov model. the copy numbers are represented by the hidden states and as default we have used states from  <dig> to  <dig>  these six states can be interpreted in biological context as homozygous deletion , hemizygous deletion , no cnv or copy neutral ,  <dig> copy gain ,  <dig>  and  <dig> copy amplification . dwt smoothed ratios, r¯ij, are fed to the model as observations. each chromosome j of each tumour-control samples pair is considered separately for copy number identification using the hmm. the fitted discrete time hmm is given below with the same notations as described by rabiner  <cit>  and fridlyand et.al.  <cit> .

 <dig>  the total number of hidden states in the model is given by k and those are denoted by s = s <dig>  s <dig> ..., sk. if there are l exons in the sample of consideration, the state of lthexon  equals to skwhere  <dig> ≤ l ≤ l and  <dig> ≤ k ≤ k.

 <dig>  the initial state distribution π = {πk} where

 πk=p,1≤k≤k 

 <dig>  the state transition probability distribution a = ampwhere

 amp=p,1≤m,p≤k 

 <dig>  the emission probability distribution is given by b = {bk} where

 {bk}=n,1≤l≤land1≤k≤k 

here, n  represents the gaussian distribution. mean  of that distribution vary with different states and the provided normal cell contamination percentage and ploidy. we used a common standard deviation, σ, to all states.

the above hmm can be represented compactly as λ =  where a, b and π represent transition probability matrix, emission probability distribution and initial state distribution. when fitting the above hmm, the k states must be fixed at first and normal contamination and tumour ploidy must be given as inputs.

the optimal λ is selected by optimizing the negative log-likelihood  <cit> . the initial state distribution π is chosen such that higher probability is attached to the most abundantly expected state or the normal state . similarly, the transition probability matrix a, is chosen such that, a higher probability is assigned to remain in the same state and lower probability is assigned to transition to another state. also the transition to normal state has higher probability than transition to a cnv state. then we used viterbi algorithm to assign the most appropriate copy number state for each exon.

relationship between doc ratio and copy number
without any imperfections, the normalized ratios between regional doc of tumour and control samples r¯ij should reflect the relative copy numbers of the regions in tumour sample compared to control sample. for example, the ratios  correspond to the relative copy numbers . with no normal cell admixture and existence of a diploid cancer genome, these ratios would be the mean of emission distributions that belonged to hidden states of hmm described above. in the presence of normal cell admixture and anueploidy, the ratios would become,

  r¯ij=αpcij+ptijpcij 

where α is the normal cell contamination in tumour cells, pcij is the ploidy of normal cells which equals to  <dig> in diploid human genome, and ptij is the ploidy of tumour cells. as proposed by fidlyand et.al.  <cit> , by performing median normalization on , the ratios will depend on tumour ploidy only. after performing median normalization, the ratio is given by

  ρij=αpcij+ptijpcij/medianαpcij+1ptijpcij=αpcij+ptijmedianptij)=αpcij+ptijpt 

where pt is the most abundant ploidy in the tumour sample.

data from  <dig> genome project
we randomly selected six samples, na <dig>  na <dig>  na <dig>  na <dig>  na <dig>  na <dig>  from  <dig> genome project, which share some common attributes, to evaluate the performance of the proposed method. these selected individuals have been studied by the hapmap project http://www.hapmap.org. the common features in these individuals are  exome sequencing was performed by the beijing genome institute, hence a common exome-capture  has been performed,  male individuals and  from chb population.

simulated data with known copy number variations
we used depth of coverage data at each exon of  <dig> genome samples to simulate cnv. this ensures that we retain as much intrinsic noise present in non copy number varying regions. the simulation procedure is as follows,

 <dig>  first, we retain only the copy number neutral regions in each sample. the cnv information were downloaded from the hapmap project genotype file.

 <dig>  we selected one sample  as the control and others as the tumour with known cnv.

 <dig>  to do the simulation of gains and losses we randomly selected a region in the chr  <dig> and reduce  or amplified  the number of reads in that particular region. for each variation type, we perform  <dig> simulations.

 <dig>  when we evaluated the performance using only one sample , we used  <dig> simulations for each variation type. when we used  <dig> samples in simulations,  <dig> variations were simulated in each individual sample.

 <dig>  to incorporate contamination in the simulation, we mix the control sample and simulated sample as per the relationship  ∗ tumor) where α is the contamination proportion.

RESULTS
exon level depth of coverage ratios to detect cnv in whole exome data
we have used normalized depth of coverage ratios of the exons among tumour/normal pair to identify the underlying copy number losses and gains. as a quality control procedure, all the regions in matched normal sample, with less than an average coverage of  <dig> are eliminated in both tumour and normal data sets. however, the useful signal to be used in cnv detection is depleted by the noise present in data itself. this can be attributed to the gc content bias, mappability, bait capture bias  <cit>  etc. in line with the observations made in  <cit> , we observed that variation in exon level doc ratios depends on the average coverage of both tumour and normal samples . this introduces higher variation in ratios in lower coverage levels.

different methods have been proposed to reduce the experimental biases present in tr data. these include gc content bias reduction using regression methods  <cit> , taking base level ratios between normal and control samples  <cit>  and bait capture bias reduction using log transformation  <cit> . those methods, adapted from acgh or whole genome sequencing based approaches, try to reduce different experimental biases separately. hsu et. al.  <cit>  proposed dwt smoothing as an effective method to extract true copy number variations from acgh data.

in this work, we propose to combine the strengths of both dwt and hmm to robustly predict copy number variations in cancer samples. the main novelty of our approach is the use of dwt smoothing to reduce experimental biases present in whole exome sequencing data prior to applying a hidden markov model. these experimental biases are modelled here as additive noise to the true signal. the wavelet coefficients, which are the differences between two nearby data blocks, can be used to reduce noise. this is achieved through approximating some coefficients that do not by pass a certain threshold to zero. after thresholding step when the inverse transform is performed on these wavelet coefficients, we can generate a smoother version of the input signal. exon level ratios, before and after dwt smoothing, for data downloaded from  <dig> genome project  are given in figure  <dig> 

after smoothing, we applied an hmm described in methods section to detect copy gains and losses. hidden markov models have been previously used to detect cnv in exome data   <cit> , but not used in this manner to detect cnv in tumour samples. the differences between exomecopy and convex are,

• exomecopy uses hmm to identify cnvs in male patients with x-linked intellectual disabilities 

• they have used depth of coverage of exons as observations or emissions of hidden states

• the robustness in copy identification is achieved by pooling coverage data from all patients

therefore, it fails to identify relative copy number in cancer samples against a matched normal.

comparison of the performance of convex against other methods
comparison against exomecnv using simulated data
we carried out a comparison between the proposed method and the existing method, exomecnv  <cit> . using simulated data, we were able to assess the performance of convex and exomecnv for different size ranges.

a true positive  is identified when the gain or loss of an exon is correctly identified by the algorithm and a false positive  identification is defined in the same manner. when using exomecnv, we used their primary cnv detection method  and the extension which combines dnacopy  <cit>   separately on our simulated data sets. the dnacopy version of exomecnv is applied to make sure that we get results for all exons that pass the default cut-off level of the coverage . we used default parameters given in exomecnv r package for cnv prediction, except for read length and admixture rate, which we set to  <dig> and  <dig>  in our evaluation.

we used simulated data as described in methods section to carry out the comparison. for this, we simulated deletions and duplications in different size ranges. the results of this evaluation are given in table  <dig>   <dig>   <dig>  both convex and exomecnv <dig> perform better compared to exomecnv <dig> in detecting deletions and duplications. this shows that detecting variations by segmenting the exome works well, rather than only considering one exon at a time and depicting its copy number when there are large variations. another note regarding exomecnv <dig> is that it doesn't produce results for about 16% of the exons in the whole exome.

performance of convex in terms of sensitivity, specificity, recall and accuracy. we listed mean and the standard deviation of the each performance measure.

performance of exomecnv in terms of sensitivity, specificity, recall and accuracy. these results are obtained from running the primary method of exomecnv. each point indicates mean and standard deviation of the measure.

performance of exomecnv in terms of sensitivity, specificity, recall and accuracy. these results are obtained from running the extension of exomecnv which includes dnacopy package. each point indicates mean and standard deviation of the measure.

when compared with exomecnv <dig>  our method showed superior performance in terms of specificity, precision and accuracy. slight decrease in sensitivity was observed in convex, this is mainly due to the detecting short variations involving  <dig> or  <dig> exons. this can be attributed to the smoothing step we performed using dwt. because of this we separately tested the performance of convex for shorter variations sizes as described below. both versions of exomecnv, showed very poor performance when it comes to precision, as it tries to detect as many as possible variations to maintain a higher sensitivity rate.

performance assessment of other methods against convex
to evaluate the performance of convex against varscan <dig>  <cit> , exomecopy  <cit>   and contra  <cit> , we used actual genotype of chromosome  <dig> in na <dig> individual  against na <dig> individual . all methods were run using their default settings. the results are given in table  <dig> 

table shows the number of exons  that have been identified as true positives and false positives by each method. the denominator shows the total true positives  or true negatives . total number of true negatives differ among methods due to filtering and quality control done by each of them.

exomecopy and contra did not identify any of the variations present in the test sample. this can be attributed to the fact that these are specifically designed for using a background sample  <cit>  or a robust baseline  <cit> . varscan  <dig> was able to identify the hemizygous duplication in the region with 60% sensitivity, however the number of false positives reported by the method was very high . convex performed well with 90% sensitivity and  <dig> % false positive rate.

performance of proposed method at different duplication and deletion sizes
we observed that small deletions or duplications only span one exon and at most  <dig> exons due to the sparseness of the exome data. to evaluate the performance of convex in short variation sizes, we carried out a performance assessment using simulated data of small deletions and duplications in chromosome  <dig> of na <dig> and na <dig> individuals. the results are given in figure  <dig> 

median sensitivity of convex for small variation detection is 100%. every deletion of size, more than  <dig> bp was detected by our method. hence, giving a mean sensitivity of 100% for detecting deletions. mean sensitivity of detecting each duplication size was more than 85%. as seen in the graph, almost every variation of size of more than  <dig> bases can be detected by the proposed method. also, a median precision of more than 30% can be achieved.

performance assessment at different levels of contamination
normal cell admixture in cancer sample is an issue that has to be taken into account when predicting copy number losses and gains. the presence of admixture shrinks the doc ratios to  <dig> . our method works on the assumption that the user will provide the contamination percentage as an input. however, these data might not be available for every experiment. hence, we carried out an evaluation of our method based on simulated data from na <dig> for two scenarios. first scenario was to consider the availability of admixture rate and second was to run the programme without any indication of contamination. the performance of convex, for admixture rates ranging 10% to 70%, in terms of sensitivity, under the first scenario is given in figure 3a and the second scenario in figure 3b. this admixture rate range is normally present in cancer samples  <cit> . the performance of the method drastically reduces after 50% contamination in scenario  <dig>  however, if proper estimation of admixture rate is provided, we didn't see much difference in the performance level of convex.

CONCLUSIONS
exome sequencing data can be used to detect copy number variations as an initial screening procedure. it is a cheap and time efficient method. we have successfully applied the proposed method on exome data to identify cnvs spanning one to thousands of exons. however, actual breakpoint of the cnv would not necessarily lie in the coding region. this limits the use of wes in identifying actual breakpoints of the cnv.

as discussed in the results and discussion section, we have achieved a higher precision than existing methods in detecting variations due to the data smoothing step. however, detection of some of the small variations may be missed by this smoothing step, as these can be recognised as noise. further analysis is needed in order to better detect these variations among higher level of noise.

although, we have used a matched normal sample to detect cnvs, the cnv identification can be done based on a pooled normal sample as described in  <cit> . this might give an advantage in finding cnvs in familial studies assuming all members have a median copy number of two.

competing interests
the authors declare that they have no competing interests.

authors' contributions
kca designed the method, evaluated the performance and drafted the manuscript. jl and skh contributed to improve the method. all authors read and approved the final manuscript.

