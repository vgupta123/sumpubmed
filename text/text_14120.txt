BACKGROUND
recent evidence from fully-sequenced genomes suggests that organismal complexity arises more from the elaborate regulation of gene expression than from the genome size itself  <cit> . it is not surprising that determining the interactions between genes, which gives rise to particular system's function and behavior, represents the grand challenge of systems biology  <cit> . in addition to structural information about the regulatory interactions, a comprehensive understanding of the dynamic behavior of these interactions requires specification of:  the type of regulation   <cit> ,  kinetics of interactions  <cit> , and  the specificity of the interactions with respect to the investigated tissue and/or stress condition  <cit> . the elucidation of a complete network of regulatory interactions parameterized with kinetic information leading to a particular gene expression is, at present, still a challenging task even for well-studied model organisms whose networks have been partially assembled either for few selected processes and conditions or at the genome-wide level  <cit> .

the ever-increasing throughput in experimental manipulation of gene activity coupled with the methods for quantitative assessment of transcriptome, proteome, and metabolome have begun to identify the effects of individual transcription factors, binding ligands, and post-translational modifications on regulated genes  <cit> . moreover, such high-throughput transcriptomics data sets can be used to identify gene regulatory modules and entire networks. understanding the complex network of gene regulatory interactions from a given transcriptome read-out necessitates the design, analysis, and testing of network-inference methods . these methods operate on two types of data sets from:  static perturbation experiments whose read-out is a pseudo steady-state expression level, and  time-resolved experiments yielding time series of gene expression.

transcriptomics time series data hold the promise of identifying the dynamics of the key genes mapped into putative interactions and kinetic laws; consequently, the temporal information must not be neglected by the applied method for reverse engineering of gene regulatory networks. however, despite the decreasing costs of experiments relying on high-throughput technologies, systems biology studies still produce relatively short time series  <cit> , largely due to the problems with gathering a big enough sample material and designing more complex experiments. in addition, time-resolved biological experiments usually involve sampling at irregular rates in order to capture processes spanning different time scales. these two challenges require a careful assessment of the existing methods for network inference from transcriptomics time series data. moreover, most of the developed methods have been applied directly on real time series data without a prior assessment of their discerning capacity on a difficult synthetic benchmark  <cit> .

the analysis of short time series is affected by the type of employed data representation. for instance, some approaches transform the discrete time series into continuous representations by different fitting methods; in addition, few studies have already considered transforming real valued time series into data-adaptive representations, including: symbols, strings, and trees . therefore, the extent to which a chosen data representation may affect the accuracy of the inferred networks should also be examined when assessing the strengths and weaknesses of different reverse engineering methods.

the simplest approach for network inference from time series data relies on applying similarity measures  <cit> . methods borrowed from bayesian inference  <cit> , regression analysis  <cit> , and econometrics models  have also been applied in this context. although there are already two valuable reviews of methods for gene regulatory network  reconstruction from transcriptomics time series data  <cit> , we believe that there is a need for a careful assessment of the existing reverse engineering methods based on similarity measures operating on short time series data.

for this purpose, we first divide the existing similarity measures  into fourclasses based on the representation on which they operate, namely: vectors, random variables, models , and symbols. we term the basic pairwise measures as simple, in comparison to their conditional and partial variants. the outcome of applying a similarity measure can further be refined via six scoring schemes: identity , algorithm for the reconstruction of accurate cellular networks , context likelihood of relatedness , maximum relevance/minimum redundancy network , time shift , and asymmetric weighting . the similarity measures and scoring schemes are schematically presented in figure  <dig> 

this table summarizes all measures of interaction included in this study. those are marked by  which, to our knowledge, have not been applied to gene expression before.

we study the performance of the relevance network algorithm for grn reconstruction, applied to synthetic gene expression data sets, and compare the capability of different combinations of  <dig> measures and  <dig> scoring schemes to detect/predict true and eliminate false links. a description of the data sets and the general definitions of the methods used in this study are given in detail in the methods section.

our contributions include:  an extensive systematic review and a comparison study which could serve as a basis for selecting a reverse engineering method based on a combination of a similarity measure and a scoring scheme suitable for a given expression data; in this context, we investigate not only the pairwise similarity measures, but also, where applicable, their respective conditional and partial variants;  introduction of approaches that are novel or borrowed from other fields, but have not yet been encountered in the field of network reconstruction; and  definition of a novel information-theoretic measure, the residual mutual information, and evaluation of its performance in unraveling gene regulatory interactions.

RESULTS
we investigate the performance of the relevance network algorithm applied to gene expression time series from a network of  <dig> genes in e. coli under optimal sampling conditions . interpolation has not been applied to the time series at this point. we show and discuss the receiver operating characteristic  curves deduced for the basic algorithm with identity  scoring scheme in combination with all measures included in our investigation, and for the five additional scoring schemes - clr, aracne, mrnet, ts and awe - with selected measures. subsequently, since optimal sampling conditions are never achieved, the performance of the similarity measures and scoring schemes is additionally investigated on noisy data. the role of sampling and interpolation on the performance is discussed as well. moreover, the influences of network properties  are shown using two additional networks, a yeast network composed of  <dig> genes from s.cerevisiae and a network of  <dig> genes from e. coli.

identity scoring scheme
the basic relevance network algorithm  is used to compare the performance of all measure's classes.

measures operating on vectors
additional file  <dig>  figure s <dig> shows the efficiency of the reconstruction of links based on classical distance measures and the dynamic time warping. in general, none of these measures is able to avoid false positives on a larger scale without loosing most of the true interactions. on the other hand, the roc curves are rather flat for high false positive rates, which implies that these measures could be useful initially to determine connections which are not present in the network. all of the curves shown in additional file  <dig>  figure s <dig> are smooth, meaning that the prediction of links is not very sensitive to the explicit choice of the threshold. from this analysis, we can discriminate that the ls norm  performs best in reconstructing the network. these results outperform the euclidean  and the manhattan  distance, which can be explained by the fact that the ls weights large distances more heavily. the dynamic time warping fails for the investigated data, which is most likely a result of the coarse sampling and the complexity of the network.

measures operating on random variables
furthermore, the id scoring scheme is evaluated using several measures which employ time series represented via random variables. in particular, we examine in detail the performance of correlation and information-theoretic measures.

in the case of the linear pearson correlation  coefficient, as shown in figure  <dig>  we obtain almost identical results from the simple and the conditional  measure, although the cpc is expected to eliminate indirect interactions. however, this does not mean that there are no indirect links wrongly deduced by the linear pc. the problem here is rooted in the estimation of the conditional probabilities, which is barely reliable for  <dig> time points.

even if a basic significance test is included -- for example the data is reshuffled  <dig> times, then the measures for the randomized series are calculated, and the results are compared to those obtained from the original time series -- the results do not change significantly . the partial pearson correlation, on the other hand, shows better results for low false positive rates, but looses its accuracy when high true positive rates are reached. additionally, the results obtained from the ppc are less significant . removing links which have no significant values of the correlation leads to an almost random prediction from the partial pearson correlation.

as we cannot infer self-regulation by analyzing the similarity of expression series, the diagonal of the correlation matrix was set to zero in our computations above . comparing the reconstruction efficiency of the linear pc with that of the rank correlations , we observe that the roc curve shown in figure  <dig> is smoother for the pearson correlation than the curves obtained from the rank correlations. hence pearson's correlation measure is less sensitive to the choice of the threshold, whereas the rank correlations can achieve a slightly better overall performance.

next, we investigate the efficiency of the id scoring scheme considering information-theoretic measures. in general, we observe that the resulting reconstruction strongly depends on the method chosen for the estimation of entropies. here we present the results obtained using the r-package "infotheo"  since, for short time series, it yields better estimates of the entropy than the r-package "entropy". besides the basic pairwise mutual information , we also investigated the conditional mutual information  and the residual mutual information  in order to reduce the number of false positive links. all these measures result in roc curves which are more or less discontinuous. this is a finite size effect, as the time series are very short, and thus the estimation of the mi  becomes problematic.

we find a quite different behavior of the roc curves, as shown in figure  <dig>  in specific regions of the roc space. the simple mutual information results in a flat and comparatively smooth roc curve for high false positive rates. this means that the measure allows removing about 60% of the false positives, by loosing approximately 10% of the true links. an even better performance in the same roc space region can be achieved using the residual mutual information, which we proposed as a partial mutual information measure to distinguish indirect from direct  relationships between triplets of genes. in contrast to this, the conditional mi results in a more discontinuous curve for high fpr: here, the ratio of the true and false positive rate is nearly the same as observed for a random prediction. in principle, the cmi is stricter in removing indirect links as it also can detect nonlinear interactions. however, the conditional probabilities cannot be estimated sufficiently well from  <dig> time points. hence, the conditional mi fails for  short data sets in the region of high false positive rates.

additionally, when looking at the region of low fpr, we observe that the roc curve of the simple mi becomes more discontinuous than for the high fpr. the true positive rate decreases significantly for slightly reduced threshold values, in the region around 30% and 15% of the false positives. this is manifested as jumps in the curve due to which this measure is rather sensitive to the choice of the threshold if low false positive rates are to be achieved. in contrast to this, the residual mutual information results in a smoother curve for low false positive rates than the simple mi, indicating that the measure is less sensitive to the choice of threshold, although the curve exhibits smaller jumps as well. in the region of fpr < 10% the performance of the rmi decreases slightly compared to the simple measure. the conditional mutual information on the other hand, achieves only very low false positive rates, which also lead to low true positive rates . tuning the threshold to allow for slightly higher values of the fpr the roc curve of the cmi immediately jumps to 50% of false positives. hence, the region between about 3% and 50% of false positive links is not achievable using the considered conditional measure.

we also implemented a basic significance test for the mutual information measures by reshuffling the time series  <dig> times, calculating the measure for the randomized series, and comparing the results to those obtained for the original time series. the associated roc curves are shown in additional file  <dig>  figure s <dig>  with respect to the significance, the reconstruction efficiency of the simple and, in particular, the residual mutual information decreases, since the inferred degree of interaction for most of the gene pairs is not significant in the specified sense. in contrast to this, with the significance test, the quality of the prediction obtained from the cmi increases slightly, but its overall performance is still deficient.

that evaluation leads to the conclusion that  only the simple and the residual mutual information can provide a sufficient reconstruction efficiency using the identity scoring scheme. this holds true only in the case that we do not rely on the simple significance test.

investigating the performance of the coarse-grained measures on the short gene expression time series, we obtained roc curves which look almost the same as expected for a complete random linking in the network, as illustrated in additional file  <dig>  figure s <dig>  even though the coarse-grained measures are in principle promising for the inference of interdependency from time series of intermediate length, they are not applicable in our case. the reason for this is the limited number of available time points which makes not only the estimation of the mi, but also the identification of a proper time lag a very challenging task. interpreting the ccir as a distance, and not as a similarity measure, leads to an increase of the inferred true positives. however, the predictive power of the measure remains very low.

model-based measures
the evaluation of the id scoring scheme using model-based measures  leads to an almost random prediction of links . hence, the granger causality  measure is not suitable for the reconstruction of grn, when only very short gene expression time series are available. this is due to the fact that the results of the gc index depend strongly on the model estimation. an ar model has to be estimated for the given data set, whose order is determined based on the akaike information criterion. however, this seems to be insufficient, since the aic usually requires a higher order model , whereas the expression time series are in general very short.

measures operating on symbolic dynamics
next, we use the principle of order patterns to derive symbol sequences from the time series  <cit> . as already shown in general nonlinear time series analysis, the symbol based measures show a good overall performance in reverse engineering.

the roc curves ) obtained for these measures are rather smooth and flat for false positive rates larger than 30%, which means that only a small portion of links is lost when reducing the false positive rates down to this value. consequently, the results are robust to the choice of threshold in this particular region of the roc space. however, the roc curves become less smooth for lower values of the false positive rates. this implies that false positive rates smaller than 20% are barely possible to achieve. the best overall performance has been found here for the combination of symbol sequence similarity and mutual information of the symbol sequences , as well as for the mutual information of the symbol sequences . the latter outperforms the simple mi of the time series themselves, as the length of the series used to estimate the measure is much longer in the case of the symbolic dynamics. additionally, the conditional entropy of the symbol vectors obtained from pairs of time points shows results similar to the sysimmi and the symi in a wide range of the roc space.

symmetric scoring schemes - clr, aracne and mrnet
next, we evaluate the possibility for reconstruction of the underlying e. coli network based on the three modifications of the relevance network algorithm  as implemented in the "minet"-package, namely the clr, the arcane and the mrnet. all three algorithms represent extensions of the basic relevance network approach, to the effect that they introduce additional scoring rules for the pairwise weighting of the interactions in order to reduce the amount of links that are falsely detected.

in additional file  <dig>  figure s <dig>  we present the results, in terms of the roc curves, which we obtain using the different scoring schemes and in all cases the default weights of the pairwise interactions, namely, the squared spearman's correlation for every set of pairs. as the algorithms implemented in the "minet" are designed to reduce the number of false positives, high false positive rates  do not occur here, unless all interactions are set as links. moreover, the mrnet and the clr result in roc curves which are not smooth, meaning that their capability to reconstruct particular links is limited and strongly dependent on a proper choice of the threshold τ. the aracne, on the other hand, is restricted to an almost fixed fpr-tpr value.

asymmetric scoring schemes - ts and awe
as none of the previously described scoring schemes is able to indicate directionality from symmetric measures, we include in this study, and to our knowledge for the first time in grn reconstruction, an evaluation of the performance of the time shift  as a symmetry-breaking scoring scheme. we show the results of this modification of the relevance network algorithm removing the links which are falsely detected by the clr  or the awe . however, unraveling the directionality of interaction  using the correlation of the delayed time series has shown to decrease the maximal achievable true positive rates.

the slope of the roc curves ) indeed does not change much in comparison to the results of the clr and the awe scoring scheme. moreover, if combined with the pearson correlation of the delayed time series, the roc curve obtained from the clr becomes considerably smoother  and hence, the prediction is less sensitive to the choice of a threshold. the same does not hold true for the roc curve obtained from the application of the ts scoring scheme in addition to the awe. instead, this curve becomes flatter and is slightly shifted towards lower false positive rates in comparison to the corresponding curve in figure  <dig>  this implies that, while for low fpr the curve looks basicly the same, in the intermediate range of the roc space  similar tpr values can be obtained for lower fpr. however, in the range of high fpr, the maximal achievable tpr value is lower. hence, true positive rates of approximately 80% can be achieved with lower costs, as the according number of false positives is in general smaller when the ts scoring scheme is used. on the other hand, as already mentioned, the quality of the link detection becomes worse for higher false positive rates  compared to the corresponding results of the awe itself. the true positive rate in the roc curve in figure  <dig> is almost constant in this region of the roc space.

similar to the ts, the awe scoring scheme aims at breaking symmetries and thus allows extraction of information about the directionality of interaction from symmetric measures. however, a detailed comparison of the reconstruction efficiency of the awe using different symbolic dynamics measures shows that in contrast to the ts scoring scheme, awe does not decrease the maximal achievable true positive rates. instead, the roc curves, as shown in figure  <dig>  become more flat for high false positive rates compared to the curves obtained for the basic algorithm with the id scoring scheme using symbolic dynamics ). hence true positive rates of more than 80% are achievable by the awe algorithm with much lower costs than with the id scoring scheme. on the other hand, the roc curves obtained from awe are more steep for low false positive rates. this implies that here true positive rates up to approximately 45% can be achieved with false positive rates of less than 10%. furthermore, the curves shown in figure  <dig> are much smoother in comparison to those in figure  <dig>  indicating that the reconstruction is less sensitive to the choice of a particular threshold.

influence of noise
in general, noise-free expression measurements cannot be achieved in real experiments: in fact, intermediate and high noise level are not rare. thus, in order to account for stochasticity in the time series, and particularly to establish the robustness of the ranking of the investigated similarity measures, we additionally evaluate the roc curves for noise intensity of  <dig> .

as expected, the measures which failed in the noise-free case  did not improve their performance, as shown in additional file  <dig> figure s <dig>  on the other hand, the measures based on vectors yield very robust results with respect to noise . however, since the performance of these measures was already insufficient in the noise-free case, its general overall ranking does not improve significantly. we additionally noticed that the measures which performed best in the case of optimal sampling conditions, such as mi, rmi, correlation and symbol based measures differ in their robustness against noise, as illustrated in figure  <dig>  for example, the reconstruction efficiency of the simple and the conditional pearson's correlation slightly decreases, while that of partial pearson's correlation slightly increases. hence, all three measures result basically in the same roc curves, meaning one can abandon the more computationally intensive calculation of partial and conditional pearson's correlation under these circumstances. furthermore, mi and rmi both lose their accuracy as noise increases, and the corresponding roc curves resemble those of the pearson's correlation. however, the relation between both measures stays the same .

the reconstruction efficiency for the symbol based measures decreases significantly as well, which holds true in particular for the mutual information of symbol sequences . however, apart from that, the roc curves obtained for the symbol based measures are more continuous for noisy data than those in the noise-free case, which implies that the reconstruction process in this case is less influenced by the choice of a particular threshold.

a similar behavior is observed for the rank correlation coefficients. however, the shape of the curves appears more robust under the influence of noise than it is the case for the symbol based measures. hence, the rank based measures represent the most suitable similarity measures to study the interrelation among short time series at high noise levels.

finally, we observe that the clr and the awe are the most robust scoring schemes with respect to noise, whereas aracne fails for short and noisy time series.

a detailed analysis on the reconstruction efficiency of the top-ranking measures and scoring schemes under various stochastic conditions is considered in the discussion section. additionally, the performance as a function of the length of the time series and the noise intensity can be found in the additional files.

the role of interpolation and sampling
due to the fact that time-resolved gene expression data are usually quite coarsely sampled, general assumptions upon what happens between two time points cannot be made. this problem becomes obvious when unequally sampled data are used .

although the interpolation at the beginning of the time series  seems to be sufficient, it does not accurately capture the dynamics of the expression time series when the distance between the time points becomes larger. hence, by interpolating the gene expression data sets, artifacts are introduced, which will be further reflected in the results of the particular measures of interdependency. in order to avoid these artifacts, we renounce the interpolation in this comparison study, even though this leads to less significant results for almost all measures, as they operate far below the limit of their theoretically defined preconditions. however, we have observed that the overall results  are typically equal or even better when interpolation is not included, especially when non-uniformly sampled time series are considered. additional file  <dig>  figure s <dig> illustrates this effect exemplary for the simple mutual information.

however, some measures, such as the granger causality used in this study, as well as several scoring schemes , are explicitly time dependent. hence, they require uniformly sampled data, meaning that an interpolation is needed if only non-uniformly sampled data is available. this is in general, the case in grn reconstruction.

however, most of the well performing reconstruction tools in our study are not explicitly time-dependent, which means they do not require a specific time sampling. this implicates that they are not very sensitive concerning the spacing on the time axis. our results, as shown in additional file  <dig>  figure s <dig>  illustrate that a non-uniform sampling for these tools can even improve the quality of the reconstruction, since a larger period of the dynamics is captured.

the role of the network topology
in general, the underlying network and its properties are not known prior to the reconstruction process. however, the available experimental and theoretical research has suggested that gene regulatory networks most likely are characterized with scale-free properties  <cit> . therefore, we compare the reconstruction efficiency of the relevance network approach for various subnetworks of e. coli's and s.cerevisiae's regulatory networks, as described in details in the methods section . these networks  differ in size, average degree and clustering coefficient. nevertheless, we observe that the performance of the top-ranking measures, such as the symbol based measures, rank correlations, mi and rmi do not depend on the network topology: very similar roc curves are obtained for all of the network types analyzed, as shown in figure  <dig> . the performance in the range of low fpr was improved for most of the measures for increased average degree of the nodes. however, at the same time, the performance in the range of high fpr was usually decreased. in general, the largest differences in the reconstruction efficiency occur for the conditional granger causality and partial pearson correlation, where the quality of the reconstruction decreases significantly for an increased number of nodes  and an increased clustering coefficient, as in the s.cerevisae network.

discussion
the observation of the roc curves does not always allow conclusions on the overall performance of a measure or scoring scheme. therefore, we further compare the described modifications of the relevance network algorithm in terms of roc statistics . as an example, we evaluate the roc statistics from time series with uniform sampling  for the network of  <dig> genes of e. coli.

roc statistics for noise-free data
to evaluate and rank the overall performance of all approaches under study we calculate three common summary statistics from roc analysis: the area under the roc curve ), the y ouden index and the area under the precision/recall curve ) as explained in the methods section. furthermore, as the modifications of the algorithm implemented in the "minet" package are commonly and widely used approaches for grn reconstruction, we use the results which gave the best performance in order to establish a benchmark for the comparison of the different measures and scoring schemes. in table  <dig> we provide an overview of the results from the summary statistics for the different measures , and scoring schemes implemented in the r-package "minet". based on these results, we define a measure combined with a particular scoring scheme to be

overview on the results of the summary statistics from the roc analysis for the different parameter  in the minet package.

• well performing for short expression data sets  if:

auc >  <dig> ,

youden >  <dig>  and

auc >  <dig> ,

• sufficiently performing if

 <dig>  >auc >  <dig> ,

 <dig>  >youden >  <dig>  and

 <dig>  >auc >  <dig> 

• and deficient otherwise.

by calculating the summary statistics in the noise-free case, as shown in figure  <dig>  we conclude that several information-theoretic measures , correlations  and measures based on symbolic dynamics  perform sufficiently well in combination with the basic relevance network algorithm . here, it stands out that the simple spearman correlation performs better than the simple pearson correlation, and symi is better than the simple mi. this is due to the fact that symbol and rank based measures are less sensitive to finite size effects and the distribution of data.

the modifications of the relevance network algorithm in the "minet" package having best performance in the reconstruction of grn from short data sets, are the clr and the mrnet . here the auc indicates almost no change compared to the basic algorithm with identity scoring , while the y ouden index decreases for the clr and increases for the mrnet. however, the opposite is true for the auc. the overall performance of the clr  is slightly better than those of the mrnet . moreover, the measures combined with the ts scoring scheme perform sufficiently well. however, the summary statistics do not change much compared to the results obtained for the same measures using the id. in contrast, the asymmetric weighting yields a significant increase among all the summary statistics compared to the performance of the same measures using only the identity scoring scheme.

hence, in the noise-free case, we obtain the following ranking of measures with the highest capability to detect true and eliminate false positive links:

 <dig>  awe + ts ,

 <dig>  awe + ts ,

 <dig>  awe,

 <dig>  awe,

 <dig>  awe and

 <dig>  μs clr

the asymmetric weighting  significantly improves the prediction at this point, since it breaks the symmetry of a particular measure based on topological consideration and, therefore, reduces the number of false positive links. hence the awe  clearly shows the best performance when short time series are considered .

roc statistics for noisy data
in order to account for stochasticity in the time series as well as to establish the robustness of the investigated  similarity measures against noise, we evaluate additionally their performance for two different noise intensities, namely  <dig>   and  <dig>  . only those measures which perform sufficiently well in the noise-free case  are tested. in particular, we examine the pearson's ), spearman's ) and kendall's ) correlation coefficients as well as the symbol based measures , , , and  using the id scoring scheme. additionally, we investigate the performance of clr, mrnet, aracne, awe and ts scoring schemes based on the same measures as in the noise-free case.

under the influence of noise, the quality of the results of the symbol based measures  decreases. as noise strongly influences the process of symbol assigning, it can principally enhance or distort the information content. the direction of the influence is not predictable a priori, but in the presence of strong noise, symbols are no longer reliable . on the other hand, measures operating on random variables are rather robust against noise .

the aracne has proven to be very sensitive with respect to noise. in contrast to this, the asymmetric weighting  still performs well within the given limits, as it is only based on topological considerations, and it is not influenced by the presence of noise. furthermore, to investigate how noise influences the reconstruction efficiency, we calculated the area under the roc curve and the youden index as a function of the noise intensity for the  <dig> combinations of similarity measures and scoring schemes which performed best in the noise-free case, namely the symbolic measures and the asymmetric scoring schemes, mentioned in the previous section. additionally, we compared the results to those obtained for time series of different lengths . we conclude that for short time series, the capability of the measures and scoring schemes to detect true and at the same time eliminate false positive links depends both on the number of time points and the noise intensity . however, this dependence is small compared to the differences in the reconstruction efficiency between the various measures. moreover, the sensitivity against noise is reduced with increased length of the time series . in general, we observe a decrease in the reconstruction efficiency if the noise levels increase or the length of the time series decreases. for the short time series used in this study, however, these dependencies are not monotone.

CONCLUSIONS
by performing an extensive comparison analysis of the reconstruction efficiency of the relevance network algorithm using  <dig> scoring schemes and  <dig> different measures, we showed that with a suitable choice of a measure and a scoring scheme, this approach is applicable to short time series to gain knowledge about the underlying gene regulatory networks which differ in various properties. however, most of the currently used measures have highly limited capabilities, as the number of time points of the gene expression data is usually not sufficient to infer the underlying structure of the network. this in turn make the distinction between direct and indirect interactions an even more challenging task.

this study could serve as a basis for the selection of a reverse engineering method for network reconstruction, based on the combination of a similarity measure and a scoring scheme suitable for given data. our results showed that rank and symbol based measures  have a significantly better performance in inferring interdependencies, whereas most of the standard measures  fail when short time series are considered. the residual mutual information, which we proposed in this work as a partial mutual information measure, increased the reconstruction efficiency of the relevance network algorithm compared to simple and, in particular, conditional mutual information.

nevertheless, from the analysis presented here, we conclude that it is necessary to move further from the standard similarity measures based on the time series directly, towards measures rooted in the study of symbolic dynamics or ranks deduced from the time series, in order to increase the efficiency of the relevance network algorithm for grn reconstruction. although measures based on symbolic dynamics performed significantly well in the noise-free case, their performance was decreased as the noise level in the system increased, and for high noise intensities it became comparable to that of mutual information. this implied that in the presence of strong noise, rank correlations  are most efficient tools for grn reconstruction, since their performance was not significantly affected as the noise level increased. additionally, we note that the results obtained for rmi, rank correlations and symbol based measures are robust with respect to the network topology. we also showed that an unequal sampling of the data in general does not pose additional problems if measures are considered where interpolation is not essential .

we point once again that all rank and symbol based measures described here are symmetric. this means that the directionality of the interactions cannot be inferred, unless a symmetry-breaking scoring scheme is considered in addition. in that direction, we showed that a novel scoring scheme, the asymmetric weighting , which we proposed in this work stands as a valuable approach to overcome the problems of introducing directionality in the reconstruction of the regulatory networks.

it would be interesting to compare in future the observed reconstruction efficiency of the relevance network approach to that of other reverse engineering methods, such as the bayesian network approach.

