BACKGROUND
computational discovery of motifs corresponding to functional sites in proteins or binding sites in dna is an established field within bioinformatics. in particular, the discovery of transcription factor binding sites in dna has received much attention. experimental identification of binding sites is a tedious process. given the ever increasing number of genomes that are sequenced, computational identification of regulatory elements is needed to speed up the annotation process.

a typical approach for motif discovery is to use regulatory  regions for genes that are believed to be co-regulated as input, and try to predict individual dna binding sites and possibly associated transcription factors that can explain the co-regulation. typical software tools are meme  <cit>  and alignace  <cit> . this has turned out to be a very challenging problem. in particular the large number of false positive binding sites predicted by most methods represents a problem  <cit> . one promising improvement to this strategy is to search for combinations of binding sites, rather than individual occurrences.

gene regulation usually has a combinatorial complexity  <cit> , i.e. a combination of transcription factors  is often needed for active regulation. these tfs may be co-acting either directly through physical contact or indirectly through additional factors. as co-acting tfs may be expected to be in physical proximity, their binding sites are often clustered in sequence space. however, this is not a strict requirement as the dna strand may form loops between distant sites  <cit> . also, a given regulatory region may contain several possibly independent subsets of tf binding sites, representing alternative regulatory contexts. clusters of binding sites involved in co-regulation are often referred to as cis-regulatory modules , composite motifs or structured motifs  <cit> , and they usually contain binding sites for a few tfs  <cit> . in this paper we refer to the model of a binding site of an individual tf as a single motif, and a given set of single motifs as a composite motif. we also use the term module when we want to emphasize the biological aspects of the tf combination.

several computational methods have been developed for the discovery of composite motifs  <cit> . one line of methods, often called de novo module discovery, tries to find composite motifs using only dna sequences as input data . this is a notoriously difficult problem, in many cases with close to random performance. however, biologists will often have some prior knowledge about potential regulators for the sequences of interest. therefore another line of methods takes a list of single motifs as input along with the sequence data . these methods can also be used in a de novo setting by first finding candidate motifs using a single motif discovery method, and then running composite motif discovery with the candidate motifs as input. the differences between composite motif discovery methods lie mainly in 1) how single motifs and inter-motif distance conservation are modeled, 2) how motifs are evaluated and ranked, and 3) how the search space of composite motifs is explored. composite motifs can be modeled in a discrete or probabilistic framework. discrete methods typically use a set-model for composite motifs, requiring all single motifs to occur in a composite motif instance  <cit> . this is typically combined with a discrete model for inter-motif distance restriction, the most common approach being a window model that requires all motifs to occur within a sequence window of given length, but without any constraints on internal order or distances between single motifs . the discrete approach has several advantages, such as efficient inference and straightforward interpretation of motifs, and often an exhaustive mapping of the search space is possible. however, the reliance on hard thresholds for discretization may pose problems because of uncertainty and variability of tf binding. therefore, the recent trend has been towards probabilistic models of composite motifs. hidden markov models  have often been used  <cit> , typically containing different states for each single motif as well as for intra- and inter-module gaps. however, given the advantages of discrete methods we believe that they still can be a useful supplement and alternative to probabilistic methods.

this paper describes a new method compo, which revisits the discrete approach to composite motif discovery. compo relaxes the limitation of hard discretization thresholds by using multiple threshold values. by using p-values as a general significance measure, comparison of motifs across threshold settings becomes possible and thus automatic selection of the most interesting motifs across several threshold values. furthermore, the automatic selection across parameter values means that compo is able to infer properties of composite motif structure. compo is therefore able to exploit overrepresentation across co-regulated sequences for improved composite motif detection. although parameter inference from data is also possible with models such as hmms, most proposed methods only scan hmms against target sequence, using fixed parameters for module structure . this is basically equivalent to a single-sequence approach. compo supports a richer composite motif model than previous discrete methods.

in addition to the standard set-model of component motifs, it optionally allows some component motifs to be missing  in composite instances, and distance restrictions on composite instances can optionally be enforced. as motif significance is computed as p-values for all supported models, the significance of composite motifs having different structure can easily be compared. an improved background model is also introduced, which combines empirical scanning against real background dna at the single motif level with model based computations at the composite level. compo can return either an ordered list of motifs, ranked according to p-values, or a pareto front  corresponding to a multi-objective evaluation with sensitivity, specificity and spatial clustering as independent objectives. the multi-objective approach gives a collection of resulting motifs displaying more varying characteristics, and it allows necessary trade-offs between objectives to be made while analyzing the results, rather than prior to running the method.

RESULTS
here we present the compo algorithm for motif discovery by first introducing the necessary definitions and specifying the relevant problems. we then give the practical implementation of the algorithm. finally we present the experimental evaluation of the implementation.

definitions
let s = {s <dig>  ..., si, ..., sn} be a set of n symbol sequences each of which is defined over the alphabet Σ; for dna sequences Σ = {a, c, g, t}. let m = {m <dig>  ..., mj, ..., mm} be a set of m motifs of interest. we assume that for each sequence – motif combination there exists a specific function which gives start positions for all instances of the motif on the sequence; i.e., a function Φ : Σ* × m → 2{ <dig> ,...,|Σ*|}.

definition  <dig>  given the function Φ, sequence si is said to support motif mj, denoted sssi, if Φ ≠ ∅. moreover, the support set of mj is all the sequences in s that support mj; i.e. sss = {si|si ∈ s ∧ Φ ≠ ∅}. the absolute support is then the size of sss, i.e. |sss|.

definition  <dig>  given the function Φ, sequence si ∈ s is said to support module ms ⊆ m, denoted sssi, iff ∀mj ∈ ms Φ ≠ ∅. moreover, the support set of ms is all the sequences in s that support ms; i.e. sss = {si|si ∈ s ∧ ∀mj ∈ ms Φ ≠ ∅}. the absolute support is then the size of sss, i.e. |sss|. note that sssi is an indicator variable but sss is a set of sequences.

proposition  <dig>  given any s, and any mt ⊆ ms ⊆ m, then sss ⊆ sss.

interesting modules are modules supported by many of the sequences in s. this notion is formally defined as follows.

definition  <dig>  for a given support threshold σ ∈ { <dig> ...,|s|}, module ms is said to be frequent in s iff |sss| ≥ σ.

the useful metric of support is a set metric, i.e. defined over the sequence set s. on the other hand, given a single sequence seq ∈ Σ*, it is also relevant to ask how likely it is that a given module has a hit in the sequence. we call the relevant metric module hit-probability which is formally defined next.

definition  <dig>  given a sequence seq ∈ Σ*, hit-probability of module ms ⊆ m is probability of seq supports ms. formally, the module hit-probability of ms ⊆ m is prob).

proposition  <dig>  given any s, and any mt ⊆ ms ⊆ m, then prob) ≤ prob).

the hit-probability can be virtually defined over arbitrary sequences. in this work, we are particularly interested in representative background sequences or sequences generated from the background model bm. for this reason, lower hit-probabilities correspond to higher specificity .

definition  <dig>  given a representative background sequence bgseq ~ bm, and specificity threshold ψ, module ms ⊆ m is called specific module iff prob) ≤ ψ.

in addition to support and hit-probability, an important metric is the statistical significance  defined below. significance is interpreted as how improbable the observed support is in a corresponding set of background sequences.

definition  <dig>  given s and bm, significance of module ms ⊆ m is probability of having support of at least |sss| in a background sequence set bs which is generated from bm and structurally equivalent to s, i.e. |s| = |bs| and ∀i ∈ { <dig> , ..., |s|}  ∧  ∧ . formally, the module significance of ms ⊆ m is prob| ≥ |sss|).

definition  <dig>  for a given significance threshold θ ∈ , module ms ⊆ m is significant if prob| ≥ |sss|) ≤ θ.

problem specification
we consider three basic problem specifications  within the setting presented above.

problem  <dig>  for fixed s, bm, m, and given support threshold σ and specificity threshold ψ, find all modules ms ⊆ m which are frequent and specific.

problem  <dig> is very similar to well established itemset and sequential itemset mining problems  <cit> . in these problems, the solution space typically grows very large and many solutions are usually not interesting. therefore users are allowed to define their interest by specifying constraints. the user defined constraints are enforced by the mining system in order to focus the search on the interesting solutions only  <cit> . moreover, certain classes of constraints  make the search efficient: this is done by pushing the constraints inside the mining process.

what is common to itemset and sequential itemset mining approaches is the generation of complete solutions; i.e. every solution  satisfies the user specified threshold parameters and constraints. on the other hand, in motif discovery problems, incomplete solutions employing heuristic searches are usually preferred. these solutions are supposed to optimize some well-defined optimality criterion . however, there is usually more than one optimality criterion, thus making the problem a multi-objective optimization problem  <cit> . there are basically two different ways to approach this. one possibility is to define a scheme for combining the different optimality criterions into a single criterion, score every motif according to this combined criterion, and return a list of motifs ranked according to score. the scheme for combining criterions may be ad hoc, or it may for instance be based on an unexpectedness scheme with ranking of p-values as described in motif scoring. ranking according to a single criterion is easy to relate to for a user. it is thus advantageous for novice users, when several data sets are analyzed rapidly, or when an objective criteria for selection is needed, such as with automatic benchmarks. we define the combined-objective approach to solution space as follows:

problem  <dig>  given the motif set m, module size c, a desired number n of composite motifs to be returned, and a score function f mapping composite motifs to scalar score values, find the n top-ranking modules according to the score function, i.e. ms ⊆ m s.t. |ms| = c and f >= f for any non-returned motif mt.

the other possibility is to fully treat motif discovery as a multi-objective optimization problem with each objective representing a separate dimension of optimality. one can then return the pareto front of composite motifs. the pareto front contains all non-dominated motifs, where dominated means that there exists another motif with equal or better score values for all objectives. as this selects motifs that score high in different dimensions of optimality, it may give a more varied collection of output motifs. for in-depth analysis of a data set this may give a richer picture of potential regulators. we define the multi-objective approach to solution space as follows:

problem  <dig>  given the motif set m, module size c, find pareto front of m, i.e. ms ⊆ m s.t. |ms| = c and ms is non-dominated in specified dimensions.

the definition given in problem  <dig> is very general in the sense that any number of dimensions can be incorporated. for instance, support and hit-probability can be selected as dimensions.

given the dimensions of interest, the input sequence set and the background model, a straightforward complete solution to problem  <dig> or problem  <dig> can be obtained as follows.

generate every ms ⊆ m s.t. |ms| = c and output any motif satisfying the criteria in problem  <dig> or  <dig> 

the number of subsets of m can grow exponentially, for instance when c ≈ |m|/ <dig>  thus making the straightforward approach infeasible when |m| is large. fortunately, though the motif set m can be large , most biological modules comprise at most several individual motifs. so, by bounding c with a relatively small constant , the straightforward approach becomes feasible, as the number of such subsets grows polynomially. this observation allows us to exhaustively consider only modules with up to several constituent motifs. the straightforward approach may become unpractical when |m| is large even though c is fixed to at most several. as a realistic approach for solving problem  <dig> or  <dig> efficiently we propose the compo algorithm as described in the next section. the main advances are in exploiting monotonicities and using heuristics and approximations for efficient module discovery. this enables compo to cope with large |m| .

the compo algorithm
this section gives a general overview of the compo algorithm. details on each step of the algorithm are given under relevant subsections of implementation, as indicated below.

the general workflow of compo is shown schematically in figure  <dig>  a set s of regulatory regions is retrieved from a sequence database, and a set m of regulatory motifs is retrieved from a motif database or discovered de novo by any external method. the hit positions of all motifs mj ∈ m in every sequence si ∈ s are then found . composite motifs are enumerated in an implicit search tree. for each enumerated composite motif node, the support and hit-probability are calculated. support is the number of sequences with module hit; hit-probability is the  probability of having at least one module hit in a background sequence. for each node in the tree, these values are calculated from the values at the parent node and the values of the added single motif . compo supports two alternative forms of output – a list of motifs ranked according to a combined significance measure , or a pareto front of optimal motifs according to a multi-objective optimization . compo can optionally allow non-perfect matches  and enforce distance constraints . finally techniques used to make compo as efficient as possible are briefly discussed .

implementation
pre-processing of input
the first step of the analysis is determination of motif hits, i.e. the function Φ. as compo operates on discretized motif hits, and thus works independently of the internal representation of single motifs, any external de novo motif discovery method or motif library can be used for this first step. if probabilistic motifs  are to be used with compo, the continuous match values at each position have to be discretized into hits and no-hits. this can be done by setting a hit threshold for each motif. hit thresholds can be calculated algebraically or determined based on the resulting distribution of hits in input sequences and background sequences.

when the match values of motifs have a clear probabilistic interpretation, such as log-likelihoods or log-odds, it can be meaningful to simply set all hit thresholds to a universal, analytically reasoned value. similarly, as p-values can be computed from match scores, hit-thresholds may be found that correspond to a specific p-value of motif match according to a stochastic sequence model. alternatively, hit-thresholds may be set to control some property of the resulting hit-distribution, for example to achieve a specific frequency of hits in the input or background sequences. in general, any function can be defined on the number of hits in input and background sequences respectively, and the hit-threshold set to the value that optimizes this function.

in the current implementation we calculate a desired number of hits as the number of input sequences multiplied by a hit density factor, and then set the hit-threshold of each motif to the value that achieves this desired number of hits across the input sequences. for the initial step of obtaining continuous match values of motifs against sequences, we make use of the tamo motif tools  <cit> . in the default setting, several values are tried for the hit density factor and the most significant motifs across density factor values are returned.

enumeration of composite motifs
combinations of single motifs are conceptually explored exhaustively in a search tree as shown in figure  <dig>  each node  is associated with a single motif and each path from the root to a leaf node corresponds to a unique combination of single motifs . the number of levels in the search tree is constrained by a maximum number |ms| = c of motif components, given as a parameter to the algorithm. a search tree of c levels encompasses all combinations of up to c motifs. each leaf or non-leaf node, z, with the respective single motif mz ∈ m, has two basic variables associated with it: the support set hz = sss and the hit-probability pz = prob). the values of hz and pz are pre-computed and used whenever needed. additionally, each node has two other variables hx.z and px.z for incrementally updating the partial module support and hit-probability, respectively. these values represent support and hit-probability of composite motifs represented by the path from root to node z. the hx.z and px.z values for node z are calculated based on the accumulated values for parent node and hz and pz values, respectively.

the support set hx.z of module x.z, where x is the set of single motifs down to node z, can be computed from module support hx and single motif support hz by just intersecting the sets hx and hz. formally, hx.z = hx ∩ hz. the hit-probability px.z can similarly be computed as px.z = px·pz. the root node of the search tree is an empty module, and as there are no single motifs that require match, proot is trivially  <dig>  and hroot is the set of all input sequences. values for the nodes in the tree are then calculated incrementally down the tree in a depth-first order. this model was also considered in a previous paper  <cit> .

motif scoring
compo can assign a score to each candidate composite motif and return a ranked list of composite motifs as output. this requires that several desirable characteristics, such as high support and low probability of hit in background, are combined into a single score value. we use an approximated p-value of observed composite motif support as our score measure. the generality of the p-value as a measure allows composite motifs with differing characteristics to be directly compared.

the significance of a composite motif, i.e. the approximated p-value of observed support, is computed by the following four steps:

 <dig>  position-level probability: the probability that a single motif occurs at a specific location in a background sequence. this is estimated as the frequency of motif hits in real dna sequences serving as background.

 <dig>  sequence-level probability: the probability that a single motif occurs at least once in a sequence of given length. this is computed as the union of probabilities of occurring at any location. as an approximation, the match probabilities are assumed to be equal at all locations, ignoring auto-correlation. this gives the formula:  <dig> - l, where l is average length of sequences and ppos is the probability of motif hit at a single position from the background model bm.

 <dig>  hit-probability : the probability that a composite motif is occuring in a sequence of given length. this is computed as the product of sequence probabilities of each motif component.

 <dig>  significance p-value : the probability of seeing at least the observed support in a corresponding set of background sequences. this is computed as the right tail of a binomial distribution, i.e. as the probability of obtaining at least k out of n successes with bernoulli trial probability p. here, p is the composite motif-level probability, n is the number of input sequences, and k is the support of the composite motif.

this scoring procedure is a mix of model-based  and empirical evaluation of significance. a purely empirical evaluation would compute a p-value directly in point  <dig> by comparing observed support with support in several different background sets of sequences. conversely, a purely algebraic evaluation would compute match probabilities in step  <dig> algebraically from probabilities at each motif position according to a simplified dna model.

the empirical and algebraic approaches each have their strengths and weaknesses. as the motif score is used to contrast potential binding sites against surrounding dna sequence, having a background that is as realistic as possible is desirable. dna sequences have several properties that depart from random sequence models, and using the frequency of hits in real genomic sequence may thus capture the background more accurately. on the other hand, estimates based on empirical frequencies become inaccurate when the frequency is low, and are limited by the minimum frequency. as the p-values in step  <dig> of the scoring procedure are often extremely low, the observed support would have to be compared against a huge collection of background sequence sets. also at the third step the probability values are often very low when there are many motif components.

the mixed solution we have chosen combines advantages of both approaches. as the position-level probability is estimated from hits in real dna, we have avoided assuming a simplified model of genomic background sequences at the local level. using algebraic computations at step  <dig> and  <dig> instead assumes a random  model of the spatial distribution of motif occurrences. it is of course possible that motifs are unevenly distributed even in the background model of non-modules, but we consider this assumption less problematic. as the values at step  <dig> and  <dig> are computed algebraically, they are not limited by the lowest possible empirical frequency. also, efficient algebraic formulas are used for computing values at step  <dig>   <dig> and  <dig> in the large search space of composite motifs, while the computationally demanding process of scanning against real negative data in step  <dig> is only performed once for each single motif, in the initial phase of the analysis.

our calculations in step  <dig> and  <dig> are based on simple and approximate formulas which ignores correlations. the main motivation for this approach is the efficiency of the simple and incremental calculation in the search tree, as described in enumeration of composite motifs. actually, similar tradeoffs for increased efficiency are inherent in most motif discovery methods  <cit>  due to the difficulty of the problem.

pareto front
as an alternative to motif ranking based on a combined score, compo also supports motif discovery as a multi-objective optimization problem. the composite motif-level probability described in motif scoring then constitutes an independent final objective. composite motif support and enforced distance restriction form additional separate objectives, and a pareto front of motifs is returned as described in problem specification.

intuitively, the pareto front contains motifs that have at least one or a few very good characteristics. this may make the motif discovery process more informative, as the returned motifs typically represent a broader view of the composite motif space  compared to the same number of motifs from a list ranked according to a single combined objective. the pareto front can be visualized as an n-dimensional heat map, allowing the user to get an overview of trends in the results. after the search is finished, the user may decide on how to balance different criteria against each other and inspect motifs with desired combination of properties.

allowing non-perfect matches
it is in some cases biologically relevant to allow for occasional absence of individual tf binding sites in module instances. this may be a desirable feature even if we assume that the module always contains the full set of binding sites, as it makes the approach more robust against inaccuracies in the single motif scanning step.

in this case we need to know the number of allowed motif mismatches in order to determine hit-probability and the support set. we say that a composite motif is defined by its component motifs, and refer to the different possibilities of allowed number of lacking motif matches as variants of the composite motif. a variant allowing q mismatches for a composite module consisting of a set x of single motifs is denoted as vxq. when we want to isolate a particular component motif we write vx.yq, where y is the single motif of particular interest and x is the set of remaining single motifs. in order to compute values incrementally from the already computed values of parent and newly added single motif, we need to keep values for different numbers of allowed motif misses. more specifically, a variant vx.yq generally uses the pre-computed values of two variants of the parent single motif, vxq and vxq− <dig>  as well as values of the additional motif y. in this case the support set and hit-probability is computed incrementally as follows, where q refers to the number of allowed mismatches.

 hx.yq=hxq−1∪ 

as hits for the new motif y are assumed independent from hits for the motifs x in background, and since hxq− <dig> is a strict subset of hxq, the formula for hit-probability becomes :

 px.yq=pxq−1+⋅py <dig> 

in the case when the number of allowed mismatches is equal to or greater than the number of components, h is trivially the set of all sequences and s is  <dig>  for each composite motif, values are computed for variants with  <dig> ..q mismatches .

incorporating distance constraints
as co-acting tfs may be expected to be in physical proximity, their binding sites are often clustered in sequence space. this is not a strict requirement as the dna strand may form loops between distant sites. however, in particular in combination with flexibility regarding single motif mismatches, which increases the general robustness of motif discovery, limits on motif distances can still be a reasonable assumption. compo supports constraints on the distance between motifs by requiring component motifs to have hits within a sequence window of a specific length.

as each component motif may have several instances in a given sequence, it is not entirely trivial to check distance constraints. one possibility is to slide a window through a sorted list of all motif occurrences and check whether the sliding window at any point contains occurrences of all components. a second possibility is to enumerate all combinations of occurrences from each motif component and check whether all occurrences of any combination are within the window. we have as default chosen the second method, as it allows an intuitive recursive implementation and can easily be combined with options such as non-overlapping motifs and single motif mismatches.

distance restrictions are also taken into consideration in motif scoring. hit-probability is then the probability that the composite motif occurs within a distance window in a background sequence. as the composite motif may occur in any of the  windows of the sequence, hit-probability is computed by combining the probability of occurring in the first window of the sequence, and the probabilities of occurring in any of the remaining windows given that it did not occur in the preceding window. the details on how distance constraints are enforced when computing the support set of a composite motif, and how hit-probability is computed, are given in additional file  <dig> 

computational efficiency
the running time of compo is mainly determined by the number of input sequences |s|, the number of input single motifs |m|, and the maximum number of motif components c considered. several techniques are employed to increase the computational efficiency. while exploring the search space, motif values are computed incrementally down the tree from parent values and pre-computed active node values, instead of being computed from ground up each time. as the support sequences hx are computed as a set intersection, and the incremental computation of hit-probability is done algebraically, values at each node are computed with small computational effort. furthermore, if there are many input sequences the computation of support set can be done very efficiently using bit strings. a branch-and-bound approach is used to prune the search tree. for each node visited in the tree, a bound on the highest achievable score for any node in the subtree is computed and compared against the pareto front or ranked motif list discovered so far. if the bound is dominated by the current pareto front or ranked list, the whole subtree is discarded from search space. for large runs more than  <dig> % of the search tree is typically discarded this way. details of the branch-and-bound approach are given in previous publication  <cit>  and in additional file  <dig> 

testing
compo was tested on a large benchmark suite  <cit>  compiled from the transcompel data base   <cit> , in addition to two smaller suites compiled from muscle-  <cit>  and liver-specific  <cit>  genes, and a recent suite compiled from the redfly database  <cit> . it was run with automatic parameter selection, meaning that for each data set compo automatically selected parameter values from a list of discrete possibilities. although the performance of compo could have been further improved by manually specifying optimal parameter values, this could easily have caused overtuning and was therefore avoided.

in the main benchmark suite , target pwms are mixed with randomly selected transfac pwms that have no annotated binding sites in a given data set. these pwms without annotated binding are referred to as noise pwms, and are introduced to simulate a situation without accurate knowledge of the true regulators. the benchmark suite defines  <dig> different noise levels, where the percentage of noise pwms varies between 0% and 99%. the highest noise level, denoted as 99%, uses the whole transfac as input and has thus really around  <dig> % noise pwms.

at each noise level, ten different data set versions are defined, corresponding to different random selections of noise pwms. this benchmark thus defines a total of  <dig> runs on individual data sets, with each data set consisting of between  <dig> and  <dig> input sequences. the results on this benchmark are shown in table  <dig>  compo outperforms all other methods on all noise levels of the benchmark.

prediction performance on the transcompel benchmark data sets. the given scores are for the custom matrices version of the benchmark, with different levels of randomly selected matrices  added to the data set. score values equal to or better than compo are shown in bold.

given the good performance of compo we further investigated how the performance was influenced by relevant unique features of compo, in particular the background based on real dna sequence and the possibility of inferring motif properties across co-regulated sequences. the partly empirical background computations are unique to compo, while the possibility of inferring motif properties is shared with cma and modulesearcher. table  <dig> compares the default score of compo with scores achieved when using only a random model of dna  and when considering each sequence in isolation . it seems that both the empirical background and the inference of composite motif properties across co-regulatory regions contribute strongly to the high performance of compo. when either of these elements is removed, the performance of compo drops to a level comparable to other methods on the transcompel suite.

the table shows how prediction performance is influenced by using only a random dna model in background computations , and by making predictions on sequences independently .

on muscle and liver benchmarks the performance of compo is equal to or better than most other methods, except for mscan on muscle data and cluster-buster on liver data . the benefit from support is less obvious here when judged by the ncc score. however, using support tends to give more conservative solutions with less false positives compared to independent sequence runs . this benchmark also shows the effect of allowing non-perfect matches. the effect is most pronounced in the muscle data set where the relevant binding site motifs  on average are found in only 42% of the modules, compared to 57% for the liver data set and motifs .

prediction performance on the muscle and liver data sets. score values equal to or better than main compo run are shown in bold.

the benchmarks discussed above each have their strengths and limitations. the transcompel benchmark is broad and robust, with  <dig> data sets, different levels of noise, and a total of  <dig> runs. however as transcompel currently contains almost exclusively tfbs pairs, methods are only tested on the discovery of small composite motifs. the muscle and liver benchmark data sets have larger composite motifs, but with only  <dig> data sets and a total of  <dig> runs, the results are less robust. an interesting addition to these two benchmarks are presented in a recent article by ivan et al.  <cit> . a total of  <dig> data sets were compiled based on data from the redfly database  <cit> . the data sets from this benchmark have been made available, together with a relatively simple evaluation procedure. performance data according to this evaluation procedure has also been made available for a few selected methods. the accompanying evaluation procedure requires exactly one composite motif instance to be predicted for each sequence, requires all predicted instances for a given data set to have equal length, and only evaluates the predictions of start locations, not length predictions of composite motif instances. based on this, the sensitivity of predictions are calculated for each data set, along with a p-value of whether predictions are significantly better than random. the main performance measure is the number of data sets with significant prediction .

we evaluated compo on this benchmark according to the accompanying evaluation procedure that assumes crm length of  <dig> bp for all data sets. results are given in table  <dig>  compo made significantly good predictions  on  <dig> out of the  <dig> data sets. this is better than random and better than the methods cismodule  and mcd , similar to d2z  and stubb , and lower than csam , the best performing method which was accompanying the benchmark.

prediction performance  on the drosophila data sets. there is a total of  <dig> data sets in the benchmark. score values equal to or better than compo are shown in bold. results for other methods have been taken from table  <dig> in supplementary material for  <cit> ).

further details on the experimental setup are given in additional file  <dig> 

pareto front
compo may optionally return a pareto front corresponding to a multi-objective evaluation on sensitivity, specificity and spatial clustering. intuitively, the pareto front contains motifs that have good values for at least one or a few of these characteristics. this gives a broader view of possibly interesting motifs, and leaves the final selection of output motifs to a subjective evaluation by the user. in addition to giving a broad view, this also avoids combining different objectives by general formulas that are typically inferior to expert judgment. this defining property of multi-objective optimization, however, also means it is not suited for use in automatic benchmarking procedures. for this reason, we used a standard ranking of motifs according to a combined score in the benchmarks.

to give an example of properties of pareto fronts for composite motifs, we show the pareto front for one of the data sets of the transcompel benchmark presented above. on this data set, the highest-ranked motif predicted by compo was not accurate. the top-ranking composite motif was composed of pwms related to the ets and gata tfs, while the annotations for the data set specified a composite element composed of an ap1-related and a nfat-related pwm. figure 3a shows a heat map of the pareto front for this data set, with support as first dimension, distance restriction as second dimension and specificity as third dimension . an interesting composite motif should typically have high support, be closely spaced, and be specific with respect to background. to the upper left are very specific  composite motifs with low support and low spatial clustering, while at the lower right are less specific  with high support and high spatial clustering. expert users may then make subjective judgements regarding trade-offs between these characteristics and further inspect composite motifs of interest.

discussion
given a set of genes , the objective with composite motif discovery methods is to predict transcription factors that are underlying regulators of the gene set. the starting point would be the gene list with known motifs for individual factors available from databases such as transfac  <cit>  and jaspar  <cit> . alternatively, de novo single motif discovery may be performed to discover overrepresented short contiguous motifs in the sequences.

given upstream gene regions and either known or de novo motifs, composite motif discovery methods such as compo may be used to discover enriched combinations of motifs, which may correspond to cis-regulatory modules. with cc scores ranging from  <dig>  to  <dig>  on the transcompel benchmark, compo is consistently able to give useful computational binding site predictions for sets of co-regulated genes even when the true regulators are not known.

users may have different levels of prior knowledge about the composite motifs they are seeking when they resort to a computational method. some users may e.g. know the exact composition of the relevant module, whether all tfs are obligatory for the function of the composite motifs, and what the typical distances between binding sites in a module are. other users may know nothing more than a list of tfs potentially regulating a list of genes. a computational method should therefore allow such intuitive parameters to be set if known, but it should not be necessary to set arbitrary values when no prior information is available. compo allows many intuitive parameters to be set, but all of these parameters may also be estimated automatically. as compo uses p-values as a universal significance measure, motifs discovered using different parameter settings can be directly compared. this allows compo to be run with multiple settings and then automatically selecting the most significant motifs across these settings. by default compo tries a large range of values for the number of components in modules; the size of the distance window, the allowed number of component motif misses, and the hit density factor used to determine hit-thresholds in the initial discretization. furthermore, compo has no so called nuisance parameters – parameters that reflect properties of the algorithm rather than properties of the module to be discovered.

the composite motif discovery method that is most similar to compo is probably modulesearcher  <cit> . however, although compo and modulesearcher are similar in search algorithm, there are also important differences. compo uses real background dna in its score computations, and may instead of a ranked list also return a multi-objective solution as output. if a standard ranked list is chosen as output in compo, the composite motifs are ranked by p-values, which also allows composite motifs to be compared across parameter settings. instead of relying on a fixed or specified value for each parameter, compo can thus take a list of candidate parameter values as input and select the highest scoring motifs across parameter settings automatically. furthermore, compo explicitly models fault-tolerant absence of motif instances in composite motifs. finally, compo is able to use several different approaches to pre-processing in the search procedure.

CONCLUSIONS
the results on the benchmark suite show a very competitive quantitative performance for compo using default parameters, in particular in cases where support across sequences may be utilized. in addition to this, compo has some qualitatively advantageous properties. the intuitive parameters and discovery algorithm make the method relatively transparent, and the results are more easily interpretable compared to many other methods. the option of considering composite motif discovery as a multi-objective optimization problem allows users to spot higher-order trends in results and to postpone making trade-offs between objectives until after the search. finally, with a general discovery algorithm and a relatively accessible python source code, compo lends itself to experimentation and further development.

