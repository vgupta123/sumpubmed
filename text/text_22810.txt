BACKGROUND
the introduction of microarray technology has marked a paradigm shift in genomics. the first studies in  <dig>  <cit>  showed its potential for the functional analysis of genomes. instead of being focused on single or small sets of genes of interest the microarray technology provides a holistic view on gene expression of an organism due to the analysis of thousands of genes in a single experiment. this high-throughput technique is used in functional genomics due to its wide range of applications, relative cost-efficiency, and its potential to support genome-wide studies  <cit> .

practices in functional genomics have reached a turning point where standardization of data storage, management and data-mining of large data sets, documentation of experimental processes, and a guidance on the applicable analysis methods have gained an increasing importance  <cit> . microarray experiments are often conducted within larger international projects with a large number of participants. to standardize the annotation of microarray data, the minimum information about a microarray experiment   <cit>  recommendation, the microarray gene expression markup language  format for data interchange  <cit> , and ontologies such as the mged ontology  <cit>  have been proposed.

there exists a variety of software applications aiming to simplify the analysis, annotation, storage and retrieval of experiments and data. also public repositories such as arrayexpress  <cit>  and geo  <cit>  have been developed to integrate data analysis tools and gene expression visualization.

as has been recently noted combining gene expression data with functional annotation data such as metabolic pathways, gene regulatory networks or metabolome data can open new perspectives for generating hypotheses and understanding regulatory interactions  <cit> . the substantial benefits of data integration are the availability of up-to-date functional knowledge from external or internal sources and taking advantage of external data within new data analysis methods.

as an example for an approach to integrate data the genome expression pathway analysis tool  offers an analysis of gene expression data under genomic, proteomic and metabolic context. it supports various normalization and analysis methods, but it does not support mage-ml, the mged ontology, and web-services  <cit> .

the mars system is an example for database software that provides mage-ml support and web-service access to raw data  <cit> . it provides no integrated analysis functionality, instead it requires external software which requires to transfer large files between applications. base  <dig> is another database application that supports mage-ml export and has an integrated analysis system using pipelines  <cit> . furthermore, it can make use of the carmaweb  <cit>  web-service for normalization of spotted and affymetrix arrays. currently base  <dig> does not support mage-ml import and integrated cluster analysis. although the mage-ml format is a widely accepted standard, none of the mentioned microarray data analysis tools support import and export of the complete model, and only loosely integrate the mged-ontology into the annotation of experimental conditions. it is also desirable to allow queries for gene expression data over system-independent interfaces such as soap-based web-services.

to address these requirements, a novel standards-compliant system, emma  <dig>  was developed based on the experiences gained with its predecessor emma  <dig>  <cit> . emma  <dig> has been completely implemented from scratch as emma  <dig> was based on a self-designed persistent data model which imposed large limitations with respect to full mage-om support. also, the emma  <dig> system did not support data integration via web-services. the data model also restricted the application of emma  <dig> to dual channel arrays because the aspect of two channels was strongly represented in the design of the system. while emma  <dig> is capable of handling different normalization and test methods, it did not support to keep more than one result within one experiment at a time, which would be important for method comparison.

all steps in the workflow of an experiment are annotated in a mage-compliant way, ranging from acquisition of experimental protocols to handling of raw and transformed data. the system also provides a close integration of other data-sources, such as genome annotations, metabolic pathways, and proteome measurements. in contrast to other microarray databases and analysis tools, emma  <dig> provides a wide collection of algorithms and a database to store, retrieve, and comprehensively analyze genome-wide datasets in a miame and mage-ml compliant format.

implementation
architecture
the application is realized using an extended 3-tier architecture. the standard 3-tier approach was augmented by using the object-relational mapping layer o2dbi, which provides a fully object-oriented abstraction to the underlying database. o2dbi uses mysql tables to store persistent perl objects and can convert data models into sql and perl code automatically.

furthermore, we have added an additional communication layer to the application tier , which is responsible for the communication with remote applications  <cit> . finally, the presentation layer is divided into the web-interface and the web-services interface that provides soap based web-services. within the web-interface layer, we have adapted the concept of the model-view-controller  design pattern   <cit> .

model driven approach 
the system was designed and implemented using a model driven approach   <cit> . within the mda framework, object-oriented methods were applied during the design process using the unified modelling language .

we decided to implement the full mage object model  as the core database model, because we wanted to provide full support for each valid mage-ml document. this is made possible by providing a one-to-one implementation of the classes found in mage-om within our framework. as mage-om is very complex and in order to speed up implementation of the database layer and the application api, we decided to automate the code-generation process of the application logic, database back-end, and mage-ml export classes.

two auxiliary model components have been added to supplement mage-om. the access control model  implements access control lists to be able to configure access to each mage-om object. the second addition contains classes for the execution of analysis tools and the storage of results . both models are only sparsely interlinked with mage-om, which makes them re-usable for other applications.

to increase the efficiency of the database we have optimized the automatically generated sql model. the optimizations include additional sql indices and sql views for frequently used queries such as the mapping between features, reporters, and composite sequences. the mapping between these data structures is highly complex in mage-om as it involves join operations over multiple tables and can be simplified using sql views using one virtual table.

development tools and dependencies
the system is implemented using perl, the apache web-server, and mysql databases as storage back-end. for the purpose of code-generation from xml definitions we used xsl transformations .

the web-interface is based on an apache web-server, the cgi perl module, html templates and ajax to improve interactivity. to browse cluster analyses, the web-interface contains a java-applet. we use the soap::lite perl module for client-server communication via web-services.

analysis functions are implemented using the r statistical programming environment  <cit>  and bioconductor packages  <cit> . we are using the rsperl module from the omegahat project to embed r within our perl application  <cit> . this module allows to flexibly create and transfer data-structures between both languages and avoids data-exchange by passing temporary files.

microarray data sets consist mainly of large numeric data arrays of variable length dimensions. relational database tables are not the optimal storage engine for this type of data. therefore, numeric quantification data are stored efficiently and in a platform-independent way using hdf <dig>   <cit>  files. we use the perl data language  as an efficient interface to hdf <dig> files.

supported formats
the system supports the upload of array data using the imagene or genepix software formats as well as general comma or tab-separated files and cel-files. for nimblegen arrays, pair files containing pairwise probe intensities are imported. due to the modular architecture of the importer, new formats can be added easily.

RESULTS
the web-interface
the emma  <dig> software has been developed as a web-application requiring a standards compliant web-browser on the client side. the interface has been designed to be highly user-friendly and interactive. it aids the user in miame compliant annotation of microarray experiments while hiding the complexity of the underlying object model. the interface is built around the central notion of an experiment, which forms collections of data and annotation. further analysis results, such as images or pdf documents, are depicted as attachments within an experiment . for a precise annotation, experimental conditions need to be defined using a controlled vocabulary. for this purpose, emma provides an ontology browser containing the mged-ontology .

different levels of context dependent help and documentation are available ranging from usage hints to a detailed user's manual and a documentation wiki. the interface makes use of modern web-technologies such as ajax to increase interactivity and responsivenes of the application.

analysis pipelines
the data analysis mechanisms in emma  <dig> have been developed and designed to be both highly flexible and easy to use for users without much experience. data analysis in emma  <dig> is carried out within so called pipelines. analysis pipelines are composed of three components represented in the database model: firstly, functions implement the actual r functions used for data analysis. they have input and output data types and a set of parameters. secondly, tools form linear compositions of type compatible functions together with actual values for the parameters. lastly, jobs encompass the combination of tools with data sets of matching input type. jobs are executed on a grid-computing system.

pipelines represent a linear arrangement of single analysis functions and a set of corresponding parameter settings. all elements of the analysis system are recorded within the database. pipelines can be pre-defined by project administrators together with appropriate parameter settings. functions are typed with respect to mage-om classes.

as analysis functions can be arranged in various sequences, a type system is crucial to enforce sensible combinations of analysis functions. the type system has been designed to automatically feed the correct type of data  into the analysis pipeline. new functions can be easily added to a project by importing an xml document that contains a description of functions and data types using the tools-ml document language designed to closely resemble mage-ml. analysis pipelines can be pre-configured with sensible default values, while more experienced users are able to adjust analysis parameters and choose different input datasets. all pipeline executions, parameter settings, and the resulting data are automatically recorded in the database.

normalization and pre-processing functions
pre-processing of raw data is necessary as a first step in a microarray analysis pipeline after image analysis to remove weak or flagged measurements, handle background estimates, and do further transformations. normalization is commonly used to remove systematic bias from the data and to make empirical distributions between arrays comparable  <cit> .

emma  <dig> provides normalization and preprocessing pipelines for two-color arrays as well as for single channel arrays . for two-color arrays we provide median based and intensity dependent normalization , which are available in the marray-package  <cit> .

for affymetrix arrays we provide an interface to pre-processing functions available in the affy package  <cit>  such as mas <dig>  rma, and mbei by means of the 'expresso' function and also gcrma by using the respective package  <cit> . for quality control, emma  <dig> allows to create pdf documents with various statistics and plots as provided by the r-package affyqcreport.

for nimblegen arrays we have implemented the 'nixpresso' r function in emma  <dig> to adapt rma backgroud correction, normalization, and summary statistics for single channel analysis. array descriptions can be uploaded using an adf or mage-ml file.

statistical inference
the second step of a data analysis pipeline is often the identification of significantly expressed genes. many statistical inference methods have been proposed recently, some of which are applicable for two-sample comparisons and others are also suitable for multi-factorial experiment designs. the range of inference statistics available in emma  <dig> includes one-sample and two-sample t-tests, wilcoxon's rank-sum statistic, significance analysis of microarrays   <cit> , the cybert method  <cit> , the limma package  <cit> , and anova for multi-factorial designs.

cluster analysis
emma  <dig> provides many clustering algorithms, such as agglomerative and divisive hierarchical clustering. all linkage methods provided by r are available by default . an experiment can contain an arbitrary amount of cluster analyses to compare different methods and filter settings. the results can be exported in a newick file or browsed directly with the interactive heatmap viewer java applet . the heatmap viewer allows to cut and inspect the cluster dendrogram and to export dendrograms and heatmaps as vector graphics. the heatmap viewer links to the sequence annotation in emma.

data integration and advanced visualization features
in emma  <dig>  every sequence information  on a microarray can be crosslinked to the corresponding sequence in the genome annotation system gendb  <cit>  and vice-versa. the implementation relies on the bridge layer which provides transparent access to the perl api of remote applications  <cit> .

by communication over this bi-directional layer, functional annotations such as kegg pathway information and functional classifications are directly accessible. the kegg-pathway projection is a versatile visualization utilizing the bridge layer. it allows the projection of expression values on corresponding enzymes in a kegg-pathway graph. another example application of data integration is the kegg-violin plot. this novel visualization method allows to depict gene-expression over all pathways. each violin in the plot represents a kegg pathway map. the shape of the violin is determined by a smoothed density estimate of gene expression values. thereby, it is easy to spot pathways which react homogenously to experimental stimuli, and others which exhibit alternate ways of response. outliers are also depicted within the graphic to easily spot genes which deviate from the general reaction of the encompassing pathways.

array designs in emma can also link to annotation data from remote databases by means of web-services. web-services present a popular standardized mechanism for data-interchange via internet protocols independent of the programming language. emma  <dig> supports the soap  <cit>  messaging protocol within its communication layer to implement web-service support. communication between emma  <dig> and other applications is bi-directional, while emma  <dig> serves as a web-services provider that enables querying expression data using a given sequence identifier.

the opposite direction of communication is represented by the web-services client built into the communication layer. the client allows to connect sequence data to external web-services in a similar way as it allows to add links to external database resources. all web-services that use the web services definition language  can be directly accessed without further programming. wsdl is an open standard to describe web-services. the web-services connected to a sequence can be queried whenever a sequence is viewed. the results of such queries can be added to data sheets from statistical tests. in particular, regulatory networks can be retrieved from the coryneregnet software  <cit> . coryneregnet is a data-warehouse of regulatory interactions for corynebacteria. a reference implementation of such an integrated application framework between transcriptomics data , a genome annotation system  and coryneregnet is provided by the corynecenter system  <cit> .

collaborative functions
collaborative functionality is an essential requirement in large distributed projects involving many individuals and institutions. in such projects it is crucial for research groups to easily share experimental data and jointly conduct the annotation of biological experiments and analyze microarray data. moreover, after a certain level of quality is reached, an experiment needs to be published within the consortium. furthermore, control on who can or cannot view, export, or edit data is required.

authentication and authorization
authentication by username and password is handled by the general project management system  that is used for all cebitec software. gpms supports the management of multiple projects and provides a role-based authorization model. emma  <dig> comprises of a collection of roles suitable for different degrees of user experience or trust from system administrators who can perform each possible action to an less privileged guest user. users and accounts can be managed via the gpms web-interface.

access control and shared data
although role-based access control is already very flexible, it is not suitable to model access rights to individual objects, as objects are dynamically created and destroyed during run-time. therefore, we have implemented another layer of control based on access control lists . acls can be used to bind access privileges of users or groups of users to certain objects within the database.

in the repository, each mage-om object can have its own set of acls to grant or restrict access to it. initially, the user creating an object is recorded as its owner and can change access privileges by adding or removing acls to the object. acls work intuitively for users and groups of users, such that for example granting the 'view' right on an experiment to the predefined group 'all' will make the experiment visible to all members of a project.

applications
emma  <dig>  became available in  <dig> and has been constantly developed and maintained since then. the current version  <dig>  is applied in various national and international functional genomics projects.

emma  <dig>  is the central transcriptomics server for the genomik-plus initiative. genomik-plus is a project funded by the german federal ministry of education and research  to foster genomic research in microorganisms. within the network emma  <dig> has been used to characterize the gene expression of the model organisms sinorhizobium meliloti  <cit> , corynebacteria  <cit>  and xanthomonades  <cit>  under many different growth conditions. emma  <dig> is also the central microarray analysis platform of the plant-genomics projects molmyk  <cit>  and grain legumes  <cit>  as well as for the eu network of excellence marine genomics. altogether, the emma  <dig> databases contain microarray data of more than  <dig> different organisms. in total, over  <dig> microarrays provided by the microarray core facility at the cebitec or external project partners and commercial vendors have been processed using the system.

application studies
to demonstrate the capabilities of the system, we have collected data from studies which have used emma  <dig> for microarray analyses within a demo project. these studies are related to the reconstruction of regulatory networks in bacteria and the study of beneficial plant-microbe interactions.

genome-wide reconstruction of gene regulatory networks in bacteria
global transcription profiling with dna microarrays is an essential prerequisite for the experimental reconstruction of microbial transcriptional regulatory networks. in particular, the detection of differential gene expression upon environmental changes or in defined regulatory mutants provides in vivo data on transcriptional control circuits and the contributing gene regulatory networks. the emma  <dig> platform, in conjunction with a whole-genome dna microarray produced on glas slides, was used for the systematic analysis of expression changes in gene regulatory mutants of corynebacterium glutamicum  <cit> .

differential expression patterns provided the seed information to search for common transcription factor binding sites in the upstream region of the detected genes by pattern matching approaches. for instance, the deletion of the regulatory gene ltbr, supposed to be involved in leucine-dependent gene regulation of c. glutamicum, revealed surprising results, since the evaluation of the microarray data with emma  <dig> showed differential expression not only for genes involved in leucine biosynthesis, but also for the tryptophan operon. in general, these data can be evaluated in vivo by real-time reverse transcription pcr or in vitro by electrophoretic mobility shift assays. accordingly, emma  <dig> substantially supported the reconstruction of regulatory interactions in c. glutamicum on a global scale  <cit> .

gene expression analysis of plant-microbe interaction
legume plants establish two different endosymbioses with soil microorganisms: the nitrogen-fixing root nodule symbiosis and the arbuscular mycorrhiza . whereas nodulation is almost exclusively restricted to legumes and requires the organogenesis of a root nodule that houses the rhizobial prokaryotes capable of symbiotic nitrogen fixation, more than 80% of terrestrial plants enter an am with fungi of the phylum glomeromycota  <cit> .

in a recent study, we applied  <dig> mer oligonucleotide microarrays  representing app. 35% of the gene space of the model legume medicago truncatula to specifiy the overlapping genetic program activated by two commonly studied microsymbionts, glomus mosseae and glomus intraradices  <cit> . in total,  <dig> plant genes were significantly co-induced at least 2-fold in either interaction. a range of well-known am marker genes, e.g. the gene encoding the phosphate transporter mtpt <dig>  were found to be activated, thus validating the transcriptome data obtained. using the same microarrays, we have studied the transcriptome of nitrogen-fixing root nodules induced by sinorhizobium meliloti. comparisons of the data sets obtained and cluster analyses revealed the co-induction of only a limited number of genes during both nodulation and mycorrhization. amongst those were gene functions associated with later stages of the symbiotic interaction, e.g. encoding proteins associated with the specific modification of plant membranes that enclose the symbiotic microbes  <cit> . the comparative analysis of the symbiotic transcriptome is facilitated by the fact that the reporter sequences stored in emma  <dig> are linked to the sams software  <cit>  that provides automated annotations, functional classifications, and the possibility to map expression data onto metabolic pathways. we are currently extending our analyses by using the more genome-wide affymetrix medicago genechips® for expression profiling. similar to the emma  <dig> analysis platform for  <dig> mer oligonucleotide microarrays, a link to the sams software allows to connect probe annotations and expression information. in summary, the use of the emma software platform has substantially facilitated research on the transcriptome of legume root endosymbioses  <cit> .

performance
the performance of a database system greatly depends on the hardware and software infrastructure as well as on an efficient database implementation. although the system can be installed on a single linux box in principle, we decided to integrate it into our server architecture using specialized shared application servers for performance reasons. the current reference installation of emma  <dig> runs on a sunfire v <dig>  application server. two redundant sunfire x <dig> servers with attached storage  are used as database servers running mysql  <dig>  computational jobs are executed on a cluster of dual-core opteron cpus . all servers are linked to our network via gigabit ethernet. all servers are running solaris  <dig> and are shared between multiple software applications.

with this set-up, the import of the array design of the mt16koli <dig> microarray  from a generated mage-ml file takes approximately three hours. a mage-ml export of an experiment containing six mt16koli <dig> arrays takes approximately  <dig> minutes without including the arraydesign package and  <dig> minutes with the arraydesign included. the performance of general analysis jobs such as normalization and clustering depend on the respective implementations in r.

all further database-based operations, such as searching for expression data for certain genes are executed in a timeframe of seconds. all file-based operations on large data from hdf <dig> files such as sorting and filtering are executed within milliseconds.

discussion
we have implemented a web-based system for the integrated storage and analysis of microarray data which incorporates all major microarray formats. it supports the whole mage-om and provides an object-oriented api to its underlying database model. it is built using a flexible object-relational mapping approach which allows for a high level of automated code generation during the development process. despite the complexity of the underlying data model, emma  <dig> provides a user friendly web-interface that hides the complexity of the model. the current level of usability is achieved by using simplified metaphors and modern web technologies throughout the interface.

mage-om is a data model that is known for its high complexity and was originally designed as a document format. we had to evaluate mage-om to see if it satisfied the requirements of a data storage model for real-world software applications. there was a significant need to increase the efficiency of the derived data model with respect to storage requirements and query speed. despite the complexity of the model, the implementation in emma  <dig> demonstrates that with minor extensions and by the use of a few manual optimizations mage-om provides high flexibility and efficiency in the targeted domain.

with respect to system performance we could demonstrate that database indices and database views are highly important optimization techniques as well as file based storage mechanisms for large matrices. however, in order to improve database efficiency for affymetrix arrays, we restrict our treatment of array designs to compositesequences and do not model each individual probe within our database because this would result in the creation of  <dig> to  <dig> million database objects, which are never used in subsequent analyses.

in comparison to the previous data model of the emma  <dig> software the increase in flexibility and complexity is evident. the emma  <dig> model consists of approximately  <dig> classes without inheritance, while the full emma  <dig> model consists of over  <dig> classes with deep inheritance relations imposed by mage-om. the use of a model driven approach has been crucial for the implementation of such a software project, even though it is not used very frequently in current bioinformatics applications. it might turn out to become highly relevant for the design of other repositories or general database applications in this field in the near future. the main reason we see for this development is the need for novel software applications following the rapidly evolving trends in high-throughput methods and the resulting need for new open standards to annotate results.

the implementation and integration of an ontology browser in emma  <dig> allows for a structured annotation and retrieval of data derived under certain experimental conditions. the integration of external data sources offers the potential to generate novel hypotheses, where results relying on expression values alone would not be sufficient. the system consists of reusable parts such as the perl api for mage-om, the pipeline system, and the access control model, which could also be beneficial for other database applications. unlike the mage software toolkit , which provides code-generators for creating document apis to mage-ml, the emma  <dig> api provides functions for storage and retrieval of mage data in a database interface. our implementation provides additional mage importers and exporters and reaches an increased flexibility over mage-stk in this repsect.

cluster analysis is a commonly used step in the analysis of gene expression data. most integrated systems  do not provide an integrated tool to compute and view cluster analyses within the system. arrayexpress provides expressionprofiler as an integrated solution to cluster analysis. nevertheless, the process of selecting the correct data columns from a large data matrix is rather complicated and the results cannot be stored within the database. in emma  <dig>  the clustering process has been simplified by using pipelines, as they allow us to feed compatible data types into the analysis automatically.

the ability of the emma  <dig> software package to integrate data from external data sources via two different communication channels is an outstanding feature. the level of bi-directional web-service integration is unique when compared to other microarray analysis systems and also in comparison to public repositories such as arrayexpress, which of course have a different focus than emma  <dig>  arrayexpress provides programatic access via web-services to raw experimental data and also access to raw and processed data via its web-interface and provides some data analysis tools. in addition, emma  <dig> also allows to query normalized data via its soap interface.

the flexibility of its analysis pipelines is another important advantage of the presented software. especially with respect to high-throughput data it is beneficial to be able to distribute the compute load to a compute cluster. such a system could also be applicable for novel methods in transcriptomics such as high throughput sequencing techniques. it will be highly interesting for future database applications to integrate array based and sequencing based transcriptomics approaches.

outlook
the system is under active development. support for nimblegen microarrays is currently in the testing-phase. furthermore, we are working on integrating quantitative matabolomics data, for example from our novel meltdb software  <cit>  via web-services. we further intend to develop the system into a general transcriptomics platform by incorporating new pipelines. these could include fast mapping algorithms which will allow to map sequenced tags to the genome sequence efficiently and normalization and statistical test for count data. while the mage-om model could be partially sufficient for the purpose of experimental annotation and quantitative data, building repositories for handling ultra-fast sequencing transcriptome data will require more effort in designing efficient database systems.

CONCLUSIONS
we have developed a versatile system for the integrated analysis of microarray data, called emma  <dig>  it is unique in its cummulated support for two-channel and affymetrix analysis. adherence to public standards such as mage-ml and the mged ontology is a prerequisite for the reproducibility and interpretability of microarray experiments. the system also supports data integration by use of standard protocols such as web-services that is unprecedented in other software systems. the overall concept of the system could be shown to be adequate and extensible to new technologies. the system has contributed to many collaborative functional genomics studies with many international contributors and is actively used and developed. due to its flexibility and efficiency, the system seems well suited to be extended for the analysis of quantitative transcriptomics data from the novel ultra-fast sequencing technologies.

availability
• the emma  <dig> server and documentation is available at: 

• demo projects with representative data have been set up.

• source code packages are available under the gpl upon request.

• system requirements for local installation: unix/linux, apache, mysql, perl, r, and bioconductor, and additional system libraries, rsperl.

• local installation requires skills in linux/unix administration.

• web-client requirements: java-enabled web-browser .

• instructions on usage of the programmatic soap interface are available at: 

authors' contributions
md designed and implemented most of the core system and wrote the manuscript. sa, sj, jg, ft, and tk contributed to the web-design and implementation. dm implemented and evaluated statistical inference methods. hk and at provided substantial intellectual contribution to the manuscript and provided the application cases. tk implemented the lims component. tg and ft developed java applets. kh and ckk built analysis pipelines and parsers for affymetrix and nimblegen. bl contributed the o2dbi layer within our model-driven approach. vm contributed to the documentation and manuscript. hn and ag implemented data integration layers and contributed substantial intellectual input to the manuscript. kjr developed the mage-ml exporter generator framework. kjr and ft integrated the ontology. ap and ag initiated, supervised, and directed the whole project. all authors read and approved the final manuscript.

