BACKGROUND
comprehensive and predictive models of biological systems are expected to improve our ability to analyze complex systems, from molecular pathways to populations of organisms. thus, there is much interest in sophisticated computational modeling techniques and high-throughput data generation  <cit> . one of the major difficulties in modeling cell signaling networks is the identification of the directionality and strength of relationship between molecular species in specific pathways. however, once this has been done, the knowledge can be formalized in mathematical models based on various computational methods. in particular, differential equations are widely used in biological modeling to describe dynamic processes in terms of rates of change  <cit> . the variables in these models represent the concentrations of molecular species and the directionality and strength of their relationships are encoded in the rate parameters governing their interactions. following the construction of a mathematical representation, cycles of experimental validation and model improvement are essential for generating a predictive model, by ensuring that all required molecular species are adequately represented and that the parameter values are accurate. however, calibration of the mathematical model is not trivial because non-linearity and feedback/feedforward connections commonly found in cell signaling pathways make the analysis difficult  <cit> . here, we develop a systematic methodology for validating quantitative models of biological processes and apply our methodology to an existing model of trail-induced apoptosis  <cit> .

systematic procedure of model calibration
model calibration or regression by data fitting is necessary for computational modeling in any field of science or engineering. systems biology faces the same challenge to construct experimentally validated models. however, formal tools for quantitative biological models have not been established yet and manual analysis is common in practice. in fact, manual fitting has the advantage that researchers may apply their experimental intuition or prior knowledge to the model relatively easily with minimal aid of mathematical or computational skills. however, the structural complexity of signaling pathways makes it difficult to fit the model heuristically based on intuition or simple analyses only. there are three dominant differences between manual fitting and systematic calibration:  as in yang's work  <cit> , manual fitting is attempted to estimate uncertain parameter values which cannot be decided directly by experimental measurement or literature. on the other hand, the systematic calibration in our study aims principally to estimate, among uncertain parameters, only the most important. we investigated the individual effect of parameters and focused on the dominant parameters to calibrate the model.  manual fitting is carried out mainly by a trial-and-error process that does not guarantee optimal fit of the model. on the other hand, our systematic calibration method approaches the problem globally over the multi-dimensional domain of important uncertain parameters. thus, it has higher probability of finding the optimal solution.  manual fitting ends with what are, at the time, the best parameter values, while systematic calibration provides additional information, such as important subsets of pathways in a network or possible local optimum solutions.

we have developed a systematic calibration procedure for testing and improving models as shown in figure  <dig>  in the first step, the model is constructed based on information from the literature and analyzed qualitatively to ensure that it is in agreement with prior knowledge about the network. usually, the construction of the network model is based on information from the literature and published experimental results are what we aim to qualitatively reproduce. because only the structural characteristics of the model are of interest in this step, a model with tentative parameter values is not necessarily expected to reproduce experimental data quantitatively. the suitability of the proto-model can be assessed by analyzing output sensitivities to input variables values under presumed uncertainties of the rate parameters . candidate model modifications are iterated until a satisfactory qualitative match to the prior knowledge is obtained.

in the second step, we assess whether a subset of pathway reactions dominantly affects the model outputs, focusing on the outputs that are described by the experimental data to be used in the calibration step . identification of dominant reactions is done by sensitivity analysis; many methods exist  <cit>  and we adopted two methods that are most appropriate to nonlinear network models .

in the third step, we perform a quantitative fit, or calibration, of the model to experimental data, to determine parameter values that minimize the deviations between experimental results and model simulations . parameter estimation by global optimization has been developed for engineering optimization problems  <cit> . below we investigate the advantages and disadvantages of three methods for biological applications, including computational efficiency, and compare the results .

lastly, as the model evolves in light of newly available data, the overall procedure should be iterated. we believe that by implementing the intermediary steps where sensitivity analyses are used both to assess the qualitative behavior of the model and determine which parameters to optimize, our systematic method will significantly facilitate model calibration.

RESULTS
qualitative analysis of a proto-model
analysis of sensitivity with respect to initial species concentrations provides a criterion for the qualitative correctness of a cell signaling model. sensitivity analysis assesses how changes in model inputs contribute to model output variability, and its ability to deduce model input-output relationships makes sensitivity analysis one of the critical parts of model development, verification, and evaluation. changes in initial species concentrations can mimic the effects of mutations or changes in the expression level of the molecular players involved, and the sensitivity of the model output to changes in initial species concentrations should match the expected change in system behavior.

the simplest and most generally used sensitivity analysis method is a gradient-based index as follows,  

where model outputs and inputs are represented as yi and pj respectively. this method is often called local sensitivity because it reflects output variability accurately near a given nominal input value, p*. however, most kinetic parameters are quite uncertain and a range rather than a single parameter value is available, either from the literature or from biophysical constraints on the reactions. thus, "model-independent", or more precisely, parameter-independent, global sensitivity analysis techniques have generated great interest <cit> . averaging of local sensitivities over a range of plausible values for uncertain parameters is one possible method for global sensitivity. local sensitivities are calculated with multiple parameter choices that are selected randomly or regularly within parameter ranges. the sensitivities for those parameter choices, integrated over the time interval of interest in the monitoring of the output, ∫|sij|dt, are then averaged to determine global sensitivity  <cit> . importantly, because integration over time and averaging are necessary, a compromise must be made between accurately calculating the magnitude of the effects by using absolute sensitivity values, and assessing the directionality of the effects, by maintaining the sign of the values.

the model on which we applied our methodology simulates the response of a single cell to trail. trail is a protein ligand which triggers the process of programmed cell death, or apoptosis. this model of trail-induced cell death signaling network encompasses the activation of initiator  and effector  caspases, the onset of mitochondrial outer membrane permeabilization and the death of the cell, as marked by cleavage of the caspase- <dig> substrate, parp. according to a recent study  <cit> , extrinsic apoptosis shows a specific behavior of all-or-none effector caspase activation at the single-cell level. as the authors termed it, the process shows "variable-delay, snap-action": a long, variable delay between trail stimulation and effector caspase activation is followed by rapid and sudden progression to completion. the original model is composed of  <dig> ordinary differential equations based on mass action kinetics. eighteen out of  <dig> protein species have non-zero initial concentrations, and  <dig> rate constants regulate the reactions in the model network. the original parameters were determined from the literature and manual fitting. in this study, we applied our methods to analyze qualitative properties of the model and fit the model to dynamic quantitative experimental data in a systematical and computationally effective way. hereafter, the original model in  <cit>  will be referred to as the manually calibrated model, to distinguish it from our improved model.

in our analysis, cleavage of parp is the key output; because the process is all-or-none, if >50% of parp is cleaved, it is eventually all cleaved and thus a simulated cell is deemed dead at 50% cleaved parp . we first evaluated sensitivities of the cleavage of parp with respect to changes in initial species concentrations, sampling over a range of plausible parameter values . in this case, instead of averaging the sensitivities over the sampled range of parameter values, we plotted their distributions in a box plot, to preserve the directionality of the effect in the sign of the sensitivities . we interpreted the results in three ways. first, proteins with positive sensitivity would promote parp cleavage and thus were pro-apoptotic, and by corollary, proteins with negative sensitivity would repress parp cleavage and had an anti-apoptotic effect. the pro- or anti-apoptotic nature of trail-induced signaling proteins has been identified in the literature and should be encoded properly in the mathematical model. for instance, xiap  is a well known anti-apoptotic player, and the sensitivity of parp cleavage with respect to xiap was correctly shown to be negative . conversely, smac, when released from the mitochondria, inhibits xiap and thus the positive sign of sensitivity with respect to the mitochondrial store of smac, smacm, agrees with its pro-apoptotic nature . by similarly assessing the sign of the sensitivity of each protein, the trail-induced cell death proto-model could be validated.

second, the absolute value of sensitivity provides a measure of how strongly the perturbation of a single species' concentration affects the model output. the sensitivity with respect to perturbation of xiap was found to be relatively high on average, implying that the model output can be changed dramatically by small changes in xiap . this prediction is supported by biological evidence that xiap directly inhibits the enzymatic activity of caspases and the degree of inhibition is highly dependent on the concentration of xiap <cit> . cleavage of parp is insensitive to the concentration of caspase- <dig> , in agreement with experiments in which reducing the expression of caspase- <dig> by ~90% did not affect trail-induced cell death . overall, our sensitivity analysis agreed with the known effects of varying protein concentration. if, however, the signs or strengths of the sensitivities in our analysis had not agreed with experimental results, the model construction would have to be re-examined. modification of the model and this qualitative analysis would be done iteratively until a satisfactory result could be reached. although the trail model study does not provide us with an example of failure of qualitative agreement at this step of the procedure, it is still worth noting that qualitative agreement with known experimental system behavior can be a strong preliminary criteria for adequacy of the model structure. in effect, it sets a minimal qualification that must be met before more computationally intensive methods are applied to improve the proto-model by quantitative fitting.

in a third type of assessment of the results our sensitivity analysis of parp cleavage, we analyzed the influence of the uncertainty of rate constants on the sensitivity with respect to initial species concentrations. sensitivities that are not affected by parameter values will have narrow distributions, and by consequence, their sensitivity value is very reliable. the sensitivities related to the perturbation of some species like xiap and caspase- <dig> were found to be broadly distributed and thus to be relatively uncertain . particularly interesting is the fact that the sensitivity of parp cleavage to caspase- <dig> is negative in some cases, even if it is known to have a pro-apoptotic function, invalidating certain parameter sets.

dominant parameter selection
when global sensitivities are determined by averaging local sensitivities as we did above, no assumptions are made in the relationships between input parameters and output variables, so this method is applicable in most nonlinear and non-monotonic problems. for the model of trail-induced apoptosis, the significance of each rate parameter to the total model output variation can be identified by global sensitivity analysis in a matrix of  <dig> parameters  by  <dig> variables  . the height of each bar represents the global parameter sensitivity of the corresponding species concentration with respect to changes in the reaction rate constant, or parameter. we observed that certain rate constants, such as p, the rate of complex formation between trail and free, inactive receptor, p, the rate of dissociation of trail and receptor, or p the rate of dissociation of the activated trail-receptor complex, can influence most protein concentration outputs. therefore, some of the parameters involved in the reactions for activating the receptor complex are critical to the quantitative description of most downstream molecular species. meanwhile other parameters have nearly zero sensitivity and thus do not affect any species concentration. two of these parameters correspond to the reactions for dissociating the complex of the active caspase- <dig> and inactive caspase- <dig> ), and the complex of cytochrome c and the mitochondrial pores ). while these parameters will be difficult to constrain with any time series data, our analysis shows that their value should not impact model behavior. for trail-induced apoptosis, the experimental data to which we aim to fit the model describes the cleavage of parp, which marks the activation of caspase- <dig> and cell death. therefore, we compared the  <dig> rate parameters based on their sensitivity to cleaved parp  and observed that eight parameters had a large impact .

* the common parameters identified by all the sensitivity indices were highlighted in bold style and the parameters by any of two different sensitivity indices were underlined.

† global optimization  was executed with respect to the parameter combination selected by each sensitivity index.

importantly, there are often biologically meaningful quantities of interest for which partial derivatives cannot be defined, and these may be the outputs for which the dominant parameters need to be identified. for example, for trail-induced apoptosis we can define biologically meaningful features of the dynamic behavior of cell death. one example is the delay time  that measures how long it takes from the time of trail addition to the time at which 50% of parp is cleaved. another is the switching time , which measures the rapidity of parp cleavage after caspase- <dig>  activation. these features are variables that are discontinuous with respect to input parameter variation, and to determine the dominant parameters in controlling tdelay, we therefore explored other sensitivity analysis methods to replace gradient-based sensitivity analysis.

variance-based sensitivity methods form another category of global sensitivity analysis. in using these methods, the variance of a model output is decomposed into partial variances contributed by individual model input variations, and the sensitivity indices are derived from the ratio of the partial variance to the total variance of model output. among the several variance-based sensitivity methods, we adopted sobol's method  <cit>  to analyze the trail-induced apoptosis model. sobol's method generates two kinds of sensitivity indices. one is a first-order sensitivity that measures the fractional contribution of single inputs to the variance of output, neglecting any interactions with other model inputs by maintaining these at constant values. the other, a true global sensitivity, is the total effect sensitivity, or the sum of all the sensitivities involving the model input of interest over the full range of parameters values explored. these two sensitivity indices were computed simultaneously by monte carlo method and the results are summarized in figure  <dig>  the computational cost for sensitivity analysis varies widely by method, as shown in table  <dig>  sobol's method requires more computation  to satisfy the convergence of the monte carlo approximation while the average of local sensitivities method converges with  <dig>  sets of parameter values.

to determine which parameters dominate the control of parp cleavage dynamics and tdelay, the model parameters were ranked by highest to lowest amplitude in sensitivities  and the eight most dominant parameters from each of the three sensitivity indices are listed in table  <dig>  the parameters that are commonly selected by all three methods are bolded, and those selected by two are underlined; the nomenclature of the parameters follows that of albeck et al <cit> . for example, k <dig>  which is the forward reaction rate constant of parp cleavage by caspase- <dig>  is ranked within the eight dominant parameters by all three sensitivity indices. k <dig> and kc <dig>  relevant to caspase- <dig> activation and death ligand binding to the receptor respectively, are also dominant by all three methods. even though all the reactions in the network play a role in cell death signaling, the sets of reactions rate constants listed in table  <dig> were identified as the most critical in regulating the dynamic of parp cleavage. this prediction, that reactions relevant to caspase- <dig> activation are critical in regulating the delay time to death was arrived at by our computational sensitivity analysis, but, importantly, it is supported by experimental evidence: the reactions involved in caspase- <dig> substrate cleavage strongly influence tdelay  <cit> .

once the ranking of parameters has been determined, the next question is how many parameters to target during a calibration to accurately capture network behavior. while there are no general and definitive criteria, it should be noted that estimation of too many parameters increases the number of degrees of freedom and the probability that inadequate local optima are detected. on the other hand, choosing too few parameters decreases fitting performance as well as the reliability of the optimal solution. to address this trade-off, we used the ranked parameters to determine the optimal cut-off for the calibration of the model of trail-induced cell death. in figure 4b, the  <dig> parameters on the x-axis were ordered by their ranking number . we observed that the sensitivities dropped off sharply after a few steps - ranked sensitivities generated l-shaped curves. the three different sensitivity algorithms have a common property that the parameter of 8th highest sensitivity was approximately at the border between horizontal and vertical lines. this analysis suggested that for this particular model, the eight most sensitive parameters can cover much of the variation in parp cleavage, and should be sufficient to include in model calibration.

parameter estimation by global optimization
most models of biological processes are non-linear and thus model parameter estimations are complex problems that can have multiple solutions. to avoid potentially poor decisions made by identification of local optima, it is essential to develop a search for the global solution. global optimization methods are roughly categorized into deterministic and stochastic approaches. a conceptual illustration of these two approaches is given in figure  <dig>  here, the 2-dimensional parameter space of two rate constants  was explored. as the contour of the objective function showed, there exists a valley-shaped optimum in the lower part of parameter space. it is interesting that this characteristic contour of the objective function is relevant to the discussion of dominant parameters in sensitivity analyses. the parameter k <dig> was ranked as one of the eight most influential by only one type of sensitivity analysis , while k <dig> is ranked by all three sensitivities . so it is expected that perturbations of k <dig> affect the model output more strongly than changes in k <dig> do. the valley-shaped contour of objective function in k <dig> vs. k <dig> parameter space indeed supports this idea, because the slope in much steeper in the k <dig> than in the k <dig> axis.

among the various approaches for global parameter estimation, the simplest one is the deterministic multi-start method where a large number of local estimations start from different initial parameter combinations ; red circles). the logarithmic space of parameters is divided uniformly in a grid and deterministic local estimation starts from every grid point, comparing the fit of nearby points. because the entire parameter space is explored, the guarantee for finding the global optimum is high, as long as the grid samples the space sufficiently well. in figure  <dig>  parameter sets starting from initial grid points converge to the points aligned along the valley after local estimations have terminated. however the computational load increases exponentially with the number of parameters, as dimensions are added to the sampling grid. to overcome this difficulty, random sampling in a latin hypercube of parameter space <cit>  or parallel computing with cluster processors could be utilized.

stochastic methods on the other hand, can find the global solution with relatively less computational effort. these methods start with parameter values that are randomly sampled in parameter space, and, according to a set of rules, explore new solutions in the neighborhood of the initial point looking for a better solution and repeat until no further improvement of fit is found. genetic algorithms and simulated annealing are well known examples of stochastic methods <cit> . in a comparative study of various optimization methods, stochastic ranking evolutionary strategy  showed the best performance  <cit> . in sres, a "population" composed of randomly selected "elements", or sets of parameter values, is generated. the elements are ranked by their fit to the data using a bubble-sort procedure <cit> . only highly ranked elements are retained as ancestors for the next generation, which are used to probabilistically produce a new population of random elements with a better fit, on average. the source code of sres is available in the public domain <cit> .

for the model of trail-induced cell death, we compared the performances of the deterministic multi-start method and sres in a global optimization of the eight most dominant parameters identified by average of local sensitivities. for the multi-start method, local estimations started from the lower bound, middle value and upper bound in the range of each parameter so that the total number of cases was  <dig> . out of  <dig> local estimations,  <dig> cases successfully detected their adjacent optimum solutions, although  <dig> cases failed due to their poor initial guess values. in figure  <dig>  the results of all the local estimations were sorted according to the magnitude of their objective function ; every point in the curve indicates individual local optimum; the best fit had an objective function of  <dig> . the optimal parameter values are listed in additional file  <dig>  and fits to data are shown for a local optimum and a global optimum case  and  <dig>  respectively).

it is not surprising that many local minima were detected using a multi-start method because nonlinear and complex models like cell signaling networks usually exhibits objective function surfaces with multiple local optima. the plateaus near the global optimum and around the objective function values of  <dig> and  <dig> in figure  <dig> could be due to: 1) a wide well on the hypothetical surface of parameter space so that estimations from many nearby starting points converge to a single minimal solution, allowing us to easily arrive at the optimal solution or 2) a valley-shaped local optima on the surface of objective function. because a wide well on the surface of parameter space is rare in network models, the most likely causes of the plateaus were valley-shaped optima. along a valley, solutions may be distinct if they are located far apart from one another, but nevertheless fit the model in similarly well. ideally, when constructing predictive models, this situation should be avoided by reducing valleys to more focused wells on the surface of parameter space by adding constraints to the optimization problem.

despite its ability to find good fits to the data, the multi-start method had the critical drawback of having a heavy computational load . as an alternative, optimization was significantly accelerated by using sres . for sres, the initial population of parameter value combinations, or "elements", was generated by random selection from a uniform distribution over the 8-dimensional parameter space with the boundaries described in methods. the population was composed of  <dig> individuals and, for each round,  <dig> individuals with best fits were defined as parents for the next generation. to decide when to terminate the optimization, we posed as a requirement a minimum of a double-digit decline in the objective function value from the first generation, and the estimation was stopped at the 33rd generation, after ~ <dig> h of computation time. using this fast method, we compared the fits obtained by including each of the three sets of dominant parameters obtained by the different sensitivity analysis methods. we found that the set of parameters identified by the average of local sensitivities was the best, although none of the fits obtained were as good as that obtained with the deterministic multi-start method . if, in the case of the parameters identified with the average of local sensitivities, we allowed the evolution to proceed further, the fit did improve very slowly while the cpu usage time increased significantly . to obtain a goodness-of-fit equivalent to that achieved with the deterministic multi-start method, we implemented a previously described hybrid method <cit> . using this method, the optimization was carried out in two sequential phases: first, a local solution in the vicinity of the global optimum was rapidly reached by the sres method and, second, the solution was refined by a fast local estimation method until a pre-defined tolerance was satisfied . as table  <dig> shows, this hybrid method could fit the model in much less computation time than the deterministic multi-start method, with an objective function as good as that obtained with the laborious multi-start method. generally, the choice of optimization methods is dependent on not only model type but also on resource availability or approximation tolerance. each method may have different performance for different models. with respect to the model in this study, the combination of sres and local estimation performed the most efficient survey of the parameter space in a global optimization results. this efficiency was due to its combination of rapid stochastic surveying of the whole space and deterministic searching within local regions.

† sres, evolutionary strategy using stochastic ranking;‡ g, generation number of evolution.

influence of dominant parameter choice on optimization
to validate our choice of eight dominant parameters to estimate, we examined goodness-of-fit and computational cost while varying the number of parameters to be estimated for two deterministic optimization methods, where the number of parameters optimized has the greatest impact on computation time. in figure  <dig>  we show cpu time for the multi-start search and optimal objective function values as a function of the number of parameters estimated, for both the local search and the multi-start search. the fit to the data at the global optimum solution detected by multi-start search improved with increasing number of parameters, reaching a plateau at eight parameters, while computational cost increased exponentially. importantly, the performance of the local search deteriorated significantly when the number of parameters increased. this is because when the local search starts from a poor initial guess, the chance of arriving at local optimum solutions with poor fitting performance increases, and with a larger parameter space to sample, the local search is more likely to start from a poor initial guess. this result shows how important it is to apply a global, or hybrid, optimization algorithm to obtain the best fits , or to adequately limit the search space when using a local search. overall, the good performance  and affordable computational cost lead us to conclude that choosing the eight parameters identified as dominant in global sensitivity analysis for quantitative model fitting was indeed an appropriate compromise. fitting more than eight parameters for the trail model optimization would yield only little improvement in fit, at much greater computational cost. the number of dominant parameters in a particular model would certainly be dependent on its size and complexity, but the sensitivity analysis-based method described above allows their identification.

finally, figure  <dig> shows how much the model improved using our method relative to the manual calibration used in the original study  <cit> . it is noteworthy that adjustment of a few important parameters could substantially improve agreement between model output and experimental data. the procedure to identify those important parameters and estimate them is straightforward by systematic methodology compared to manual calibration which is inevitably labor-intensive and time-consuming with less guarantee of successful model fitting.

CONCLUSIONS
in this report, we proposed a framework for efficiently calibrating computational models of biological systems, and applied it to a model of trail-induced apoptosis while comparing several sensitivity analysis methods and model optimization algorithms. importantly, we showed how sensitivity analysis can be used to rapidly test whether the model structure adequately allows qualitative matching to the behavior of the biological system. this step implements a minimal qualification, focusing the initial search on the qualitative performance of the proto-model. within our framework, this validation step is required before proceeding to quantitative optimization of the model, ensuring that computationally costly optimization algorithms are used effectively. furthermore, we showed how global sensitivity analysis methods can be used to identify the parameters that dominantly regulate the dynamics of the output of interest. with the application of sobol's algorithms, we were also able to identify parameters that control the trail-induced delay time to cell death , a biologically relevant quantity that is not a state variable of the model. undoubtedly, this type of sensitivity analysis will prove useful within our outlined framework for other models as well, for example in models of oscillatory systems where, in certain cases, the period of the oscillations is more meaningful than their amplitude. finally, while comparing different model calibration algorithms, we showed that global sensitivity analysis could successfully identify the parameters to include in quantitative optimization, allowing great computational savings by constraining the search to the important model dimensions. in the future, we foresee that the predictive quality of models would be further improved by repeating this cycle of model validation, identification of dominant parameters and optimization with different model outputs that are controlled by other parameters, allowing the determination of more and more parameter values.

