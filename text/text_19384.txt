BACKGROUND
the antiparallel double helical structure of dna and its self-recognition form the basis for the conservation and the transfer of genetic information. the model of the “canonical”b-dna form proposed by watson and crick  <cit>  has later been enriched by detailed structural data from single-crystal structures of the biologically prevailing b-form  <cit>  and of its kin right-handed a-form  <cit> . in addition, the first dna single crystal  <cit>  revealed atomic details of a third major form of a dna double helix, left-handed z-dna. the atomic resolution structures of b-dna duplexes  <cit>  revealed the existence of sequence-dependent structural deviations which provide the required specificity for dna recognition by proteins and drugs  <cit> . the association of dna with proteins is known to induce a local deformation of the b-form toward the a-form  <cit>  in various protein-dna complexes such as, e.g. high mobility group  proteins  <cit> , trp repressor/operator complex  <cit> , tata box binding protein  <cit> , hiv- <dig> reverse transcriptase  <cit> , various dna polymerases  <cit> , zinc finger protein  <cit> , hyperthermophile sac7d protein  <cit> , and ecorv endonuclease  <cit> . along the transition pathway between the b- and a-forms  <cit>  various intermediate b-to-a conformations were identified  <cit> . the importance of conformational sub-states of the dna backbone for protein binding to the minor groove was suggested by several analyses  <cit> . besides the a-, b- and z-forms, dna can also adopt other biologically relevant structures, such as single-stranded hairpins  <cit> , triple helices  <cit> , three- and four-way junctions  <cit> , four-stranded g-quadruplexes  <cit>  or parallel helices  <cit> . their existence indicates that dna structure is much more polymorphic than it might be deduced from the misleading simplicity of the canonical b-dna duplex.

the base morphology in a dna double helix is commonly described  <cit>  by parameters giving mutual position between bases in a base-pair  and in a base-step   <cit> . the same parameters can also be used for other unusual dna structures such as triple helices  <cit> , g-quadruplexes  <cit>  or three- and four-way junctions  <cit> . in addition, for the last two groups of structures additional specific parameters such as the g-quartet planarity  <cit>  or the angle between the junction arms  <cit>  were also defined. another set of quantitative measures that can be used to characterize secondary structure of dna are backbone torsional angles α, β, γ, δ, ϵ, ζ together with the glycosidic torsion χ <cit> . though the relationship between the phosphodiester backbone states and local distortions of dna double helix was described in the ' <dig> and '90s  <cit> , the backbone was regarded as a passive link holding bases at their positions in several early analyses  <cit> . however, nowadays it is clear that the backbone must be considered as an active dynamic element while defining the conformational properties of double-helical dna  <cit> . the main role of the backbone is in restricting the conformational space available for the placement of bases, and in steric coupling of the adjacent base steps  <cit> . an overall conformational flexibility of dna thus results from the interplay between the optimal base positions and the preferred conformations of the sugar-phosphate backbone. an increasing number and quality of dna structures led to several detailed analyses of the conformational space of the dna backbone, most of these studies have been based on crystal structures  <cit>  but structures determined by various solution-based techniques of nmr spectroscopy have also contributed significantly to our understanding of biology of nucleic acids  <cit> . nmr methods were successfully applied to study a dynamics of dna phosphodiester backbone in solution  <cit> , nmr studies also provide evidence for the bii states in solution and help to unravel a role of the phosphorus atom in a bi-bii transition  <cit> .

to uncover a potential role of the sugar-phosphate backbone in the dna structural polymorphism we have analyzed a set of carefully selected double-helical structures of naked and protein bound dna resolved at high resolution   <cit> . we have identified all the known major conformers  as well as several minor conformations corresponding to various transitional states between the b and a forms. the investigation was based on the technique of fourier averaging in combination with a cluster analysis applied previously on the annotation of rna conformers  <cit> . the main disadvantage of the fourier averaging approach is that it requires a considerable amount of manual work  <cit> . to automate this process we introduce here a machine learning workflow that deals with two following tasks:

 <dig>  classify data points into one of the existing classes.

 <dig>  recognize data points that cannot be classified and identify new possible conformational classes.

the first task is accomplished by the application of the supervised machine learning approaches. in supervised algorithms a classification function is inferred from the labeled training data . as a training set we used previously published classification of dna local conformers  <cit> . in the present study we applied and compared several supervised methods: multi-layer perceptron  neural network, radial basis function  neural network, k nearest neighbors , and ridge regression . the best method  not only achieves high classification accuracy, but also allows identifying conformers that cannot be assigned to any of the known classes. such conformers were subsequently investigated for the presence of new clusters using a modified clustering method based on a leader algorithm <cit> . the proposed classification workflow  was applied on the analysis of x-ray data updated by structures released after  <dig> july  <dig>  and of nmr data released until  <dig> february  <dig> 

methods
data sets
for the development of the machine learning workflow we used a previousy published data set  <cit>  consisting of  <dig>  dinucleotides collected from  <dig> high quality crystal structures with a resolution of  <dig>  Å or better and from  <dig> structures with unusual topologies . these structures were released into the nucleic acid database  <cit>  before  <dig> july  <dig>  in this data set we originally identified  <dig> conformational families. to reduce their number for the classification purposes, we critically evaluated the data for the presence of outliers and for the size and quality of the clusters.  <dig> outliers were removed, and the number of conformationally distinct families was condensed into  <dig> classes  resulting in a data set consisting of  <dig>  data points. these data were split into  <dig>  dinucleotide units  classified previously by the fourier clustering, and into  <dig>  dinucleotides that were not assigned to any class in our previous work  <cit> . a stratified sampling was used to divide the datasetf into the training  and test  sets in the ratio 80: <dig>  datasetf_train was used for classifier’s learning, and the datasetf_test was used for assessing its performance. training set contains  <dig>  data points, and test set contains  <dig> data points. in a stratified division each of the classes is sampled with the ratio present in the total population. for example, class number  <dig>  covers  <dig> % of the total population, and is present in this proportion also in datasetf_train and in datasetf_test.

“class id” is the symbolic label of the class. “description ”is a short annotation of the class. “n” is the number of suites  with the given class membership. values of torsions represent the arithmetic means for individual classes. torsions are defined in figure  <dig> 

our machine learning classification workflow was then applied to  <dig> x-ray structures, resolved with a crystallographic resolution of  <dig>  Å or better, and released between  <dig> july  <dig> and  <dig> february  <dig>  which contained  <dig>  dinucleotides, and to  <dig> nmr structures released before  <dig> february  <dig>  which contained  <dig>  dinucleotides.

for our analysis a concept of a “suite”  <cit>  was adopted. “suite” is a conformational subset of a dinucleotide unit  going from sugar to sugar and consisting of  <dig> backbone torsions . the analysis also includes two glycosidic angles χ and χ +  <dig>  each data point is therefore represented by a vector composed of  <dig> torsion angles. in the following text we also use the convention  <cit>  by which it is common to describe the backbone torsional angles of ~ 60° as gauche+ , of ~ 300° as gauche- , and of ~ 180° as trans . for glycosidic torsion χ following regions are commonly used: syn , anti , and low anti .

data preprocessing
the input data  were used either directly  or they were normalized using one of the following methods:

 <dig>  in a geometric preprocessing each torsion was transformed from the space of dihedral angle θ ∈ {δ, ϵ, ζ, α +  <dig>  β +  <dig>  γ +  <dig>  δ +  <dig>  χ, χ + 1} to the linear metric coordinate space built up by the series of trigonometric functions {sin nθ, cos nθ} with the geometric order parameter n =  <dig>  …, d. this preprocessing method accounts for the circular character of angular data  <cit> , however it increases the length of the input vector from  <dig> to 2d ×  <dig>  this preprocessing was used in rr, mlp and rbf methods.

 <dig>  in a linear preprocessing each angle was converted into the 〈 −  <dig>  1〉 range. this conversion increases the performance in the matlab environment that was used for all neural networks simulations. this preprocessing was used in mlp and rbf methods.

depending on the classification method, the output data  were encoded in two different ways:

 <dig>  the original class numbering  was used in k-nn.

 <dig>  classes were renumbered to the interval 1- <dig>  and the class membership was then encoded as a binary vector of the length  <dig>  this encoding was used in rr, mlp and rbf methods.

training and cross-validation
each classifier is characterized by one or more parameters that are tuned to capture the underlying relationships in the training data set, and that influence the ability of an algorithm to perform accurately on new, previously unseen examples . the combination of one particular method  with particular values of parameters  is designated as a model. the most appropriate values of the parameters were chosen using a well established method of k-fold cross-validation. in k-fold cross-validation, a training set is divided into k parts. a classifier is trained k-times, each time leaving out one of the subsets , which is used to assess the classifier’s performance. at the end, the final validation error is obtained as the average of all errors from k individual validation runs. in the present work a 10-fold cross-validation was adopted using the stratified division of the datasetf_train. the quality of the trained model was evaluated by the mean squared error of validation msevalidation.

  msevalidation=n1Σi=1npi−ti <dig> 

where pi is the predicted class membership and ti is the known class membership. to smooth out possible biases caused by an unfavourable random data set division, the 10-fold cross-validation was repeated  <dig> times, and the final msevalidation was obtained as an average of validation errors from all individual runs. a model with the lowest msevalidation represents the “best” model. once it was identified the final model was trained using the whole datasetf_train. the quality of individual classifiers was compared using the msetest calculated for the datasetf_test.

classifiers
a multi-layer perceptron 
mlp represents the most common architecture of neural networks. it consists of simple processing units  arranged into three or more layers: one input layer, one or more hidden layers, and one output layer. every neuron in one layer is connected to every neuron in the following layer, and no intra-layer connections exist. the strength of neuron connections is represented by numerical weight values. the weights are free variables of the system which are determined during the training phase. neurons transform a numerical input to an output value via the transfer function. in the present work, a two-layer perceptron consisting of one input, one hidden and one output layer was used. several transfer functions were tested: linear, log-sigmoid and tan-sigmoid. log-sigmoid function is given as

  logsigu=11+e−u 

and tan-sigmoid function is given as

  tansigu=e2u−1e2u+ <dig> 

where a potential μ of a neuron is given as u=∑iwixi−ϑ, x¯=x <dig> …,xi is the input vector, w¯=w <dig> …,wi is the weight vector, and ϑ is the neuron’s bias . as the neuron’s input goes from negative to positive infinity, the log-sigmoid function generates outputs between  <dig> and  <dig>  and the tan-sigmoid function generates outputs between - <dig> and  <dig> 

radial basis function network 
rbf is also a two-layer neural network. the input layer serves only as a mediator in passing a signal to the hidden layer. while mlp is based on units which compute a non-linear function of the scalar product of the input vector and a weight vector, in rbf the activation of a hidden unit is determined by the distance between the input vector and a prototype vector. each hidden neuron modulates the input signal by the gaussian transfer function called radial basis function . each rbf is characterized by two parameters: by its center  representing the prototype vector, and by its radius . the centers and spreads are determined by the training process. when presented with the input vector x¯, the euclidean distance of the input from the neuron’s center is computed by the hidden neuron, and the rbf kernel function is applied to this distance. the output from the network is constructed as a weighted sum of the rbf’s outputs. the weights are also determined in the training phase. while mlp separate the classes by using hidden neurons which form hyperplanes in the input space yielding a global approximation, rbf networks model the separate class distributions by local radial basis functions.

k-nearest neighbor 
in k-nn method objects are classified based on the class of their nearest neighbors. a new point is assigned to the majority class among the k nearest points. k-nn is a lazy algorithm meaning that there is no explicit training phase, it makes no generalization , and the decision is based on the entire training data set which must be available during the prediction phase. euclidean distance is used as a measure of the proximity of two data points. to get the euclidean distance between two torsion angle vectors the similarity vector s¯ must be calculated first. its elements si are distances between individual components of compared vectors. to correctly calculate the similarity vector s¯ the circularity of the angular data must be taken into account. the distance si between two angles ϕ and ψ is given as  <cit> 

  si=180−|180−|ϕ−ψ|| 

where both ϕ and ψ angles are given in degrees. the euclidean distance d is calculated as

  d=∑isi <dig> 

in k-nn approach, the number of nearest neighbors k represents the only adjustable parameter of the method. the class membership of k nearest neighbors was used to assign the class of the classified point. to take into account a fact that near neighbors influence the resulting class membership more than the distant ones contributions of the neighbors were weighted by 1/d <dig>  the point was assigned to the class with the highest sum of weighted contributions. however, if this sum was less than a threshold vcrit =  <dig> , the data point was declared as unclassified. the value of vcrit was obtained empirically and, based on our experience, optimally balances the accuracy of the method and the number of unassigned points in the dataset.

regularized regression 
rr  <cit>  is a standard statistical method of linear modeling and parameter identification. in rr pattern set is represented as a pair , where x is an input matrix of the size m × n, y* is an output matrix of a size m × n, m is the number patterns, n is the number of inputs and n is the number of outputs. ridge regression penalizes the size of the regression coefficients by the penalty calculated as a weight matrix w = -1xty* where λ ≥  <dig> is a regularization parameter and i is an n × n identity matrix. if the matrix y* represents the class membership, the rr response is calculated as y = xw and the ith pattern is assigned to the jth class for which the yi,j element is maximal. main advantages of rr are fast learning procedure and ability to solve ill-posed problems with a high number of possibly dependent explanatory variables. the disadvantage of rr is the linearity of the underlying model. however, the linearity limitation can be suppressed by an appropriate nonlinear preprocessing of the data.

comparing classifiers
the quality of classification models is assessed by various measures based on the counts of correctly and incorrectly predicted test data  <cit> . such information can be tabulated as a confusion matrix. each row of the matrix represents the instances in the actual class, and each column represents the instances in the predicted class. to compare the performance of various classification models this matrix is usually boiled down to the single number. in the present work two such performance metrics – accuracy and κ coefficient – were utilized. accuracy is defined as a percentage of correctly classified data points, i.e. the main diagonal in the confusion matrix is summed  and the sum is divided by the total number of observations n:

  accuracy=tpn• <dig> 

the disadvantage of the accuracy is that it does not reveal if an error is evenly distributed between classes or if some classes are really bad and some really good. to include this information the κ coefficient  <cit>  takes into account also the off-diagonal elements

  κ=n×∑i=1nxii−∑i=1nxi+×x+in2−∑i=1nxi+×x+i 

where n is the number of rows in the confusion matrix, xii is the number of observations in row i and column i, xi+ and x+i are the marginal totals of row i and column i, respectively, and n is the total number of observations. κ coefficient measures the improvement of classifier’s predictions over a purely random assignment to classes.

cluster analysis
the main objective of clustering is to find a grouping of similar objects within a data  <cit> . the objects are not labeled, and cluster analysis belongs between unsupervised methods. in the present work we used a nonhierarchical single-pass method that works on the basis of a single scan of the data set. the most common single-pass algorithm is called the leader algorithm <cit>  which is simple to implement and very fast. however, its major drawback is that it is order dependent meaning that if the compounds are rearranged in a different order then the resulting clusters can be different  <cit> . therefore we developed a modified leader algorithm which retains high speed, and is order independent. the used algorithm consists of the following steps to provide a set of clusters:

 <dig>  set the number of existing clusters to zero.

 <dig>  for each data point  di

•start new cluster ci

•calculate a neighborhood of di

•go through all data points except di. data points belonging to the neighborhood of di are appended to the cluster ci

 <dig>  remove duplicated clusters getting a set of unique clusters .

 <dig>  repeat until the unique set is empty

•identify the biggest cluster bi in the unique set

•if the size of bi is higher than predefined threshold append bi to the final set of clusters

•identify all clusters that overlap with bi

•remove bi and all overlapping clusters from the unique set

in point  <dig>  a dinucleotide belongs to the neighborhood of di if its torsion deviates from di by no more than 20° for α, ϵ, ζ, and χ, 30° for β, 15° for γ, and 10° for δ. these intervals were selected on the empirical basis reflecting common conformational variability  of the individual torsion angles. a cluster is defined by at least six points in the presented study, which gives a value of a threshold in point  <dig> 

RESULTS
optimal parameters of the classification methods
in mlp, we determined the input preprocessing method, the number of hidden neurons and the type of transfer function by the 10-fold cross-validation. the number of hidden neurons varied between  <dig> and  <dig> with the step of  <dig>  we performed the cross-validation with every possible combination of linear, log-sigmoid and tan-sigmoid transfer functions using either linear or geometric preprocessing. the order parameter n of the geometric preprocessing was cross-validated, its values varied from  <dig> to  <dig> by one. the optimal mlp model uses the geometric preprocessing with n =  <dig> , has  <dig> neurons in a hidden layer, and uses log-sigmoid  transfer function at hidden neurons and tan-sigmoid  transfer function at output neurons.

in rbf, the input preprocessing method, the number of hidden neurons and the optimum spread of the gaussians on hidden neurons were recognized using the 10-fold cross-validation. the order parameter n of the geometric preprocessing varied from  <dig> to  <dig> by one, the spread varied in the interval of  <dig>  and  <dig>  with the step of  <dig> , and the number of hidden neurons varied by one between  <dig> and  <dig>  the optimal rbf utilizes a geometric preprocessing with n =  <dig> and has  <dig> hidden neurons with the spread of  <dig> .

in k-nn, the number of nearest neighbours k was varied between  <dig> and  <dig>  its optimum value found by 10-fold cross-validation is equal to  <dig> 

in rr, 10-fold cross-validation was used to set the order k of the geometric preprocessing and the regularization parameter λ. the order k was varied between  <dig> and  <dig> by one, and the regularization parameter λ was set either to  <dig> or it was altered by factors of  <dig> from 10- <dig> to 10- <dig>  the optimum order of the geometric preprocessing is  <dig> which leads to the increase of the length of the input vector from  <dig> to 2×6× <dig> =  <dig>  the optimum regularization parameter λ is zero. with this regularization parameter the ridge regression is equivalent to the standard linear regression.

performance of the classification methods
the accuracy of individual classification methods is summarized in the table  <dig> and the confusion matrices showing the class predictions given by individual classifiers are available in the additional file  <dig> 

these were evaluated using test set . the mlp model uses geometric preprocessing with the order k =  <dig>  has  <dig> hidden neurons with the log-sigmoid transfer function and output neurons use the tan-sigmoid transfer function. the best rbf model uses geometric preprocessing with the order k =  <dig>  has  <dig> hidden neurons with the spread of  <dig> . the optimal value of k in k-nn is  <dig>  in rr, the optimal regularization parameter λ is zero, and the order of the geometric preprocessing expansion k is  <dig> 

the best performing classifier both in terms of accuracy and κ coefficient is the multi-layer perceptron mlp followed by the k-nearest neighbors k-nn and by the ridge regression rr. mlp and k-nn are both non-linear classifiers, while rr represents a linear method. the penalization of the coefficients in the ridge regression is not necessary , and the ridge regression is therefore reduced to the standard linear regression. however, rr performs similarly to nonlinear methods due to the sophisticated preprocessing method motivated by the geometrical nature of the input angular data. a careful inspection of the confusion matrices  reveals that the decrease in accuracy is caused mainly by misassignment between two pairs of classes: points belonging to the class  <dig>  can be assigned to the class  <dig> , and points belonging to the class  <dig>  can be assigned to the class  <dig>  classes  <dig> and  <dig> are distinguished mainly by a slight difference in the sugar pucker at both deoxyriboses , the conformational transition between these classes is continuous and a limited blending of the conformers can be expected. similar behavior show also classes  <dig> and  <dig> as they differ primarily in the δ +  <dig> torsion, the difference is 24° .

a poor performance of rbf comes as a surprise. reason for this behavior can be that the classification boundary in rbf is constructed in a local manner, while mlp and rr are global methods and in k-nn the classification boundary is not constructed explicitly. however, an rbf confusion matrix  reveals that the decrease in accuracy is also caused by misassignments between classes  <dig> and  <dig>  and between classes  <dig> and  <dig> . as explained above, certain extent of the mixing of these conformers can be expected, and we can thus conclude that a lower accuracy of the rbf network is only seeming and rbf performs similarly as the other investigated methods.

of the studied methods, k-nn offers one important advantage: it allows to discriminate between conformations that can be assigned to one of the pre-defined classes and between the conformations for which such a class does not exist. from this reason we propose k-nn as a method of choice for the classification of local conformations in nucleic acids.

analysis of the newly characterized conformers
x-ray structures
we analyzed  <dig>  dinucleotides unassigned to any class in our previous work  <cit> , and  <dig>  dinucleotides from  <dig> x-ray structures released between  <dig> july  <dig> and  <dig> february  <dig>  utilizing the k-nn approach  we assigned  <dig>   dinucleotides to one of  <dig> possible  classes. applying a clustering procedure on remaining  <dig> unassigned dinucleotides representing results of incorrect refinement of the crystallographic model or yet unidentified clusters we identified  <dig> new conformational classes . a data set containing all x-ray structures analyzed in the present work can be found in additional file  <dig> 

“class id” is a symbolic label of the class. “description” is a short annotation of the class. “n” is the number of suites  with the given class membership. values of torsions represent the arithmetic means for the individual classes. torsions are defined in figure  <dig> 

four of six new conformers can be found exclusively in two functionally distinct types of non-double helical structures. conformer  <dig> occurs in four-way  junctions, and conformers  <dig>   <dig>  and  <dig> are found in guanine quadruplexes of the oxytricha nova telomere. other two conformers  are found in various dna-protein complexes. a detailed description of new conformations is given in the following paragraphs.

conformations  <dig>   <dig> and 114
these conformations are found exclusively in guanine quadruplexes  of the o. nova telomere. g-quadruplexes represent biologically very interesting non-canonical dna structures  <cit> . g-rich sequences, in which g-quadruplexes often appear, are abundant in the genome, and are found e.g. in telomeric regions  <cit> , immonugloboluline switch regions  <cit>  or gene promoter regions  <cit> . g-quadruplex of o. nova telomere is a well-studied  <cit>  example of bimolecular, antiparallel quadruplex with the sequence d <dig>  a core structural element of g-quadruplexes are planar g-quartets  that stack on top of each other. they are connected by loops of variable length and composition whose variations lead to a wide variety of topologies of g-quadruplexes.

in our previous work  <cit>  we were able to match several dinucleotides in o. nova g-quadruplex with distinct types of conformers and new conformers  <dig>   <dig>  and  <dig> identified in the present work further enhance this structural annotation ,  and ). class  <dig> is a highly distorted bi-like conformation with ϵ/ζ in t/g+, α+1/γ+ <dig> switched into g+/t values and χ+ <dig> in the syn region . conformer  <dig> represents a bi-like conformation with anti/syn arrangement of χ and χ+ <dig> torsions, high β , and unusual g-  value for γ+ <dig> torsion. conformation  <dig> represents a bii conformation with α+1/γ+ <dig> switched into t/g+ values, and with χ+ <dig> in low anti region .

by analyzing crystal  and nmr  structures we were able to construct a consensus conformational map  and ) showing the succession of conformers in the o. nova g-quadruplex. from the studied pool of structures, four  represent a complex of the g-quadruplex with a drug acridine, while the rest are not complexed. acridine binds to the quadruplex within its t <dig> loop in chain a  <cit>  influencing a conformation of the whole t <dig> loop. thus, we have considered naked and acridine-complexed structures separately in our analysis.

the consensus conformational map of the naked g-quadruplex is shown in figure  <dig>  and that of the complex with the acridine in figure  <dig>  common to both are conformations present in the chain b, and in the g-tracts of the chain a. o. nova g-tracts exhibit a well-known 5′-syn-anti-syn-3′ pattern  <cit>  of guanine glycosidic torsion angles manifested by alternating conformations 119–122– <dig> in the g1g2g3g <dig> sequence, and conformations 119–114– <dig> in the g9g10g11g <dig> sequence. the t <dig> loop in acridine complexes shows much higher conformational variability than in uncomplexed structures. this variability is manifested by the presence of unusual conformations labeled qa, qb, qc, and qd that are not homogenous enough to form distinct clusters but they do share several common structural characteristics. conformation qa is typical by a glycosidic angle in the low anti  region, β+ <dig> torsion in t  and α+1/γ+ <dig> in t/g+ combination. conformer qb is similar to the cluster  <dig>  but with a second sugar moiety in the canonical bi c2′-endo conformation. a common feature of the qc conformer is a presence of α+1/γ+ <dig> torsions switched into the g+/g+ values. qd conformation can be, based on δ and δ+ <dig> values, labeled as bi-like with α+1/γ+ <dig> switched to the g-/t values, β in g+, and with χ +  <dig> in the syn region.

described conformational assignment demonstrates that o. nova g-quadruplexes are conformationally homogenous structures that could be decomposed into the clustered conformers some of which are unique to these structures . the complexation with the acridine molecule results in a higher conformational variability of the t <dig> loop compared to the g-tracts.

conformation 115
this class describes a conformation found exclusively in holliday  junctions. it was noticed previously  <cit>  as potentially existing, but only the larger data set including the recent data lead to its identification. it can be characterized as a bi-like conformer with unusually high ϵ  and a-like χ+ <dig> . this conformation is found in the sharp bend of the dna strand between residues number  <dig> and number  <dig> .

conformation 117
this class represents a bi-like conformation with both δ and δ+ <dig> torsions in the c2′-endo region but its torsions α+ <dig>  β+ <dig> and γ+ <dig> acquire values  not typical for the bi conformer  <dig>  in addition, glycosidic torsion χ+ <dig> of the second residue is in a-like low anti region near 210°. this conformation was almost exclusively observed in protein/dna complexes, about a half of them in complexes of nucleosome-core particle. the dna bending induced by interactions between dna and histone octamer has been explained  <cit>  by the periodic alteration of bi and bii conformers with occasional insertion of conformation  <dig> . the new conformation  <dig> is its rarer kin found only in some nucleosome structures located outside the protein/dna interface.

conformation 35
class  <dig> can be characterized as a transitional bi-to-a conformation with the first residue in bi and the second residue resembling an a-form whose character is disturbed by unusual values of β+ <dig> , α+ <dig> , and γ+ <dig> torsions . this conformation occurs in diverse protein/dna complexes, about a half in dna complexed with polymerases. dinucleotides in this conformation are in direct contact with protein atoms via the phosphate charged oxygen.

nmr structures
we clustered a set of  <dig>  dinucleotides from  <dig> nmr structures released before  <dig> february  <dig>  utilizing k-nn procedure with k =  <dig> and vcrit =  <dig> . we assigned  <dig>  dinucleotides , and subsequently applied a new round of clustering to the remaining  <dig> points. however, clustering did not reveal any new conformation that would be present in nmr and not in x-ray data.

across-the-database assignment of dinucleotide conformers for  <dig> x-ray and  <dig> nmr dna structures exhibit similar general features . the bi conformer  <dig> is dominant in both data sets, and the bi conformer  <dig>  the bii conformers  <dig> and  <dig>  and several a-dna conformers  are also significantly populated. similar qualitative features of the assignment of the local dna backbone conformers demonstrate that dna in solution and in the crystal phase, which is highly hydrated, show similar behavior. however similar the overall features are, both populations also exhibit significant differences. perhaps the most noticeable is the difference of the overall bi population  that forms 65% in nmr, and only 47% in crystal structures. the bi conformers are more populated in nmr than in crystal structures, striking is especially a large population of the conformer  <dig> in nmr . also the fractions of some other conformers differ significantly. nmr structures have more populated the mixed b-a conformer  <dig>  and crystal structures the canonical a-form  <dig>  the mixed a-b form  <dig>  and the bii conformers  <dig> and  <dig>  nmr structures have a slightly larger proportion of unassigned dinucleotides than crystal structures, 8% versus  <dig> %.

reason for the above-mentioned differences between nmr and crystal structures is not obvious, and we propose just a few possible explanations. protein/dna complexes form 65% of structures resolved by x-ray crystallography, but this fraction is only 17% in nmr. the higher number of protein/dna complexes resolved by x-ray crystallography could perhaps explain a larger number of the a-form in crystal than in nmr structures as the a-form is often induced by interactions with proteins. a larger population of bi and a smaller population of bii in nmr structures cannot be explained so easily. either of these forms has only limited sequence preferences, and there seem to be no obvious rationale supporting a hypothesis that crystal packing favors the bii over the bi conformation. a different hypothetical explanation could lie in the process of interpretation of the nmr experimental data. their relative scarcity caused by the low density of protons, and sometimes equivocal interpretation of experiments such as indirect spin−spin couplings  may cause uncertainties especially in the assignment of torsions α and ζ of the phosphodiester linkage  <cit> . the resulting dna structure may then be influenced by the refinement protocol in which the experimental restrains are combined with force fields in a computer simulation. relatively low number of the experimental restraints and imperfection of the force fields, namely their incorrectly set torsion preferences, may perhaps favor bi over bii forms.

CONCLUSIONS
in the present work we investigated several supervised machine-learning approaches , multi-layer perceptron  neural network, radial basis function  neural network, and k nearest neighbors ) to develop a protocol for an automatic classification of local dna conformations. the classifiers were trained and tested using the previously published manually classified set of dinucleotides  <cit> . various parameters of the machine learning methods were set to their optimum values utilizing a 10-fold cross-validation procedure. according to the results of our testing, the best method is k-nearest neighbor. this technique not only achieves high classification accuracy, but also allows identifying conformers that cannot be assigned to any of known classes. we subsequently investigated the unassigned conformers for the presence of new clusters using a modified clustering method based on the leader algorithm <cit> . by the proposed machine learning workflow  we successfully analyzed x-ray and nmr structures of both naked and complexed dna released until  <dig> february  <dig>  in addition to  <dig> conformational classes compiled in  <cit>  we identified  <dig> new classes in x-ray structures, and no additional new classes in nmr data. we assigned four of these conformers to two structurally important dna families: guanine quadruplexes and holliday  junctions. the new clusters enhance structural annotation of o. nova telomeric g-quadruplex  <cit>  and we were able to construct its consensus conformational map  and ). comparison of frequencies of individual conformers found in x-ray and nmr structures showed that they have similar qualitative features so that dna in the crystal phase and in solution populate the same regions of the conformational space. observed differences between populations of x-ray and nmr conformers can be partially assigned to different composition of both datasets, partially to the refinement protocol of nmr structures that may favor bi over the bii form.

competing interests
the authors declare that they have no competing interests.

authors’ contributions
pČ designed and implemented mlp and rbf neural network models, performed tests of all used methods and drafted the manuscript. ds instigated the study, participated in its coordination, implemented the k-nn method, annotated new conformers, and drafted the manuscript. bs was responsible for data selection and data processing, performed the analyses of nmr data, and drafted the manuscript. jk implemented and applied the regularised regression method. jČ participated in data selection, data processing, and implemented additional support scripts. all authors read and approved the final manuscript.

supplementary material
additional file 1
data sets.datasetf contains  <dig>  dinucleotide “suite” units classified previously  <cit>  into  <dig> classes. we used this classification as a “gold standard” in the present work. datasetf was stratifically divided into the training set  and into the test set . sheet “x-ray data” contains all crystallography data, and sheet “nmr data” contains all nmr data analyzed in the current work.

click here for file

 additional file 2
confusion matrices. confusion matrices of the ridge regression , the multi-layer perceptron  neural network, the radial basis function  neural network and the k nearest neighbors . the “true” class  <cit>  is shown in the rows, and the class predicted by the given method is shown in the columns.

click here for file

 acknowledgements
this project has been supported by the research grants msm  <dig>  msm  <dig> and financial support from specific university research . bs and jc are supported by the czech science foundation, grant p305/12/ <dig>  and by the institutional grant av0z <dig> 
