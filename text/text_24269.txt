BACKGROUND
microarrays provide large-scale comparative gene expression profiles between biological samples by simultaneously detecting either expression or differential expression in thousands of genes. the lack of agreement among various technologies putatively measuring the same processes has prompted calls for microarray results to be validated with other technologies before they are published  <cit> . microarray findings are usually validated on a gene-by-gene basis to lend support to biological models. it is not always clear, however, the extent to which the validation of these genes reflects the entire microarray experiment, in part because validation procedures often fall short of optimal sampling and statistical requirements  <cit> . thus, microarray results where only a handful of genes have been validated, with little concern regarding the remainder of the data, are common. moreover, public repositories of microarray experiments contain an ever increasing number of archived studies for which it is not readily possible to evaluate the quality. global validation of microarray experiments is necessary to address these shortcomings. a global validation approach should provide an index of the quality of the fold-change estimates regarding all differentially expressed genes. such an approach would be a valuable tool for investigators to assess the value of their microarray experiments. furthermore, if routinely provided in archived gene expression experiments, global validation information would identify studies most useful for hypothesis generation and would also provide a study confidence index that could be used for several applications including meta-analysis  <cit>  and bayesian network modelling  <cit> . three important aspects of global validation must be considered: what measurement should be validated, how should a subset of differentially expressed genes be chosen for follow-up, and what statistical evidence is needed to confirm validation of the microarray results in total?

it has been proposed that fold-change , rather than raw expression, is the appropriate measure for comparing results across platforms  <cit> . otherwise, various technology-specific artifacts  can compromise direct comparisons between gene expression measurements. at the same time, there is general consensus that whereas fc is a reasonable measure of effect size, it is inadequate as a test-statistic  <cit> .

investigators may select genes for validation based on reagent availability or they may select genes based on ad-hoc or a-priori biological models. one common strategy is to select the largest fcs or the most statistically significant differentially expressed genes, based on the idea that large effects are more likely to be valid  <cit> . such non-random sampling strategies have limited utility as gene selection procedures because validation results do not readily generalize to the entire set of differentially expressed genes. moreover, the "regression toward the mean" statistical artifact  <cit> , whose effects are exacerbated by selecting genes with the largest fcs, may lead to underestimating the global level of agreement between microarray and validation samples. we describe two random sampling strategies which provide data appropriate for global validation.

finally, what statistical evidence is needed to assess global validation? perfect agreement between two sets of fc measurements is indicated by correspondence of the paired data points to the identity line . extent of agreement between this identity line and the data is not captured, however, by the commonly-used pearson r correlation coefficient. for example, high r <dig> values could be obtained between two sets of observations even if the average of one set differed greatly from the other . by contrast, low r <dig> values could be obtained, despite the two sets agreeing quite well on average . a better indicator of validation is provided by the concordance correlation coefficient   <cit> , which combines accuracy and precision coefficients in one index.

the ccc can vary from  <dig>  to - <dig> , with zero representing no agreement. its precision coefficient squared is the pearson r <dig>  which measures how close the data points are to the least-squares regression line; the ccc's accuracy coefficient measures how closely the regression line agrees with the identity line. precision-squared and accuracy can vary from zero  to  <dig> . ccc values can be small because precision is low, accuracy is low, or both.

we present simulated and empirical  data to illustrate deficiencies in selecting only the largest effects for retest and to propose better gene selection methods. we also examine frequently-used statistical metrics for assessing validation and contrast their performance with the ccc index. we show that ccc is a useful predictor of global validation of microarray experiments, and that it can be used as an index of quality for all microarray studies.

RESULTS
performance of sampling strategies using simulated data
the selection of a subset of genes for global validation is critical. to evaluate the effects of sampling, we compared three strategies  by generating  <dig> simulated data sets each containing  <dig> upregulated genes. these  <dig> fcs were simulated to correlate approximately  <dig>  with retest fcs; for each simulation run,  <dig> observations were selected for each sampling strategy . the output from one of the simulation runs is presented in figure 1a. for each simulation run, five measures were calculated for the full  set of  <dig> observations and for each of the three sampling strategies: least-squares regression slopes and y-intercepts, cccs .

boxplots of the statistical indices produced by the  <dig> benchmark values and by the  <dig> values for each of the three sampling strategies across the simulation runs are shown in figures 1c–g . figures 2a–e display the  <dig> benchmark values subtracted from the calculated values for each sampling strategy, reflecting how closely the respective strategies approximate the ideal of validating all genes .

the top-ranked sampling procedure produced inferior estimates of all five statistical indices relative to random and random-stratified sampling. slope and y-intercept values were accurately estimated across all sampling methods, although estimates for top-ranked sampling were highly variable . moreover,  <dig> % of the slopes for the top-ranked samples were negative  compared to  <dig> %  and  <dig> %  .

top-ranked sampling also generated both highly inaccurate  and highly variable estimates of precision, accuracy, and ccc compared to random-stratified and random sampling . moreover, only 32% of the top-ranked precision values were greater than  <dig>   compared to 93% and 87% for the random-stratified and random samples, respectively  .

the extent of the bias in the precision estimates of both random and random-stratified sampling will vary with the true population correlation and with sample size. this bias should be, however, negligible in microarray validation studies. for random sampling, there are formulas which provide approximate corrections for the negative bias, which can be as high as  <dig>  –  <dig>   <cit> . to estimate the size of the bias for the type of stratification in the present study, we conducted additional simulations  in which we varied the number of "genes" selected per stratum . for randomly stratified data, the upward bias  of the sample correlation coefficient ranged from a high of  <dig>   to a low of  <dig>  .

in summary, random and random-stratified sampling performed similarly well, although random sampling was slightly more variable and produced more outliers on all indices . moreover, the top-ranked sampling strategy performed substantially worse than either of the two other strategies.

performance of sampling strategies using empirical microarray data
we performed three identical replicate experiments with mouse nih 3t3-l <dig> preadipocytes treated or not with the steroid hormone dexamethasone  for  <dig> h prior to harvesting. labelled rna from each experiment was hybridized to affymetrix mg u74av <dig> microarrays . the overlap of statistically significantly differentially expressed genes among the three experiments is displayed in a venn diagram . a substantial number of genes were statistically significant in opposite directions across the experiments, despite setting the false discovery rate  at  <dig>  within each experiment. moreover, many more genes were significant in experiment  <dig> because variability among replicates was substantially lower than in the other two experiments . one-hundred and fifty genes were significantly upregulated in all three experiments . good agreement was observed among the three microarray replicate experiments for these genes .

to further examine differences in random-stratified versus top-ranked sampling, we selected  <dig> of the  <dig> upregulated genes to validate with qrpcr: the top  <dig> differentially expressed genes and  <dig> genes from a random stratification scheme . the  <dig> top-ranked genes and nine of the  <dig> genes selected by random stratification were significantly differentially expressed by qrpcr in all three experiments. of the remaining five genes in the stratified sample, three were significant in two experiments  and two were significant in one experiment .

to obtain more stable estimates of the various indices, we averaged the data across the three experiments . compared to sampling top-ranked genes, random-stratified sampling was  <dig>  times more precise  and  <dig>  times more accurate . moreover, the ccc was robust to departures from linearity , influential regression data points  and log <dig> fcs <  <dig>  .

results from each microarray experiment were also compared to the qrpcr results obtained from the rna samples from the two other experiments , yielding similar results . figure  <dig> shows the distributions of the various indices for the technical and biological validations. contrary to expectation, there are no obvious differences between the technical and biological validation results.

relation between microarray and qrpcr
predicted qrpcr fcs were larger than microarray fcs, an effect which increased with increasing fcs, as indicated by the least-squares regression  lines being above the identity  lines for most of the data range in figures  <dig>   <dig>  this pattern is also evident in figures 7a–b, which combine the data from figures 5a–b. we note also that we obtained better validation results  with qrpcr for both sampling strategies when qrpcr data were calibrated by the standard curve method rather than assuming 2-fold amplification of the pcr reaction using the ct measurements . also, the robust multichip analysis  used in our analysis is one of many algorithms available for normalizing affymetrix data. comparison of results with other normalization algorithms is beyond the scope of the study and is complicated by the fact that genes were selected for subsequent validation based on the rma data. caveats notwithstanding, we provide validation indices for other popular normalization algorithms .

regression toward the mean
the lower precision and accuracy of the top sampling strategy can be explained by the regression toward the mean phenomenon. the phenomenon describes the tendency for extreme values of one set of observations to be less extreme on a second set. the lower the true correlation and the more extreme the values on the initial set, the more pronounced the tendency. note also that regression toward the mean is bidirectional; the artifact remains if the initial and the retest sets are reversed.

the regression toward the mean effect depends solely on the correlation between two sets of observations; it occurs whenever the correlation is less than perfect   <cit> . this correlation in turn depends on the variability of the true  values and the variability of the random error associated with the measurements. reducing random error  and sampling across the entire data range maximizes the observed correlation and minimizes the adverse effects of regression toward the mean. finally, although for ease of exposition we conducted our simulations assuming linearity and normally distributed random error, the regression toward the mean phenomenon does not depend on these assumptions  <cit> .

the strength of the adverse effect of top-ranked sampling will depend on the distributions of the microarray and validated sample data. accordingly, choice of microarray and qrpcr preprocessing methods  will affect the regression toward the mean effect to the extent that they affect the data distributions, although the effect will always be present to some degree. assuming linearity and homoscedasticity, restricting the microarray data to the top-ranked effects will underestimate the population correlation between microarray  and validation samples  according to the following formula  <cit> :

ρxtop−ranked,y=ρxfull−range,yρxfull−range,y2+1
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaiigacqwfbpgcdawgaawcbagaemieag3aasbaawqaaiabdsfaujabd+gavjabdchawjabgkhitiabdkhayjabdggahjabd6gaujabdugarjabdwgaljabdsgakbqabawccqggsaalcqwg5bqeaeqaaogaeyypa0zaasaaaeaadaqadiqaamaaliaabagae83wdm3aasbaasqaaiabdiha4naabaaameaacqwgubavcqwgvbwbcqwgwbaccqghsislcqwgybgccqwghbqycqwgubgbcqwgrbwacqwglbqzcqwgkbazaeqaaawcbeaaaoqaaiab=n8aznaabaaaleaacqwg4baedawgaaadbagaemoraykaemydaunaemibawmaemibawmaeyoei0iaemocainaemyyaemaemoba4maem4zacmaemyzaugabeaaasqabaaaaagccagloagaayzkaagae8xwdi3aasbaasqaaiabdiha4naabaaameaacqwggbgrcqwg1bqdcqwgsbabcqwgsbabcqghsislcqwgybgccqwghbqycqwgubgbcqwgnbwzcqwglbqzaeqaasgaeiilawiaemyeakhabeaaaoqaamaakaaabawaaewaceaadawccaqaaiab=n8aznaabaaaleaacqwg4baedawgaaadbagaemivaqlaem4ba8maemicaanaeyoei0iaemocainaemyyaemaemoba4maem4aasmaemyzaumaemizaqgabeaaasqabaaakeaacqwfdpwcdawgaawcbagaemieag3aasbaawqaaiabdaeagjabdwha1jabdygasjabdygasjabgkhitiabdkhayjabdggahjabd6gaujabdeganjabdwgalbqabaaaleqaaaaaaogaayjkaiaawmcaaiab=f8aynaadaaaleaacqwg4baedawgaaadbagaemoraykaemydaunaemibawmaemibawmaeyoei0iaemocainaemyyaemaemoba4maem4zacmaemyzaugabeaaliabcycasiabdmha5bqaaiabikdayaaakiabgucariabigdaxawcbeaaaaaaaa@af95@

where ρ and σ are the population correlations and standard deviations, respectively.

regression toward the mean can be most easily illustrated when the two sample means and standard deviations are at least approximately equal, as is the case for the simulated data in figure  <dig> and the microarray-microarray data in figure  <dig>  note the larger distances between the identity  line in figure 1a and the benchmark data least squares regression  line for the extreme  values of the initial sample . similar differences are seen between the identity  line and the least squares regression  line in figures 3b–d. for low initial sample values, predicted values on retest are larger; for large initial sample values, predicted values on retest are smaller.

pair-link diagrams provide another graphical illustration  <cit>  . the lines linking the initial scores to their respective retest scores tend to cross. on average, high scores on the initial sample have negative  slopes, low scores have positive  slopes, and middle scores have flat slopes. the upshot of this tendency is that retest values will have lower precision and lower accuracy when top-ranked initial values are selected for retest.

by contrast, the pair-link diagram for the microarray/qrpcr data  shows that most lines linking the microarray fcs to their respective qrpcr fcs have a positive slope, especially among the top-ranked microarray values. despite appearances, regression toward the mean is nonetheless present and provides an explanation for the lower level of agreement observed among the top-ranked genes. this type of apparent "regression away from the mean" can only occur when the standard deviation of the validation sample is larger than the standard deviation of the initial sample, as here . regression toward the mean, however, is a phenomenon of standardized scores . when variance is taken into account and measurements are converted to standardized z-scores, the regression toward the mean effect is evident . extreme standardized qrpcr fcs are less extreme than their corresponding microarray fcs. larger sample sizes would be needed to determine if the lower agreement among the top-ranked genes is due solely to regression toward the mean or to regression toward the mean plus some other effect .

discussion
routine global validation of microarray results would provide valuable information on the quality of microarray studies and would complement existing standards for validating individual genes. our results demonstrate that the outcome of global validation depends on how a subset of genes is chosen. random-stratified sampling provides more accurate and more precise estimates of agreement between microarrays and qrpcr than does the often-used top-ranked sampling procedure. our empirical results confirm the theoretical argument that selecting top-ranked differentially expressed genes for validation leads to underestimating the level of agreement between microarray and qrpcr validation fc values.

genes which are deemed especially important to the experimenter can be validated separately from genes required for validation of the microarray experiment in total. appreciation for the regression toward the mean effect, however, is still necessary for informed decisions regarding these specific genes. the tendency for extreme fcs to be less extreme on validation will still be operating, although the non-random sampling will make it difficult to assess the extent of the effect.

ccc index of validation
we argue that a one-to-one correspondence between microarray and validation fc estimates is the gold standard for validation. this tight clustering of retest fc values around the identity line is indexed uniquely among validation indices by the ccc measure. accordingly, the ccc provides dimensionless metrics with which to compare technology platforms, statistical procedures, and laboratory protocols, and ultimately, the overall quality of any given microarray study. in the case of unusually low ccc values, the accuracy and precision components provide clues on how the validation samples deviate from the standard which may in turn suggest procedural or statistical remedies. regression slope and intercept estimates provide additional information to convert microarray fc estimates into estimates from lower throughput methods. finally, the reported robustness of the ccc with as few as  <dig> data points  <cit>  is supported in our data, as influential  data points and deviations from linearity had little effect on the ccc estimates, although robust analogues of the ccc are also available  <cit> .

sampling
the relatively high ccc values we observed in pairwise comparisons between our microarray experiments  lend support to fc as a good index of effect size for platform comparison purposes. however, fc measurements present a statistical technical difficulty when attempting to validate the entire fc range, including non-differentially expressed genes. most log fcs near zero represent non-differentially expressed genes whose variation merely reflects noise. correlation with qrpcr for these genes will be close to zero and the least squares line will be flat within this range. differentially expressed genes, on the other hand, will have positive slopes for both up and down regulated genes. if only differentially expressed genes are selected for validation, up and down-regulated genes should be examined separately. analyzing them together will upwardly bias correlation values due to a "range enhancement" artifact  <cit> ; in extreme cases, the correlation between microarray and qrpcr fcs may be close to  <dig>  despite zero correlations when up and down-regulated genes are analyzed separately.

the adverse effects of regression toward the mean are sometimes avoided when specific genes of interest are selected and they cover the full fc range coincidentally. the strategy remains less than optimal as a global validation strategy, however, because the non-random sampling nonetheless prevents the generalization of the conclusions to the remaining majority of differentially expressed genes.

threshold index of validation
all top-ranked, but only nine out of the  <dig> random-stratified genes in our study were statistically significant by qrpcr in the three samples. non-significant p values tended to occur among the smaller fcs, but this effect was not uniform, as the smallest average microarray fc gene was significant in all three pcr samples. the seemingly paradoxical difference between the statistical significance threshold and the ccc approaches to validation can be explained as follows.

one difficulty with this type of threshold-based strategy is the choice of threshold. it can be shown that the smaller the initial p value, the more probable a second test will meet a specified probability threshold  <cit> . a true positive gene that is differentially expressed at p =  <dig>  has only a 50% chance of being differentially expressed at p <  <dig>  on retest; at p =  <dig> , the probability of obtaining p <  <dig>  on retest increases to 80%  <cit> . accordingly, the larger its initial fc, the more likely the gene will exceed the decision threshold in the validation sample despite regression toward the mean. this threshold approach to validation, however, is adequate only if one is interested in the largest fc effects to the exclusion of more moderate but potentially important effects.

additionally, consider the following example. using a p <  <dig>  threshold, a gene that is differentially expressed at p =  <dig>  by microarray but at p =  <dig>  by qrpcr would be said to not have validated despite almost identical p values. by contrast, a gene that is differentially expressed at p =  <dig>  by microarray and at p =  <dig>  by qrpcr would be said to have validated despite a large discrepancy in p values. one way around this difficulty would be to require that the effect size of the validated sample not be significantly different from the effect size of the initial sample for a conclusion that the gene was validated, although this raises the additional question of how many replicate samples would be needed to provide sufficient statistical power for detecting differences  <cit> . moreover, the issue arises whether a gene would be considered validated if it were significant in both initial and validated samples but with significantly different effect sizes in the two samples. despite their limitations however, threshold approaches do provide a framework for dichotomous decisions regarding whether or not an individual gene has been validated.

the question arises of how one can reach this type of decision on individual genes with the validation approach that we are advocating. one approach might be to first determine the extent of validation across a number of appropriately  sampled genes by some index of global validation . if the results of global validation were found to be inadequate, then the microarray experiment might well be considered a failure and the validation of individual genes moot. if on the other hand global validation were found to be adequate, then regression diagnostic methods might be used to identify outlier genes whose validation results deviated from the pattern of the majority of genes for a variety of reasons .

these regression outlier genes could then be investigated further to determine their status; non-outlier genes would be considered validated.

a corollary to this approach is that one could extend the conclusion of validity to those microarray findings not selected for validation with pcr but whose effects fall within the sampled  range. our approach advocates selection of genes through a random process; therefore, any index of global validation should be uninfluenced by the specific sample selected and should generalize to the non-validated genes. moreover, the relative proportions of outlier and non-outlier genes would provide an indication of the relative risk involved in making such a generalization.

CONCLUSIONS
our results point to the importance of gene selection strategy, choice of qrpcr calibration methods, and choice of validation index in the assessment of microarray validation results. sample sizes of  <dig> to  <dig> genes should be adequate for most validation purposes, although more observations may be needed to reliably estimate non-linearity between microarray and validation fc values. the ccc provides a global indication of the reproducibility of gene expression fcs estimated by microarrays, providing that a suitably random procedure is used to select genes for validation. thus, we propose that the ccc be used as a universal measure of study quality.

