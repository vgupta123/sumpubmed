BACKGROUND
notwithstanding the continuous improvement in predictive methods, witnessed every two years by the world wide casp experiment  <cit> , predicting the structure of a protein, given its sequence, is still in general beyond our capabilities. brute force approaches, like exhaustive conformational searches or molecular dynamics simulations of the folding process, are precluded by the computing power available at present. alternative, faster methods have been developed along two main lines:

 <dig>  assemblying the structure of a protein using structural fragments of similar sequences, available in the protein structure repository , and later screening the feasibility of the resulting structures, using energetic criteria;

 <dig>  representing the protein chain by a highly simplified model which is, hopefully, treatable.

this second class of approaches is appealing in many respects  <cit> : first, the linkage between kinetics and thermodynamics of protein folding process and the basic intramolecular interactions is more easily addressable, because of the lesser number of variables. second, the use of a simplified model agrees with the idea that details of atomic interactions between aminoacids are less important than the overall character of these interactions, because protein structure is flexible and can accommodate changes in the volume and shape of aminoacids much better than changes in their character . besides aiming at catching essential features of the protein folding process, simplified models have important computational advantages: generating and evaluating the energy of a conformation is efficiently done due to the reduced number of variables. a less evident benefit is that sampling  may be much more efficient due to the smoothness of energy surface due, once again, to the reduced number of degrees of freedom. many lattice models have been used for simplified representation of proteins, up to date. their capability of reproducing the secondary structure of proteins, as well as their relative arrangement has been reviewed by godzik et al.  <cit> . a reasonable tradeoff between accuracy and the need to keep limited the number of base vectors is achieved by the face centered cubic () lattice studied by toma and toma  <cit> . in particular both α-helices and β-strands are modelled with a very low rmsd from standard regular structures. lattice models have been used mainly for understanding general properties of proteins, rather than for real predictive tasks, although their use, especially in hierarchical protocols has been proposed and realized. in particular, the  lattice has been used successfully by skolnick and kolinski in prediction of a small beta protein  <cit>  and many other useful applications have been reported since these earlier works . a deep analysis of realistic lattice models of proteins proposed so far is definitely out of the scope of the present work, but there are few aspects of lattice models of proteins which need to be mentioned. the successful application of a lattice model depends obviously on the efficiency in generating conformations and searching for local minima. this aspect is dealt in the present work using constraint logic programming, and taking advantage of all theoretical and implementative developments that have been realized in this context. the approach  has been very seldom applied in the context of protein modeling and it has not been used for realistic protein structural predictions, to the best of our knowledge. a different, but equally important, aspect concerns the reliability of the model itself and of the forcefield used to evaluate conformational free energy. this aspect will not be dealt with by this work. an appropriate forcefield must take into account both local propensities to adopt a particular secondary structure  and their tendency to be in contact . contact potentials have been derived by many groups  based on the observed versus expected contacts stored in the database. a similar approach could be followed in order to derive a torsional potential in order to describe local conformational propensities. however, it is not obvious how these potentials should be derived for lattice models and how the two potentials are to be considered together. these problems are not investigated here. rather we consider contact potentials previously derived by our group from statistical analysis of the database  <cit> , which are expected not to be accurate for a lattice model, but nevertheless should be able to reproduce essential features of aminoacid interactions. the local propensity to adopt a particular secondary structure can be computed by predictive methods  <cit> . however, for the small peptides analyzed in this paper, the correct secondary structure is selected from the deposited structures for testing purposes.

constraint logic programming   <cit>  is a declarative programming paradigm particularly well-suited for encoding combinatorial minimization problems. it is the natural merger of the two declarative paradigms known as constraint solving and logic programming.

one of the peculiar features of  is the independence of the problem modeling and of the search's strategy. problem modeling is based on traditional declarative programs in which one can use the built-in notion of constraint. constraints are first-order formulas concerning variables that can assume values in some domains. the scheme is general. various possible constraints and domains can be used. however, for combinatorial problems it is common to use finite domain constraints, namely arithmetic constraints between arithmetic expressions, where variables range over finite subsets of ℕ. constraint logic programming over finite domains is known as (). we briefly introduce this programming paradigm with a simple example. let us consider three variables x, y, z that denote the number of possible items of some kind.

domain

is a constraint that states that the three variables x, y, z have  domain { <dig>   <dig>  ..., 10}. suppose we wish to state that the weight of each item of x is  <dig>  of y is  <dig>  and of z is  <dig> and the total weight of selected items must be less than or equal to  <dig>  moreover, we wish to state that the number of items of x plus those of y must be less than those of z. this can be simply stated as:

 <dig> * x +  <dig> * y +  <dig> * z ≤  <dig>  x + y <z

we have modeled a sort of knapsack problem using (). in general, in the modeling stage we can use constraints as well as declarative programs involving them.

solution's search is performed by a constraint solver that is available in the language. the constraint solver uses constraints for sensibly pruning the search tree. one of the main capabilities is called constraint propagation. constraint propagation reduces the domains of the variables eliminating those values that cannot lead to constraint solutions. for instance, in the considered example, constraint propagation reduces the domains of the variables x, y, and z to { <dig>  ..., 4}, { <dig>  ..., 4}, and { <dig>  ..., 6}, respectively. for finding a possible solution, a further built-in capability – the labeling predicate – can be used. we can look for a generic solution as well as for a solution minimizing some function. in the example above, we could ask for minimizing the function -2x <dig> + y + 4z. this can be done by adding a constraint of the form:

f = - <dig> * x * x + y +  <dig> * z, labeling], ).

the constraint solver then exploits the solution's search using constraint propagation and branch-and-bound techniques returning the answer:

f =  <dig>  x =  <dig>  y =  <dig>  z = 5

the library clpfd of slcstus prolog  <cit>  allows to effectively program in this framework. let us observe that it is not required that f be a linear function.

the above described approach to optimization combinatorial problems is the so-called constrain & generate technique introduced as opposed to the generate & test technique of the classical logic programming approach . in the latter approach, a first phase generates non-deterministically a possible solution, and then the deterministic test-phase checks whether the solution is acceptable or not. if the search space is exponential, this technique is not applicable. in the former approach, a first deterministic phase introduces a number of constraints, then a non-deterministic phase starts the generation of the solutions' space. the constraints introduced allow to sensibly prune the solutions' space in order to make the procedure effective. moreover, in this phase one can take advantage from language built-in strategies  and it is possible to further drive the solution search by means of problem-dependent heuristics.

we have followed the constrain & generate programming style for encoding the protein structure prediction problem. as a matter of fact, the main predicate of our solution is of the form reported in figure  <dig> 

in the definition of the predicate constrain the protein structure prediction problem is modeled using constraints. in particular, the energy function is encoded in the energy parameter, the predicate solution_search is aimed at looking for the solution minimizing the energy parameter. the other predicates are auxiliary predicates. initialization resets some parameters, protein recovers the relevant input , writetime and print_results are output predicates. the constraint predicate is defined using several predicates each of them modeling one of the properties of the problem. for instance, the predicate next_constraints sets the distance between consecutive aminoacids .

briefly, next_constraints recursively calls the predicate next for each pair of consecutive aminoacids. assume that <x <dig>  y <dig>  z1> and <x <dig>  y <dig>  z2> are the variables that will store the positions of a consecutive pair of aminoacids, then the predicate next states that |x <dig> - x2| + |y <dig> - y2| + |z1- z2| =  <dig> and that |x <dig> - x2| ∈ { <dig>  1}, |y <dig> - y2| ∈ { <dig>  1}, |z <dig> - z2| ∈ { <dig>  1}. this is exactly the notion of adjacency in the face-centered cubic lattice of size  <dig> that we have used .

RESULTS
constrained optimization problem in ()
in table  <dig> we report the results of the experiments with the () code described in the methods section. all tests are done using sicstus prolog  <dig> . <dig>  <cit>  and a pc p <dig>   <dig>  ghz. the structures of the protein model systems analyzed are known and stored in the pdb  <cit> . in the protein model systems 1le <dig>  1pg <dig>  and 1zdd terminal protecting groups have been neglected.

from left to right, the meaning of each column is as follows: the protein pdb identification code, the number n of aminoacids, the execution time, the energy of the best model found and its rmsd from the native structure for all the residues and for the core residues only. when there is not explicitly written "limit" it means that the program successfully terminated in the time reported; otherwise the program terminated due to time limit. we wish to observe that the results with time limit  <dig> h/ <dig> h are typically computed in few hours. the rest of the time is used to further explore the solutions' space.

when a cf = η is reported a further constraint on the compactness ratio η is added before the search. cf = η bounds the linear distances |xi - xj|, |yi - yj|, and |zi - zj| between all pair of residues i and j to ηn where n is the length of the primary list. if η is low , this constraint imposes a compact form to the protein and strongly reduces the running time.

one of the structural constraints considered is the presence of disulfide bonded residues . the rigid structure of the lattice is such that a low value of euclidean distance  between ssbonds often precludes all possible solutions. for this reason the default is chosen as  <dig>  however, in some cases we tried computations with lower value. in these cases in the table the text ss = γ is reported.

the secondary structure, as computed from the deposited structure in pdb, has been input as constraint. as a unique exception, in the case of 1vii we have instead predicted it using the gor iv secondary structure prediction method  <cit> .

the predicted structures have been also transformed into all atoms models as described in the detailed models from lattice models section. there is some improvement in general on rmsd from native structure. this is especially significant when the starting structure is already close to the native one, being not merely due to increasing compactness of the structure. it is moreover reassuring that the procedure we are discussing is able to recover realistic models starting from the very simplified lattice models. the rmsds of the resulting detailed models from the corresponding native structures are reported in table  <dig>  in order to assess the quality of the detailed model, the trace of the native structure and the reconstructed and optimized all-atom model are shown in figure  <dig> for the core residues  of the ww domain .

we conclude the section comparing some results of our prediction with those returned by the well-known hmmstr/rosetta prediction system  <cit> . this program does not use a lattice as underlying model: aminoacids are free to take any position in ℝ <dig>  for the sake of comparison, we have used it as an ab-initio predictor . the comparison is obviously not fair because in our case secondary structure is known and not predicted. times are obtained from the result files, but it is not clear to which machine/cpu occupation they refer. results are reported in table  <dig>  hmmstr/rosetta prediction runs presumably faster, but our predictions  improve the rmsd .

constrained molecular dynamics simulation
we have used secondary structure information in conjunction with the well-established methodology of molecular dynamics simulations in order to implement a procedure similar to the one implemented using  on the  lattice. secondary structure elements have been imposed through a constraining potential as described in the methods section. in order to search the conformational space a simulated annealing procedure has been adopted. globularity of the simulated proteins is forced by a harmonic constraint on the radius of gyration.

the simulation time, ranging approximately between one and four cpu days, required for folding each protein on a  <dig>  ghz amd athlon processor is reported in table  <dig>  the columns  in table  <dig> report the pdb identification code of the protein, the number of residues, the rmsd from native structure computed on cα atoms on the whole protein and only on core residues and the simulation time. the last column reports the rmsd from native structure for models obtained by  after addition of all atoms and energy minimization as described in the methods section.

the simulation time needed for obtaining structures similar to native structures increases with the size of the protein both for the increasing size of the system and for the longer simulated annealing runs needed because of increasing complexity of the free energy landscape. unfortunately a safer scheme would employ substantially longer simulation times.

this fact prompts for searching alternative ways to employ the same ideas.

the results in terms of rmsd from native structure support the idea that folding may be achieved, at least in simulation, by a hierarchical approach where local secondary structure elements are formed first and later their arrangement and contacts are optimized. a similar conclusion has been reached using a different model by maritan and coworkers  <cit> . the rmsd on core residues is, in all but one case, less than  <dig>  Å. in four out of six cases the rmsd on core residues is close to  <dig>  Å. in the worst case, which is also the longest simulated chain, the rmsd on core residues is  <dig>  Å.

CONCLUSIONS
the purpose of the present work was to demonstrate that the protein folding problem can be approached by a well-established programming paradigm like . with respect to the few applications reported in the literature so far using the same methodology  <cit> , mainly on the hp protein model  <cit> , the present work takes a step further towards more realistic modeling. notwithstanding the use of a protein simplified lattice model with a simple contact potential realistic models for a few small proteins have been generated by using . in the present application the known secondary structure of the protein has been imposed as a constraint.  has been applied on face centered cubic lattice models of proteins where every aminoacid is represented by a single point on the lattice that can take one out of six possible positions with respect to the previous three aminoacids. it is immediately seen that the time needed for a systematic space search for such model grows exponentially with the number of free aminoacids.  is a programming paradigm that is suited for the solution of optimization combinatorial problems. in  the problem and the related heuristics are extremely natural to be programmed. moreover, the constraint propagation allows to control the search in the huge solution's space.

the results obtained using this approach and reported in tables  <dig> to  <dig> show that for small proteins a solution for the optimization problem is obtained in less than few hours. for the larger proteins studied here the inaccuracies of both the lattice model and contact potential prevent finding a compact solution. these problems are more likely to appear with increasing size of the protein and when the length of non-constrained chain connecting two secondary structure elements is short, because the lattice allows a limited set of conformations.

further work is being devoted towards a more realistic modeling representation of the protein, with at least two centers of interaction per residue, and towards refinement of the potential function by including a term for rotamer preferences. this term should map on the lattice the directional preferences of each unit with respect to the previous three units. each of the six possible next positions for each unit should be weighted by an energy term derived from database analysis.

also the optimal size of non constrained parts of the chain will be determined in order to allow more possible relative orientations among constrained secondary structure elements, possibly without increasing significantly the computation time. at present, however, when the positions of all atoms are reconstructed from the lattice cα trace, the rmsd on core residues of the resulting models, after energy minimization, compared to native structures, is as low as  <dig>  Å for the thermostable domain of villin headpiece ,  <dig>  Å for the ww domain ,  <dig>  Å for the coat protein-binding domain of bacteriophage p <dig> .

it should be also noted that both the thermostable domain of villin headpiece and the ww contain three secondary structure elements that can be arranged in different ways in order to produce a compact structure. the low rmsd is therefore significant.

a comparable protocol employing a molecular dynamics simulated annealing procedure still leads to superior results for larger proteins, as expected because the protein representation is more accurate, but it takes longer execution times between one and four days on a  <dig>  ghz p <dig> machine.

recent results have shown that simplified models and more refined models can be employed successfully in hierarchical modeling procedures  <cit> . the results obtained in the present work suggest that  could be useful for finding starting conformations for further refinement.

