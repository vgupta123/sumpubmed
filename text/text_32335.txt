BACKGROUND
vocal prosody is one of the most important features of human communication enabling individuals to recognize the affective state of people in order to react quickly and appropriately in social situations. changes in respiration, phonation, and articulation determine the acoustic signal of a voice and accompany emotional reactions, similar as changes in facial expressions  <cit> .

the encoding of emotional prosody is based on various acoustic features, such as pitch and pitch variation, syllable duration, and voice quality  <cit> . the quality of the voice is determined by different laryngeal and supralaryngeal aspects. the extraction of emotional prosody has been suggested to be automatic  <cit> . event-related potential studies have shown that similar to the processing of facial expression, emotional vocalizations  elicit a fronto-central positivity  <dig> ms after stimulus onset compared to frequency-matched artificial sounds  <cit> . other studies have focused on the dissociation between vocal emotional processing and the processing of person-identity information in human voices  <cit> . early erp priming effects have been observed for happy voices but not for sad voices in the time range of the p <dig>  a positivity with a latency of  <dig> ms, whereas the erp speaker identity matching effect did not start until around  <dig> ms  <cit> . the authors referred their results to physical differences related to emotional prosody. they suggested that higher frequencies are presented in happy voices than in sad voices, which might contribute to a faster and more efficient processing of happy vocal stimuli  <cit> . another study has shown a modulation of erps by the emotional valence of voices in the p <dig> time range as well  <cit> . the authors interpreted their results as evidence for a rapid emotional decoding.

in humans, an enhanced brain activity has been observed to emotional compared to neutral voices in auditory association areas including the superior temporal sulcus   <cit>  and the right middle superior temporal gyrus  <cit> . these activation patterns have been observed irrespectively of which vocal prosody was used  <cit> . a recent study used functional near-infrared-spectroscopy  and reported an increased activation in the auditory cortex in response to pleasant and unpleasant sounds in comparison to neutral sounds  <cit> . this activation pattern suggests that even sensory areas differentially respond to emotional prosodies, which nicely matches corresponding results in the visual system  <cit> . however, brain imaging data do not allow to conclude whether changes of sensory cortex activity are due to changes in bottom up processing or due to feedback connections of higher cortical areas or the amygdala.

it has been a matter of debate whether the processing of emotional information depends on attentional resources  <cit> . there are a number of studies suggesting that attention is necessary to select basic stimulus features in order to store relevant stimulus properties in working memory  <cit> . however, there is evidence as well suggesting that emotional signals can be processed independent of attention and awareness and may guide attention to salient stimuli  <cit> .

although there are a few studies suggesting that the processing of facial expression requires attention  <cit>  many of the recent studies are compatible with the view that emotional features can be processed automatically. for example, a processing of emotional faces has been observed outside the focus of attention  <cit>  and even in the disregarded space by neglect patients  <cit> . by contrast, additional studies have shown that attention is capable to further enhance the processing of emotional facial expressions  <cit> . these results suggest for visual emotional stimuli both some attention independent processing but also some top down control. this combination seems highly efficient since many emotional stimuli in the environment are totally irrelevant for an individual. thus, an individual must be able to inhibit an orienting to emotional stimuli in order not to interfere with current action goals.

interestingly, brain networks involved in emotional processing show an overlap with attentional networks: both attentional and emotional processes have been found to activate higher cortical areas such as parietal, frontal and cingulated areas as well as subcortical regions . however, the emotion specific activation of the amygdala might allow emotional information to be processed prior to the attentive stimulus selection  <cit>  thus enabling emotional features to serve as exogenous cues that guide attention to relevant events.

while interactions between attention and emotional processing in the visual modality have been extensively studied, the question whether the processing of emotional prosody depends on attention or not has been addressed only recently. the situation for emotional voices might be quite different than for emotional faces, since the latter requires an orientation of the eyes toward visual stimuli in order to perceive them with a sufficient accuracy, while such an overt orienting response is not necessary in order to process emotional voices.

sander and scheich  <cit>  found amygdala activity in response to affective non-verbal vocalizations  regardless of whether the participants attended to the emotional valence of the stimuli or were engaged in a distracter task. moreover, grandjean et al.  <cit>  showed that emotion-related activity in response to angry voices in the middle right sts did not vary with selective spatial attention, suggesting a preattentive processing of emotional prosody. using the same paradigm, sander et al.  <cit>  replicated these findings and extended them to the amygdala. additionally, as for visual neglect  <cit> , auditory extinction was found to be attenuated for stimuli with an emotional as compared to a neutral prosody  <cit> . more recent studies, however, challenge the assumption of a total automaticity of emotional prosody processing. mothes-lasch et al.  <cit>  presented voices of seven different emotional prosodies: participants had to classify the gender of the speaker or they had to perform a difficult visual discrimination task. the authors found a higher response of the amygdala to angry compared to neutral voices only in the auditory but not in the visual task suggesting that orienting attention away from the auditory modality  abolishes emotional prosody processing. by contrast, emotional voice can serve as an exogenous crossmodal attention cue. brosch et al.  <cit>  showed that reaction times in a dot probe task were shorter when the visual target was presented on the side at which an angry utterance  was heard just before. the parallel recorded erps revealed an enhanced amplitude of the visual p <dig> to the target when an emotional voice was presented at the same side as the visual target compared to when the visual target was presented at the side of the preceding neutral voice  <cit> .

our study extends previous work by investigating the time course of spatial attention effects under different emotional prosody conditions. thus, the present study complements the findings of imaging studies using a dichotic listening paradigm in order to analyze spatial attention effects on the processing of human angry and neutral voices  <cit> .

the present erp-study orthogonally manipulated the focus of spatial attention and the emotional prosody of the stimuli in order to analyze whether or not physically identical emotional stimuli are processed differently within and outside the focus of spatial attention. pseudo-words comprising two identical  or two different  syllables spoken by two different female voices were presented randomly on the left and on the right side of the participant. in different blocks, participants had to attend to one of the two spatial positions. they had to respond to infrequent  deviant stimuli presented at the attended position. the present experiment, therefore allowed for a direct comparison of the processing of physically identical emotional stimuli once when spatially attended and once when unattended.

based on previous findings, we expected spatial attention to enhance erps to vocal stimuli starting around  <dig> ms after stimulus onset .

if emotional prosody is processed in the absence of spatial attention, erp modulations due to emotional valence are expected to be independent of the focus of spatial attention and thus additive to the erp spatial attention effects. by contrast, if attention is necessary to process emotional valence, an effect of emotional valence is predicted only for the spatially attended stimuli or is different for spatially attended and unattended stimuli.

methods
participants
seventeen healthy young student participants took part in the main experiment. according to self-report all participants had normal hearing and normal or corrected to normal vision. they were either paid for participation or received course credits. the experiment was conducted in accordance with the ethical guidelines laid down in the declaration of helsinki . because of low performance , only data of thirteen participants  were analyzed.

stimuli
the final stimulus set consisted of nine different two-syllable pseudo-words  spoken by two actresses in four different emotional prosodies , resulting in  <dig> physically different stimuli. three of the pseudo-words were deviant stimuli ; the remaining six were standards .

stimulus selection and evaluation
in a first step  <dig> two-syllable pseudo-words comprising two identical syllables , and  <dig> pseudo-words with two different syllables  were generated. stimuli with two identical syllables were later used as standards, those with two different syllables as deviants or targets. two actresses spoke these pseudo-words three times in four different emotional prosodies . stimuli were recorded with a dat recorder in an anechoic chamber. they were transferred to the computer and saved as wav-files. preprocessing was done with the goldwave software . the volume of the single sound files was equalized by setting the root mean square of each stimulus to  <dig> .

the best two of the three recordings of each pseudo-word and each speaker were preselected by one of the authors  for an evaluation study in which  <dig> students of the university of marburg  rated each of the remaining  <dig> stimuli  on three dimensions  using scales from − <dig> to + <dig>  – pleasant ; dominance: submissive  – dominant ; arousal: calming  – stimulating ).

the nine experimental stimuli  were selected using the criteria of duration as well as ratings of valence. stimuli shorter than  <dig> ms or longer than  <dig> ms were discarded. rating values were transformed on a scale ranging from  <dig>  to  <dig> . in order to make sure that stimuli of different emotional categories would differ in their perceived valence, cutoff scores for the mean valence ratings were applied. these cutoff scores  were defined to guarantee distinct stimuli for each voice in the four emotional categories.

for different sets of stimuli, analyses of variance with the factor emotional prosody  were calculated for the following dependent variables: duration, pitch, intensity, valence rating, dominance rating, and arousal rating. for the final set of standard stimuli, the duration did not differ between emotion conditions  =  <dig> , p > .1). mean pitch differed between emotions  =  <dig> , p < .001). the mean pitch of neutral vocal stimuli was significantly lower compared to happy, threatening and fearful voices  = − <dig> , p < .001; neutral versus threatening: t = − <dig> , p < .001; neutral versus fearful: t = − <dig> , p < .01). moreover, happy voices had a higher pitch compared to threatening and fearful voices   =  <dig> , p < .05; happy versus fearful: t =  <dig> ; p < .01). threatening and fearful voices did not differ in the mean fundamental frequency  =  <dig> , p > .1).

valence ratings  depended on emotional prosody  =  <dig> , p < .001). all pairwise comparisons between emotional prosodies were significant . dominance ratings depended on emotional prosody as well  =  <dig> , p < .001). all differences between emotional prosodies in dominance ratings were significant . by contrast, arousal ratings for the four emotional prosodies did not differ  = . <dig>  p > .1).

table  <dig> lists the means and standard errors of duration , pitch , intensity  and valence rating, dominance rating, and arousal rating separately for the four emotional prosodies for the final set of standard stimuli and table  <dig> the same values for deviant stimuli.

*intensity refers to the degree of energy which is present in a given sound wave. it is directly proportional to amplitude, or, more precisely, it is directly proportional to the squared amplitude .

*intensity refers to the degree of energy which is present in a given sound wave. it is directly proportional to amplitude, or, more precisely, it is directly proportional to the squared amplitude .

the difference in duration of the deviant stimuli in different emotional prosodies was not significant  =  <dig>  p < .1). dominance ratings depended on emotional prosody  =  <dig> , p < .001). all pairwise comparisons were significant , with the exception of the comparison neutral vs. happy . by contrast, arousal ratings did not depend on emotional prosody  = . <dig>  p > .1).

the final stimulus set consisted of nine different two-syllable pseudo-words  each spoken by the two actresses in four emotional prosodies, resulting in  <dig> physically different stimuli. three of the pseudo-words were deviant stimuli , the remaining six were standards .

procedure
training
in order to learn to discriminate the voices and to get familiar with the experimental procedure all participants took part in a 3– <dig>  hours training session, one or two days prior to the eeg session. the training session consisted of five different units each of which had to be performed three times. the stimuli  were different from those used for the main experiment but came from the same stimulus pool. since we did not analyze the factor voicea, the first four training units are not described in detail. the last phase of the training session was identical to an experimental block.

main experiment
for the main experiment the stimuli were presented from two speakers positioned in front of the participant at a distance of  <dig>  m, one 45° to the left and one 45° to the right of the participant. stimuli of both voices and of all emotional prosodies were presented with an equal probability and in a random order from the left and right speaker. stimulus onset asynchronies varied between  <dig> ms to  <dig> ms with a mean of  <dig> ms.

participants were instructed to attend to stimuli which were presented at one of the two spatial positions  and which were spoken by one of the two female speakers. their task was to respond by lifting the left or right index finger out of a light gate whenever they detected one of the deviant stimuli spoken by the attended voice and presented at the attended position . response hand was switched after half of the trials . a specific instruction concerning the varying affective prosodies was not given. thus, there were four experimental conditions . only the spatial attention effects were analyzeda.

the experiment comprised  <dig> blocks lasting for six to seven minutes each . a block comprised  <dig> standard stimuli  and  <dig> deviant stimuli ,  <dig> of which were targets . attention instruction was changed every two blocks. participants were blindfolded throughout the experiment. the correct position of the cap was achieved by aligning it at the nasion, the inion, and the preauricular points. the participant’s head was immobilized by using a chin rest. moreover, participants were instructed to avoid excessive blinking, eye and head movements during a run. breaks after a block were allowed whenever the participant wanted. the duration of the eeg experiment without any breaks was about  <dig>  hour. including breaks, practice and the electrode-preparation and removal, the whole experimental session lasted between  <dig> and  <dig> hours.

electroencephalographic recording
the eeg was continuously recorded from  <dig> ag/agcl electrodes mounted equidistantly in an elastic cap . the central electrode m_ <dig>  is positioned between fz and cz of the international 10– <dig> system. the horizontal electro-occulogram  was assessed with a bipolar recording of two electrodes attached to the outer canthi of the eyes, the vertical eog  was monitored with an electrode placed under the right eye against the common reference. all electrodes were referenced to the right earlobe during recording and were re-referenced off-line to the averaged left and right earlobe references. impedances were kept below  <dig> kΩ for scalp recordings and below  <dig> kΩ for eog recordings by preparing the skin of participants with every  and alcohol. eci electrogel  served as the electrolyte for all electrodes. the ground electrode was placed on a position at the middle of the forehead . signals were amplified with two synamps-amplifiers . the sample rate was  <dig> hz and the bandpass was set to  <dig>  –  <dig> hz. signals were recorded continuously and saved on a hard disc.

data analyses
behavioral data
a response was classified as a hit if it occurred within a time window of  <dig> to  <dig> ms following a target stimulus. all other responses were considered as false alarms . trials in which the participants did not respond to a target were defined as misses. the miss rate was derived by dividing the total number of misses by the total number of target trials. correct rejections were defined as non-responses to deviants at the non-attended location.

performance accuracy for discriminating the positions as a function of emotional prosody was assessed for each participant by calculating d’ ) − z);  <cit> ). the hit rate was defined as the number of correct responses to target stimuli spoken by the attended voice at the attended position divided by the total number of targets. the false alarm rate  was defined as the number of incorrect responses to deviant stimuli spoken by the attended or by the unattended voice but at the unattended position divided by the number of deviants at the unattended position.

mean reaction times  and percent correct were calculated for each condition and participant from which we derived inverse efficiency scores)  in order to compensate for possible speed-accuracy trade offs . for calculating ie scores, mean rt are divided by percent correct  <cit> . trials with reaction times below  <dig> ms or exceeding  <dig> ms were disregarded. analyses of variance  with the repeated measurement factor emotional prosody  were run for the dependent variables d’ and inverse efficiency scores. a main effect of emotion was further analysed with t-tests  for dependent samples. percent correct  and reaction times are reported in table  <dig> 

erp data
the continuous eeg was epoched from  <dig> ms prior to the stimulus onset until  <dig> ms after stimulus presentation separately for each participant and condition. the pre-stimulus interval was defined as baseline. only segments following standard stimuli were analyzed, segments with responses to standard stimuli were discarded.

artifacts due to eye movements , muscle activity  or amplifier saturation  were eliminated prior to averaging. the averaged erp to standard stimuli of each participant is based on  <dig> to  <dig> trials  and four emotional expression conditions). participants with a rejection rate of higher than 40% of the epochs were discarded. adjacent recording sites were combined to clusters of three electrodes each , resulting in eight clusters for each hemisphere. the number of electrode sites  was reduced to  <dig> electrode clusters in order to reduce the number of statistical comparisons and still guarantee a satisfying coverage of the frontal, temporal and parietal scalp of both hemispheres. each cluster score represents the mean amplitude of three adjacent electrodes. they were located either on the left or right hemisphere of the head.

since no middle-line electrode was included in the electrode clusters, m_ <dig> was additionally analyzed because it is well known that the auditory vertex potential has its maximal amplitude at this site. clusters of the left and right hemisphere were converted to the hemisphere ipsilateral or contralateral to the stimulation. this calculation  was included because we expected the attention and emotion effects to be higher at contra- than ipsilateral electrode sites. we report results of the central electrode m_ <dig> first and then report the cluster analysis in order to show the robustness of our results. we report significant contrasts between erps following stimuli in different emotional prosodies in table  <dig> 

numbers without the letters i or c denote bilateral cluster activation.

for statistical analyses, mean amplitudes were calculated for the following three time epochs: first time window , second time window , and third time window . time windows were chosen by visual inspection and mean amplitudes were calculated around peak values of the grand average . we expected early attention and affective prosody effects in the time range of the n <dig> and p <dig> 

for each time epoch mean amplitudes of erps were submitted to anovas comprising the four repeated measurement factors, spatial attention , emotional prosody , cluster , and hemisphere . higher order interactions were followed up with appropriate sub-anovas or t-tests. recordings from the fronto-central electrode m_ <dig> were analyzed without the factors hemisphere and cluster.

additionally, we calculated erp difference waves  for each emotion . an anova including the factors emotional prosody , hemisphere  and cluster  was run. the anova for the electrode m_ <dig> was run with the factor emotional prosody only.

all statistics were computed with the program package spss, subroutine glm for repeated measurements. greenhouse geisser -corrected p-values are reported  <cit> . in order to prevent an inflation of the alpha error, the bonferroni-correction  was applied.

in the following result section, we first report the behavioral data including d’ scores and ie scores. in the erp result section we first report the results for site m_ <dig> followed by the results for the analyses including all clusters.

RESULTS
behavioral data
d’ scores
participants were well able to discriminate the two positions . moreover, the anova with the repeated measurement factor emotional prosody and d’ scores as dependent variable revealed a main effect of emotional prosody  =  <dig> , p < .01). d’ scores tended to be higher for neutral  compared to happy, threatening and fearful voices, although this difference failed to reach significance  =  <dig> , p < .1; neutral versus threatening: t =  <dig> , p < .1; neutral versus fearful: t =  <dig> , p > .1) . there were no differences in d’ scores between happy, threatening and fearful emotional prosodies  .

ie scores 
using ie scores as dependent variable, the main effect of emotional prosody was marginally significant  =  <dig> , p < .1). ie scores were lower for neutral  compared to threatening voices   = − <dig> , p < . <dig> ). all the other comparisons were not significant .

event-related brain potentials
m_4
see figure  <dig> for the spatial attention effect, figure  <dig> for difference waves  minus erp ), and figure  <dig> for the emotional prosody effect at the attended and unattended position for recording site m_ <dig> 

110– <dig> ms: in the latency range of the n <dig> the overall anova revealed a main effect of spatial attention  =  <dig> , p < .01), a main effect of emotional prosody  =  <dig> , p < .001), and an interaction of spatial attention and emotional prosody  =  <dig> , p < .05). the n <dig> was more negative going to spatially attended than spatially unattended standards . separate subordinated anovas for different emotional prosodies found a significant enhancement of the n <dig> to standard stimuli due to spatial attention for fearful stimuli  =  <dig> , p < .01), while this effect was not significant for neutral, happy, and threatening stimuli  =  <dig> , p > .1; happy: f = . <dig>  p > .1; threatening: f = . <dig>  p > .1).

moreover, subordinated anovas confirmed that the effect of emotional prosody was significant at both the attended and the unattended location but the higher f-value for the attended  =  <dig> , p < .001) than the unattended position  =  <dig> , p < .01) suggests a stronger emotional prosody effect at the attended location . post-hoc t-tests revealed that erps to happy stimuli were significantly less negative going than erps to neutral stimuli at both attended and unattended positions  = − <dig> , p < .01; unattended: t = − <dig> , p < .05). the erp to threatening stimuli was less negative going than the erp to neutral stimuli only if stimuli were attended  = − <dig> , p < .01; unattended t = − <dig> , p > .1). the erp to fearful stimuli did not differ from the erp to neutral stimuli, but the erp to fearful stimuli was significantly more negative than the erp to happy stimuli at the attended position  =  <dig> , p < .01; unattended: t =  <dig> , p > .1). at the attended position erp differences between threatening and fearful stimuli reached the significance level  =  <dig> , p < .01) while the difference between happy and threatening voices was only marginally significant  =  <dig> , p < .1). happy stimuli elicited the least negative going erp, followed by threatening stimuli.

the anova for the difference waves  minus erp , see figure 4) found a significant main effect of emotional prosody  =  <dig> , p < .05)b.

190–260: the overall anova revealed a highly significant main effect of spatial attention  =  <dig> ; p < .01) in the absence of a significant interaction of spatial attention and emotional prosody  =. <dig>  p > .1). the spatial attention effect consisted of a more negative erp to stimuli at attended positions .

in addition, the overall anova found a significant main effect of emotional prosody  =  <dig> , p < .001). post-hoc t-tests comparing the different emotion conditions averaged across the two levels of spatial attention revealed that the erp to neutral stimuli was significantly different from erps to stimuli in all other emotional prosodies  = − <dig> , p < .05; neutral vs. threatening: t = − <dig> , p < .05; neutral vs. fearful: t =  <dig> , p < .01): fearful stimuli elicited a more negative erp than neutral stimuli, and happy and threatening stimuli elicited less negative going erps than neutral stimuli. the differences between erps to happy and fearful stimuli and between threatening and fearful stimuli were significant, too  =  <dig> , p < .01; vs. fearful: t =  <dig> , p < . <dig>  see figure 5).

the anova for the difference waves  did not reveal a main effect of emotional prosody  = . <dig>  p > . <dig>  see also figure  <dig> and endnoteb).

260–350: the overall anova revealed a highly significant main effect of spatial attention  =  <dig> , p < .001) but no interaction of spatial attention and emotional prosody  = . <dig>  p > .1). the spatial attention effect consisted of a more negative erp to stimuli at attended positions . the overall anova found a significant main effect of emotional prosody  =  <dig> , p < . <dig>  see figure 5). as revealed by post-hoc t-tests, the erp to happy stimuli was less negative than the erp to neutral voices  = − <dig> , p < .01), whereas the erp to fearful stimuli was only marginally significant more negative than the erp to neutral stimuli  =  <dig> , p < .1). the erp to threatening stimuli did not differ significantly from the erp to neutral stimuli, but erp-differences between happy and threatening  =  <dig> , p < .01) as well as between threatening and fearful stimuli  =  <dig> , p < .05) reached the significance level. moreover, erps to happy and fearful stimuli differed from each other  =  <dig> , p < .01).

the anova for the difference waves  did not reveal an effect of emotional prosody  = . <dig>  p > . <dig>  see figure  <dig> and endnoteb).

cluster
figure  <dig> shows the grand mean event-related potentials to voice stimuli with a neutral , a happy , a threatening  and a fearful  prosody.

figure  <dig>  summarizes the corresponding significant main effects of spatial attention and emotional prosody, and the interactions of these factors for the three time windows and for each cluster.

110– <dig> ms: in the overall anova the interactions of spatial attention and emotional prosody  =  <dig> , p < .05), of spatial attention and cluster  =  <dig> , p < .05) as well as of spatial attention, emotional prosody, and cluster reached significance  =  <dig> , p < .05). the spatial attention effect was significant at cluster  <dig>  =  <dig> , p < .05), and marginally significant at clusters  <dig> and  <dig> . when analyzing emotional prosodies separately, a main effect of spatial attention was found for fearful stimuli  =  <dig> ; p < .01; interaction of spatial attention and cluster: f =  <dig> , p < .01); this effect was reliable at clusters  <dig>   <dig>   <dig>   <dig>  and  <dig> ). an interaction of spatial attention and cluster was significant for threatening stimuli  =  <dig> ; p < .05) as well. however, no more than a marginally significant main effect of spatial attention was found for cluster  <dig>  =  <dig> ; p < .1).

moreover, the overall anova revealed a highly significant main effect of emotional prosody  =  <dig> , p < .001), and an interaction of emotional prosody and cluster  =  <dig> , p < .001). main effects of emotional prosody were highly significant at the attended position  =  <dig> , p < .001) as well as at the unattended position  =  <dig> , p < .001). the emotional prosody * cluster interaction was significant at both the attended and the unattended position . at clusters  <dig>   <dig>   <dig>   <dig>  and  <dig>  main effects of emotional prosody were confirmed for stimuli at the attended  as well as for stimuli at the unattended position . at the posterior clusters  <dig> and  <dig> the emotional prosody effect reached significance only at the unattended position . table  <dig> summarizes the significant comparisons between emotional prosodies  at the different clusters.

the anova for the difference waves  revealed a significant effect of emotional prosody  =  <dig> , p < .05; see endnoteb).

190– <dig> ms: more negative erps in the attended than in the unattended condition were observed. because of significant interactions of spatial attention and cluster  =  <dig> , p < .01) as well as of spatial attention, hemisphere and cluster  =  <dig> , p < .05) in the overall anova, separate anovas for single clusters were calculated ). the spatial attention effect was significant for all clusters , and with the exception of cluster  <dig>  the interaction of spatial attention and hemisphere was significant for all clusters  as well. at clusters  <dig>   <dig>   <dig>  and  <dig>  the main effect of spatial attention was found at contralateral as well as at ipsilateral clusters . at clusters  <dig>   <dig>  and  <dig>  this effect was significant only at ipsilateral clusters . moreover, the overall anova revealed a highly significant main effect of emotional prosody  =  <dig> , p < .001), and a significant interaction of emotional prosody and cluster  =  <dig> , p < .001). a significant main effect of emotional prosody was found at all  <dig> clusters . table  <dig> summarizes the significant comparisons between emotional prosodies  at the different clusters.

the anova for the difference waves  did not reveal a significant main effect of emotional prosody  = . <dig>  p > .1; see endnoteb).

260– <dig> ms: a significant main effect of spatial attention was observed  =  <dig> , p < .05). the interactions of spatial attention and cluster  =  <dig> , p < .001), of spatial attention and hemisphere  =  <dig> , p < .01), and of spatial attention, hemisphere, and cluster  =  <dig> , p< .05) reached the significance level as well. the spatial attention effect was reliable at clusters  <dig> to  <dig>  . at these clusters and at cluster  <dig>  the spatial attention * hemisphere interaction reached significance, . at clusters  <dig>   <dig>  and  <dig>  the spatial attention effect was found at ipsilateral as well as at contralateral clusters . at clusters  <dig> and  <dig>  the effect was significant only at ipsilateral clusters , at contralateral clusters marginal effects were observed .

moreover, in the overall anova the main effect of emotional prosody  =  <dig> , p < .001) as well as the emotional prosody by cluster interaction were highly significant  =  <dig> , p < .001). the effect of emotional prosody was significant at all clusters  with the exception of the posterior cluster  <dig> 

the anova for the difference waves  did not reveal an effect of emotional prosody  = . <dig>  p > .1; see also endnoteb).

in sum, the posthoc t-tests for single clusters largely confirmed the results obtained for m_ <dig> .

discussion
the present study investigated effects of spatial attention and emotional prosody on the processing of vocal stimuli. two-syllable pseudo-words spoken in four emotional prosodies  were presented in a random order from two spatial positions. participants attended to one position only in order to detect infrequent deviant stimuli. both behavioral and erp indices of stimulus processing were assessed. the main findings were as follows:

even though marginally significant, neutral targets were detected with a higher precision than targets spoken in a happy, threatening or fearful prosody.

erps differed as a function of emotional prosody both at the spatially attended and spatially unattended location. importantly, the early spatial attention effect  was mostly pronounced for fearful stimuli. the n <dig> following fearful stimuli was more negative than the erps following neutral stimuli, while erps elicited by happy and threatening stimuli were less negative than erps to neutral stimuli. the emotional prosody effect was significant for stimuli at attended and unattended positions.

behavioral processing of vocal prosody
in most previous studies, aversive stimuli have been found to be detected faster than neutral or positive emotional stimuli  <cit> . by contrast, in the present study, detection rates were higher and processing was more efficient for neutral compared to happy, threatening and fearful stimuli. in the present study targets were defined as two different rather than two identical syllables. if the emotional prosody is partially automatically extracted, as suggested by the present results, it seems plausible to assume that the emotional tone might have distracted the participants and thereby caused lower target identification based on syllables. however, this speculation has to be treated with caution since the number of targets was relatively low.

early erp modulations by spatial attention for fearful human voices
the finding of an enhanced negativity starting in the latency range of the n <dig> replicates once again the well known spatial attention effect discovered by hillyard et al.  <cit> . early attention effects starting around  <dig> ms post-stimulus are generally found for easy to discriminate channels such as two locations one in the left and one in the right hemifield  <cit> .

however, it might be wondered why reliable spatial attention effects starting in the n <dig> time range were mainly seen for fearful voices while later erp spatial attention effects emerged similarly for all emotional prosodies. a specific processing for fearful stimuli has often been reported  <cit>  and has been seen as adaptive in a social context.

on the other side, it has to be noticed that relatively long isis were used in the present study. it is well known that n <dig> attention effects are most likely if short isis are employed  <cit> . this might explain why attention effects for most of the emotional voices were observed relatively late. however, on this background, the earlier emergence of spatial attention effects for fearful stimuli stress the preferred processing and specific enhancement of the processing of these stimuli by spatial attention.

according to treue  <cit> , bottom-up features of the stimulus itself and attentional top-down influences are integrated in a common saliency map which is a representation of the environment that weighs every input by its sensory features and behavioral relevance. stimuli of high salience are processed even if unattended, while the processing of less salient unattended stimuli is suppressed. applied to the present study, the spatial attention effect in the n <dig> time range might be interpreted as a release of an active suppression of the processing of task irrelevant fearful stimuli or as a further enhancing of the processing of this stimulus class. the finding that the n <dig> amplitude of erps to fearful stimuli arose as a function of spatial attention to the level of the n <dig> to neutral stimuli might be interpreted as evidence for the first interpretation.

it might be argued that emotion specific features  cause the differences between erps to emotional stimuli.

of course, we cannot rule out the possibility that other low-level features contribute to the n <dig> emotional prosody effects. accordingly, previous research has suggested that a number of acoustic features such as fundamental frequency  and intensity differ among different emotional utterances  <cit> . as described, our stimuli varied in fundamental frequency as a function of emotional category as well, suggesting that our actors were able to produce valid stimuli. eliminating these features would be equal to eliminating emotional prosody. however, there are many arguments, why our results cannot be fully accounted by simple differences in physical stimulus features: first, we controlled for the duration of stimuli across all emotional prosodies. second, the successful control of physical stimulus features is supported by similar latencies of the vertex potential across the four emotional prosodies . third, physical stimulus features would be expected to mainly affect exogenous erps, in other words maximally the vertex potential. however, we observed erp differences as a function of emotional prosody for all analyzed time epochs. fourth, erp differences due to physical stimulus features are supposed to be independent of top-down modulation that is attention in our study. however, the n <dig> amplitude differences between different emotional prosodies were different for the attended and the unattended condition.

modality specific processing of emotions and the influence of spatial attention
the present results coincide with the results reported by sauter and eimer  <cit>  who used human vocalizations as stimuli and found an erp positivity  for different emotions  compared with their spectrally rotated counterparts analog to previous findings for emotional faces  <cit>  and pictures  <cit> .

similar findings for the processing of auditory and visual affective stimuli are surprising, however. for auditory processing, the existence of subcortical pathways to the amygdala has been demonstrated by studies of fear conditioning to acoustic stimuli in rats and guinea pigs  <cit> . this subcortical route has been suggested to be particularly fast and to enable a quick detection of emotionally relevant stimuli. for the processing of facial stimuli, several studies have proposed a fast subcortical pathway as well  <cit> . however, according to pessoa and ungerleider  <cit>  such a short route has not yet been unequivocally demonstrated in the visual system. indeed, pessoa and ungerleider  <cit>  have found an enhanced processing of emotional faces only when they were attended. these authors argue that a detailed analysis of facial features is rather impossible via a subcortical route . this would argue for a quicker and more automatic processing of auditory emotional stimuli compared to visual emotional stimuli. on the other hand, the identification of the valence of auditory stimuli requires the integration of the auditory stream across an extended time epoch while visual scenes are picked up at one glance. however, in contrast to visual stimuli which in most cases need to be foveated in order to be identified, no overt shifts of attention are necessary to identify auditory stimuli. in line with this reasoning we found that erps differed as a function of emotional prosody both in the spatially attended and the spatially unattended channel. thus, the emotional valence of auditory stimuli might be partially extracted automatically or at least without spatial attention. this conclusion is in agreement with the brainimaging results of klinge et al.   <cit>  who did not find a difference in amydala activation as a function of whether or not the emotional prosody of voices had to be attended. by contrast another fmri study found that when all auditory input had to be completely discounted   <cit>  a differential activation of the amydala for different emotional prosodies did not emerge. by manipulating spatial attention within the auditory modality, our experiment more resembles the within modality manipulation of klinge et al.   <cit> .

therefore, we interpret our results in line with reports suggesting that the emotional valence of stimuli can be extracted in the absence of  attention, but that attention nevertheless modulates emotional processing  <cit> .

finally, it has to be pointed out that we observed different prosody effects for early and later erps, i.e. processing steps. this observation might be related to the two roads of emotion processing proposed by ledoux . the “quick but dirty low road” is assumed to mediate an automatic processing of both attended and unattended events. while it seems not to be able to fully distinguish the whole range of emotional prosodies, e.g. two different aversive stimulus classes, such as fearful and threatening stimuli, at least not at unattended locations, the slower “high road” allows for a more elaborated and differential processing of both attended and unattended stimuli. this finding would suggest that later erp effects of emotional prosody are independent of spatial attention.

CONCLUSIONS
the present results suggest that while emotional prosody is processed independent of spatial attention, spatial attention nevertheless modulates the degree of voice processing as a function of emotional valence at sensory processing stages. by contrast, at later stages emotional prosody is processed independent of the focus of spatial attention. further research has to investigate whether this rule holds for stimuli of other modalities or other types of attention  as well.

endnotes
aoriginally, the main experiment comprised an additional orthogonally manipulated factor. participants had to selectively attend to one voice only. however, the voices of the two female speakers were too similar and participants did not manage to distinguish between them. even after excluding participants  with very low performance in discriminating the voices , mean d’ ) - z)  for the remaining participants  was low .

bsee results of the overall anova .

abbreviations
eeg: electro-encephalogram; erp: event-related potential; sts: superior temporal sulcus; eog: electro-occulogram; fa: false alarm; rt: reaction times; ie score: inverse efficiency score; anova: analysis of variance.

authors’ contributions
jg and br designed the experiment. jg run the erp experiment. jg, jf and br analyzed the data. jg, jf, and br wrote the paper. all authors read and approved the final manuscript.

