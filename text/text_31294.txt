BACKGROUND
for each sequenced genome, the basic step of annotation is the prediction of genes. in prokaryotes, an average of over 80% of the genome consists of genes which are mostly protein coding
 <cit> , meaning that correct identification of protein coding genes is a key aim in computational biology. a complicating factor is that a fraction of microbial genomes consist of degenerated genes with no remaining functionality
 <cit> . a gene finder must therefore be a rather complex ’engine’ capable of distinguishing real protein-coding genes from dna sequence regions consisting of degenerated genes, non-coding regions and more. to map genes, gene finders typically identify a set of gene-candidates commonly referred to as open reading frames . the number of orfs found by gene finders is typically large compared to the true number of genes. to reduce the number of orfs and minimize the false predictions of real protein-coding genes, a gene finder must take into account several genomic properties like the existence of upstream regulatory sequences , degree and type of overlap between open reading frames, as well as the content of the coding genes themselves. considering the above mentioned properties, a gene finding procedure can be sketched as follows: 1) identify all possible orfs in the genome, 2) score all orfs by various criteria, e.g. their length, their base composition, their upstream sequence, their overlap with other orfs, etc. 3) classify orfs as coding genes or non-coding regions based on the scores achieved in the previous steps.

although the performance of prokaryotic gene finders is relatively good compared to eukaryotic gene finders
 <cit>  there is room for improvement. prokaryotic gene finders have a tendency to be biased towards identifying false positive orfs
 <cit> . short genes are difficult to identify correctly
 <cit> , and genes in gc rich genomes are challenging to predict accurately
 <cit> . it is therefore important that proper algorithms for coding sequence modeling are implemented in gene finders. algorithms used by gene finders should have the ability to extract sequence parameters from coding sequence modeling of putative genes , and then classify new genes as orfs based on similarity to the estimated sequence parameters
 <cit> . several popular gene finders use models based on some sort of markov chain methodology to identify orfs
 <cit> . markov chain based models are ”trained” on a set of sequences  and use the statistical parameters extracted from this training to classify new sequences
 <cit> . the training procedure in glimmer3
 <cit> , which is a markov chain-type model, identifies long orfs from dna sequences which are used to build the interpolated context model. the interpolated context model  is then used to classify orfs in dna sequences having similar characteristics to the training data sequences. this means that the classification power of gene finders based on training relies heavily on the properties of the sequence data used. thus, for gene finders, it is important that the sequence data used for training has as many general characteristics of genes as possible, which emphasizes the relevance of procedures that facilitates sequence data for accurate gene prediction. to obtain sequence data that may have such characteristics we turn to pangenomics
 <cit> . the re-sequencing of multiple strains within the same species or phylotype has resulted in the study of microbial pangenomes
 <cit> . a pangenome is the collection of genes found in all strains within a population. by considering the set of highly conserved genes within a pangenome, we are close to obtaining a data set consisting of “true” genes since these sequences are highly conserved across many strains and are therefore considerably more reliable than data sets based on genes from one genome sequence only. thus, we argue that data sets consisting of genes obtained from pangenomic inspired analyses may be an adequate starting point for a general testing and comparison of gene finders. indeed, we use such sequence data to compare the capabilities of a multivariate coding sequence modeling algorithm using different methodology to that of the markov chain based coding sequence modeling algorithms. although multivariate methods  are extensively applied in other scientific fields only one such method known to the authors has been suggested as a gene finding algorithm
 <cit> . data sets used for gene finding typically have a large number of variables p  in comparison to the number of orfs n. as a consequence we have to deal with the unbalanced p >n situation, making it hard to classify orfs since unique estimates cannot be found. multivariate tools like partial least square  regression are widely used to address unbalanced p >n problems
 <cit> . a recent advancement to the pls regression scheme combines a novel data compression method, canonical correlation analysis , to additionally estimate latent variables enhancing classification in regression type problems even further. this method has been termed canonical powered partial least squares 
 <cit>  and we explore the performance on the modeling of coding genes.

method
approach
gene modeling data
the genomic data which was used to train the coding sequence modeling algorithms was divided into two groups. one group, termed ‘positives’, contained orfs considered to be real genes. the other group, termed ‘negatives’, consisted of orfs known to be non-coding, i.e. sequences recognized as non-genes. we only considered protein coding genes in this study.

positives
to assure that the data set representing coding genes was as reliable as possible, we applied an approach, outlined below, based on refseq
 <cit>  annotated genes from multiple strains . refseq genes are considered to be comprehensive, non-redundant and well-annotated. we studied  <dig> prokaryote species having at least  <dig> completed genomes with refseq-annotations available . genomes that were sequenced twice were excluded. all the genomes of these species were downloaded from ncbi , together with their refseq-annotated genes . the lists of refseq genes for all genomes within each species were compared by an all-against-all reciprocal megablast
 <cit>  search. for any two orfs, a pairwise distance was computed as follows: if s is the bitscore of the alignment between query sequence i and database sequence j, the distance between them is given by: 

  d=1−s+ss+s 

an overview of the species used in the current study along with respective group, number of genomes and gc-content.

where d always gives a value between  <dig> and  <dig>  next, all orfs were represented as nodes in an undirected graph, with edges added between two nodes if the corresponding distance d between them was below or equal to some threshold t that designates sequence similarity. hence, we considered two orfs to be connected if they were sufficiently similar according to a specified threshold value t. if multiple orfs fulfill this similarity criterion a graph will form consisting of many nodes . such a graph will form clusters of connected nodes. clusters with nodes designating orfs from the genomes of multiple strains are more likely to be real coding genes since they are conserved across several genomes. a highly conserved orf  is therefore represented as a graph with nodes from the genomes of all respective strains within a species. for each hco cluster, the node  with the smallest sum of distances, as measured using the weighted edges to all other nodes  in the same cluster, was extracted. such nodes are referred to as medoids. the medoide thus represents the whole hco cluster. the same procedure is subsequently applied repeatedly generating a list of hcos for each species. the list of hcos for each species contains our candidate genes and we designate that set as positives. for illustration purposes figure
 <dig> shows a visualized graph for a very small data subset taken from acinetobacter baumannii.

negatives
algorithms involved in coding sequence modeling must separate sequences that are genes and sequences that are not genes. sequences that are not genes are designated negatives. the set of negatives will further enable classifying sequences as coding or non-coding genes. negatives are considerably harder to identify than positives since prokaryotic genomes are densely covered with genes. even if a sequence is not among our hcos it may very well be a coding gene, or at least part of a coding gene. however, the reading frame is an indispensable concept with respect to coding sequences, as elaborated by
 <cit> , and due to different selection pressure in-frame and out-of-frame sequences are evaluated differently and form completely separate clusters
 <cit> . consequently, we consider the out-of-frame interior from the set of positives as negatives in the current study. this implies that no positive has a complete overlap with another positive. it is, however, typically accepted that functional genes in prokaryotes can overlap over short stretches
 <cit> . hence, a small fraction of our negatives may actually be part of a gene, making negatives difficult to classify correctly. there are always  <dig> out-of-frame reading frames, and all are considered as negatives, i.e. for each positive we have  <dig> negatives. sequences designated as negatives will hence not have a proper start and stop codon, but are likely to contain spurious stop codons since they are out-of-frame. in order to use this approach, we therefore eliminated the first start- and all stop-codons from every sequence labeled as either negative or positive.

data splitting and cross-validation
for each species, the sets containing positives and negatives were randomly divided into  <dig> equally sized subsets. one of these subsets was used as test data while the other  <dig> subsets were used as training data. the procedure was repeated in a 10-fold cross-validation.

orf sequence representation
genes can be represented as dna sequences, codon sequences or protein  sequences. we describe all representations below with respect to coding sequence modeling.

dna sequences
the dna alphabet consists of  <dig> symbols; but the reading frame concept must also be taken into consideration. hence, the bases we observe in codon positions  <dig>   <dig> and  <dig> must be considered separately, otherwise it is impossible to distinguish in-frame from out-of-frame sequences. markov chain models therefore need three separate sets of transition probabilities, each set corresponding to the target symbol in reading frame  <dig>   <dig> or  <dig>  the pretext, i.e. the subsequence a markov chain model is conditioned upon, consists of all preceding k symbols regardless of which reading frame is considered. a markov chain model will therefore traverse a dna sequence, nucleotide by nucleotide, constantly consulting transition probabilities from all reading frames. such is the case for genemark
 <cit>  and glimmer
 <cit> . from this perspective, the dna alphabet of coding sequences has  <dig> ∗  <dig> =  <dig> and not  <dig> symbols.

codon sequences
each protein coding gene may also be represented by its codon alphabet. the codons consist of three consecutive nucleotides and code for amino acids, thereby giving  <dig> possible combinations. ignoring the  <dig> exclusive stop codons,  <dig> symbols are free to code for amino acids. since there are only  <dig> different standard amino acids, the codon alphabet is redundant. in other words, some codons code for the same amino acid. hence, some codons are synonymous while others are non-synonymous. in fact, the redundancy of the codon alphabet allows organisms and genes to prefer specific codons coding for specific amino acids. this is typically known as codon bias
 <cit> . although the codon alphabet, with its  <dig> symbols, provides more resolution than the dna and protein alphabets, the added information can be a computational challenge.

protein sequences
due to the redundancy of the codon alphabet gene comparisons may often be more successful using protein sequences. since different codons can code for the same amino acid, dna sequences representing homologue genes may be very different in terms of base composition and therefore hard to detect using dna based search engines. in such cases, using protein sequences instead of dna sequences may give better results since there is no redundancy. protein sequences are expected to be highly conserved by purifying selection, in contrast to the more variable dna sequences
 <cit> .

algorithm
classification of coding sequence
the methods used to classify genes were interpolated markov model 
 <cit>  and canonical powered pls 
 <cit> . both models need to be trained and from the training data set of n sequences we create a n ×  <dig> numeric response vector y containing the value  <dig> if the respective sequence is from the positive set and - <dig> if the respective sequence is from the negative set.

interpolated markov models 
markov chain models are widely used to detect patterns in biological sequences. unfortunately, these models are hampered by the necessity to find the appropriate order of the markov chain. a higher order markov chain model has more parameters and therefore less bias since it is capable of describing more accurately the real probabilities behind the observed sequences. however, for a fixed size data set the information per parameter is less, resulting in estimators with increased variance
 <cit> . thus, the improvement obtained due to less bias may be lost to the increased variance. a fifth order markov chain model is employed by genemark, while the gene finding algorithm in glimmer is based on the interpolated markov model . the latter model  estimates several chains with different orders, of which the separate scores are subsequently combined into one, making it a more general approach than the prior 5th order model. since we are comparing coding sequence modeling algorithms we use the imm approach used by the glimmer software
 <cit> . this means that the final probability of a symbol is a linear combination of several markov chain models from order k =  <dig> up to some upper limit k = k, where the markov chain transition probabilities from various orders are weighted based on the size and information content of the training data. some additional effort is required to estimate these weights since there is no closed form solution for the maximum of the likelihood function. the expectation maximization  algorithm
 <cit>  is applied iteratively to find local optimum solutions which are consequently applied to optimize the weights used in the linear interpolation. from the training data two interpolated markov chain models are fitted, one for positives  and the other for negatives . thus, for both positives and negatives we need to estimate the transition probability matrices
t1+,…,tk+ along with the weights used in the interpolation procedure. then, for each sequence from the test data the posterior log-probability scores for the positive and negative models are computed using the estimated transition probability matrices and weights. finally, each test set of sequences is assigned to the class  depending on the log-probability score. in an approach like this, the upper model order k must be restricted due to space and computation time limitations. for the codon alphabet, having  <dig> symbols, even a second order model  includes  <dig> =  <dig> transition probabilities, and is therefore computationally very slow. also, a training set of considerable size is required to estimate all probabilities with reasonable variance. the addition of pseudo counts is considered useful method to stabilize the estimates of a markov chain model
 <cit> . we have chosen to use this as well, but in a very careful way. if we have m observations  in our data set, we add
m <dig> pseudo counts as well, all having probabilities given by a 0-order markov chain model for the positives or negatives, respectively.

canonical powered pls 
from the training data set of n sequences, together with response y, the predictor n × p matrix x is formed by word frequencies for each sequence from the training data. a word is a fixed length consecutive segment from the sequence. since the amount of information required for a kth order markov chain model corresponds to k +  <dig> word frequencies, all words of length from  <dig> up to k +  <dig> were included to make this approach comparable. the association between y and the predictor matrix x is assumed to be explained by the linear model, i.e. 

  e=xβ 

β are p regression coefficients relating every word frequency to the class status . this results in a ’large p and small n’ situation, where ordinary least squares type methods provide poor solutions. the pls method can estimate the regression coefficients for such a case using an iterative procedure described in
 <cit> . there are many algorithms in the pls-family, and for classification purposes we use the cppls method
 <cit> . thus, from the training data we estimate the regression vector β describing the contrast between positives and negatives. for a given test sequence, the corresponding word frequency  <dig> × p vector x is computed. based on the cppls estimated regression coefficients
β^ a score is predicted by
y^=xβ^ classified as + <dig> or - <dig>  that is as negative or positive
 <cit> .

model sizes
in general, the performance of a classifier is linked to the number of parameters being estimated. for the markov chain model, this means the number of transition probabilities and weights, while for the pls-approach it means the number of regression coefficients. the optimal model complexity, which is measured by the number of free parameters, is always a trade-off between bias and variance
 <cit> . since comparisons are carried out between different methods and sequence representations, there should be a comparable number of parameters. table
 <dig> presents the number of transition probabilities to be estimated for all three sequence representations using interpolated markov chain models of different orders. it appears that for a reasonably fair comparison with the cppls method, the interpolated markov chain model should be of order  <dig> for dna, order  <dig> for protein and order  <dig> for codon sequences. it is important to recall that the number of transition probabilities required for a kth order markov chain model corresponds to k +  <dig> word frequencies. hence, for the cppls method frequencies of 4-words, 3-words and 2-words are used for codon, protein, and dna sequences, respectively.

the columns represent the number of transition probabilities to be estimated with an interpolated markov model from k =  <dig> to k =  <dig>  while the rows designate the different sequence types . the number of probabilities in a kth order imm corresponds to the number of regression coefficients for the k +  <dig> word frequencies in the cppls method.

mixed effect model
the main objective of the study is to make comparisons of methods  and sequence representations  on the ability to classify coding sequences. the study has been conducted on genomes from many different species, and in order to present all results in a single analysis, we have adopted an analysis of variance  approach. we were primarily interested in how the choice of method and sequence representation affected the classification performance , and the  variability in results between species should be considered as random ’noise’ in the analysis. this was accomplished by the use of a mixed-effect anova model, where the fixed effects on performance are the focus of our attention  and a random effect of species is included to deal with variation between species.

the performance is defined as the percentage of correctly classified orfs in a test data set using 10-fold cross validation. anova analyses assume constant performance variance at different levels of the fixed effects, which was originally not the case in our data set. to stabilize the variance, the original performance y  was transformed to z as
z=sin−1y/ <dig> 

we fitted the following mixed effect model 

  zi,j,k=μ+αi+βj+i,j+sk+ei,j,k 

where the outcome zi,j,k is the observed transformed performance, μ is the overall expected transformed performance level, αi is the fixed effect of method i =  <dig>   <dig>  βj is the fixed effect of sequence representation j =  <dig> , <dig>  i,j is the interaction term combining method i and sequence representation j, sk is the random effect of species k =  <dig>  …,  <dig> and ei,j,k is the residual variation. as part of the model assumptions in a standard anova we used normal distributed error terms
sk∼n and
ei,j,k∼n.

RESULTS
data sets
even if the refseq database is curated, there may still be errors. in order to eliminate uncertain sequences we only considered those which were conserved across all genomes within each species. additional file
1: figure s <dig> shows how the number of gene clusters grows by the choice of threshold t, which represents the similarity between sequences inside a cluster. in our analysis we have chosen to use t= <dig> , meaning that clusters will contain sequences that are roughly 100%  = 70% similar. for each such cluster having members from all genomes, we allocate the medoide sequence to the set of positives for the corresponding species. as seen from additional file
1: figure s <dig>  this results in a rather large number of positives for all species and we are assured that these sequences are coding genes. so instead of taking all hcos at t =  <dig> , if a species has more than  <dig> hco’s, we sampled  <dig> sequences at random as positives. we have chosen to use as negatives sequences that constitute the out-of-frame interior of the positives. the reason for this is actually straightforward; coding genes predominantly cover prokaryotic genomes therefore the intergenic regions are few and small. for instance, the refseq annotated genes cover, on average, more than 92% of the genomes in this study. on the other hand, annotations of genes with large overlaps are few in number; therefore we assume that if there is some region where we know there is a coding gene, there will be a small chance that any other coding gene is present in the same region. thus, we presume that sequences from the out-of-frame interior of the positives are the types of sequences that have the same base compositional properties as the majority of non-coding orfs . we also eliminated the first codon  as well as all stop-codons from both positives and negatives, in order to make the classifications based on the content and not the endpoints.

coding sequence recognition
in figure
 <dig> we show the distributions of performance for each species by applying both the imm and cppls methods on codon, protein and dna sequences. the difference between the imm method  and the cppls method  is the most striking result. it can be seen that the codon representation  appears to be better than protein and dna, especially for the imm-approach. we observe non-constant variance of performance over different levels, for instance, an f-test indicates that the variation observed using cppls with codon representation was significantly smaller than the corresponding variance for imm  based on the original performance measure. to make a more formal test, we used a mixed interaction effect anova-type model  with results presented in table
 <dig> based on transformed performance. the analysis supports that significant variation among levels of methods , sequences  and method sequence interaction . a tukey test
 <cit>  with adjusted p-values for multiple comparisons, was carried out to compare the difference of means of  performance between methods and sequence representations. we found that cppls performed, in general, better than imm , while codons were better sequence representations than both protein and dna . no difference was found between the latter two sequence representations. further, testing for method and sequence interaction, we found that cppls with codon representation performed significantly better than imm with protein  and with dna  representations. mean performance of imm with codon representation was similar to cppls with codon representation, but variation of results were significantly lower for cppls  indicating superior performance. the estimated standard deviation of transformed performance due to random effect of species was
σ^s= <dig> , which is bigger than the general error term . this indicates that performance varies a lot between species . in general, the average performance for both the imm and cppls algorithms is very good. even the worst combination, using imm on dna data, has more than 95% correct classifications  in the majority of the performed tests. thus, both the imm and cppls methods support the notion that the positive and negative sequences have a base composition more intrinsically similar to each other and, therefore, that our division of sequences into these two categories is meaningful. the high performance is largely an effect of our strict choice of threshold t when selecting positives. we only included as positives the highly conserved genes, and it is quite likely that these genes have more in common than less conserved genes. we also tried more lenient thresholds, giving larger and more heterogeneous sets of positives , subsequently resulting in a drop in overall performance. however, the differences between methods and sequence representations found for subset of t =  <dig>  hold throughout.

analysis of variance for transformed performance  as an effect of method , sequence  and their interaction method:sequence. the estimated standard deviation of the random effect of species is
σ^s=  <dig>  and for the residual
σ^e =  <dig> .

it should also be noted that the archaeon sulfolobus islandicus gives a notable drop in performance for the imm, but less so for the cppls. this is possibly explained by a difference in variance in the sets of positives and negatives. we expect positive sequences  to be more homogenous than negatives . in any genome, the number of non-coding orfs is many magnitudes larger than the number of coding genes and since these non-coding orfs are regarded as negatives the variance in this set is considerably larger than the positives set. it is therefore reasonable to expect this difference in homogeneity between the positives and negatives. when fitting markov chain models to the positives and the negatives, we end up describing the ’average’ of both classes without taking the heterogeneity of their respective variances into account. hence, for imm, information about within-class heterogeneity and class size is lost. for cppls the regression coefficient estimates are affected by both the average and the variance in word-frequencies, as well as the number of sequences within each class. to illustrate this effect, sensitivity  and specificity  were computed for both methods using codon frequencies . sensitivity is on average the same for both methods, but cppls exhibited a stronger ability to identify negatives. for further understanding why a multivariate approach like cppls outperforms imm, we have focused on the results for sulfolobus islandicus, with codon representation. figure
 <dig> presents the density of the imm scores and cppls scores. for each test sequence, the imm score is computed as the difference of positive log-probability and negative log-probability, and cppls scores are simply the fitted values. it is clear from figure
 <dig> that the area of overlap between the red and blue density is larger for imm  than for cppls , and especially the negatives  seem to stretch into the positive side, producing false positives. another issue is that a multivariate approach makes simultaneous use of all the available frequencies and their covariance structure. by taking this into consideration, multivariate analysis can identify important frequency effects and detect contributions from frequencies that are too small to be detected by the univariate markov chain models. cppls will therefore provide superior statistical power compared to the markov chain models as long as a model selection procedure preventing under- or over-fitting is implemented.

although cppls based on codon frequencies, performs extremely well for orf classification there are a few positives missed. in the genome of sulfolobus islandicus we miss an iron-sulfur binding domain protein and some hypothetical proteins. in pseudomonas putida we fail to detect the genes annotated as “rnd family efflux transporter mfp subunit”, “copper resistance b”, as well as some hypothetical proteins. in mycobacterium tuberculosis we miss some hypothetical proteins and a “transmembrane serine” protein. for escherichia coli we fail to classify an “intimin adherence” protein as positive. this is a protein with no clear function defined also found in some shigella and citrobacter species.

we note that these genes are all involved in pathogenecity, e.g. the intimin gene is usually found on pathogenicity islands known collectively as lee’s
 <cit> . pathogenicity is a trait prone to be horizontally transferred
 <cit> . the fact that these genes are quite different in codon composition from all other hco’s in their respective populations may indeed be taken as an indication of recent horizontal gene transfer. this illustrates another potential use of coding sequence modeling besides gene finding. when a highly conserved orf is not recognized as such, it is an indicator of ’foreign’ dna. the recognition of horizontally transferred genes, which are often linked to virulence factors and antibiotic resistance
 <cit> , can be aided by the capability of coding sequence modeling. for instance, it is known that the gc content of the third codon position is highly correlated with genomic gc content
 <cit> . since genomic gc content is associated with the environment of the bacteria
 <cit> , the codon frequencies of horizontally transferred dna may be very different to that of the host
 <cit> .

CONCLUSIONS
results of comprehensive comparisons in coding sequence modeling on multiple data sets show that the cppls approach provides superior performance compared to the imm. furthermore, codon representations were found to be superior in classifying orfs compared to dna and protein representations for the cppls method. we therefore conclude that a multivariate approach like cppls should be more utilized in coding sequence modeling, as well as in pattern recognition problems where sequences are to be classified by their content, like for instance, in the detection of horizontally transferred dna.

competing interests
the authors declare that they have no competing interests.

authors contributions
tm and ls initiated the project and the ideas. all authors have been involved in the later development of the approach and the final algorithm. tm has done the programming, with some assistance from ss. tm, abk, jb and ls has drafted the manuscript, with inputs from all other authors. all authors have read and approved the final manuscript.

supplementary material
additional file 1
figure s <dig>  the number of positives against different thresholds. the number of positive genes obtained for different thresholds t for all species. a threshold of t =  <dig>  means members in a gene cluster differ by no more than roughly 30%, and the ’center’ gene  in each cluster is used as a positive. if a species has sequences more than  <dig>  then a sample of size  <dig> sequences are taken as positives. a small threshold  gives fewer, but tighter, clusters.

click here for file

 acknowledgements
tahir mehmood’s scholarship has been fully financed by the higher education commission of pakistan.
