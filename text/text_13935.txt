BACKGROUND
the next generation sequencing  technologies have dramatically increased the throughput. the new technologies, including those being developed currently, improve on many aspects of dna sequencing but a higher accuracy than the traditional sanger sequencing does not appear to be one of them. the nature of the technology would result in specific types of sequencing errors inherent in each process. in general, the new sequencing methods have an error rate between  <dig> % and  <dig> %  <cit> . due to the non-random distribution of errors across sites where some sites can be  <dig> times more error prone than the average, single nucleotide polymorphism  calling can often be difficult  <cit> .

in this study, we are concerned with estimating a fundamental parameter of natural populations, namely, watterson's θ of dna polymorphism  <cit> . briefly, θ is the number of nucleotide differences between two sequences of the same locus, randomly chosen from the population. it is a good measure of genetic diversity and a basic parameter for doing population genetic analysis . as polymorphism in natural populations is dominated by low frequency variants  <cit> , which are often indistinguishable from sequencing errors, using the new sequencing technologies to estimate polymorphism will remain a challenge in the near future. a number of methods have been proposed to separate errors from rare polymorphisms  <cit> . among them, nielsen et al.'s approach  <cit>  is most direct by filtering out errors from the raw read data. however, since error signals may vary from operation to operation, its general applicability will need to be evaluated.

there are two ways to prepare samples for sequencing and polymorphism estimation. first, sequencing is done on individual samples, or at least on pooled samples with each sample individually barcoded  <cit> . we call this type of data “single-line data”. second, dna samples from multiple individuals are pooled in equal quantity for sequencing without individual identification  <cit> . it is referred to as “pooled-line data”. we should note that sequencing each diploid sample individually is in fact a pooled-line approach as two haploid genomes are sequenced together. in order to call snp accurately for both haploids, the diploid has to be sequenced to a sufficient depth   <cit> . since individual samples are generally not sequenced to such a depth , most methods cited above examine the aggregate properties of these individual sequences. in other words, although individuals may be sequenced separately, the data are pooled in the analysis. hence, for many population genetic questions, little information would be lost by sequencing pooled samples and the efficiency would be greatly improved when the sample number is large. it would then be possible to sequence each pool with greater exactitude in order to filter out errors from the data.

we now propose a method which minimizes the confounding effects of sequencing errors by combining two different sequencing applications. dual sequencing applications have previously been carried out on the illumina ga and solid platforms for the same samples  <cit> . it has been shown that the two technologies have nearly non-overlapping error distributions  <cit> . dual platform is in fact a standard method as ngs sequencing, on whichever platform, needs to be backed up by another method, usually by sanger sequencing or other genotyping tools  <cit> . dual applications on two ngs platforms is simply a more systematic and large-scale method of error correction. such dual applications can also be expected on newer and very different technologies such as hiseq  <cit> , ion protons  <cit> , pacbio  <cit>  and mspa nanopore  <cit> . when dual platform sequencing is not feasible, dual applications of the same platform on the same dna sample, independently prepared for sequencing, may serve the same purpose. the correlation of error distribution between two applications on the same platform is slightly higher than those on different platforms but is often adequate for error corrections.

in this study, we first investigated a simple single-line method by extracting haploid information from individual diploids. we then propose dual sequencing applications to improve the pooled-line method for analyzing pooled samples of diploids.

RESULTS
single-line data
if the effort of data collection is not a limiting factor, the best method is to sequence each diploid individual to a sufficient depth such that true polymorphisms, with the variant frequency at  <dig> , can be unambiguously separated from errors.

to ensure false positive error rate being less than 10%, it need more than 20x depth for most next generation sequencing platforms  <cit> . with a lower coverage, there would be many sites where the distinction between errors and polymorphisms is not possible. therefore, when data are obtained with low coverage of diploid individuals , we suggest taking data from only one haploid genome per diploid individual. in this scheme, an average depth of 2x would ensure that 86% of individuals could be covered at each site, provided that the distribution of sequencing depth at each site follows a poisson distribution, p = 1-e- <dig>  since we are interested in comparing various methods of estimating genetic diversity, all of them are applied to data with an average depth of 2x per diploid individual.

theory
define θ as the nucleotide diversity per site. let s denote the number of segregating sites and l denote the total number of sites. watterson showed that

  es=anθl, 

where an=∑i=1n−11i and n is the sample size  <cit> . we assume n individuals with an average depth of 2x per individual. hence, at site j, only nj individuals would be sequenced . among these nj individuals, we randomly select one read to represent a haploid genome of this individual. when this site is observed to be polymorphic among the nj genomes, sj = 1; otherwise, sj =  <dig>  in the absence of sequencing error, the estimate of θ is

  θ^=1l∑j=1lsjanj, 

where anj=∑i=1nj−11i.

because some variants observed among the nj individuals would be sequencing errors, we need to consider a more reliable portion of the frequency spectrum in the estimation of θ. given the current sequencing error rate  <cit> , sequencing errors would usually appear as singletons  or doubletons . ewens showed that 1b/∑i=1n−11i is the probability that a mutant is represented b times in n samples and the estimate of θ should be

  θ^=1l∑j=1lsja′nj, 

where a′nj=∑i=1+znj−1−z1i <cit> . in this formula, z =  <dig> when singletons are removed and z =  <dig> when both singletons and doubletons are removed.

simulations
we simulated a 100 kb region of different θ and sequencing error rate. the results are presented below the heading of “single-line” in table  <dig>  s> <dig> denotes that all segregating sites detected by reads are counted. s> <dig> represents all segregating sites excluding singletons, while s> <dig> excluding both singletons and doubletons.

the average depth is 2x per individual in single line method, 2x per haploid genome in single platform method and 1x per haploid genome in each application in dual applications method. the means  of θ are estimated from  <dig> replicates. error rate is per site.

when the error rate is set to  <dig>  the estimates of θ using s> <dig> are very close to the true values. when the error rate is  <dig>  to  <dig> , the estimates of θ using s> <dig> become extremely unreliable, as expected, and the removal of singletons and doubletons becomes necessary. with an error rate of  <dig> , the estimate of θ using s> <dig> is  <dig> , very close to the true value of  <dig> . if the error rate is as high as  <dig> , estimation by the single line method becomes unreliable even the singletons and doubletons are removed.

a serious problem in snp calling is the non-random distribution of errors across sites  <cit> . in reality, some sites can be  <dig> times more error prone than the rest  <cit> . we hence conducted simulations with the assumption that the error rate is beta distributed ). we use different shape parameters . it is clear from table  <dig> that, when the error rate is non-constant, the single line method is not accurate for estimating θ even with the removal of singletons and doubletons.

the average error rate is  <dig>  per site. the average depth is 2x per individual in single line method, 2x per haploid genome in single platform method and 1x per haploid genome in each application in dual applications method. the means  of θ are estimated from  <dig> replicates.

pooled-lines data from single platform
from the section above, it appears that the most efficient strategy for accurately estimating genetic diversity would not be single-line sequencing. given the low coverage for each individual, variant frequencies, rather than the genotypes of individuals, are the quantities of interest. pooling samples for bulk sequencing may be equally informative but at a lower cost and effort  <cit> . when pooled samples are sequenced, each haploid genome would not present equally in the final data and the coverage would vary from site to site. the statistics to correct for these fluctuations are given below. in this and the next sections, the pooled samples are sequenced by one single application or by dual applications. the ability to separate errors from true polymorphisms differs greatly between the two approaches.

theory
equal amount of dnas from each individual are pooled and the pooled samples are sequenced on one sequencing platform. assuming a segregating site with b mutants in a sample of size n is covered by r reads in an illumina ga or solid dataset, jiang et al. <cit>  showed that the probability q <dig> that this segregating site is detected by reads is

  q1b,r=1−1−b/nr−b/nr, 

for 0 < b < n, and the probability q <dig> that a segregating site with an arbitrary b value is detected by reads is

  q2r=∑b=1n−1qnbq1b,r. 

ewens showed that qnb=1/b/an=1b/∑i=1n−11i is the probability that a mutant presents b times in n samples  <cit> .

let st denote the number of segregating sites detected by reads, and we can obtain

  est=sl∑j=1lq2rj, 

where rj is the number of reads covering the site j. hence the estimate of θ is

  θ^=s/anl=estan∑j=1lq2rj. 

replacing q <dig> with equation  yields

  θ^=est∑j=1l∑b=1n−1q1b,rjb. 

now we shall consider a more realistic case with sequencing errors in the data. let’s assume a case in which a site is covered by r reads in a single platform and has mismatches in x read caused by sequencing error. the probability pϵ of its occurrence at a non-segregating site is

  pϵr,x=crxϵx1−ϵr−x, 

where ϵ denotes the sequencing error at this site. since the average raw error rate ranges from  <dig> % to  <dig> %  <cit> , the sequencing error can cause severe problems when estimating polymorphism.

however, if using an observed segregating site only when the minor allele has more than z reads, we may obtain more accurate estimates. instead of equation , the probability that a site with b mutants in a sample of size n is detected by r reads as a segregating site with more than z reads of each allele is

  q1z,b,r=1−∑x=0zcrx1−b/nr−xb/nx−∑x=r−zrcrx1−b/nr−xb/nx. 

the estimate of θ is now

  θ^=es>z∑j=1l∑b=1n−1q1z,b,rjb. 

s>z denotes the number of segregating sites at which two different alleles are both detected by more than z reads. all segregating sites detected by reads are counted when z =  <dig>  hence, s> <dig> is equal to st.

the procedure to estimate θ using pooled-lines data from single platform is as follows. for each site, we  treat the data as missing if the number of reads is less than rmin in this platform;  retain alleles having more than z reads. if there is only one allele in this platform, we treat this site as a nonsegregating site; if two, as a segregating site; if more than two, we treat the data as missing;  use equation  to calculate θ for the single platform. rmin should not be no lower than . in the following simulations, we set rmin =  <dig> 

simulations
we used the simulated data to test this method. the results are referred to as “single platform” in table  <dig>  when singletons  or both singletons and doubletons  are discarded , the standard deviation becomes larger if there is no sequencing error. in reality, sequencing error cannot be ignored.

we assume that the error rate is constant across sites. different error rates  are used in the estimation. the simulation results are displayed in table  <dig>  for example, when s> <dig> is used with an error rate of  <dig> , sequencing errors lead to very poor estimates of θ. the mean estimate of θ is  <dig>  per kb if all segregating sites are used, which is many times higher than the true value of  <dig>  per kb. the estimation becomes more accurate when s> <dig> or s> <dig> is used. thus, when the error rate is low , this method can be used to estimate θ with both singletons and doubletons discarded. however, when the error rate is high , even excluding singletons and doubletons  does not lead to acceptable estimates. for simulations with the assumption that the error rate is beta distributed and its mean is  <dig> , the estimates are also unacceptable .

pooled-lines data from dual sequencing applications
it is customary to validate calls of variants by another method. for example, variant calls on the illumina platform are often validated by sanger sequencing or by fast snp genotyping methods, e.g. sequenom genotyping  <cit> . because validation is often laborious and incomplete, it may be more efficient and informative to deploy two sequencing methods fully and independently. if the two applications have distinctive error-distribution patterns, the errors could be identified and excluded by reciprocally correcting each other’s errors. indeed, several widely used sequencing methods  are based on very different chemistry and protocols. as shown below, we analyzed the sequencing results obtained by illumina based data and solid, and as expected, we observed the two datasets showed non-overlapping errors.

data on error correlation between sequencing applications
dual platforms - we re-analyzed sequencing data from a species of mangrove trees, sonneratia alba, known to be completely monomorphic within some populations  <cit> . dna sequences for  <dig> genes from one such population were generated using the illumina ga and solid platforms at a depth of ~2500x and ~5400x, respectively. for sites with more than 2000x depth in both platforms, we called variants using a set of criteria more stringent than the previous study. as shown in figure 1a, illumina ga and solid systems both call many false snps, few of which are called by both. because the sample is known to be monomorphic by sanger sequencing  <cit> , the detected variants are all false snps, which fortunately do not show overlap between platforms. pearson's correlation coefficient of the error rate distributions between the two platforms is only  <dig> .

single platform - for analyzing the correlation of two samples sequenced on the same platform, we use our own unpublished data from the illumina hiseq platform. a sample of  <dig> individuals from a mangrove species, avicennia marina, was taken from each of two nearby populations in thailand. equal amount of dnas from  <dig> individuals  were pooled.  <dig> genes were amplified for both of the two pooled samples and sequenced on an illumina hiseq platform. for sites with more than 2000x depth in both samples, we called snps at the sites whose minor allele frequency  is lower than  <dig>  in both samples. in total,  <dig>  sites were retained and were plotted in figure 1b. almost all of these variants are sequencing errors as explained in methods. figure 1b shows the observed error rates on these sites. pearson's correlation coefficient of the error rate distributions between these two samples is only  <dig> , a little higher than that between platforms of figure 1a. therefore, for samples prepared and sequenced twice on one platform, sequencing errors also overlap only rarely.

theory
if sequencing errors from two applications do not overlap, segregating sites detected by both should be true variants. the probability q <dig> that a segregating site with b mutants in a sample of size n is detected in both applications is

  q1b,r <dig> r2=∏k= <dig> −1−b/nrk−b/nrk. 

the overall estimate of θ by the combined data is

  θ^=est∑j=1l∑b=1n−1q1b,r1j,r2jb, 

where r1j is the number of reads covering site j in the first dataset, while r2j is the number of reads covering site j in the second dataset.

for non-overlapping errors, a site with b mutants in a sample of size n that is detected as a segregating site with more than z reads of each allele in both applications is associated with the probability

  q1z,b,r <dig> r2=∏k= <dig> . 

the θ estimated by the dual applications method is

  θ^=es>z∑j=1l∑b=1n−1q1z,b,r1j,r2jb. 

here s>z denotes the number of segregating sites in which two different alleles are both detected by more than z reads on both applications.

the procedure to estimate θ using data from dual sequencing applications is as follows. for each site, we  treat the data as missing if the number of reads is less than rmin on either applications;  retain alleles having more than z reads on both applications. if there is only one allele on either application, we treat this site as a non-segregating site. a site is considered segregating only when reads from both applications report segregation;  use equation  to calculate θ for the combined dataset. we set rmin =  <dig> in the following simulations.

simulations
the simulation procedure is almost the same as that for the single platform, but with data from an additional sequencing application. the means and the standard deviations of θ estimates using different parameters are reported in table  <dig>  for sequencing data without errors, the dual platform method can accurately estimates θ, although the standard deviation values are slightly larger than those obtained by the single platform method. however, with the increase of the error rate, the advantage of the dual platform method compared with other methods becomes obvious . with an error rate of  <dig> , the mean estimate of θ is  <dig>  per kb when using s> <dig>  which is only 2% higher than the real value . this estimate is dramatically better than the corresponding single platform estimate  or the single line estimate . this method is also better than the others when the error rate is beta distributed as shown in table  <dig> 

in figure  <dig>  we used different region lengths to test the dual applications method. the estimations of θ is acceptable even when the region is small . for a 40 kb region , the standard deviation of θ estimates is account for only 5% of the real θ.

discussion
while ngs has increased the power of dna sequencing by orders of magnitude in the recent years, its accuracy per read is the one aspect that has not been improved. for example,  <dig> pyrosequencing is susceptible to homopolymer indels  <cit> . the illumina ga and solid platforms are both pcr based systems and are prone to base substitution errors. the first glimpses of newer technologies do not offer promises for improving per read accuracy either. nevertheless, the nature of the substitution errors may differ among platforms since major sources of errors, from library construction to base-pair determination, depend on different physical and chemical principles among these technologies. the method described herein takes advantage of the non-overlapping distributions to minimize error rates.

the error rate across all sites is platform-dependent and not constant   <cit> . when doing the simulation, we assume that a nucleotide has an equal probability of being read incorrectly as one of the three other nucleotides. however, the patterns of error rates for the real data are much more complex. the frequencies of base substitution error could vary by  <dig> to  <dig> fold, with a to c transversions being among the most frequent substitution errors and c to g transversions among the least frequent ones  <cit> . therefore, if a non-segregating site  has two reads with sequencing errors, a doubleton error is more likely  rather than two singleton errors . in other words, the unevenly distributed errors can cause severe problems in estimating polymorphism. in this situation, we strongly suggest using dual sequencing applications to avoid this kind of errors.

CONCLUSIONS
our model can estimate θ accurately by combining data from two different sequencing applications. the method is robust even when the error rate is extremely high and variable across sites. we also evaluated the relative merits of pooled-lines versus single-line data. if the coverage per line is low, dual sequencing application on pooled lines yields the best results. however, the inherent high error rates in the ngs technologies impose constraints on the estimation of polymorphisms. even under the best of conditions with sequencing done on two platforms, singletons and doubletons still have to be removed. if the estimation requires accuracy in the low frequency portion of the variant spectrum, it will be necessary to carry out sequencing on each line individually with a high coverage of >20x. for many scientific questions, our strategy of dual sequencing applications on pooled samples with modest coverage can yield the most information for the same level of effort.

