BACKGROUND
with the increasing number of genome and metagenome projects, sequence databases have grown exponentially. on the one hand, the august  <dig> release of the uniprotkb/trembl database  <cit>  contains about  <dig> , <dig> protein sequences. in the last month, more than  <dig>  new sequences have been added to that repository, and about  <dig> , <dig> entry annotations have been revised. on the other hand, the pfam database of protein families  <cit>  represents about  <dig>  families, and about 20% of these are domains of unknown function , revealing that state-of-the-art sequence similarity-based and even profile-based annotation methods have had limited success in assigning functions to novel proteins.

protein structural classification databases, such as scop  <cit> , also present difficulties in keeping up with the increasing number of protein structures solved and deposited in public repositories. approximately 53% of the protein data bank   <cit>  entries are classified by the current release of scop  as of april  <dig>  and after removing redundancy , the coverage drops to about 41%. as international structural genomics initiatives have produced a huge number of structures of unknown function, attempting to automatically assign functions to these proteins is becoming even more necessary, and significant efforts have been devoted to this task  <cit> .

in this context, novel paradigms, models and methodologies for automatic annotation must be investigated. because protein structure and function are more conserved than protein sequence  <cit> , the identification of similarities between novel sequences and known structures would greatly improve the characterization of these sequences. fold recognition refers to identifying main structural features by the connections and positions of secondary structure elements. conversely, according to murzin et al.  <cit> , structural classification is conducted at hierarchical levels  that embody evolutionary and structural relationships. in this work, we focused on structural classification, which encompasses the problem of fold recognition. both fold recognition and structural classification are important steps toward function prediction.

over the years, protein fold recognition has been addressed through different approaches. the authors of  <cit>  extracted a series of features from protein sequences and used support vector machines and neural network learning methods as the base classifiers in a dataset composed of scop folds. later, ensemble classifiers  <cit>  were applied to these same feature vectors, improving the success rate. the use of a combination of sequence and structure information brought an improvement to fold recognition, as mentioned in the information retrieval approach introduced in  <cit> .

likewise, several efforts toward structure-based protein function prediction have been made. we can quote, for instance, the search for structural motifs  <cit>  and functional residues , the use of 3d templates  <cit>  and the comparison of protein folds by structure alignments  <cit> . there have also been attempts to infer function from structure without the use of alignment algorithms, such as in enzyme classification  <cit> . similarly, in the present work, we do not use alignment techniques or any sequence information in our method, relying only on structural grounds. a primary problem faced when dealing with protein function, as pointed out in  <cit> , s defining the scope and function. protein function prediction may be understood from different perspectives. it could mean the prediction of the cellular process in which a protein is involved, its enzymatic activity or even its physiological role. for instance, a proteinâ€™s enzymatic activity could be described by ec numbers, while its physiological role might be related to its subcellular localization. in this work, the aspect of protein function considered is enzyme activity. however, the study might be extended, without loss of generality, to other functional features, like the terms of the gene ontology   <cit>  annotation.

even though function cannot be directly implied from the specific fold adopted by a certain protein, structural data can be used to detect proteins with similar functions whose sequences have diverged during evolution  <cit> . in this context, one possible strategy is the definition of structural signatures, which are sets of features that are able to unequivocally identify a protein fold and the nature of interactions it can establish with other proteins and ligands. these feature sets are concise representations of protein structures, and we believe that their discovery and comprehension will be an important milestone in the protein function prediction field, being a step beyond sequence homology-based methods.

in this paper, we investigate a special type of feature that might be part of structural signatures: the patterns in inter-residue distances . proteins with different folds and functions present significant differences in the distribution of distances among residues as a consequence of the underlying interaction and packing of the atomic network, which is fundamental for defining protein folding  <cit> . in  <cit> , we have used these distribution distances to compare and correlate different methodologies of protein inter-residue contacts. we found, surprisingly, that the traditional cutoff-dependent approach was a simpler, more complete and more reliable technique for contact definition than other cutoff-independent methods, such as delaunay tessellation  <cit> , especially when the target is the discrimination of first-order contacts. in this work, we propose using inter-residue distance patterns for protein classification.

the structural data we used are the cumulative contact distributions based on the euclidean distances among alpha carbons, the cutoff scanning matrix . the motivation for the use of this kind of information lies in the fact that proteins with different folds and functions have significantly different distributions of distances between their residues, and protein similarity is reflected in these distance distributions, information that is captured in the csm. after generating this structural data, we apply singular value decomposition  to reduce dimensionality and noise. the processed matrix is finally submitted to different, previously described classification algorithms. therefore, the main innovation of this work relies more on the powerful combination of the new structural feature of inter-residue contacts used as a discriminator and principal components selection by svd rather than in the creation of a new classification method per se. indeed, we showed our methodology to be, in general, independent of the classifiers utilized, giving even results for different classification heuristics.

having in mind these considerations, we showed that the patterns derived from csms might effectively be used in automatic protein function prediction and structural classification. at first glance, in the case of enzyme function prediction, the proposed method achieved  an average precision of  <dig> %  and average recall of  <dig> % , using a gold-standard dataset of enzymes  <cit> . using a much larger set of enzymes with their respective ec numbers , csm was able to achieve up to  <dig> % precision and recall results. for the recall results, considering the levels of hierarchical structure of scop  <cit> , we were able to accomplish an average precision of  <dig> %  and average recall of  <dig> % . in comparison to the state-of-the-art methods used in this context, such as that given by jain and hirst  <cit> , using very similar database input , our methodology presented more robust and homogeneous results, with an average precision a bit below that of those authors:  <dig> % versus  <dig> %, but with less dispersion . we had remarkably better recall results: an average of  <dig> % versus  <dig> %, with significantly lower dispersion . further details are discussed in the next section.

RESULTS
to test the ability of our method to successfully predict functions and recognize folds, we performed two sets of experiments with datasets designed for these different tasks.

for function prediction, as mentioned in the methods section, we built one database based on manually curated protein superfamilies and another based on ec numbers to test if the present structure-based method could help in protein function annotation.

for structural classification, we performed experiments to verify our ability to assign scop class, superfamily, family and fold to protein domains. furthermore, to place this work into the context of the literature, we also tested a superset of the dataset used by jain and hirst in  <cit> . as far as we know, their work presents the highest precision in protein fold recognition published thus far.

finally, we relate some experiments that aimed to evaluate an svd-based noise reduction strategy.

function prediction
in the function prediction experiments, our goal was to assess how well three different classification algorithms predict protein function according to protein ec numbers and a mechanistically diverse gold-standard database of functional family classes  <cit> . we used 10-fold cross validation for all the experiments.

for the dataset of the top  <dig> most-populated ec numbers, csm was able to achieve  <dig> % precision and recall after svd processing using the knn  algorithm. the four levels of the ec number were used together as the classes to train and test the classifier. additional file  <dig>  figure s <dig> shows the variation in the performance metrics for each ec number class considered. even though the number of proteins assigned to each ec number is very unbalanced, the majority of classes were classified properly, with high quality according to the metrics extracted.

considering the gold-standard dataset, without svd and using knn, our method achieved an average precision of  <dig> %  and a recall of  <dig> %  . for naive bayes, it achieved  <dig> %  precision and  <dig> %  recall , and for random forest, it achieved  <dig> %  precision and  <dig> %  recall . we also showed that by using svd, we may significantly improve these results, and in the worst case, we had  <dig> % precision and  <dig> % recall for the enolase superfamily using naive bayes. the knn and random forest methods were able to detect isoprenoid synthase type i with 100% precision and recall. additionally, we performed experiments using all six superfamilies to train a single classifier. in this scenario, even with a greater number of families in the training and testing phases, we were still able to achieve up to  <dig> % precision with knn and random forest after svd preprocessing.

prediction performance for the gold-standard dataset using knn. the experiment was performed in an intra-superfamily fashion, and the classes for prediction represent the enzymeâ€™s families. the precision and recall metrics are weighted averages. ten-fold cross validation was employed.

protein structural classification
to the best of our knowledge, no test of the structural classification of very large databases, such as the entire scop containing about  <dig>  domains, has been published. due to svd dimensionality reduction ability and the possibility of representing protein instances by a few significant attributes, we present a method that can efficiently handle such volume of data.

we may recognize protein folds at a  <dig> % precision and  <dig> % recall using knn . even broad proteins categories, such as the scop class level, can be separated using csm with very significant precision and recall . the proposed method was able to classify proteins in the four levels of scop hierarchy with very high precision and recall, showing that csm is a suitable method for fold recognition and also that csms are a very promising component of protein structural signatures. additionally, we verified the impact of imposing a minimum number of entities per node of the scop hierarchy on the precision of the prediction. additional file  <dig>  figure s <dig> shows an approximately linear correlation between these variables for the fold, superfamily and family levels with and without the svd processing. this correlation was not analyzed for the class level because all of the classes have more than  <dig> entities.

prediction performance for the full-scop dataset using knn. the experiment was performed for each classification level of scop. the precision and recall metrics are weighted averages. a 10-fold cross validation was employed.

performance comparison
in  <cit> , the authors presented a random forest-based method to predict the scop class, fold, superfamily and family levels based on secondary structure element descriptors that achieved precisions of up to  <dig> %. using a similar dataset, we tried to compare our results to theirs. as far as we are concerned, this was the state-of-art method for automatic structural classification. they used a subset of scop database as they aimed to recognize protein folds. in our comparison of results, we were able to achieve similar precision levels but with higher recall  in most of the cases. in only  <dig> of the  <dig> experiments, we obtained a lower recall value with our method and our f <dig> scores were also superior. the complete set of information regarding this experiment is available in table  <dig>  figure  <dig> shows the performance comparison for each experiment in terms of precision and recall. csm significantly overcomes the recall of the aforementioned study while preserving a compatible precision level. we stress that our method is not limited to small proteins. these results show that our method is not only comparable to  <cit>  but also presents a considerable gain in terms of recall.

a comparison of prediction performance between the current study and the method introduced by  <cit> . the precision and recall metrics are weighted averages. this result comprises a 10-fold cross validation in knn.

noise reduction strategy
as we mentioned, svd-based noise reduction was able to improve the precision and recall levels. we obtained a gain of up to  <dig> % with the knn classifier,  <dig> % with naive bayes and  <dig> % with random forest. interestingly, we verified that the different classifiers achieved comparable results after the use of svd for dimensionality reduction . dimension reduction ability is important for scalability in this scenario because many protein domains are experiencing exponential growth. there are about  <dig>  domains, i.e., instances to classify, in the scop database. each of these instances can be represented by  <dig> attributes  in the case of the csm with a cut-off of up to 30Ã….

to find the point that maximizes the noise reduction, we studied the singular value distribution obtained for the gold-standard dataset. figure  <dig> shows the elbow of the curve of the contribution of each singular value to represent the original information. using about  <dig> dimensions we can represent the same information  and obtain very high precision in classification with a considerably smaller dataset. as shown in figure  <dig>  maximum precision can be achieved with about  <dig> singular values for all experiments.

CONCLUSIONS
function and fold prediction, while means of understanding the composition, operation, interaction and evolution of proteins, are still great challenges in the face of the explosive growth of protein data generation and storage in public databases. to keep up with the frenetic pace imposed by this increasing data availability, novel, efficient methods for automatic and semi-supervised annotation are needed. as a mechanism to exploit the close relationship between protein structure and function, we developed a structure-based method for function prediction and fold recognition based on protein inter-residue distance patterns. the motivation for this approach arose from the hypothesis that proteins with different structures would show different inter-residue distance patterns, and structural similarity would be reflected in these distances.

one of the most remarkable advantages of the csm-based structural signature is its generality, as we successfully instantiated it in different problem domains, such as function and fold prediction. also, as a requirement and demand for its application to databases that are continuously growing, it is scalable for real-world scenarios, such as whole-scop classification tasks, as shown in previous sections, and it shows an efficacy comparable or superior to state-of-the-art protein folding and function predictors. we would like to stress that our method is probably the first to present a full-scop automatic classification in acceptable time .

the interpretation and understanding of the intrinsic distance patterns generated by csm demand further investigation. as part of future studies, we intend to explore the generality of csms in other aspects of protein function, such as subcellular localization prediction and prediction of go terms, as well as under different structural classification databases, such as cath  <cit> . we also plan to contrast svd with feature selection as methods for discriminant information discovery in csms.

furthermore, the significant gain in prediction power provided by svd processing might imply that there is room to improve in terms of the data input, indicating that other cutoff ranges and granularities should also be tested, which is a study already in progress in our group.

