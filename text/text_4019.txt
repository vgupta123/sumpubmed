BACKGROUND
gene expression data are commonly used to develop multi-gene prediction models for various clinical classification problems. several gene expression-based multivariate prognostic and treatment sensitivity predictors have been developed for breast cancer and numerous other "gene signatures" have been reported to predict specific biological states including pathway activity and mutation status of p <dig>  brca, pik <dig> and other genes in cancer  <cit> . however, many genomic predictors yielded low accuracy in independent validation  <cit> . it also seems apparent that some classification problems are easier to solve than others in the mrna expression space. for example, it is straightforward to construct accurate classifiers for breast cancer that predict estrogen-receptor  status or histologic grade due to the large scale gene expression differences that exist between er-positive and -negative or low grade versus high grade cancers  <cit> . many of the empirically developed first generation prognostic and predictive gene signatures for breast cancer derive their predictive value from recognizing molecular equivalents of er status and tumor grade. this is because prognosis, drug response rates and even p <dig>  pi3k or brca mutation status are not evenly distributed between er-positive and -negative breast cancer  <cit> . when clinically more homogeneous subtypes of breast cancers are analyzed, it has been difficult to develop outcome predictors with good performance metrics  <cit> .

supervised classification models are developed through comparison of groups of samples that differ in clinical outcome of interest. the first step typically involves identification of informative probe sets/genes  that are differentially expressed between the groups. next, these informative features are considered as variables to train a multivariate classification model. intuitively, the predictive performance of classifiers must depend on the number of informative features, the magnitude of difference in feature expression levels between the groups of interest, and the number of informative cases in each group. these critical parameters are expected to vary from classification problem to classification problem and from data set to data set. however, it is not well understood how each of these components influence the success of the classifier development process and what the minimum requirement to develop successful predictors might be.

the goal of this analysis was to take public breast cancer gene expression datasets, spike these with a series of artificial "gene signatures" and assess how well these spiked-in gene signatures could be recovered and used to develop a multi-gene classifier to predict "spiked-in" status of a sample. the artificial gene signatures consisted of real probe sets whose expression values were increased  with a constant. the extent of perturbation varied over a broad range for three key parameters:  the number of samples perturbed ,  the number of probe sets included in the artificial signature , and  the fold increase in mean expression value for the spiked probes . to place our findings into context, we also calculated gene signature size and strength for nine different real-life clinical prediction problems in six different data sets.

methods
data sets
we used  <dig> publically available human breast cancer gene expression data sets each generated with affymetrix u133a gene chips. these included the microarray quality control consortium  breast cancer data  to be perturbed in each data set. in the classification exercise described below, these s perturbed samples represent one class and the remaining samples in the dataset represent the other class. for each s sample set, we randomly selected g probe sets  to represent the informative features . we altered the normalized, log2-transformed expression values of each g probe sets by adding the same c constant . this is equivalent to multiplying the original scale value by 2c. so, c =  <dig> corresponds to unperturbed data, c =  <dig>  corresponds to a 2-fold increase and c =  <dig> corresponds to a 4-fold increase. by perturbing probe sets only in the s randomly selected samples, we are generating gene signatures between the two classes of increasing size and strength. we also created perturbed data sets where the probe sets were perturbed with randomly picked constants within brackets of c values using uniform distribution including c = , , , , , , , and . we repeated the entire perturbation process  <dig> times for each possible s-g-c combination in all  <dig> data sets.

classifier model building
we used t-tests to compare the spiked cases with the rest of the cases to identify differentially expressed probe sets among all probe sets represented on the arrays. we ranked all probe sets by p-value and used the top n features  to construct multivariate prediction models using diagonal linear discriminant analysis  for each s-g-c combination  <cit> . during model building we used the known perturbation status of the samples to train the models.

we tracked how many of the spiked probe sets  were included in the top n features in each iteration of the t-test. as reference point for these observations, we also used the same method to identify informative probe sets for  <dig> real clinical classification problems. first we compared er-positive with er-negative breast cancers, then cancers with pathologic complete response  to chemotherapy versus lesser response , and subsequently cases with pcr versus rd among er-negative cancers . during these analyses we kept the overall sample sizes and the proportion of informative cases identical for each  <dig> comparisons in order to standardize the power of the analysis. the smallest sample size was the comparison of pcr versus rd among er-negative cancers that included  <dig> cases . therefore, we only used a randomly sampled subset of  <dig> cases from the total of  <dig> maqcii cases for the "er-positive versus er-negative" and "pcr versus rd" comparisons and also fixed the proportion of informative cases to  <dig> versus  <dig> for each comparisons. to obtain further reference values to interpret our spiked-in simulation results we also generated lists of informative probe sets to distinguish cancers that relapsed with those that did not relapse , inflammatory from non-inflammatory breast cancer , p53-mutant from p53-normal  and pik3ca-mutant from pik3-normal cancers  <cit> . these analyses were performed separately for er-positive and er-negative cancers in each data set in order to avoid contamination by phenotype-related genes. false discovery rates were estimated using the fdrtool software package  <cit> .

assessment of prediction models
our goal was to predict which samples were perturbed. we built prediction models with the top  <dig>   <dig>   <dig>   <dig>   <dig> features selected by t-test and ranked by p-value within each s-g-c combination  ×  <dig> ×  <dig> ×  <dig>  =  <dig>   <dig> data sets). to estimate predictive performance, we performed stratified 3-fold monte carlo cross-validation  with  <dig> iterations. during cross validation, we randomly selected 2/ <dig> of the data to train the model and the remaining samples were used as a test set. this selection process was done separately within the spiked and non-spiked groups in order to maintain the same proportion of perturbed and unperturbed cases in the training and testing sets. new feature selection was performed during each iteration.

the classification process was assessed by two metrics:  the area above the receiver operating characteristic curve  which is the complement of the area under the curve   and  the spiked probe recovery rate. when the total number of spiked probe sets is less than the number of features included in the classifier, we computed the recovery rate by dividing the number of correctly selected spiked probes included in the model by the number of all spiked probes. if the number of spiked probes was greater than the number of features included in the classifier we calculated the recovery rate by dividing the number of correctly selected spiked probe sets by the number of all features included in the classifier. the ability to include the perturbed/spiked probe sets in the classifier is critical for producing a model with good predictive accuracy . thus the rate at which spiked probe sets are included in the classifier  is a useful metric for evaluating the classification process.

an r-code package has been developed to run the complete probe set spiking, model building and predictor evaluation process and is included in additional file  <dig> 

RESULTS
the effects of sample size and signature strength on spiked-in gene recovery
first, we examined the spiked probe set recovery rates as function of signature strength and number of spiked samples. figure  <dig> shows the probe set recovery rates when the number of spiked probes was set to  <dig> while we varied the number of spiked-in samples from s =  <dig> to  <dig>  and the fold change of the spiked probe sets over c =  <dig> ,  <dig> ,  <dig> , and  <dig> . fold change  had the greatest effect on feature recovery rate. with c =  <dig> , the average recovery rate was > 60%  even when only  <dig> samples were spiked. when the spiked sample size reached  <dig>  the average recovery rate increased to > 80% . on the other hand, when the c was a modest  <dig> , the recovery rate remained low, around 40% even when the spiked-in sample size was  <dig>  similar trends were seen when  <dig> or  <dig> probe sets were spiked . these observations were consistent across all  <dig> data sets and indicate that fold increase in the expression value of informative probe sets has a major influence on feature recovery rate. probe sets with less than  <dig> -fold difference in mean expression values between comparison groups are difficult to identify as informative features.

the effects of sample size and signature strength on classifier performance
next, we examined how increasing the number of perturbed cases and the fold difference in spiked probe sets influence predictor performance. the classifier performance improved dramatically as the signature strength increased. the predictors reached almost perfect accuracy at c =  <dig>   when 20- <dig> samples  were spiked . increasing the number of spiked cases gradually improved model performance when the c was a modest  <dig> , but even at sample size of  <dig> , the aac was  <dig> . the same was observed in all  <dig> data sets and over a broad range of spiked probe sets , results were least sensitive to the number of features included in the classification models .

we also examined the more realistic scenario when we altered the expression of the selected probe sets over a range of fold change that differed from probe set to probe set but remained within brackets of pre-specified maximum c including , ,  and . the individual c constants that were added to the log <dig> expression values of each of the probe sets selected for spiking were randomly picked from all possible values within a given bracket. this experiment yielded similar results as presented on figure  <dig> but with slightly reduced performance at signature strength below 2-fold expression change . essentially perfect predictors could be constructed once the spiked-in sample size reached 10% of the study population and the signature strength bracket was ≥  <dig> - <dig> .

effect of signature size on prediction accuracy
we also examined how the signature size, the number of perturbed probe sets, affects prediction performance. since predictive accuracy rapidly reached a plateau when the fold increase in the expression of informative probe sets reached  <dig>  , for this analysis we fixed c at  <dig> . we varied the number of samples that were perturbed  and the number of spiked probe sets from  <dig> to  <dig> but kept the feature set size used for model building at  <dig>  predictive performance improved gradually as the signature size increased at each sample size level . predictive performance also improved as the sample size of perturbed cases increased. however, increasing the feature set size in a model led to modestly deteriorating performance when the number of informative probe sets was small and the signature strength was low, due to inclusion of noise in the model. as the number of truly informative probe sets converges towards the number of features included in the model, the performance improves rapidly even at small sample sizes.

to further explore the effect of noise  on predictor performance, we kept the number of spiked probes at  <dig> and set the the predictive model size at  <dig> features. figure  <dig> shows that increasing the signature strength dramatically improves predictive performance even if a large number of non-informative features are included in the model. for example, if a gene signature consists of  <dig> probe sets each of which has a 4-fold increase in expression in a subset of  <dig> %  of the entire study population a highly accurate predictor could be built with an aac of  <dig> . these results indicate that the most critical determinant of model performance is signature strength. if the magnitude of expression difference is ≤  <dig> fold and the true signature size is small, model performance depended strongly on the number of cases that were perturbed and on the number of non-informative probe set included in the model. greater than 30% of samples need to be informative in order to develop and train a model with an aac around  <dig> - <dig>  if the true signature includes only  <dig> probe sets with a 2- <dig> fold difference but also includes a large number of spuriously selected, non-informative features .

gene signature size and strength for real clinical prediction problems
genomic classifiers developed to predict clinical outcome in breast cancer usually yield substantially lower auc values than what we could achieve in our simulation experiments  <cit> . this suggests that real life clinical classification problems often involve low level expression differences in a modest number of genes . to estimate signature size and strengths for various real-life prediction problems we calculated fold change differences for the top  <dig> most differentially expressed probe sets between  er-positive and er-negative cancers,  highly chemotherapy sensitive  and less sensitive cancers and  chemotherapy sensitive versus less sensitive cancers among er-negative breast cancers using a standardized sample size of  <dig> and a fixed proportion of informative cases for each of these comparisons. in the er-positive versus -negative comparison, the top  <dig> probe sets all had >  <dig> fold mean expression difference with very low fdr. in the pcr versus lesser response comparison without stratification by er status, the top  <dig> list included only  <dig> genes that had >  <dig> fold difference but all the rest had expression difference between 1- <dig> fold and all features had low fdr. when the same analysis was restricted to er-negative patient only, the top  <dig> differentially expressed list contained no genes with ≥  <dig>  fold expression difference and fdr values were high suggesting that many of these may not be truly informative. even after extending the differentially expressed list to include the top  <dig>  it contained only  <dig> probe sets whose expression difference was ≥  <dig>  and <  <dig> . we found similarly small and weakly informative signatures for  <dig> other prediction problems and the associated fdr values were high .

1random sample of  <dig> er positive and  <dig> er negative samples

2random sample of  <dig> pathologic cr and  <dig> residual cancers regardless of er status.

3random sample of  <dig> pathologic cr and  <dig> residual cancers all er negative.

4log <dig> difference = abs where "abs" is absolute value.

the numbers of probe sets with a given level of differential expression are shown for the  <dig> comparisons including  estrogen receptor -positive versus er-negative cancers,  cancers with pathologic complete response  to chemotherapy versus lesser response  and  cases with pcr versus rd in er-negative cancers only. probe sets with mean log <dig> transformed expression difference > <dig> between comparisons groups are highlighted in bold. fdr = false discovery rate . fdr adjusted p-values  are the estimated fdr values that would be incurred if the p-values associated with the selected genes were used as the threshold for significance . so for the feature # <dig> column, the reported fdr adjusted p-value is the q-value associated with the 10th highest ranked gene.

*log <dig> difference = abs where "abs" is absolute value.

the numbers of probe sets with a given level of differential expression are shown for the  <dig> comparisons. analyses were performed separately for estrogen receptor -positive and er-negative cancers. ibc = inflammatory breast cancer, pi3k = phosphatidylinositol- <dig> kinase, fdr = false discovery rate. the wang, transbig, mainz data sets correspond to references  <dig>   <dig> and  <dig>  probe sets with mean log <dig> transformed expression difference > <dig> between comparisons groups are highlighted in bold.

these observations confirm that for easier classification problems, such as er status prediction, a large number of informative probe sets exist and these show large fold differences but for all other prediction problems that we tested the number of informative features was low and feature strength was modest at best.

discussion
the goal of this project was to assess how gene signature size , signature strength  and the number of informative cases in a data set influence the success of developing multi-gene prediction models. we also examined how model performance deteriorates as increasing amount of noise  are included in a model. to study these variables we altered the true expression values of randomly selected genes in real human gene expression data sets. what motivated this research was to find out what signal elements in the genomic model building process may explain the substantial difficulty to find clinically relevant multi-gene predictors for many cancer classification problems.

our results demonstrate that signature strength had the greatest influence on the success of model building followed by the size of the gene signature and the number of informative cases. predictors tolerated large amounts of noise included in the model as long as it also contained numerous strong informative features. it was remarkably easy to develop almost perfect predictors with as few as  <dig> informative probe sets if the fold difference in the expression values of these probe sets was >  <dig> , even if the informative samples represented < 10% of the total sample size. these simulated results are better than the reported performance of the majority of empirically developed genomic outcome predictors  <cit> . to examine the causes of this discrepancy, we calculated the number of informative probe sets and their fold difference  for  <dig> different real clinical prediction problems in  <dig> publically available breast cancer data sets. we only found sufficiently large and strong predictive signature for one prediction problem, to distinguish er-positive from er-negative breast cancers . surprisingly, there was no strong signature for the clinically more relevant problems of predicting chemotherapy sensitivity among er-negative cancers  and for a series of other diagnostic or mutation prediction problems.

these results indicate that current statistical methods efficiently identify highly informative features in complex gene expression data sets if such features exist. features can be considered highly informative if at least a 2-fold expression difference exists between the means of the two comparison groups. with as few as  <dig> such features almost perfect classification models can be built. however, highly informative features do not appear to be common for many clinically relevant prediction problems. there may be several biological explanations for this. first, the dynamic regulation of the expression of the thousands of mrna species in cancer cells is not well understood. what level of change in mrna expression leads to functionally important consequences  is unknown and it is likely to be different from gene to gene. some physiological variables are very tightly regulated, a 10% change in serum sodium levels can lead to life threading consequences whereas variables such as hear rate or blood pressure have broad normal dynamic range. it is likely that similar phenomena also occur in the mrna world and a 15-50% percent change in the expression level of some mrna species may result in functional consequences but such genes would not define strong predictive features. also importantly, protein expression levels correlate with mrna expression only moderately and protein levels or posttranslational changes in proteins may represent the functional activity of biological pathways more accurately than mrna levels. structural variations in genes at the dna level can profoundly alter the functional activity of proteins such mutations may also not cause large scale changes in mrna expression.

while our spike-in simulation studies yielded much useful information, they are limited in several respects. in real datasets expression values responding to regulatory influences would presumably change in a coordinated rather than random fashion. however, the degree of change and number of genes involved in a particular coordinated change may be relatively small and thus not conducive for use in a predictive model. overall these observations are consistent with previous sensitivity analysis of prediction models that have highlighted the vulnerability of predictors to feature strength  <cit> .

CONCLUSIONS
in summary, our findings suggest that in the currently available mrna gene expression data sets of breast cancer there may not be enough highly informative genes to develop clinically useful genomic classifies to predict certain types of clinical outcomes. we recognize that the sample sizes that are currently available for analysis are modest, and particularly small analyses are performed in disease subsets. our simulation results suggest that predictor performance in the absence of strong predictive signatures may improve only modestly even if sample size increases. we developed an r software code package that could be used to estimate the number of informative probe sets, based on gene spiking, that is needed for accurate model building in any experimental data set. this could be used as a tool to estimate the adequacy of a given data set to yield empirically derived classifiers.

authors' contributions
conception and design kh, lp; acquisition of data wfs, yq, lp; analysis of data cw, kh, yq, ti, lp; interpretation of data kh, cw, yq, ti, wfs, lp; drafting the manuscript or revising kh, cw, yq, ti, wfs, lp; final approval kh, cw, yq, ti, wfs, lp.

grant support
the breast cancer research foundation 

supplementary material
additional file 1
r code. r language programming code used to perform the analyses presented in the paper.

click here for file

 additional file 2
supportive results. supportive results of analyses on additional datasets.

click here for file
