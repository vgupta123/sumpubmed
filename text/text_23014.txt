BACKGROUND
several new short-read sequencing technologies are now actively competing in the race towards the $ <dig>  genome. each of these technologies produces raw sequence data with particular characteristics and distinct error models. however, it has become clear that three major contenders  aim to produce high volume, 25– <dig> base paired-end reads.

short read sequencing has lead to a new surge of interest in the old problem of sequence assembly. these new technologies have only recently started producing data suitable for de novo assembly. several teams are now building short-read assemblers , but the protocols optimizing assembly projects  are still being invented.

in this paper we present our assembler shorty, targeted towards paired-end microread sequencing data. shorty uses a very small volume of "seeds", perhaps 5– <dig> reads/contigs per bacterial genome. these seeds can be either virtually constructed using a conventional single-ended read assembler, or purchased with a trivial amount of sanger sequencing. still, these seeds enable us to produce significant assemblies with a short-read coverage of 100×, easily obtainable on one run of any of the new machines. further, our final assemblies prove very accurate even though our reads contain base error rates associated with the machines available today. certain previous work on microread assembly underestimates the complexity of the problem by simulating assembly on error-free reads.

shorty exploits two ideas which we believe of interest to the short-read assembly community:

• seed reads for crystallizing assemblies – several other assemblers intermix low  coverage from sanger or  <dig> reads with a higher coverage of short reads to fill up gaps. instead, we use a single  <dig> –  <dig> base computed seed read to grow a neighboring contig of greater or equal to sanger length. by repeating this process on the new contig, we can walk across the full genome assembling perhaps 90% of the genome into 15– <dig> kb contigs. assembling the results of such walks from a trivial number of seeds produces contigs with an n <dig> size  of  <dig> kb on bacterial genomes and 98% coverage in non-trivial contigs.

the seed coverage assumed by our protocol is so modest it eliminates the need for a lab to own more than one type of sequencing platform. these trivial number of reads can be generated from short reads by following any simple assembly algorithm or likely even extracted from highly-conserved ribosomal rna sequences scavenged from databases. already existing assemblers  for single-ended short reads can generate these starter seeds.

• inter-contig distance estimation from spanning paired-end reads – sequencing protocols specify the mean separation distance and variance between the ends of the paired-end reads. typically, these insert lengths are normally distributed, say with a mean distance of  <dig> bases and a standard deviation of  <dig> bases. our walking assembly strategy naturally produces two neighboring contigs separated by some insert distance. the substantial number of paired-end reads with one end anchored in each contig provides the possibility of accurately estimating the distance between the contigs. such estimation enables us to order contigs and fill gaps using shorter overlaps that would be unconvincing in the absence of distance information.

huson et. al  <cit>  proposes an idea to order contigs from mate-pair reads but it is not scalable for the volume of data we have in a short read assembly project. in this paper, we use such distance estimation efforts in a way that scales for short read assemblers.

we survey related work on short-read assembly below. the primary research issue today is not the head-to-head comparison of which assembler is "best", but to identify the most cost-effective short-read sequencing protocol which results in data that can be reconstructed when coupled with the right assembly strategy.

short read sequencing technologies
although the sanger sequencing method  <cit>  has been the dominant sequencing technology for decades, novel technologies for short read sequencing are being developed by several groups.  <cit> . see  <cit>  for a recent survey and analysis of these technologies. these new short-read sequencing technologies differ in details of localizing molecules, amplification and sequencing approach. our assembler has been developed for microread technologies that generate mate paired short reads. hence, it is suitable for data generated by companies like:

• applied biosystems: they recently released their solid™ sequencing machine, which uses technology that is acquired from agencourt bioscience corporation. agencourt commercialized their technology based on polony sequencing developed by church and mitra  <cit> . indeed, the parameters underlying our simulations were selected with solid™ in mind.

• solexa: they were recently acquired by illumina. their sequencing machine, illumina genome analyzer, can load to eight samples onto their flow cell surface for simultaneous analysis. the platform offers high accuracy, high throughput and relatively low cost , and promises real support for double-ended reads forthcoming very soon.

• helicos biosciences: they are pioneering a single-molecule approach to sequencing based on technology from  <cit> . this offers advantages in capacity and eliminating amplification-specific bias. their heliscope™ sequencing machine contains two flow cells where billions of single molecules of sample dna are captured on an application-specific proprietary surface to serve as templates for the sequencing-by-synthesis process. recently, they published  <cit>  m <dig> genome re-sequencing data based on their new technology.

related work
the success of shotgun sequencing  <cit>  led to the development of several successful assemblers for sanger reads. most of them were based on the overlap-layout-consensus  <cit>  paradigm, while others took a graph-theoretic approach. some assemblers were suitable for hierarchical sequencing, while others targeted whole genome shotgun  sequencing.

as short read sequencing technologies mature, several bioinformatics groups have started working on short read assembly projects. most algorithms are still tested on simulated data, as true assembly-quality data is not yet readily available for most platforms. solexa double-ended reads and applied biosystems' solid™ system have just entered the market, so real data should be available in relatively short order. we classify short read assemblers in three different groups, based on the type of reads they expect. the first class of assemblers are similar to ours in targeting mate-paired data generated from solexa/abi machines:

• allpaths  <cit>  is an assembler being developed at the broad institute reporting excellent assembly on paired-end solexa-type data with 80× coverage using a protocol with three different insert sizes . shorty is different in  assuming a substantially simpler, single library experimental protocol and  employing shorter reads .

• medvedev and brudno's recomb  <dig> paper  <cit>  reports assembly results for bacterial scale genomes which are more directly comparable to ours. they assemble simulated 25-base paired  reads into contigs with n <dig> contig sizes around  <dig> kb. we produced bigger n <dig>  even with the presence of sequencing errors.

• velvet  <cit>  augments 50× solexa data to produce high quality assemblies. they use reads of  <dig> bp length whereas shorty can handle  <dig> bp long reads, which is more realistic for solid data. our n <dig> size is comparable with those of velvet despite the shorter read length.

the second class are assemblers targeting  <dig> data, which include:

• newbler  <cit>  is a proprietary de novo assembler from  <dig> life sciences corporation which is designed to handle their data which is in the form of flowgrams. it is based on the overlap-layout-consensus paradigm and consists of three modules: overlapper, unitigger and multialigner. as  <dig> doesn't typically produce paired-end data, newbler generates a set of unlinked contigs.

• euler  <cit>  analyzed the feasibility of short read assembly of read length 70– <dig> using euler. on simulated data from several bacterial genomes, they produced a mix of long and short contigs.

• euler-sr  <cit> , the new version of euler is particularly designed for reads generated by next generation sequencing technologies. the results are based on a hybrid approach where they used  <dig> and sanger type data together to generate an assembly. they presented some results for simulated paired  <dig> reads as well.

• shrap  <cit>  is another assembler that assemble reads of length around  <dig> base pairs using a proposed sequencing protocol for mammalian-scale genomes.

a final class of short-read assemblers focuses on single-ended reads produced by the first generation of solexa machines:

• ssake  <cit>  is a short read assembler that was tested with simulated error-free  <dig> mers. it performs well with viral genomes. in a recent release, ssake started supporting paired end reads.

• sharcgs  <cit>  is a de novo short read assembler that handles short reads as short as 25– <dig> bases. it generates a set of large contigs but without any ordering information. their algorithm was tested against illumina's  <dig> g sequencing instrument. it uses a method that it calls contig elongation: a read is extended by looking for other reads in a prefix tree for potential extensions. it doesn't handle paired-end reads.

• phusion  <cit>  was used by sanger institute to assemble many genomes from shotgun sequences. recently they showed  <cit>  possibilities of assembling short reads by mixing a low coverage  of capillary reads with them. they used  <dig> and solexa data for their prototype.

• adena  <cit>  is a recently published short read assembler that works on  <dig> bp long illumina data and performs better and less resource hungry in comparison to ssake and sharcgs. n <dig> sizes presented in their paper was in the range 6– <dig> k bp long.

RESULTS
data preparation
we have rigorously tested our assembler on simulated sequence data generated from three bacterial genomes – m. genitallium, s. suis  and e. coli . the reference sequences are  <dig>  075;  <dig>   <dig>   <dig> and  <dig>   <dig>   <dig> bases long. our simulations were designed to conform as closely as possible to an assembly project on the applied biosystems' solid platform. indeed our coverage, insert distribution, and base error distribution are derived the actual data set discussed below.

solid is an ultra high-throughput technology. thus we can exploit the resulting huge coverage to discard bad reads based on the base quality scores  <cit> . after discarding all the reads from the real data set that had average quality scores below  <dig>  we still had 200× of raw reads with a  <dig> % base sequencing error rate. the insert length for the data set was found to be normally distributed with mean length of  <dig>  and standard deviation  <dig> 

we maintained these properties in our simulated dataset, except that we sampled our reads uniformly whereas the real data set contains artifacts like thinly sampled regions. all reads were  <dig> bases long and sampled in solid's color space. starter seeds used in the experiments were around  <dig> bases long. all data were sampled from both strands of the corresponding genome. all datasets were generated in solid's two base encoding format and hence the contigs we generate are also two base encoded.

experiments with simulated solid data
results for one dataset from each of the three species under consideration are shown in table  <dig>  all the datasets were assembled with 100× input coverage and a small number of starter seeds. the results are shown in different levels of minimum contig accuracy  along with the overall assembly score  which basically shows the quality of our contigs. for a definition of these terms, please see the end of the methods section.

                              a
experiments with real solid data
we obtained access to an initial real dataset of 300×  coverage of e. coli  in june  <dig>  throwing out the "bad reads"  still left us with 200× coverage. after running shorty on it, we managed to maintain more than 90% coverage of the reference sequence in pieces of length  <dig> or more. however the maximum contig length was only  <dig>  where the simulated data with half the coverage produced a contig as big as  <dig>  bp . we ran three experiments  with each of them processing three randomly chosen seeds from the reference. all of them show similar results in terms of coverage, contig length and distribution of gaps. gaps were of short length and uniformly distributed over the sequence. this was due to the thinly sampled regions  or missing points which we believe is an artifact that needs to be overcome by solid.

                              a
to put our performance on the real dataset into perspective, we tested the data against other available assemblers. none of them currently works with abi's color space data, making it difficult to find suitable assembler that could run solid data with minor format change. we tried sharcgs  <cit> , but even the  <dig> g memory available in our machines did not suffice for assembly. we tried the latest version of ssake  <cit>  with the default setting for paired end reads. ssake produced only  <dig> contigs  that were longer than  <dig> bases, with the maximum contig size of  <dig> bp.

resource consumption
all experiments mentioned here were running in machines with two  <dig>  ghz amd opteron processors. in the end, shorty was proved to be extremely efficient in memory consumption. a 100× single seeded experiment with m. genitallium took  <dig> m of memory. experiments with s. suis and e. coli consumed  <dig>  g and  <dig>  g memory respectively. their corresponding running time was  <dig>   <dig> and  <dig> hours. when using multiple seeds, we run each seed in parallel in different machines. that means, shorty is capable of running in most of today's personal computers. we have seen that resource consumption was one of the major concerns with short read assembly due the the huge volume of data.

CONCLUSIONS
we have presented what we believe to be the first results on the de novo assembly of abi solid data. the results we have presented here provide evidence that high-quality short read assembly is indeed possible using simple and economical protocols on real short-read data. unlike previous works, our protocol uses a single sample preparation as opposed to a mix of insert sizes or or runs on a mix of different platforms . our assemblies thrive on significant variance in insert length, further simplifying preparation over others in the literature.

our use of single seed reads is more of a nuisance than a problem, as this data can be obtained cheaply through outsourcing services. an interesting question is whether they are really necessary. database sequence from closely-related species should suffice, but even more to the point is noting how little information they add to the process. three  <dig> base seeds represent only  <dig>  bits of information in an assembled genome of  <dig> , <dig> bits, making it hard to believe they really are essential. our proposed alternative to this is to run an existing assembler on the initial reads to get few contigs large enough to serve as starter seeds. we hope add this to shorty as part of a future release.

our primary direction of further work is demonstrating significant de novo assemblies on each of the major short-read platforms, namely abi solid™, solexa paired-read data, and helicos biosciences data as they become available to us. we are also working to raise our n <dig> sizes through gap filling techniques based on accurate positional estimation.

