BACKGROUND
motif search has applications in solving such crucial problems as identification of alternative splicing sites, determination of open reading frames, identification of promoter elements of genes, identification of transcription factors and their binding sites, etc. . there are many formulations of the motif search problem. a widely studied formulation is known as -motif search or planted motif search   <cit> . given two integers l,d and n biological strings the problem is to find all strings of length l that appear in each of the n input strings with atmost d mismatches. there is a significant amount of work in the literature on pms .

pms considers only point mutations as events of divergence in biological sequences. however, insertions and deletions also play important roles in divergence  <cit> . therefore, researchers have also considered a formulation in which the levenshtein distance , instead of mismatches, is used for measuring the degree of divergence  <cit> . given n strings s,s,…,s, each of length m from a fixed alphabet Σ, and integers l,d, the edit-distance-based motif search  problem is to find all patterns m of length l that occur in atleast one position in each s with an edit distance of atmost d. more formally, m is a motif if and only if ∀i, there exist k∈ ,j∈  such that for the substring sj,k of length k at position j of s, edsj,k,m≤d. here ed stands for the edit distance between two strings x and y.

ems is also np-hard since pms is a special case of ems and pms is known to be np-hard  <cit> . as a result, any exact algorithm for ems that finds all the motifs for a given input can be expected to have an exponential  worst case runtime. one of the earliest ems algorithms is due to rocke and tompa  <cit>  and is based on gibbs sampling which requires repeated searching of the motifs in a constantly evolving collection of aligned strings, and each search pass requires o time. this is an approximate algorithm. sagot  <cit>  gave a suffix tree based exact algorithm that takes o time and o space where w is the word length of the computer. adebiyi and kaufmann  <cit>  proposed an exact algorithm with an expected runtime of o) lognm) where ε=d/l and pow is an increasing concave function. the value of pow is roughly  <dig>  for protein and dna sequences. wang and miao  <cit>  gave an expectation minimization based heuristic genetic algorithm.

rajasekaran et al.  <cit>  proposed a simpler deterministic motif search  that has the same worst case time complexity as the algorithm by sagot  <cit> . the algorithm generates and stores the neighborhood of every substring of length in the range  of every input string and using a radix sort based method, outputs the neighbors that are common to atleast one substring of each input string. this algorithm was implemented by pathak et al.  <cit> .

following a useful practice for pms algorithms, pathak et al.  <cit>  evaluated their algorithm on certain instances that are considered challenging for pms: , ,  and so on  <cit> , and are generated as follows: n= <dig> random dna/protein strings of length m= <dig>  and a short random string m of length l are generated according to the independent identically distributed  model. a separate random d-hamming distance neighbor of m is “planted” in each of the n input strings. such an  instance is defined to be a challenging instance if l is the largest integer for which the expected number of spurious motifs, i.e., the motifs that would occur in the input by random chance, is atleast  <dig> 

the expected number of spurious motifs in ems are different from those in pms. table  <dig> shows the expected number of spurious motifs for l∈  and d upto max{l− <dig> }, n= <dig>  m= <dig> and Σ={a,c,g,t} . the challenging instances for ems turn out to be , , ,  and so on. to compare with  <cit> , we consider both types of instances, specifically, , , , ,  and .

l
∞
∞
∞
∞
∞
∞
 <dig> 
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
 <dig> 
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
 <dig> 
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
 <dig> 
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
∞
the instances in bold represents challenging instances



the sequential algorithm by pathak et al.  <cit>  solves the moderately hard instance  in a few hours and does not solve the next difficult instance  even after  <dig> days. a key time-consuming part of the algorithm is in the generation of the edit distance neighborhood of all substrings as there are many common neighbors.

contributions
in this paper we present several improved algorithms for ems that solve instance  in less than a couple of minutes and instance  in less than a couple of hours. on  our algorithm is more than  <dig> times faster than ems <dig>  our algorithm uses an efficient technique  to generate the edit distance neighborhood of length l with distance atmost d of all substrings of an input string. our parallel algorithm in the multi-core shared memory setting has more than  <dig> % scaling performance on  <dig> threads. our approach uses following five ideas which can be applied to other motif search problems as well:

efficient neighborhood generation: we show that it is enough to consider the neighbors which are at a distance exactly d from all possible substrings of the input strings. this works because the neighbors at a lesser distance are also included in the neighborhood of some other substrings.

compact representation using wildcard characters: we represent all possible neighbors which are due to an insertion or a substitution at a position by a single neighbor using a wildcard character at the same position. this compact representation of the candidate motifs in the neighborhood requires less space.

avoiding duplication of candidate motifs: our algorithm uses several rules to avoid duplication in candidate motifs and we prove that our technique generates neighborhood that is nearly duplication free. in other words, our neighborhood generation technique does not spend a lot of time generating neighbors that have already been generated.

trie based data structure for storing compact motifs: we use a trie based data structure to efficiently store the neighborhood. this not only simplifies the removal of duplicate neighbors but also helps in outputting the final motifs in sorted order using a depth first search traversal of the trie.

modified radix-sort for compact motifs: our parallel algorithm stores the compact motifs in an array and uses a modified radix-sort algorithm to sort them. use of arrays instead of tries simplifies updating the set of candidate motifs by multiple threads.

methods
in this section we introduce some notations and observations.

an -friend of a k-mer l is an l-mer at an exact distance of d from l. let fl,d denote the set of all -friends of l. an -neighbor of a k-mer l is an l-mer at a distance of atmost d from l. let nl,d denote the set of all -neighbors of l. then 
  <dig> nl,d=∪t=0dfl,t. 

for a string s of length m, an -motif of s is an l-mer at a distance atmost d from some substring of s. thus an -motif of s is an -neighbor of atleast one substring sj,k=sjsj+1…sj+k− <dig> where k∈. therefore, the set of -motifs of s, denoted by ml,d, is given by 
  <dig> ml,d=∪k=l−dl+d∪j=1m−k+1nl,d. 

for a collection of strings s={s,s,…,s}, a  -motif is an l-mer at a distance atmost d from atleast one substring of each s. thus the set of  -motifs of s, denoted by ml,d, is given by 
  <dig> ml,d=∩i=1nml,d). 

one simple way of computing fl,d is to grow the friendhood of l by one distance at a time for d times and to select only the friends having length l. let g denote the set of strings obtained by one edit operation on l and g=∪t=1rg. if g1=g, and for t> <dig>  gt=g) then 
  <dig> fl,d={x∈gd:|x|=l}. 

using eqs. , ,  and , pathak et al.  <cit>  gave an algorithm that stores all possible candidate motifs in an array of size |Σ|l. however the algorithm is inefficient in generating the neighborhood as the same candidate motif is generated by several combinations of the basic edit operations. also, the o memory requirement makes the algorithm inapplicable for larger instances. in this paper we mitigate these two limitations.

efficient neighborhood generation
we now give a more efficient algorithm to generate the -neighborhood of all possible k-mers of a string. instead of computing -friendhood for all 0≤t≤d, we compute only the exact -friendhood.

lemma <dig> 
ml,d=∪k=l−dl+d∪j=1m−k+1fl,d.

proof.
consider the k-mer l=sj,k. if k=l+d then we need d deletions to make l an l-mer. there cannot be any -neighbor of l for t<d. thus 
  <dig> ∪t=0dfl,t=fl,d. 

suppose k<l+d. any -neighbor b of l is also an -neighbor of l′=sj,k+ <dig> because ed≤ed+ed≤+1=d. thus 
 ∪t=0dfl,t⊆fl,d⋃∪t=0dfl,t 

which implies that 
  <dig> ∪r=kk+1∪t=0dfl,t=fl,d⋃∪t=0dfl,t. 

applying  repeatedly for k=l−d,l−d+ <dig> …,l+d− <dig>  along with  in  and  gives the result of the lemma.

we generate fl,d in three phases: we apply δ deletions in the first phase, β substitutions in the second phase, and α insertions in the final phase, where d=δ+α+β and l=k−δ+α. solving for α,β,δ gives max{ <dig> q}≤δ≤/ <dig>  α=δ−q and β=d−2δ+q where q=k−l. in each of the phases, the neighborhood is grown by one edit operation at a time.

compact motifs
the candidate motifs in fl,d are generated in a compact way. instead of inserting each character in Σ separately at a required position in sj,k, we insert a new character ∗∉Σ at that position. similarly, instead of substituting a character σ∈sj,k by each σ′∈Σ∖{σ} separately, we substitute σ by ∗. the motifs common to all strings in s is determined by using the usual definition of union and the following definition of intersection on compact strings a,b∈l in : 
  <dig> a∩b=∅if∃js.t.aj,bj∈Σ,aj≠bjσ1σ2…σlelse, whereσj=bjifaj=∗ajifbj=∗. 

trie for storing compact motifs
we store the compact motifs in a trie based data structure which we call a motif trie. this helps implement the intersection defined in . each node in the motif trie has atmost |Σ| children. the edges from a node u to its children v are labeled with mutually exclusive subsets label⊆Σ. an empty set of compact motifs is represented by a single root node. a non-empty trie has l+ <dig> levels of nodes, the root being at level  <dig>  the trie stores the l-mer σ1σ2…σl, all σj∈Σ, if there is a path from the root to a leaf where σj appears in the label of the edge from level j− <dig> to level j.

for each string s=s we keep a separate motif trie m. each compact neighbor a∈fl,d is inserted into the motif trie recursively as follows. we start with the root node where we insert a1a2…al. at a node u at level j where the prefix a1a2…aj− <dig> is already inserted, we insert the suffix ajaj+1…al as follows. if aj∈Σ we insert a′=aj+1aj+2…al to the children v of u such that aj∈label. if label≠{aj}, before inserting we make a copy of subtrie rooted at v. let v′ be the root of the new copy. we make v′ a new child of u, set label={aj}, remove aj from label, and insert a′ to v′. on the other hand if aj=∗ we insert a′ to each children of u. let t=Σ if aj=∗ and t={aj} otherwise. let r=t∖∪vlabel. if t≠∅ we create a new child v′ of u, set label=r and recursively insert a′ to v′. figure  <dig> shows examples of inserting into the motif trie.
fig.  <dig> inserting into motif trie for Σ={a,c,g,t} and l= <dig>  a after inserting ∗g
t into empty trie. b after inserting another string a∗c




we also maintain a motif trie ℳ for the common compact motifs found so far, starting with ℳ=m. after processing string s we intersect the root of m with the root of ℳ. in general a node u2∈m at level j is intersected with a node u1∈ℳ at level j using the procedure shown in algorithm  <dig>  figure  <dig> shows an example of the intersection of two motif tries.
fig.  <dig> intersection of motif tries. a trie for a
g∗∪c∗t. b intersection of trie in fig. 1
b and trie in fig. 2
a






the final set of common motifs is obtained by a depth-first traversal of ℳ outputting the label of the path from the root whenever a leaf is traversed. an edge  is traversed separately for each σ∈label.

efficient compact neighborhood generation
a significant part of the time taken by our algorithm is in inserting compact neighbors into the motif trie as it is executed for each neighbor in the friendhood. our efficient neighborhood generation technique and the use of compact neighbors reduce duplication in neighborhood but do not guarantee completely duplication free neighborhood. in this section, we design few simple rules to reduce duplication further. later we will see that these rules are quite close to the ideal as we will prove that the compact motif generated after skipping using the rules, are distinct if all the characters in the input string are distinct.

to differentiate multiple copies of the same compact neighbor, we augment it with the information about how it is generated. this information is required only in the proof and is not used in the actual algorithm. formally, each compact neighbor l of a k-mer sj,k is represented as an ordered tuple 〈sj,k,t〉 where t denotes the sequence of edit operations applied to sj,k. each edit operation in t is represented as a tuple 〈p,o〉 where p denotes the position  where the edit operation is applied and o∈{d,r,i} denotes the type of the operation – deletion, substitution and insertion, respectively. at each position there can be one deletion or one substitution but one or more insertions. the tuples in t are sorted lexicographically with the natural order for p and for o, d<r<i.

the rules for skipping compact neighbors are given in table  <dig>  rule  <dig> applies when sj,k is not the rightmost k-mer and the current edit operation deletes the leftmost base of sj,k, i.e., sj. rule  <dig> applies when the current edit operation substitutes a base just after a base that was already deleted. rule  <dig> skips the neighbor which is generated from a k-mer except the rightmost by deleting a base and substituting all bases before it. rules 4– <dig> apply when the current operation is an insertion. rule  <dig>  apply when the insertion is just before a deletion and a substitution, respectively. rule  <dig> applies when the insertion is just after a deletion. rule  <dig>  apply when the k-mer is not the leftmost. rule  <dig> applies when the insertion is at the leftmost position and rule  <dig> applies when all bases before the position of insertion are already substituted. rule  <dig> applies when the k-mer is not the rightmost and the insertion is at the right end. the first in each pair of the figures in fig.  <dig> illustrates the situation where the corresponding rule applies.
fig.  <dig> construction of l
′ under different rules in the proof of lemma  <dig>  insertions are shown using arrows, deletions using − and substitutions using ∗. rule  <dig> case  is similar to rule  <dig> case 
j,k,t〉



let m¯l,d denote the multi-set of tuples for the compact motifs of s that were not skipped by our algorithm using the rules in table  <dig> and ml, d be the set of compact motifs generated by . let Γ be the resulting string when the operations in t are applied to sj, k and Γ=∪l∈zΓ.

lemma <dig> 
Γ)=ml,d.

proof.
by construction, Γ)⊆ml,d. we show ml,d⊆Γ) by giving a contradiction when ml,d∖Γ)≠∅.

we define an order on the compact neighbors l1=〈sj <dig> k <dig> t1〉 and l2=〈sj <dig> k <dig> t2〉 as follows: l1<l <dig> if Γ<Γ and l2<l <dig> if Γ<Γ. when Γ=Γ we have l1<l <dig> if and only if ∨∧)∨∧∧) where 〈p <dig> o1〉∈t <dig> 〈p <dig> o2〉∈t <dig> are the leftmost edit operations where t <dig> t <dig> differ.

suppose m∈ml,d∖Γ). let l=〈sj, k,t〉 be the largest  tuple skipped by our algorithm such that Γ=m. for each r= <dig> …, <dig> we show a contradiction that if l is skipped by rule r then there is another l′=〈sj′,k′,t′〉 with the same number of edit operations and Γ=m but l<l′. figure  <dig> illustrates the choice of l′ under different rules.

rule  <dig>  here j+k≤m and 〈j,d〉∈t. consider t′=∪{j+k,d}, and j′=j+ <dig> k′=k.

rule  <dig>  consider t′=t∖{〈j+t,d〉,〈j+t+ <dig> r〉}∪{〈j+t,r〉,〈j+t+ <dig> d〉}, and j′=j,k′=k.

rule  <dig>  t′=t∖{〈j,r〉,〈j+t+ <dig> d〉}∪{〈j+t+ <dig> r〉,〈j+k,d〉}, j′=j+ <dig> k′=k.

rule  <dig>  for this and subsequent rules k<l+d as there is atleast one insertion and hence k′ could possibly be equal to k+ <dig>  we consider two cases. case  j+k≤m: t′=t∖{〈j+t,d〉,〈j+t,i〉}∪{〈j+t,r〉,〈j+k,d〉}, j′=j,k′=k+ <dig>  case  j+k=m+1: here deletion of sj is allowed by rule  <dig>  t′=t∖{〈j+t,d〉,〈j+t,i〉}∪{〈j− <dig> d〉,〈j+t,r〉}, j′=j− <dig> k′=k+ <dig> 

rule  <dig>  the same argument for rule  <dig> applies considering 〈j+t+ <dig> i〉 instead of 〈j+t,i〉.

rule  <dig>  t′=t∖{〈j+t,i〉}∪{〈j+t+ <dig> i〉}, and j′=j,k′=k.

rule  <dig>  t′=t∖{〈j,i〉}∪{〈j− <dig> r〉}, j′=j− <dig> k′=k+ <dig> 

rule  <dig>  t′=t∖{〈j+t,i〉}∪{〈j− <dig> r〉}, j′=j− <dig> k′=k+ <dig> 

rule  <dig>  t′=t∖{〈j+k,i〉}∪{〈j+k,r〉}, j′=j,k′=k+ <dig> 

consider two compact motifs m1=〈sj <dig> k <dig> t1〉 and m2=〈sj <dig> k <dig> t2〉 in m¯l,d. for q∈{ <dig> }, let pq,oq,pq,oq,…,pq,oq be the sequence of edit operations in tq arranged in the order as the neighbors are generated by our algorithm, and the intermediate neighbors be lq=sjq,kq,pq,oq,pq,oq,…,pq,oq for all h= <dig> ,…,d. we also denote the initial k-mer as a neighbor lq=〈sjq,kq,∅〉.

lemma <dig> 
if sjs are all distinct and Γl1=Γl <dig> for 1≤h≤d then p <dig> o1=p <dig> o <dig> and Γl1=Γl <dig> 

proof.
to simplify the proof, we use pq,oq,lq to denote pq,oq,lq, respectively, for all q∈{ <dig> }. without loss of generality we assume p1≤p <dig> 

as p <dig> p <dig> are positions in s, it would be enough to prove 〈p <dig> o1〉=〈p <dig> o2〉 because that would imply Γl1=Γl <dig> 

if 〈p <dig> o1〉≠〈p <dig> o2〉 then either  o1=o <dig> and p1<p <dig> or  o1≠o <dig> and p1≤p <dig>  giving us the following  <dig> possible cases. we complete the proof by giving a contradiction in each of these  <dig> cases:

case
o
1
o
2
cond.
case
o
1
o
2
cond.
case
o
1
o
2
cond.
d
d
p
1<p
2
r
d
p
1≤p
2
i
d
p
1≤p
2
d
r
p
1≤p
2
r
r
p
1<p
2
i
r
p
1≤p
2
d
i
p
1≤p
2
r
i
p
1≤p
2
i
i
p
1<p
2


cases  <dig>   <dig>   <dig>  7

our algorithm applies edit operations in phases: first deletions, followed by substitutions and finally insertions. in all these cases, one of Γ,Γ does not have any ∗ because only deletions have been applied so far and the other has at least one ∗ because a substitution or an insertion has been applied. this implies Γ≠Γ, a contradiction.

case 1

l <dig> has sp <dig> deleted. as Γ=Γ, sp <dig> must have been deleted in some operation prior to reaching l <dig>  as the deletions are applied in order, left to right, we must have p1=p <dig> which is a contradiction.

case 5

this case has been illustrated in fig. 4a. l <dig> has no substitution at a position >p <dig> and no insertion at all. the ∗ at p <dig> in l <dig> must be matched with the ∗ at p <dig> in l <dig> and as the characters in s are distinct, all of sp1+ <dig> …,sp <dig> cannot appear in l <dig> and hence must be deleted in l <dig> 
fig.  <dig> proof of uniqueness . subfigures a,b,c,d illustrates the cases  <dig> , <dig> , <dig> respectively



now for each t<p <dig>  right to left, and y=t+p2−p <dig>  we have the following: sy is either deleted or substituted in l <dig>  which implies that sy must be substituted in l <dig> as the deletion of sy in l <dig> is prohibited by rule  <dig>  and finally to match this ∗ in l <dig>  st must be substituted in l <dig> as st cannot be deleted in l <dig>  again by rule  <dig> 

but this makes rule  <dig> applicable to l <dig> and l <dig> must have been skipped. this is a contradiction.

case 6

by rule  <dig> the insertion in l <dig> cannot be at the rightmost position and hence l <dig> must have at least one character after the insertion. by rules  <dig> and  <dig>  sp <dig> must not be deleted or substituted in l <dig> and hence it must not be deleted or substituted in l <dig> either. thus p1<p <dig>  there cannot be any insertion or substitution at a position >p <dig> in l <dig>  thus the ∗ due to the insertion at p <dig> in l <dig> must be matched by the ∗ due to the substitution at p <dig> in l <dig> and all of sp1+ <dig> …,sp2− <dig> must be deleted in l <dig> 

by rule  <dig>  sp <dig> cannot be the leftmost in sj <dig> k <dig>  so we consider sp2− <dig> in l <dig> l <dig>  it is either deleted or substituted in l <dig> and hence by rule  <dig>  it must be substituted in sp <dig> . to match this ∗, sp1− <dig> must be substituted in l <dig> 

using a similar argument as in case  <dig>  st must be substituted in l <dig> for each t<p1− <dig>  but this again makes rule  <dig> applicable to l <dig> and l <dig> must have been skipped, which is not possible. this case has been illustrated in fig. 4b.

case 8

due to rules  <dig>   <dig> and  <dig>  sp <dig> must not be deleted or substituted in l <dig> and hence it must not be deleted or substituted in l <dig> either. thus p1<p <dig>  the ∗ due to the insertion in l <dig> must be matched by a substitution at p3<p <dig> such that all of sp3+ <dig> …,sp1− <dig> are deleted in l <dig> 

by rule  <dig>  p <dig> cannot be the leftmost in l <dig>  for each t<p <dig>  right to left, and y=t+p3−p <dig>  we have the following: sy is substituted in l <dig> because as the deletion of sy in l <dig> is prohibited by rules  <dig> and  <dig>  sy must be substituted in l <dig> again by rule  <dig>  and to match this ∗, st must be substituted in l <dig> 

but this makes rule  <dig> applicable to l <dig> and l <dig> must have been skipped which is not possible. this case has been illustrated in fig. 4c.

case 9

this case has been illustrated in fig. 4d. due to rules  <dig>   <dig> and  <dig>  sp <dig> sp <dig> must not be deleted or substituted in l <dig> l <dig>  the insertion at p <dig> in l <dig> must be matched by a substitution at a position p <dig> in l <dig> such that p1<p3<p <dig> and all of sp3+ <dig> …,sp2− <dig> must be deleted in l <dig> 

now for each position y, from right to left, where p1<y<p <dig>  sy is either deleted or substituted in s <dig>  sy cannot be deleted in l <dig> by rules  <dig> and  <dig> and hence must be substituted in l <dig>  which again must be matched by a substitution at a position t in l <dig> such that p1<t<p <dig>  however this is impossible as the number of possible ys is larger than the number of possible ts.

if all sjs are distinct and Γ=Γ then applying lemma  <dig> repeatedly for h=d,d− <dig> …, <dig> gives us the fact that starting k-mers sj <dig> k <dig> sj <dig> k <dig> as well as the corresponding edit operations in t <dig> t <dig> for m <dig> m <dig> must be the same. this is another way of stating the following theorem.

theorem <dig> 
if sjs are all distinct then m¯l,d is duplication free.

in general sjs are not distinct. however, as the input strings are random, the duplication due to repeated characters are limited. on instance  our algorithm generates each compact motif, on an average,  <dig>  times using the rules compared to  <dig>  times without the rules .
fig.  <dig> histogram of number of times a motif is repeated with and without using the skipping rules 1–9



implementation to track the deleted characters, instead of actually deleting we substitute them by a new symbol − not in Σ′. we populate the motif trie m by calling genall) given in algorithm  <dig>  rules 1– <dig> are incorporated in g, h and i which are shown in algorithms  <dig>   <dig>  and  <dig>  respectively where sub substitutes lj by σ and ins inserts σ just before lj.









modified radix-sort for compact motifs
a simpler data structure alternative to tries for storing compact motifs could be an array. however, it becomes difficult to compute the intersection in  as defined in  when the compact motifs are stored in arrays. one straight-forward solution is to first expand the ∗s in the compact motifs, then sort the expanded motifs and finally compute the intersection by scanning through the two sorted arrays. this, to a great extent, wipes out the advantage using the ∗s in the compact motifs. however, we salvage execution time by executing a modified radix-sort that simultaneously expands and sorts the array of compact motifs: compact-radix-sort where the first parameter a represents the array of compact motifs and the second parameter represents the number of digits of the elements in a which is equal to the number of base positions l in a motif.

as in the standard radix-sort, our algorithm uses l phases, one for each base position in the motif. in the ith phase it sorts the motifs using bucket sort on the ith base of the motifs. however, in case of compact motifs, for each ∗ at a base position, the bucket counters for all σ∈Σ are incremented. while reordering the motifs as per the bucket counts, if there is a ∗ at ith base position of a motif, |Σ| copies of the motif are created and they are placed at appropriate locations in the array after finalizing the correct σ for the ∗. the details are given in algorithm  <dig>  in each phase a bucket counter b and a cumulative counter c are used. the temporary array t stores the partially expanded motifs from the current phase.

discussion we did an experiment to compare the time taken by the two approaches –  using the expanded motifs, i.e., without using the wildcard character, and  using compact motifs and sorting them using compact-radix-sort. for a single input string of instance , the first approach generated in  <dig>  s  <dig> , <dig> expanded motifs in which  <dig> , <dig> are unique. the second approach generated in  <dig>  s  <dig> , <dig> compact motifs with the same number of unique expanded motifs. this shows the effectiveness of the second approach.



parallel algorithm
we now give our parallel algorithm in the multi-core shared memory setting. to process each input sequence s the algorithm uses p+ <dig> threads. the main thread first prepares the workload for other p threads. a workload involves the generation of the neighborhood for a k-mer of s, where l−d≤k≤l+d. there are total ∑k=l−dl+d= workloads. the number of neighbors generated in the workloads are not the same due to the skipping of some neighbors using rules 1– <dig>  for load balancing, we randomly and evenly distribute workloads to threads. each thread first generates all the compact motifs in its workloads and then sort them using compact-radix-sort. if i> <dig> then it removes all neighbors not present in m which is the set of common motifs of s,s,…,s. the master thread then merges the residue candidate motifs from all the p threads to compute m. the merging takes place in log2p phases in a binary tree fashion where the jth phase uses 2log2p−j threads each merging two sorted arrays of motifs.

RESULTS
we implemented our algorithms in c++ and evaluated on a dell precisions workstation t <dig> running rhel  <dig>  on two sockets each containing  <dig> dual intel xeon processors e5- <dig>  and  <dig> gb ram. for our experiments we used only one of the two sockets. we generated random  instances according to pevzner and sze  <cit>  and as described in the background section. for every  combination we report the average time taken by  <dig> runs. we compare the following four implementations: 
ems1: a modified implementation of the algorithm in  <cit>  which considered the neighborhood of only l-mers whereas the modified version considers the neighborhood of all k-mers where l−d≤k≤l+d.

ems2: a faster implementation of our sequential algorithm which uses tries for storing candidate motifs where each node of the trie stores an array of pointers to each children of the node. however, this makes the space required to store a tree node dependent on the size of the alphabet Σ.

ems2m: a slightly slower but memory efficient implementation of our sequential algorithm where each node of the trie keeps two pointers: one to the leftmost child and the other to the immediate right sibling. access to the other children are simulated using the sibling pointers.

ems2p: our parallel algorithm which uses arrays for storing motifs. we experimented with p= <dig> , <dig> , <dig> threads.



we run the four algorithms on the challenging instances , ,  and on the instances , ,  which are challenging for pms and have been used for experimentation in  <cit> . we report the runtime and the memory usage of the four algorithms in table  <dig> 
time is in seconds , minutes  or hours . an empty cell implies the algorithm did not complete in the stipulated  <dig> h



our efficient neighborhood generation enables our algorithm to solve instance  in less than two hours which ems <dig> could not solve even in  <dig> days. the factor by which ems <dig> takes more memory compared to ems <dig> gradually decreases as instances become harder. as ems <dig> stores  <dig> child pointers for a,c,g,t in each node of the motif trie whereas ems2m simulates access to children using only  <dig> pointers, ems <dig> is faster. memory reduction in ems2m is not exactly by a factor  <dig> because we also keep a bit vector in each node to represent the subset of {a,c,g,t} a child corresponds to. the memory reduction would be significant for protein strings.

our parallel algorithm ems2p using one thread is significantly faster than the sequential algorithms ems <dig> and ems2m but uses more memory. this space-time trade off is due to the fact that the arrays are faster to access but the tries use lesser memory. moreover, the repeated motifs are uniquely stored in a single leaf node in the trie but stored separately in the array. the scaling performance using multiple threads are shown in fig.  <dig> where we plot the ratio of time taken by p threads to the time taken by a single thread on the y-axis. the time required for handling  <dig> threads turns out to be costlier than actually processing the motifs in the smallest instance . we observe speed up consistent across other bigger instances. for example, instance  takes about  <dig> s using  <dig> thread and  <dig> s using  <dig> threads. this gives more than  <dig> % scaling performance using  <dig> threads.
fig.  <dig> scaling performance of our parallel algorithm



CONCLUSIONS
we presented several efficient sequential and parallel algorithms for the ems problem. our algorithms use some novel and elegant rules to explore the candidate motifs in such a way that only a small fraction of the candidate motifs are explored twice or more. in fact, we also proved that these rules are close to ideal in the sense that no candidate motif is explored twice if the characters in the input string are all distinct. this condition may not be practical and ideas from  <cit>  can be used when the characters in the input string are repeated. nevertheless, the rules help because the instances are randomly generated and the k-mers in the input string are not much frequent. the second reason for the efficiency of our sequential algorithms is the use of a trie based data structure to compactly store the motifs. our parallel algorithm stores candidate motifs in an array and uses a modified radix-sort based method for filtering out invalid candidate motifs.

our algorithms pushed up the state-of-the-art of ems solvers to a state where the challenging instance  is solved in slightly more than half a minute using  <dig> threads. future work could be to solve harder instances, including those involving protein strings, and possibly using many-core distributed algorithms.

additional file
additional file  <dig> expected number of spurious motifs. this file gives the expression for the expected number of spurious -motifs in n random strings of length m from the alphabet Σ. 



this work has been supported in part by the nih grant r01-lm <dig> and nsf grant  <dig> 

declarations
publication of this article was funded by the nih grant r01-lm <dig> and nsf grant  <dig>  this article has been published as part of bmc genomics vol  <dig> suppl  <dig> 2016: selected articles from the ieee international conference on bioinformatics and biomedicine 2015: genomics. the full contents of the supplement are available online at https://github.com/soumitrakp/ems <dig> git.

availability
a c++ based implementation of our algorithm can be found at the following github public repository:

https://github.com/soumitrakp/ems <dig> git.

authors’ contributions
sp and sr conceived the study. sp implemented the algorithms and px carried out the experiments. sp and sr analyzed the results and wrote the paper. all authors reviewed the manuscript. all authors read and approved the final manuscript.

competing interests
the authors declare that they have no competing interests.
