BACKGROUND
the enormous amount of sequence data available in the public domain database has been a gold mine for researchers exploring various themes in life sciences. however, the quality of such data greatly affects subsequent analyses and hence is of serious concern to researchers. data quality problems with the international sequence databanks have been reported previously  <cit> , for example, multiple representations of the same gene, vector contamination in a non-vector sequence  <cit>  and erroneous annotation of the exon/intron site in a gene  <cit> .

expressed sequence tags   <cit>  are single reads of partially sequenced cdna fragments. est sequences have been applied to studies on gene prediction, alternative splicing, differential gene expression in specific tissues, etc.. more than half of the files in genbank are est data   <cit> , which were often produced in a batch sequencing project by automated processes. a computational processing procedure is therefore needed to obtain a reliable sequence which solely represents the molecular information of the cdna. there is already a well-established procedure for est sequence processing: trace data clean-up followed by removal of vector contamination. various efficient bioinformatics tools such as phred  <cit>  have been made available on the internet for the purpose of trace data clean-up. additionally, offline software like cross_match  <cit>  by phil green, seqclean  <cit>  and lucy  <cit>  from tigr  <cit> , or the online program vecscreen  <cit>  available at ncbi  <cit>  are popular computer programs for vector contamination detection and/or removal.

cross_match was implemented based on a restricted smith-waterman algorithm  <cit> . the program executes a highly sensitive and efficient alignment to identify similarity between the two sequences under comparison, and it requires additional computer processing to remove the identified vector-like region from the target sequences. cross_match has been incorporated into some est processing packages such as partigene  <cit> , a pipeline which integrates several bioinformatics programs to accomplish processes including sequence clean-up, est clustering, assembly and functional annotation.

lucy  <cit>  searches for the greatest number of high quality subsequences in the query sequence according to the quality value of each base, which has been computed by a chromatogram base-calling program, such as phred  <cit> , on the trace data. lucy then identifies the vector spliced or ligated to the input sequence based on a depth-first search algorithm, which gives a stringency of 95% minimal sequence similarity. the program finally removes the identified vector sequence from the input.

seqclean  <cit>  utilizes blast  <cit>  to remove any sequence highly similar  to a given list of vectors, adaptors, primers, or linker sequences that is located within 30% of total est from the 3' or 5' end of the sequences to be trimmed. seqclean also removes polya repeats and applies low complexity filtering  to identify similar vector segments in the target est. following the trimming process, the program "trashes" those sequences which are shorter than  <dig> nucleotides or contain more than 3% undetermined bases  in the resulting sequences.

using blast, vecscreen can identify vector and primer contamination by comparing the input est sequences at preset parameters against the univec  <cit>  database, which contains most of the commonly used commercial vectors and primers. however, several limitations are associated with this procedure. for example, a batch search function is not provided at the vecscreen website and furthermore, it does not remove those segments from the screened ests.

the seqclean program was initially selected for use in our study. this program can be downloaded from the tigr website for free, and it has been used in several est projects  <cit>  as well as a genome sequencing project  <cit> . a large number of the est sequences deposited in the public domain database may have been subjected to vector contamination removal by seqclean. here, we report an anomaly in the seqclean trimming process and provide a refined procedure that greatly improves the trimming efficiency of seqclean. trimming efficiency was also compared to the other programs mentioned above. in addition, the error rate in the est division of genbank  <cit>  was evaluated.

RESULTS
causes of errors in est vector removal
we performed vector trimming  to clean up thousands of est sequences derived by automatic sequencing of randomly picked clones of tomato cdna libraries prepared at our facility . after initial seqclean trimming, some sequences, when examined with blast against the nucleotide sequence of their corresponding cloning vectors at scores above  <dig>  were still found to contain a significant amount of unwanted vector sequences within the trimmed segments. the problem was investigated further by closely examining some of the imperfectly trimmed ests. representative examples are shown in figure  <dig>  with condition a in figure  <dig>  seqclean overlooked two consecutive dna segments in an est including a vector fragment and a cdna insert located within 30% range of the 5' end. the entire est sequence was therefore considered to contain no insert and was trashed by the program, even though the cdna insert was longer than  <dig> bases. for other est sequences, such as in condition b, the entire vector fragment, extending from the base numbered  <dig> in its conventional expression to the ligation site, was mistakenly recognized as part of the cdna insert by the seqclean program and remained untrimmed by seqclean processing.

based on the observations above, a hypothesis was made that the trimming program neglected the circular form of the vector dna which resulted in erroneous trimming of some of the est sequences.

most cloning vectors exist in a circular form in nature. however, to conveniently manage these molecules electronically, the sequences are usually displayed in linear form by opening the circular dna at a specific position where the base is either numbered  <dig>  or the final base . discontinuous numbering of the circular dna sequence across the junction may lead to misinterpretation in bioinformatic analyses if the analysis program does not take this virtual transformation into consideration.

marked improvement made to vector trimming with modified procedure
a test of the above hypothesis was made with the seqclean trimming process by using a modified vector sequence which had been re-linearized by opening the circular vector dna at its ligation site, as depicted in figure  <dig>  the resulting dna sequences, denoted as re-linearized vector sequences  in the following parts of this paper, with the conventional sequence representation of a vector denoted as cvss. following seqclean processing against either form of the vector sequences, the trimmed ests were subjected to blast alignment against the sequence of their corresponding cloning vector to examine the completeness of the automated vector trimming process.

using  <dig>  ests produced in the research laboratories in our institute as a test set for vector removal by seqclean, vector contamination rate was reduced from  <dig> % to  <dig> % by trimming against rvs. furthermore,  <dig> of the ests were "rescued" by this modified procedure  after closely examining the trimming details provided in the output.

a % of incomplete trimming was obtained by dividing the number of incompletely trimmed ests by the number of ests to trim. for example, the percentage of incompletely trimmed ests in the cvs column was calculated as: 1118/ <dig> Ã— 100%.

comparison of seqclean, lucy <dig> and cross_match on cvs or rvs vectors
to further investigate whether our modified procedure is generally applicable to most cloning vectors with seqclean processing, and how this procedure could affect the performance of other software, two other popular trimming programs, cross_match and lucy <dig>  and an additional three sets of ests downloaded from trace archive  <cit>  at ncbi were included in this study .

a only  <dig> of the  <dig> ests cloned into pt7blue in this test used the indicated adapter while the remaining  <dig> used no adapters.

the chromatographic data of all test ests was cleaned with the program phred prior to processing by one of the trimming programs . the trimming performance of the three programs against cvs or rvs vectors were all compared in terms of number of incompletely-trimmed ests, number of low quality  ests discarded by a trimming program, and the average lengths of trimmed ests. as lucy was designed to find the longest high quality subsequences in the query sequence according to the quality value of each base, it can take a quality file in addition to a sequence file of the target est as input. therefore, lucy was tested taking either form of the input  in table 3) in this study.

a number of ests whose length is equal to or greater than  <dig> bases after being processed by a vector trimming program as indicated

among all the tested conditions , seqclean trimming against rvs markedly outperformed all the other conditions, delivering the lowest error rate without removing any additional ests .

it appears that directly trimming the phred-cleaned sequences with lucy <dig> gives a slightly better result than using quality files as input on all parameters tested . without modifying the vector form, lucy <dig> in combination with phred cleaning appeared to surpass the other two programs, giving the lowest error rate without reducing the amount of useful information . when trimming against rvss, lucy <dig> and cross_match did not seem to benefit from this modification as much as seqclean did. it is thus proposed that the design flaw found with seqclean very likely did not exist in the other two programs, hence rearrangement of the vector sequence may have little influence on these programs' performance.

to gain a closer look at the error distribution over different vectors, the results of incomplete trimming caused by each of the three programs were grouped by the vector used . the errors caused by seqclean mainly occurred to ests cloned into the vector pgem-teasy, which accounted for eight cdna libraries constructed with the similar experimental procedure  <cit> . though the ests cloned in ptriplex <dig> were cleaned very well by seqclean under either form of the vector, ptriplex <dig> ests were incompletely trimmed to a significant extent by both cross_match and lucy <dig> . the effect of the two vector forms on cross-match trimming seemed to be stochastically distributed among the ests cloned with different vectors . cross_match, based on a highly sensitive alignment algorithm, however, does not provide a cleaned segment of the target sequence after identifying segments of vector/adaptor/primer similar regions .

contamination rates of ests resulted from vector trimming under indicated conditions were grouped by the cloning vectors. the ratio was expressed in percentage showing the proportion of the ests using a specific cloning vector remained incompletely cleaned.

the program leaves users to decide on which vector-free segments in the target sequence processed by cross-match should be output as the final product. for users who wish to conduct vector trimming with cross_match, software like partigene is recommended for it provides cleaned-up versions of the processed sequences. in this comparison of the trimming efficiency with the other two programs, we simply took the longest segment as the trimmed product.

investigation of vector contamination rate of dbest
as we observed different error rates caused by the vector trimming programs tested above, we were curious to see how much overall contamination remained in the dbest  <cit> . a total of  <dig> entries was randomly sampled from the entire dbest  by retrieving every 600th est entry from the database. these ests, were then subjected to blast analysis against univec database, which contains a redundancy-reduced set of representative sequences of commonly used cloning vectors. the same filtering criteria used above were applied to the blast results with e-value cutoff adjusted for the size of univec.  <dig>  of the sampled ests were observed to match some vector or primer/adaptor/linker sequence in univec.

though the analysis above provides a rough estimation of the extent of vector contamination in dbest, it could be an overestimation of the error rate. to assess the vector contamination more accurately, the sampled ests needed to be compared against the sequence of their specific cloning vectors. as some of the est entries in dbest lacked vector information, some of the vector data were incorrect and some of the vectors' sequences were difficult to obtain, a subset of  <dig> sampled ests which had been cloned into the  <dig> most prevalent vectors, derived from  <dig> libraries and submitted by around  <dig> research groups in dbest , were used for this part of our study. following blast analysis,  <dig> of the  <dig> dbest-derived ests showed a significant match to the sequence of their cloning vectors, giving a vector contamination rate of  <dig> % with an average match length of  <dig>  bases. the  <dig> ests which had significant vector remaining were cloned from  <dig> cdna libraries, using  <dig> different vector systems, and had been submitted by  <dig> independent research groups . the  <dig> incompletely trimmed ests were grouped according to their cloning vector and the contamination rate relative to the number of sampled ests using the same vector for cloning was also calculated . among the  <dig> vector groups sampled, those ests which were cloned into pcmv-sport <dig>  and ptriplex <dig> showed the highest contamination rate . it is notable that pcmv-sport <dig>  and ptriplex <dig> were almost completely removed from the ests by seqclean . moreover,  <dig> out of the  <dig> incompletely trimmed pcmv-sport <dig> -harbored-ests sampled from dbest  were derived from the same cdna library which had been used to study the performance of the three trimming programs in table  <dig> 

anumber of ests which were cloned into the indicated vector remained to be contaminated with vector.

bnumber of ests using the indicated vector were subjected to blast analysis for identification of vector contamination

cpercentage of vector contamination for the ests using the same cloning vector.

dpercetage obtained by 575/ <dig> =  <dig> %

in summary, using vectors in cvs form, lucy <dig> resulted in the lowest error rate among the three tested programs . though using the vectors in rvs form did not influence the trimming efficiency of lucy <dig> or cross_match, rvs forms of the vectors allowed seqclean to give the best trimming results of all tested programs . thus we highly recommend our modified procedure to all researchers using seqclean for the task of vector removal from est or genomic sequences.

discussion
questions over the quality of the sequence data deposited in the public domain database have caused great concern to life science researchers. though dbest provides vecscreen to help check the quality of submitted data, and the gene indices at tigr also filter est data for further grouping, the quality of est data is still not perfect, even in such a reputable data repository. previous studies  <cit>  reported vector contamination rates of  <dig> % to  <dig> % for nucleotide sequences in genbank. in this study, not only was significant vector contamination found in dbest by analyzing randomly sampled est data , but incomplete annotation of ests was also observed in both dbest and trace archive. the former error, that is, presence of vector sequences in the ests, may cause assembly artifacts as well as errors in many other analyses depending on ests, while the latter error affects the amount of effective data for further mining.

this study re-examined the vector contamination rate in the data randomly sampled from dbest. by looking at the  <dig> ests  which had been cloned into the  <dig> most prevalent vectors in the dbest,  <dig>  ests were still contaminated with vector sequences. one concern here was that the sampling procedure used here may result in an overrepresentation of the data submitted by very large sequencing projects. if data in such giant projects were incompletely trimmed, errors that existed in the data from other small projects may be overwhelmed and become invisible in the sampled data. in that case, an alternative sampling strategy should be considered. in our test dataset, the  <dig> sampled ests used were submitted by more than  <dig> research groups, while the  <dig> contaminated ests were submitted by  <dig> of them. furthermore,  <dig>  of the  <dig> contaminated ests were "contributed" by one single group.

our study here supports previous research  <cit>  that contamination found in the genbank data mainly existed in batches submitted by specific groups rather than being stochastically distributed , suggesting the errors were derived from certain method. yet, it can also be argued that the contamination may be more submitter-dependant than method-dependant. poor data quality could be caused by various reasons including wet-laboratory practice and bioinformatics processing. however, no matter what the cause, any good vector trimming procedure ought to be able to remove as much contamination as possible.

an effective vector trimming procedure in addition to an efficient confirmation process are thus necessary prior to and during data submission to the public database, and are crucial factors in the reliability of further investigations. though numerous well-known bioinformatics tools have been made freely available for specific data processing or analysis tasks, each has specific strengths and weaknesses.

an initial vector trimming task revealed a design flaw with the seqclean program. the trimming errors with this program would occur if the size of the cdna insert was so small that the start of the vector fell into the critical 30% range from either end of the est sequences . hence a vector like ptripleex <dig>  for example, whose mcs was located far from the start point , would be unlikely to be affected by the design flaw of seqclean. ests derived from a cdna library of mostly long-insert clones may avoid encountering such errors altogether. this flaw was later almost completely overcome with the use of the modified vector form.

when errors are found with one program, an intuitively easy solution is to switch to a different program with similar features. however, there is always the possibility that any new program could give errors of a different type. the results presented in tables  <dig> and  <dig> provide good examples.

the problem with seqclean did not appear to exist in lucy <dig> , possibly due to the design of a user-provided splice file required by the program which specified the  <dig> to  <dig> bp vector sequences upstream or downstream of the ligation site. with the information in the splice file, the program can accurately anchor the vector sequence around the vector-insert border onto the ests in test. however, preparation of an accurate splice file is heavily reliant on users' thorough understanding of the cloning history and careful drafting of the border sequences.

though cross_match gave a relatively higher error rate than the other two programs tested , the length of the vector-matching segments remaining in the processed ests were all below  <dig> bases . furthermore, the trimming errors were distributed over various vectors. this implies that the incompletely trimmed sequences were more likely to result from the sensitivity of the algorithm than from an implementation error. hence, it is probable that the trimming accuracy of cross_match could be improved by properly adjusting the parameter settings. as mentioned earlier, cross_match works in a relatively primitive manner despite its ease of use compared with the other two programs. cross_match identifies the vector-similar sequences in the est without removing them, hence it requires further computer expertise to obtain a final result of trimmed sequences. certain est processing packages like partigene which incorporates cross_match for vector trimming in their multi-step pipeline would provide downstream processing to remove the unwanted vector-similar segments and to abandon the ests trimmed below a set length limit. such a pipeline may be a good choice for users to accomplish multiple tasks of a specific purpose with one single procedure; however, it would be difficult to control the errors produced by individual programs along the pipeline. in a test with partigene using the same nine sets of est data as the other programs, almost ten times as many ests  were trimmed into < <dig> bases long segments  and were finally removed, in comparison with the results shown in table  <dig>  further investigation will be required to elucidate whether the atypical result generated by the program partigene was due to an inherent design requirement of the processing pipeline, or whether it was caused by an implementation error in the post-processing scripts for cross_match alignments.

to correct an error found in a computer program, users with computer expertise may be able to modify the program code if the source code was made available. nonetheless, fixing a computer program for re-implementation is often a tedious, uninteresting and error-prone job requiring extensive rewriting and debugging of someone else's code. therefore we decided to take an alternative strategy by reforming in silico the linear form of the cloning vector with a simple word processing program like notepad or word. this allows the vector contamination to then be removed from the ests with seqclean . the resulting product is evaluated with blast.

though only vector sequences are used for blast analysis, short appendix sequences like linkers, adaptors or primers should not affect the result of this confirmation process. as long as the boundaries of the vector sequence are correctly identified, the short sequences will be removed with the vector. on the other hand, if vector does get overlooked by the trimming program, the short sequences will remain untrimmed. this modified procedure for vector trimming clearly corrected almost all of the errors originally detected .

this procedure, which requires almost no program implementation, may be applicable to a lot of wet-lab based life-science research teams, who are interested in making use of the vast amount of est data in the public domain but may lack extensive computer expertise. to simplify re-linearization of the cloning vector, a web-based dna linearization program to pre-process the vector sequences was implemented, which is now available for free on the internet  <cit> . blast evaluation of the performance of the vector trimming  confirmed that the vector re-linearization step turned seqclean into an ideal tool for removal of vector contamination from automated sequencing data.

therefore, we believe that the data quality in the public sequence databanks could be greatly improved if our modified procedure for vector removal was applied to data generated by the majority of high-throughput dna sequencing projects prior to data submission.

CONCLUSIONS
vector contamination remains a serious concern to the data quality in the public sequence database. this study identified that a modified procedure using rvs vector form could almost completely correct a design flaw found in seqclean. the modified procedure, however, had little effect on the other two programs tested, lucy <dig> and cross_match. when using vectors in cvs form, lucy <dig> performed better than the other two programs under the same test conditions. seqclean with rvs surpassed the other two trimming programs among all the tested conditions , and as it is so easy to use, seqclean is highly recommended to all researchers for the task of vector removal from est or genomic sequences.

