BACKGROUND
currently, one of the most important bibliographical information sources for life science and biomedical research is medline database  <cit> . building a web-based tool to find relevant biomedical literature in medline database in response to a query remains a challenge due to the increase in volume and diversity of topics of biomedical literatures  <cit> . the primary portal to search the medline database is pubmed  <cit>  by national center for biotechnology information . however, finding relevant publications with pubmed pertaining to users' individual interests is still daunting, especially for non-expert users. due to the difficulty of forming appropriate query statements, only experienced users such as librarians  <cit>  can obtain accurate search results using pubmed interface. it is widely reported that less-experienced users, including those who regularly use the pubmed system, do not utilize it as effectively as experienced users  <cit> . those less-experienced users either fail to employ the most relevant context-sensitive keywords or fail to effectively formulate query expressions using boolean logic  <cit> . it has been reported  <cit>  that a novice user  requires an average of fourteen separate queries to get the desired information.

in addition, pubmed does not always return the most relevant articles for user queries. pubmed's underperformance in biomedical information retrieval is partly due to the fact that it uses only a very small subset of the medical subject headings   <cit>  to index the biomedical articles. mesh  consists of  <dig>  descriptors,  <dig> qualifiers, over 213k assisting entry terms, and over 214k supplementary concept records. however, pubmed uses only the descriptors and qualifiers for indexing purposes. it means only  <dig> % of all concepts in mesh are used for the document indexing. while there are  <dig>  million biomedical concepts enumerated in umls metathesaurus 2013aa  <cit> , the pubmed index utilizes less than 1% of this available vocabulary. many studies, such as hersh  <cit> , yoo  <cit>  and abdou  <cit> , have attempted to address pubmed's low vocabulary coverage problem by expanding user queries with more concepts in mesh ontology. however, it has been observed that these query expansion approaches  <cit>  offer no significant advantages over the free-text based search methods; missing concepts and incomplete synonym sets  were found to be the major causes of the inadequacy of existing query expansion schemes.

to address these issues, we develop a new web-based literature retrieval tool, g-bean , to query documents in medline database. the major contributions of g-bean are three folds: 1) it uses a multithreaded parallel algorithm to automatically generate the document index to address the inefficiency of the pubmed's manual indexing process; this automated index generation scheme allows incremental index update for timely index maintenance; 2) it merges multiple biomedical ontologies into a single ontology graph and uses all concepts in this ontology graph to index documents, ameliorating pubmed's low concept coverage problem of using only mesh terms for indexing; 3) it automatically retrieves additional relevant articles based on user's current selection and ranks them according to their semantic similarities with all articles selected so far while pubmed can recommend a list of articles matching the same keywords with only the current viewing article  <cit> .

methods
ontology-graph construction
in g-bean, we employ a subset of umls metathesaurus as the knowledge source to construct an ontology graph. the metathesaurus of umls is the largest vocabulary database that contains information about biomedical and health related concepts and inter-relationships among concepts  <cit> . each biomedical concept in the metathesaurus is a grouping of synonymous terms and is identified by a distinct eight character alphanumeric string, called concept unique identifier . the cui is linked to a set of lexical variants strings, which is an alternative way to represent the concept. the mrconso table contains information of these cuis to resolve synonymy problems that may arise in organizing medical text. information includes concept-names, spelling variations, and acronyms, etc. the inter-concept relationships, such as parent/child, and immediate siblings, are stored in the mrrel table. our ontology graph is automatically constructed using the information from mrconso and mrrel tables where a vertex represents a concept and an edge represents an inter-concept relationship.

since four ontologies in umls, mesh, snomedct, csp and aod cover all senses of the target words in nlm database  <cit> , we obtain these four ontologies from umls 2013aa  <cit>  to construct the ontology graph with the assistance of umls metamorphosys, a multi-platform umls installation tool for umls knowledge sources  <cit> .

parallel index creation for medline database
we first download the  <dig> medline/pubmed baseline database which contains  <dig> k records from nlm  <cit>  and then adapt lucene java search library  to create index for medline documents on the g-bean server  <cit> . each medline citation has a unique pubmed identifier called pmid. since medline citation records do not contain full text articles, only the title and abstract of the documents are processed and indexed. a modified lucene standard analyzer with an enhanced mit stop-list and the porter stemmer is used to analyze , tokenize , stem  and index medline document's title and abstract respectively. moreover, metamap  <dig> is employed to map the title and the abstract into a set of associated cuis which are then indexed with our multithreaded indexing process.

the size of the  <dig> medline/pubmed baseline database is over 160gb. building an index for this large dataset is challenging with lucene library. it takes more than  <dig> days to generate the entire index for all medline documents using a computer with system parameters shown in table  <dig> 

to speed up the index creation, we modify lucene java search library to make it multithread capable. we use a threadpool  <cit>  to submit multiple tasks to the multi-core computer for medline index creation. the thread pool is created by using threadpoolexecutor, as shown below:

new threadpoolexecutor

where corepoolsize is the number of threads in the core pool, maximumpoolsize indicates the maximum number of threads allowed in the thread pool, keepalivetime  is the amount of time that waiting threads in excess of the core pool size may remain idle before being terminated, unit identifies the time unit for the keepalivetime argument, workqueue is the queue to hold tasks before they are executed, handler demonstrates the handler that blocks the execution when maximum number of threads has been reached or queue capacities are exceeded. since index creation is mostly a cpu-bound task as it does not involve much of i/o operations, the corepoolsize is set close to the number of cpu cores for our index creation.

the medline dataset contains  <dig> compressed files. during index creation, the ram size required by lucene is determined by the buffer size used by indexwriter. to maximize the throughput of index creation, we should set the indexwriter buffer as large as possible. ideally, we should create the index for all  <dig> files at once. however, due to the memory space limitation in the computer we used, we divided the  <dig> files into  <dig> groups and created one index for each group. then we use indexwriter's addindexes method to merge these  <dig> partial indices into the final index for the entire  <dig> files. with this approach, the total time for creating the medline index is:

  tp= âˆ‘i=18ti+tmerge 

where ti is the time to create the partial index for files in group i , tmerge is the time to merge the  <dig> partial indices into the final index.

evaluation of multi-thread based parallel index creation
to evaluate how the multithreaded parallel index creation approach speeds up the creation of medline index, we compare the total time for creating the medline index using this new approach with that using the original lucene library on the same computer as shown in table  <dig>  experiments show that the best performance is achieved using arrayblockingqueue with the following settings:

 ncps= <dig> nmps= <dig> nqueue= <dig> 

where ncps is the value of corepoolsize, nmps is the value of maximumpoolsize and nqueue is the size of arrayblockingqueue.

we run our experiment three times and obtain the average time to create the medline index using the multithreaded approach and the original lucene library respectively. the average time for creating the medline index using our multithread approach is  <dig>  seconds , while the average time used for creating the medline index with the original lucene library is  <dig>  seconds ; the multithreaded index creation achieved a speed-up of  <dig>  over the original lucene library on the same computer with  <dig> cpu cores. the resulting index of the medline database occupies  <dig>  gb disk space. since our proposed method computes the indices for  <dig> groups of files separately and merge the partial indices into the final index, we can also update the index weekly through merging the index of the newly posted documents with the existing index. the newly posted documents can be downloaded from medline database  <cit> .

ontology-graph based query expansion scheme
query expansion is widely used to reconstruct a seed query by adding extra related words to the input query with the purpose of matching additional related documents. it is helpful to retrieve potential relevant documents not indicated by initial query  <cit> . after getting the input query from the user, g-bean expands the query with additional related words retrieved from the constructed ontology graph. the query expansion process first uses metamap  <dig>  <cit>  to map the input query to concepts in umls to find the cuis representing the input text. these mapped cuis are marked as original cuis and are used as the initial teleportation probability vector for the personalized pagerank algorithm, which is applied over the ontology graph to calculate the personalized pagerank values  for concepts in the ontology graph  <cit> . the ppv represents the relevance of a concept to the query. we call these cuis labeled with their ppvs as ppv cuis. the top  <dig> ranked ppv cuis are selected as the concept candidates for query expansion.

because the original cuis are used as the initial teleportation probability vector in ppv computation, these cuis will always have high ppv scores and will always be ranked at the top of the ppv cui list. thus, the direct use of ppv cuis for query expansion does not make any significant difference from simply using the original cuis. furthermore, personalized pagerank algorithm has a tendency of ranking the general concepts  higher than more specific concepts since there are more links to general concepts. thus, simply selecting the top concept candidates from the ppv cui list for query expansion might greatly decrease the query accuracy since more general terms are included in the expanded query. to alleviate this problem, we employ a tf-idf weighting scheme to re-rank the ppv cuis. the ohsumed documents, a clinically-oriented medline subset which consists of  <dig>  documents covering references from  <dig> medical journals, are used to build the idf repository to estimate the popularity of the ppv cui in all ohsumed documents. we calculate a weight value for the concept ranked #i among the ppv cui list using formulas shown in  and :

  idfi=max <dig> logn-ni+ <dig> ni+ <dig>  

  wi=piÎ³â‹…idfi 

where wi is the weight, pi is the l1-normalized ppv score for this concept , Î³âˆˆ <cit>  is a tuning parameter used to increase the piÎ³ by decreasing Î³, idfi represents the inverse document frequency of this concept, n is the total number of documents in idf repository, and ni specifies the number of documents in idf repository that contain this concept.

the ppv cuis are re-ranked by their weights and top ranked ones are used to expand the query. extensive experimental results show that the query expansion scheme of g-bean outperforms the popular lucene approach by 22% while other existing query expansion approaches are unable to beat the free-text based lucene strategy  <cit> .

document retrieval
when a query is entered, query text is analyzed by the same lucene analyzer used to create the index, with an enhanced mit stop-list and the porter stemmer to extract query terms. metamap  <dig> is used to map the query text into metathesaurus cuis. the query is expanded with the ontology-graph based query expansion scheme discussed in the previous section and the expanded query is submitted to g-bean for searching the relevant documents.

after the user reviews a returned article, he/she can indicate if he/she is interested in the article. g-bean can form a new query using the key concepts automatically obtained from all articles that are interested by the user and retrieve a list of new articles that are relevant to all articles selected by the user. therefore, the user does not need to browse through the long list of initial search results to find new articles related to their interested articles. pubmed can also display a list of recommended articles when a user is viewing one particular article. however, pubmed can recommend the articles only related to the current viewing article based on keywords matching. thus, the recommendation may not accurately reflect the user's true search intention. in addition, keywords matching may return inaccurate results due to polysemy problem of natural language; it may miss some relevant articles due to the synonymy problem of natural language. g-bean utilizes the ontology-graph based query expansion to minimize these problems. with more articles selected, g-bean can accurately determine the user's true search intention by analyzing the articles that the user is interested in and provides better recommendation, especially for interdisciplinary research articles. the major steps of a g-bean search are shown in figure  <dig> 

g-bean implementation
we have implemented and published g-bean as a web-based application which accepts any biomedical related user query and returns related articles in medline database. we use the client-server architecture powered by java servlet pages  to implement the g-bean system since the java version of lucene library was used to index the medline documents. the communication between the client and the server follows the hypertext transfer protocol . the architecture of g-bean consists of client-side and server-side components, as shown in figure  <dig> 

client-side implementation
a g-bean client is developed as a web application. the jsp script collects the query from the user, dispatches it to the server and displays the search results. the user interface of g-bean is illustrated in figure  <dig>  search results are presented in three areas under the search bar: the left area lists the articles returned by user's initial query; the top right area lists the articles which the user is interested in and the bottom right area lists the articles related to all articles the user is interested in.

asynchronous javascript and xml  technique is employed to implement the following functions due to its ability to make partial page updates without reloading the whole page. 1) document retrieval: g-bean provides an easy-to-use interface for user to retrieve documents related to the query from the medline database. clicking the "search" button triggers the server to retrieve articles related to the input query; 2) document ranking: the returned articles in the left area are ranked by relevance to the query by default. g-bean allows the users to rank the returned articles by date, author name and title as well. as shown in figure  <dig>  the user can select the ranking criterion in the drop-down list a to rank the returned articles according to his/her need; 3) document preview: for a particular article, clicking the "abstract" link  allows the user to preview the abstract; 4) pubmed article retrieval: g-bean provides the pubmed link for each returned article, which allows the user to retrieve information about the article in pubmed. clicking the "pubmed" link  opens a new window to display the pubmed record for this article; 5) user intention discovery: g-bean allows the user to select articles of interest so that it can capture the user's search intention and to retrieve a list of articles relevant to all interested articles. if the user is interested in a returned article after viewing it, he/she can click the "like" link  to add this article to the article list of interest ; if a user changes his/her mind and wants to remove an article from the list f, he/she can click the "remove" link ; 6) additional related articles update: as long as the articles in list f are updated, the server retrieves articles related to those articles. the newly retrieved articles are presented in the bottom right area . these articles are ranked by the relevance to all articles in list f by default. users can select to rank the newly retrieved articles by date, author name and title as well.

server-side implementation
g-bean uses server applet  to receive and respond to requests from clients via http; apache tomcat is used as the servlet container to manage the servlet. the data flow at the server-side is shown in figure  <dig>  the document index is created offline by our proposed multi-thread process. the online part of the server side functions includes query expansion, key concept extraction, and search results ranking.

RESULTS
to evaluate g-bean's search performance, we conducted a subjective evaluation using the  <dig> benchmark queries from the ohsumed dataset, which is generated by clinicians in course of their patient care. the  <dig> queries consist of patient information  and information need  fields  <cit> .

we invited  <dig> graduate students in clemson university to use these  <dig> benchmark queries to search the medline citations through g-bean and pubmed respectively. the returned results on both search engines are set to be ranked by their relevance to the query. the students carefully examined the results returned by both search engines for each query, and decided independently which search engine produced more relevant search results. for a given query, they were asked to choose one of the following three answers after carefully reviewing the search results:

 g-bean returns better search results than pubmed does;

 pubmed returns better search results than g-bean does;

 g-bean and pubmed return similar search results.

after collecting all answers from the students, we summarize the subjective search performance comparison between g-bean and pubmed for each query into  <dig> categories:

â€¢ g-bean and pubmed return similar search results;

â€¢ g-bean is definitely better than pubmed;

â€¢ g-bean is marginally better than pubmed;

â€¢ pubmed is definitely better than g-bean;

â€¢ pubmed is marginally better than g-bean.

given a query, let na, nb, nc denote the number of students who chose , , and  respectively. we consider g-bean and pubmed return similar search results iff nc â‰¥  <dig> or na = nb . otherwise, we deem:

â€¢ g-bean is definitely better than pubmed iff nb =  <dig> or /nb â‰¥ 25%;

â€¢ g-bean is marginally better than pubmed iff nb > <dig> and  <dig> < /nb < 25%;

â€¢ pubmed is definitely better than g-bean iff na =  <dig> or /na â‰¥ 25%;

â€¢ pubmed is marginally better than g-bean iff na > <dig> and  <dig> < /na < 25%.

our summary, as shown in table  <dig>  indicates that g-bean returned definitely better search results in  <dig> of these benchmark queries and marginally better search results in  <dig> of these benchmark queries, while pubmed retuned definitely better results in only  <dig> of these queries and marginally better results in  <dig> of these queries. overall, g-bean returned better search results in  <dig> of these benchmark queries while pubmed returned better search results in only  <dig> of these benchmark queries. for the remaining  <dig> queries, these two search engines returned similar search results. this subjective evaluation confirms the efficiency of g-bean search engine on biomedical information retrieval. the details of the subjective evaluation experiment are available at http://bioir.cs.clemson.edu:8080/bioirweb/supplement.jsp.

it is worth-noting that no student could find any relevant article using pubmed for some queries such as queries # <dig>  # <dig>  and # <dig>  for some other queries, such as queries # <dig>  # <dig>  # <dig> and # <dig>  pubmed only returned one result in each case. pursuing further investigation, we found that pubmed assumed "and" operators for keywords in a query string. for instance, in query #17: "rh isoimmunization, review topics", pubmed obtained four keywords, rh, isoimmunization, review, and topics. it assumed "and" operation on these keywords to form the query for searching the medline database, i.e., it tried to retrieve articles containing all these four keywords. as a result, pubmed returned no result for ohsumed query # <dig> as shown in table  <dig> because there is no article in medline database containing all these four keywords. unfortunately, none of the graduate students found this problem in their evaluation of pubmed search interface, nor did they figure out how to get a better search result using pubmed. actually, if we take out the keyword "topics" from the query # <dig> and submit it to pubmed, it returns relevant articles as shown in table  <dig>  for an experienced user, it is not very hard to form a proper query string  to search the intended articles. however, for a novice user, such as a graduate student, it is frustrating when the query returns no search results. in an extreme situation, if a user happens to input a keyword not in any of the articles, e.g., a typo, no result will be returned. in addition, pubmed uses mesh to index documents. if a query contains no mesh terms, pubmed may either return no search results or return irrelevant results after a long period of search. on the other hand, as shown in table  <dig>  g-bean returned articles closely related to the query in most of the cases. we note that these search results are obtained in january,  <dig>  since medline database updates periodically, search results obtained later may be different from those reported in this paper.

CONCLUSIONS
in this paper, we develop g-bean for biomedical information retrieval from medline database. four major ontologies, mesh, snomedct, csp and aod, which cover all concepts in nlm database, are used to build an ontology graph. an ontology graph based query expansion scheme is used to expand the input query with additional more specific query terms to retrieve relevant articles more accurately. to address the weakness of manual indexing mechanism used in pubmed, we use a multithreaded parallel program to speed up the index creation so that we can timely update the document index for information retrieval. by discovering the user's true search intention based on articles he/she is interested in, g-bean shows significant advantage in retrieving relevant articles compared to pubmed's search interface. our performance study shows that search results returned by g-bean are more relevant than those returned by pubmed using the  <dig> benchmark queries from ohsumed dataset.

list of abbreviations used
ajax: asynchronous javascript and xml; cui: concept unique identifier; g-bean: graph based biomedical search engine; http: hypertext transfer protocol; jsp: java servlet pages; mesh: medical subject headings; ncbi: national center for biotechnology information; nlm: national library of medicine; pmid: pubmed identifier; ppv: personalized pagerank value; servlet: server applet; tf-idf: term frequency - inverse document frequency.

competing interests
we declare having no competing interest.

authors' contributions
jzw participated in the design of the study and helped to modify the manuscript. ld developed the ontology-graph based query expansion, and participated in drafting the manuscript and designing the g-bean website. yz carried out the evaluation experiment, implemented the g-bean website, created the medline index and participated in drafting the manuscript. ll participated in designing the g-bean website. pks participated in the design of the study and helped to modify the manuscript. psy reviewed the draft and provided feedbacks in the direction of the research and final manuscript. all authors read and approved the final manuscript.

declarations
publication of this article has been funded by national science foundation ; national institute of health ; guangzhou science and technology fund of china ; guangdong science and technology fund of china .

this article has been published as part of bmc bioinformatics volume  <dig> supplement  <dig>  2014: selected articles from the ieee international conference on bioinformatics and biomedicine : bioinformatics. the full contents of the supplement are available online at http://www.biomedcentral.com/bmcbioinformatics/supplements/15/s <dig> 
