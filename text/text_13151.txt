BACKGROUND
as systems biology matures, it is moving away from static representations of network interactions based on nodes and edges to dynamic representations that describe cellular processes in space and time. dynamic metabolic processes are quantitatively modelled with ordinary differential equations  in two principle ways: the aggregated rate law  <cit>  and mass action rate law  <cit>  approaches. these two models differ from one another in the level of detail at which they operate and hence the contexts in which they can be validly applied.

dynamic metabolic networks are predominately modelled using aggregated rate laws . an arl simplifies the description of a single enzymatic step by aggregating the elementary steps associated with a specific mechanism into a single reaction, where the rate becomes a non-linear function of substrate, product and regulator concentrations and a typically linear function of enzyme concentration. the classical example of an arl treatment is the michaelis-menten equation for the simplest irreversible reaction, the uni-uni mechanism. arl models are not always derived from an underlying mechanism, and in some cases, more phenomenological formulas are adopted to empirically fit experimental data. while the simplified treatment of enzyme kinetics using an arl-based approach has obvious appeal when attempting to model large metabolic networks, such a reduction of the underlying mechanism inevitably leads to a loss of some useful information about the reaction mechanism, e.g. the sequence of elementary reactions, dynamics of all enzyme intermediates, and so on. arl models are therefore equipped to capture biological processes on long time scales wherein dynamics of enzyme intermediates can be ignored. to date most experimentally determined kinetic parameters are at this level.

an alternative to the arl approach is the direct use of mass action rate laws , each of which states that the rate of an elementary reaction is directly proportional to the product of the effective concentrations of each participating molecule. by definition, mrl models involve the sequence of elementary reactions as well as track dynamics of all of the elements by describing the formation and degradation of all species in an enzymatic reaction. it is particularly suitable for modeling molecular events that happen on the microsecond to millisecond time-scale  <cit> .

regardless of the approach taken, good models of cellular systems are often guided by a pragmatic principle: a model should be as simple as possible, but as complex as necessary. the growing necessity of dealing with complexity is however highlighted by the apparent behavioural differences exhibited by biomolecules within an intracellular environment versus the test tube  <cit> . these differences can be largely attributed to a range of spatial phenomena including macromolecular crowding, caging, spatial segregation of reactants, and the unpredictable nature associated with the reaction of rare and non-uniformly distributed biomolecules  <cit> . significantly, a comprehensive quantitative understanding of most of these phenomena is lacking. meanwhile, the steady increase in computational capability, coupled with improved technology for making quantitative measurements of single molecules within single living cells, is fuelling interest in an alternative modelling approach in which individual molecules are represented as particles that are imbued with the dynamic properties of movement and reaction as a function of space and time  <cit> . this approach, referred to as particle based simulation , has the advantage that it can seamlessly link stochastic and continuous processes in a modelling environment where the spatial and physicochemical complications referred to above are represented explicitly. these explicit simulations require however the direct elementary rate constants and enzyme intermediates that distinguish mrl modelling from arl modelling. if a system has been parameterized as an arl model, it must first be converted into mrl form in order to set up a pbs simulation. thus the mrl model becomes the bridge between the arl format and the pbs format.

as a consequence of its higher level of detail, the mrl approach is starting to receive special attention for the elucidation of complex biological systems  <cit> . to date the biggest limitation associated with the mrl approach is the lack of detailed quantitative biochemical data to fuel the models  <cit> . this dearth of data has prompted the development of several estimation methods for the mass-action rate constants of enzymatic reactions.

the classic approach combines the schematic method of king and altman  <cit>  with the general rule of cleland  <cit>  . smka/grc relates unknown elementary rate constants to known arl kinetic constants. individual rate constants are then calculated by solving linear or non-linear algebraic equations. one limitation of smka/grc is that most of the experimentally determined arl constants are derived from isolated enzymes in vitro over a range of conditions. this lack of biological context calls into question the relevance of network models based on these parameters in describing complex cellular behaviour under physiological conditions. one other limitation is that it is not always possible to uniquely determine the rate constants from existing arl rate constants, when: 1) the number of mrl parameters is large, 2) there is a redundancy of values among arl kinetic constants or 3) there are technical difficulties in solving nonlinear equations. moreover, use of smka/grc method alone is not able to deal with empirical arl equations where some kinetic constants are missing or reduced to empirical constants.

recently, yang et al.  <cit>  have proposed a simpler alternative to smka/grc termed the lambda and omega approximation method. estimating rate constants from available in vitro kinetic data  involves a rapid equilibrium approximation that assumes that reactants, free enzymes and enzyme-bound intermediates reach equilibrium quickly relative to the rate of catalysis. the approach to steady-state can be controlled in the model by using large, time-invariant constant numbers  that are associated with enzyme-substrate and enzyme-inhibitor binding reactions, respectively. when compared with smka/grc, this approximation method is based on fewer kinetic constants and simpler algebraic relations, leading to easier mathematical manipulations. it does however suffer from limitations such as the existence of trimolecular association reactions that are physiologically improbable  and the inherent ambiguity imposed by the dependence of the rate constants on arbitrary values of Λ and Ω.

the final method is numerical simulation and optimization   <cit>  for network models, where non-linear least squares regression is used in combination with simulation to optimize parameters from time-course variables. in principle, this method could be used to find optimal mrl rate constants provided that enough time-course data and constraints are available. however, this strategy often meets with difficulties because even relatively simple metabolic pathways modelled by mrl expand to large and stiff systems of odes. unsurprisingly then, the use of nso in mrl modelling is not prevalent and is often constrained to the analysis of small systems  <cit> . furthermore, the complexity of the parameter space coupled with poor knowledge of the in vivo rate constants means that the optimization algorithm is easily trapped by local minima  <cit>  or returns a family of solutions  <cit> . by comparison, for arl models, nso has been successfully applied to globally optimize the parameters for more complex metabolic networks  <cit> . if a method could be developed that deals with the issues of network scale, stiffness, local minima and parameter identifiability, then nso could play an important role in the development of detailed, complex and therefore useful mrl models.

in this work, we present a novel methodology for extracting mrl elementary rate constants from arl network models, which combines the advantages of two techniques with respect to model structure. our ultimate goal is to generate an automatic transformation from arl kinetic information into the elementary mrl rate constants required for our pbs modelling effort. when it is applied to a challenging parameterization problem in regards to central metabolism of e. coli, our method proved efficient and robust, thereby enabling systemic investigation of the mass action rate laws of a large-scale cellular network.

RESULTS
method evaluation
in parameter estimation, the principle issues are the precision of the estimates and the practical reality of the computational burden. this paper presents and assesses the new method, in terms of computational cost, parameter identifiability and the effect of relative uncertainty in measured data. evaluation was conducted by setting the glycolytic pathways of e. coli to mass action kinetics and adjusting rate constants to result in same flux and concentration dynamics as the original arl model  <cit> . the mrl network is approximately three times larger than its arl analogue, owing to the expansion of individual arl steps into their mechanistic sub-steps. because of this added level of complexity, only a single set of mrl steps  is shown within its arl context  for illustrative purposes, with the full mrl decomposition presented in table  <dig>  the optimized parameters and the statistical analysis of the results are summarized in table  <dig> 

a protein abundances are taken from mass spectrometry data  <cit> , with the exception of the abundance for pykf which is taken from 2-d gel data  <cit> 

b volume concentration is calculated based on e. coli cytoplasm volume equivalent to  <dig>  × 10- <dig> l  <cit> 

a rate constants are the statistical solutions from  <dig> optimization runs which were performed with different random initial guesses for parameters of an individual enzyme. through hybrid mrl/arl model, mrl parameters for each enzyme are estimated in separate steps. units are mm- <dig> s- <dig> and s- <dig> for second and first-order rate constants, respectively.

b sd: standard deviation; cv: coefficient of variation; ci: confidence interval; fval: cost function value.

c due to uncertainty in the source data  <cit> , we have truncated to three digits, regarding of sd.

d reaction orders for allosteric enzyme pfka are non-integer with respect to atp and f6p, allowing for fractal properties  <cit>  due to enzyme conformational changes. values of m and n are  <dig>  ±  <dig>  and  <dig>  ±  <dig> , respectively, after optimization.

e reaction for allosteric enzyme pyruvate kinase is first order with respect to pep and adp, according to tormonia's paper  <cit> 

computational cost
given an optimization algorithm, one of the challenges for a large-scale nonlinear model is the computational economy of that method. this includes how to deal with large numbers of parameters and how to circumvent bottlenecks that limit algorithm performance. these issues must be addressed to make parameter estimation a practical reality; otherwise the computational effort may go beyond a reasonable amount of time for mrl models  <cit> .

the principle technique applied here is a hybrid arl/mrl strategy, which reduces the number of parameters that need to be estimated simultaneously. this technique allows us to estimate parameters of the mass action rate laws for each enzyme in separate steps. in addition, the number of free parameters is further reduced by adding equality constraints derived from algebraic smka/grc method. however, the global optimization still consumes substantial computational time, since it requires vast numerical integrations of odes in order to evaluate the cost function at each iteration step. particularly, the computational cost increases further when the target model has the significant stiffness that often appears in mass action equations for enzymatic reaction systems. in such systems, each solution requires small integration steps to accommodate the introduction of fast-varying enzyme intermediates. by converting matlab m-files for differential equations into mex-files , as well as by opting for the stiff ode15s solver, up to 10-fold faster optimization can be achieved. each optimization run was able to quickly obtain optimal solutions within several minutes with the computer environment as follows: intel core™  <dig> duo processor  <dig>  ghz cpu with memory size of  <dig>  gb, thereby facilitating the repetition of the optimization many times for statistical purposes.

identifiability
other challenges for optimizing a large-scale nonlinear model include local minima and non-convex regions over the objective function space. in this work, we adopted the simulated annealing algorithm, which combines the advantages of our two proposed techniques , for globally minimizing multivariate functions.

to ensure that the algorithm is not trapped in sub-optimal local minima within a large search space, a suitable number of optimizations  were done with different random initial guesses over the entire range of the rate constants. our cost function values  show that the method is able to consistently return parameters from which the mrl model dynamics closely matched those observed for the original arl model, thereby avoiding the local minima problem leading to a badness of fit between arl and mrl dynamics.

it has been found that the candidate values of the rate constants may be highly correlated  <cit>  and the search surface may consist of a very flat valley floor  <cit> , resulting in unreliable or unreproducible estimates although the fit of model to data may be very good. such ill-posed/non-convex optimization problems must be taken into account while assessing the quality of mrl model fit to arl data. the coefficient of variation , defined as the standard deviation divided by the mean, was used as a measure of the reproducibility of the results from  <dig> optimization runs. distributions with a cv < 10% are considered high-precision and low-variance, while those with a cv varying between 10% and 50% are considered moderate precision and variance. table  <dig> shows that cv for 80% of parameters was below 50%, with 66% of parameters with cv < 10% and with 14% of parameters with cv in the range of  <dig> – 50%, indicating that agreement between the optimization runs varied from moderate to very good for most parameters. estimates of 20% of parameters are associated with cv ranging from 54% to 122%, which suggests that these parameters are not highly identifiable from the existing kinetic information. nevertheless, the confidence interval shows that with  <dig> percent certainty the actual values for these unidentifiable rate constants fall within a much narrower range than that for the original biological bounds. apparently, these unidentifiable parameters are interval-identifiable, being bounded within a finite interval from the existing arl dynamics, algebraic equality and inequality constraints.

note that in particular cases, some biological restrictions applied to k values during optimization enable the proposed method to constrain the range of values permitted for some unknown parameters which are otherwise not determinable. the pykf pathway is an example in which the arl kinetic information is not adequate to fully specify the underlying rate constants, leaving up to three undetermined rate constants for the proposed mechanism coupling allosteric regulation with sequential bi bi reactions . experimental results have already shown that direct phosphoryl transfer takes place in the ternary complex  <cit> , thereby excluding the theorell-chance bi-bi mechanism, where only binary complexes are formed. this experimental evidence provides strong inequality constraints on the rate constants k- <dig> and k3: they cannot be very large compared to k- <dig> and k <dig>  respectively; otherwise no stable ternary complex can be formed. consequently, we include a constraint on k- <dig> to ensure that it is less than 10*k- <dig>  the value of k- <dig>  on the other hand, always converges to a solution around  <dig> s- <dig> after optimization regardless of boundary condition. so we set an upper bound of  <dig> s- <dig> for k- <dig>  similarly, the value of the other adjustable parameter, k <dig>  is constrained to be less than 10*k <dig>  this constraint enables k <dig> to fall within the region of  <dig> to  <dig> s- <dig> after optimization. apparently, these biological inequality restrictions can assistant our method to narrow the bounds of some rate constants that remain unidentifiable.

experimental uncertainty
another important issue in the parameter estimation process is the existence of uncertainty in the experimental data, including both the concentration time courses and the enzyme abundances used in our method. these uncertainties can affect the parameter estimates, especially since the enzyme concentration for pykf has been obtained through analysis of 2-d gels. such gel-based proteome technique is frequently subject to gel-to-gel variations  <cit> , so it is more susceptible to noise as compared with other measurement techniques. because of potential high noise levels in analysis of 2-d gels, we use pykf as a representative best case to investigate the bias and variation of parameter estimation caused by uncertainty in experimental measurements. we added gaussian distributed random variates to the experimentally determined value for pykf .  <dig> such noisy enzyme concentrations were generated for each of two noise levels . a 95% confidence interval  for the fitted parameters and the relative errors  between noise and noise-free solutions were used to evaluate the precision and bias due to experimental uncertainty of enzyme level.

a sd: standard deviation; ci: confidence interval; re: relative errors compared to 0% noise case.

b rate constants are the statistical solutions from  <dig> optimization runs which were performed with random initial guesses for parameters of pykf.

c rate constants are the statistical solutions from  <dig> optimization runs which were performed with random initial guesses for parameters and with gaussian noise added to the experimentally determined pykf concentration.

in short, our results indicate that the proposed method can be applied to moderately noisy data. in particular, we have shown for the pykf example the modest impact on parameter estimation for an underlying mrl model at a 20% uncertainty in enzyme level. for proteins with a dramatically high uncertainty from 2-d gel analysis, several techniques, such as prefractionation, parallel and repeated run of gels, are available to reduce the noise level before these proteomic data are incorporated in our method.

model evaluation
parameter sensitivity
we then investigated how these optimal parameters influenced the systemic response, which are normally quantified through sensitivity analysis using the methods of metabolic control analysis  at steady state. our interest, however, was to examine the effect of changing these parameters on the mrl system's temporal response, where the behaviour of interest is often found. we have therefore focused on time-dependent sensitivity analysis.

we performed time-dependent sensitivity analysis of the flux of glucose through glycolysis  with respect to rate constants along the glycolytic chain. the results are large time-varying matrices, which needs to be properly visualized. we present here the visualization results of sample analyses using time-dependent sensitivities for gapa pathway . the large sensitivity of the glycolytic response with respect to gapa parameters is found in the late portion of the transition window. the sensitivity analysis indicates, however, that a balance exists before  <dig> s where small increases or decreases in parameters have little effect on the glycolytic rate. the sensitivity with respect to the formation and breakdown of e-nad-gap  becomes significant after  <dig> s, indicating that the time-course of the system is highly dependent on the ternary complex. these results are very interesting, because they further emphasize the importance of the ternary complex for gapa rather than mere binary complexes. also of interest is the dissociation step involving the last release of nad+ from the enzyme, resulting in a high sensitivity to the parameter k <dig> 

model performance
since the rate constants for each enzyme are estimated in separate steps, the next question of interest would be what happens when these individual mrl parts are assembled together to form a coupled enzymatic reaction system. we therefore assembled these mrl parts into chassagnole's central metabolism model to check functioning of the new assembly under actual operating conditions.

the time-courses of some typical metabolites representing links between the pentose phosphate cycle and glycolysis are shown in figure  <dig>  the dynamic behaviour observed from the coupled mrl reaction system matched its arl counterpart well in response to a glucose impulse, indicating that the mrl system can successfully replace the arl system to represent the time-course data in the macroscopic regime. more importantly, the mrl system presents an opportunity to understand how an enzymatic reaction works by probing the elementary steps.

to compare the relative stabilities of the arl and mrl networks, we first computed the jacobian matrix to determine eigenvalues for both systems at steady-state. the largest mrl eigenvalue observed was - <dig>  s- <dig>  and the spectrum of arl values indicated a maximum of - <dig>  s- <dig>  the fact that all eigenvalues prove to be negative for both models indicates that the arl and mrl models are able to return to equilibrium following small perturbations. since the mrl form essentially introduces fast variables that have been eliminated in the arl form, it is not surprising that the mrl model greatly increases the eigenvalue spread, changing the smallest eigenvalue from - <dig>  ×  <dig> s- <dig> to - <dig>  ×  <dig> s-1and the smallest time constant from  <dig>  × 10- <dig> ms to  <dig>  × 10- <dig> ms.

as a result of the ensuing introduction of enzyme forms to the model, the time scale range of reaction is greatly expanded by many orders of magnitude, rendering the mrl model considerably stiffer than its arl counterpart . these widely differing time scales means that the usual numerical methods require small time step sizes to achieve stable solutions. for the metabolic network described here, we initially opted for matlab's built-in forward differencing integrator, ode <dig>  which failed to achieve solutions through its selection of inordinately small time steps for the model with both fast and slow changing variables. therefore, we used the backward differencing solver ode15s to accommodate the inherent stiffness of the mrl model. using this approach, the computational cost of an mrl simulation was still 33% larger than an arl simulation. however, by compiling the mrl model into mex binaries, the cpu time was reduced 87%.

discussion
the immediate motivation for our mrl modelling is to provide association and dissociation rate constants for the particle-based  modelling aimed at building biophysical realism through four-dimensional simulations of in vivo elemental reactions. the incorporation of rate constants into pb modelling can be implemented by using the standard smoluchowski theory  <cit>  for computing time-dependent reaction coefficients and survival probability  <cit> . due to the lack of high-quality experimentally determined rate constants, researchers have to make many, often arbitrary, assumptions on the values of these parameters, making this type of model less appealing to biologists. to the best of our knowledge, the method we present in this paper is the first step which allows passing in vivo data on an experimental basis to the dynamic multidimensional modelling at a finer scale. the work presented here provides us with some optimism that models operating at different scales can in fact be linked in a meaningful way.

in a more general sense, it is clear that increasingly sophisticated and reliable models of system dynamics will depend upon a sufficient underlying layer of biophysical detail so that they can respond and adapt realistically to changes in the physiological environment. notably the arl approach is capable of dealing with large networks by ignoring the details of enzyme intermediates and the rate constants that underpin biophysical reality. by comparison, mrl models provide the detailed framework required for a foundation for building biophysical realism. thus, there is a distinct need for developing mechanistic mrl models which can provide more realistic predictions of cellular components and dynamics in a model organism.

mrl models belong to the class of non-convex nonlinear models wherein a number of difficulties may arise when estimating parameters of a realistic dynamical system, like e.g. convergence to local solutions, flat objective function in the neighbourhood of the solution and unreasonable computational effort for a problem with a large number of parameters. while previously most research work in this area has focused on the search algorithms , our work, however, focuses on the other side of the problem of parameter estimation, i.e. the model structure. we exploit the model structure to improve the efficiency and robustness of parameterizing a large-scale mrl model. it is based upon a strategy that identifiable structures or submodels can be generated by systematically eliminating parameters of the original model until it becomes identifiable  <cit> . we present a novel methodology with respect to parameter elimination without changing the original dynamics, which combines the advantages of two hybrid techniques. by replacing a single arl pathway with its mrl equivalent, and installing this module to the same place as before while keeping other original arl pathways unchanged, each set of mrl reactions can be independently and efficiently optimized. the alternative is an extremely cumbersome optimization process involving the simultaneous adjustment of an unreasonably large number of parameters. the model structure can be further manipulated by applying equality constraints to the rate constants associated to each enzyme. the resulting technique for incorporating parameter equality constraints into numerical simulation and optimization consistently reduces the number of parameters for a single enzyme, thereby ensuring maximum efficiency and robustness of the parameterization method. consequently, our method may pave the way towards future systemic investigation of the mass action rate laws of large-scale cell network from widely accessible arl models.

a problem that attracts continuing interest is that not all parameters in a large-scale non-convex nonlinear model are uniquely identifiable. distefano  <cit>  introduced the notion of interval identifiabilty to describe finite bounds on the unidentifiable rate constants of general mammillary models. vicini et al.  <cit>  used additional parameter knowledge to narrow the bounds of rate constants that remain unidentifiable in mammillary and catenary compartmental models. in mrl models with respect to glycolysis of e. coli, we also found that 20% of parameters are not highly identifiable from the existing dynamics data. we incorporate several levels of coupling, including equality and inequality constraints and global optimization algorithm, to successfully reduce the range of computable bounds for highly unidentifiable parameters. comparing with a wide-varying range applicable to mass-action rate constants, the range shrinking applied here is the best way so far to acquire reasonable approximations of the parameters.

in addition to their immediate motivational value for the particle-based modelling, our novel methodology and the resulting mrl models have some other interesting applications. for example, starting from the steady state before glucose impulse, the initial concentration for every enzyme form can be derived from the schematic method of king and altman . then all enzyme forms freely evolve to comply with systemic dynamics under the constraint of fixed total concentration, thereby releasing the constraint of the widely-used quasi-steady state assumption . this avoidance of qssa will greatly extend the application area of the proposed method, since qssa can be problematic for some in vivo pathways at high enzyme levels  <cit>  and also for fast transient change reactions such as signalling and transduction pathways  <cit> . parameter sensitivity is another important aspect that may be applicable to experiments regarding parameter identifiability. through the time-dependent sensitivity analysis, parameters within a certain period of time demonstrate little impact on the simulator results . it is therefore not worthwhile focusing experiments on this period to tune the parameters. moreover, sensitivity analysis reveals key elementary reaction steps that would affect the overall dynamics of the metabolic network. one potential approach to accelerate optimization convergence would be to focus much of the computational effort on these crucial parameters. the prioritization of parameters and time interval to calibrate them is expected to evolve as an area of importance, providing a direction to future omics efforts in this area to provide systems-level measurements for virtually all types of cellular components and parameters in a model organism  <cit> .

CONCLUSIONS
in this investigation we incorporated the protein abundance information into our mrl framework to globally optimize elementary rate constants through a novel hybrid method. we effectively deal with the issues of network scale, stiffness, local minima, computational burden and parameter unidentifiability inherent within a large mrl model. since the proposed method makes full use of the available experimental data, it addresses the problem of the computer simulations of biological systems which have high resolution regimes but lack experimental support at such a finer scale. the work presented here provides us with optimism that models in the mesoscopic regime  can be rooted on a firm foundation of parameters generated in the macroscopic regime on an experimental basis.

moreover, the resulting mrl models are as close as possible to the biological experiments. therefore, they can be used to steer further biological experiments aimed at supporting computer simulation. for example, specific direction and guidance for sampling procedures can be issued after a time-dependent sensitivity analysis, through which the most sensitive parameters and time intervals are identified.

