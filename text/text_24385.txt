BACKGROUND
using tandem mass spectrometry  data, database-dependent searching is a popular approach for peptide identification. the searching relies on the completeness and quality of the reference database of the proteome. if a correspondent peptide sequence is not listed in the reference database, an ms/ms spectrum, even at high quality, would fail to identify a peptide. generation of a comprehensive reference database is therefore a challenging task in bioinformatics analysis towards ms/ms signals. some common databases, such as ensembl  <cit> , refseq  <cit> , and uniprot  <cit> , cannot satisfactorily meet this urgent requirement; however, some new solutions have recently been proposed to improve the completeness of proteome databases. through some attempts, such as six-frame translation from the genome  <cit>  and expressed sequence tags   <cit> , including known coding variations  <cit>  and alternative splicing events  <cit> , databases with such combined information were constructed to offer opportunities to expand the data body of novel splices, genomic variants, and new genes. however, these methods lead to significantly increased database sizes but do not greatly improve the sensitivity of peptide identification. recent studies have reported advances in peptide or protein identification with the aid of transcriptome databases, which were obtained from the unprecedented capabilities of high-throughput next-generation sequencing . rna-seq technology indeed has provided qualitative or quantitative gene expression information on a whole genome scale at a single-base resolution. since transcriptomic and proteomic analyses could be done on the same cells or tissues, a sample-specific database based upon rna-seq data would significantly enhance sensitivity for peptide identification and improve accuracy for finding novel peptides. importantly, for non-model species whose genome sequences are absent, the transcript sequences derived from rna-seq data by de novo transcriptome assembly would be beneficial to construct the proteomic database for ms/ms searching. in this strategy, the technique bottleneck is how to create an accessible and flexible bioinformatic pipeline that efficiently harnesses rna-seq data for the discovery of protein variations  <cit> . according to our knowledge, three new software, customprodb, an r package developed by wang et al.  <cit> , a workflow within galaxy-p generated by sheynkman et al.  <cit> , and sapfinder developed by wen et al.  <cit> , have made important contributions to this field. however, customprodb only provides functions for database construction without offering functions for downstream analysis, such as database searching and post-processing, which are also very important for novel peptide identification. galaxy-p provides functions for the sap database and splice database; however, it does not include a function for novel transcript-coded peptides. the software sapfinder mainly focuses on the peptides related to single amino acid polymorphisms but not for general detection of novel peptides. therefore, there is still much room for improved identification of novel peptides through the construction of a comprehensively customized proteomics database based upon rna-seq data.

herein, we describe pga, an r/bioconductor package which enables an automatic process for constructing customized proteomic databases based upon rna-seq data with or without guidance from a reference genome, searching peptides using ms/ms data, post-processing and generating an html-based report with a visualized interface.

implementation
as illustrated in fig.  <dig>  the workflow for identification of novel peptides using the customized database derived from rna-seq data is broadly divided into four steps as below.fig.  <dig> schematic overview of pga package



construction of the customized proteomic database
there are two kinds of customized proteomic databases created with pga. one was constructed from the analysis of rna-seq data with a reference genome. in this case, rna-seq data was analyzed by series software, such as the genome analysis toolkit   <cit>  or samtools  <cit> , tophat  <cit> , and cufflinks  <cit> , to generate three inputs aimed at the construction of a customized database. the three inputs included a variant call format  file containing single nucleotide variants  and indels generated either by the gatk or samtools, a bed format file containing the junction information produced by tophat, and a gtf format file containing novel transcripts reconstructed by cufflinks. the other one is constructed from the analysis of rna-seq data without a reference genome. in this case, the transcript sequences were de novo assembled using software such as trinity  <cit> . it is noted that the data format is important for the construction of a customized database, while the same data format, regardless of which software is used, is acceptable for pga processing. to assist the construction of such a database with guidance from a reference genome, numerous pieces of genome annotation information, such as genome element region boundaries and protein coding sequences, were required, which were downloaded from ensembl or the university of california, santa cruz  table browser using the methods modified from customprodb. the functions and their uses for downloading this annotation information can be found in the user’s manual of pga package. as for vcf and bed format files, customprodb could generate the rna-seq variants caused by snvs, indels, and splice alternatives to the corresponding peptides. as for the gtf format file, the new transcripts were converted to the corresponding peptides based on three-frame translation with the strand information or six-frame translation without the strand information. optionally, the new transcripts could be converted to peptides based on the longest open reading frame  in all reading frames. a customized proteomic database was therefore constructed, which contained all the canonical proteins, the potential novel peptides derived from rna-seq data, and their corresponding reverse sequences. all the proteins and peptides are in fasta format and the fasta headers for potential novel peptides are prefixed with “var” to distinguish them from the reference proteins. in general, a fasta format file containing the de novo assembled transcript sequences that are achieved from the rna-seq analysis software, such as trinity, but not from pga, can be taken as input into pga for proteomic database construction. as for this kind of database construction, the annotation information from ensembl or ucsc is not required, and the transcript sequences can be translated to protein sequences by three-frame or six-frame translation or based on the longest orf in all reading frames.

ms/ms data searching
x!tandem  <cit>  is a well-accepted and open-source search engine, and was taken as the default database searching method in pga. in the workflow of pga, the r package rtandem  <cit> , an r encapsulation of x!tandem, was automatically used to search the customized proteomic database against ms/ms spectra. it can take the different ms/ms data formats as input in database searching, such as dta, pkl, or mgf. alternatively, search results with a dat format from mascot  <cit>  or mzidentml  <cit>  format from ms-gf+  <cit> , myrimatch  <cit> , omssa  <cit>  , and ipeak  <cit>  were also accepted by pga.

post-processing
x!tandem parser  <cit>  was utilized to extract information of the peptide spectrum matches  from the rtandem results. for taking the dat format file from mascot or the mzidentml format file as input for the result of ms/ms data searching, mascotdatfile  <cit>  or jmzidentml  <cit>  was used to extract this information, respectively. taking into consideration the potential high false discovery rate  risk for novel peptide identification based on the customized proteomic database, which was constructed from the rna-seq data analysis with guidance from a reference genome, a so-called separate fdr estimation approach, proposed by karpova et al.  <cit>  for these identifications, was employed in pga. the customized proteomics database contained the information regarding the rna variants in the reference genome and the novel transcripts not annotated previously. if an identified peptide could not be mapped to the reference protein database, it was defined as a novel peptide. the fdr for novel peptides was estimated according to the following equation: fdrn=d+*dndtn+ where d+ is the number of identified decoy peptides with scores above the score threshold, tn+ is the number of identified novel peptides in the target database above the score threshold, dn is the number of identified decoy novel peptides, and d is the total number of identified decoy peptides. dn/d is an approximation for the fraction of novel sequences in the search space. after psm filtration based on a specified fdr threshold , the identified canonical peptide sequences were assembled into a set of confident proteins using the occam’s razor approach  <cit> , which provided a minimal list of proteins sufficient to explain all the identified canonical peptides. finally, the two tab-delimited text files containing the identification results of peptides and proteins were exported. in addition, for each spectrum matched to a novel peptide, a file containing the annotated spectrum was also exported for a visualized quality check of the psm. if an identified novel peptide was uniquely mapped to the amino acid sequences derived from the rna variants, it was called a peptide variant in an existing gene. if an identified novel peptide was uniquely mapped to the amino acid sequences derived from the transcript never matched with the annotated gene, it was termed as the product of a novel gene.

generation of the html-based report
using the r package nozzle  <cit> , pga outputted an html-based interactive report, which contained summary plots and tables, annotated spectra, and identification information of novel peptides and canonical peptides.

RESULTS
pga utility was evaluated using a published data set, in which rna-seq and proteomic data were collected from the jurkat cell line in parallel  <cit> . the rna-seq data were downloaded from ncbi’s gene expression omnibus  repository with the accession number gse <dig>  and the ms/ms data were downloaded from the peptideatlas repository  <cit>  with the accession number pass <dig>  the detailed processing steps for the data are described in the additional file  <dig>  two workflows were evaluated. the first one was that the protein identification was based on the customized proteomics database derived from the rna-seq data analysis with reference genome guidance. the second one was that the protein identification was based on the customized database derived from de novo transcriptome assembly from rna-seq data without reference genome guidance by trinity.

with regards to the first workflow with reference genome guidance, the fdr threshold for identification of the canonical and novel peptides was set at 1 %. as shown in fig.  <dig>  in total,  <dig> novel peptides were identified by pga, including  <dig> sap peptides,  <dig> indel peptides,  <dig> splice junction peptides and  <dig> novel transcript-derived peptides. the distribution curves of psm scores  illustrated in fig.  <dig> revealed that the curve peak for novel peptides was basically close to that for the peptides mapped to the reference proteome, suggesting that the identification quality of novel peptides was acceptable. for most users, the html-based report automatically generated was fully informative and easily understandable. the report on the data set could be found in http://wenbostar.github.io/pga/. in addition, as shown in fig.  <dig>  the number of peptides that were identified  based on searching the customized proteomics database was slightly higher than the number of peptides obtained based on searching the reference database .fig.  <dig> a pie diagram illustrating the results of novel peptide identification

fig.  <dig> search score distribution of novel and canonical peptides. the evalue was an expectation value to evaluate the psm confidence, and in this study, it was directly obtained from the search results of mascot. the greater the value of -log <dig>  the greater the confidence in the identifications

fig.  <dig> the overlap of peptides identified by searching the customized proteomic database and the reference database



in the absence of an organism genome, protein identification and quantification based on an ms approach were difficult to carry out due to the lack of corresponding gene sequences. in this case, the proteomic database derived from de novo assembly with rna-seq would be useful for ms/ms data searching. to test this postulation, the rna-seq data from the human jurkat cell line were analyzed by trinity as well, and the de novo assembly database was used for ms/ms searching. as the human proteome is arguably the best annotated of any species, it is possible to make a direct comparison of the results obtained with and without the use of a reference genome. as shown in table  <dig>  with the reads input to trinity increasing , the reconstructed transcripts  were proportionally augmented from  <dig>  to  <dig> , whereas the peptides identified appeared to be independent from the reads input, which reached a plateau  once the reads were ~29 m or more. this implied that there is a threshold for the reads of rna-seq for peptide identification, whereas expansion of the data size in reads is not always beneficial to ms/ms search  <cit> . furthermore, we also compared the results from the two different workflows. as indicated in fig.  <dig>  about  <dig>  %  of the identified peptides in the first workflow overlapped with that identified by the second workflow, suggesting that the identification results from the two workflows were comparable and each one could provide a small portion, approximately 10 %, of the compensative information.table  <dig> identified transcripts and peptides at different numbers of input reads for trinity

fig.  <dig> the overlap of peptides identified by the two workflows



CONCLUSIONS
using rna-seq data to enhance ms analysis is a promising strategy to discover novel peptides and to improve the sensitivity of peptide identification. the main bottleneck for widespread application of this strategy is lack of easily used software. we provided a novel end-to-end solution to this problem by introducing a complete pipeline in the bioconductor environment. this software was evaluated in a data set of the rna-seq and proteomic data collected in a human cell line in parallel. through construction of a customized proteomics database derived from rna-seq, pga was demonstrated as a feasible program for discovering novel peptides arising from genetic variation, alternative splice forms, and novel coding genes.

availability and requirements
gpl- <dig> licensed and available in the bioconductor framework.project name: pga software.

project home page: http://bioconductor.org/packages/pga/.

operating system: linux, mac osx, windows.

programming language: r, java.

other requirements: none.

license: gpl- <dig> 

any restrictions to use by non-academics: gpl- <dig> 



abbreviations
fdr, false discovery rate; gatk, the genome analysis toolkit; ms/ms, tandem mass spectrometry; psm, peptide-spectrum match; sap, single amino acid polymorphism; snv, single nucleotide variants; vcf, variant call format

additional file
additional file 1: supporting methods. 



