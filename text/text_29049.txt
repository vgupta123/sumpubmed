BACKGROUND
the rapid development of new dna sequencing technologies is transforming biology by allowing individual investigators to sequence volumes previously requiring a major genome center. before the development of next-generation sequencing platforms, sanger biochemistry was the basis of sequencing production. sanger sequencing, or conventional sequencing has been fine-tuned to achieve read-lengths of up to ∼ <dig>  bp and per-base accuracies as high as  <dig> %
 <cit> . however, given several bottlenecks in conventional sequencing that restrict its parallelism, the optimization in throughput and cost has reached a plateau. several alternative sequencing strategies have been proposed in the past several years to reduce sequencing time and cost.

one category of such alternatives is cyclic-array sequencing, referred to as second-generation or next-generation sequencing, which has been made available commercially, and includes products such as the  <dig> genome sequencers , the illumina  platform , the solid platform  and the heliscope single molecule sequencer . because of the much higher degree of parallelism and much smaller reaction volumes, next-generation sequencing achieves much higher throughput with dramatically lower cost. the disadvantages are shorter reads and higher error rates compared to sanger sequencing. next-generation sequencing has been applied in many areas of biology, including quantification of gene expression and alternative splicing, polymorphism and mutation discovery, microrna profiling, and genome-wide mapping of protein-dna interactions. a detailed review of sequencing technologies can be found in
 <cit> .

aware of the large impact of sequencing quality on downstream analysis, several groups have attempted to detect, quantify and understand errors that arise from next-generation sequencing pipelines. at the nucleotide level, base-calling algorithms developed by manufacturers  and independent investigators
 <cit>  provide per-base phred-like
 <cit>  quality scores as a byproduct. these methods require fluorescence intensity measurements from sequencing runs as input, and the per-base quality scores produced need to be further summarized to assess sequencing quality at higher levels. at the technology level, there have been efforts to characterize error patterns associated with different platforms, which include dohm et al. and hansen et al.
 <cit>  for the illumina platform, and huse et al.
 <cit>  for the  <dig> genome sequencers. these studies are very important in facilitating our understanding of the quality characteristics, however, they do not provide methods to assess the quality of sequencing data that are produced everyday in individual laboratories.

sequencing quality also needs to be evaluated and analyzed in light of different applications. for example, bullard et al.
 <cit>  conducted a study of statistical methods for normalization and differential expression  analysis of illumina transcriptome sequencing data. they evaluated how de results are affected by varying gene lengths, base-calling calibration methods, and library preparation effects. they obtained the number of uniquely mapped reads with  <dig> ,  <dig>  or  <dig>  mismatches and used the ratio / to estimate the per-read sequencing error rate, which is the proportion of reads that contain at least one error. we refer to this method of counting the number of mismatches to the reference genome as the mismatch counting method. this builds on the assumption that the perfect-matching reads contain no errors and that u <dig> and u <dig> contain sequencing errors but not snps. it also requires mapping to a reference genome, a step that may be problematic in applications such as threat detection, as the genome sequence of interest may not be known.

tools also exist to correct errors from next generation sequencers
 <cit>  and error rates can be estimated as a by-product. these methods are based on k-mer or substring frequencies, or finding overlaps between reads, which are very computationally intensive, require a large amount of memory, and are difficult to work with large genomes.

in this work we develop a simple and efficient method to estimate the error rates in any sequencing pipelines based on the observation that there is a linear relationship between the number of reads sequenced and the number of reads containing errors. we refer to this proposed method as shadow regression, and show that it works well in applications with moderate to high sequencing depth, such as mrna-seq, re-sequencing and sage.

as with any high throughput experiments, it is important to monitor the quality of next-generation sequencing data at the level of individual experiments. currently the percentage of reads mapped is used as a quality indicator but it does not directly address the fundamental question of how much error is present in the reads obtained from a sample. a reference genome may not be available at all. even if the reference genome is available, we show, using simulated data and real data on phix, that mapping reads to the reference genome can introduce biases even at relatively modest polymorphism rates. furthermore, having an estimate of the error rates gives one the opportunity to improve analyses and inferences in many applications of next-generation sequencing data. for example, error rates are useful in understanding the fidelity of snp or mutation calls as a function of coverage.

methods
next-generation sequencing and sage data
public next-generation sequencing data were obtained from the ncbi sequence read archive 
 <cit> . the sra accession numbers are: sra <dig> , sra <dig>  and sra <dig> . in addition, phix data were generated on illumina genome analyzer ii by the center for cancer computational biology at dana-farber cancer institute . sage data were obtained from ncbi sagemap
 <cit> . next-generation sequencing data were downloaded in fastq format and converted to read counts. sage data were downloaded as read counts. reads that contain n’s  or consist of all a’s, c’s, g’s or t’s are filtered out before shadow counts are computed. more details about the data can be found in the results and discussion section.

estimating sequencing error rates
sequencing pipelines output many short sequence reads representative of the sequences in the sample. if substitutions, insertions or deletions occur, the resulting sequence read differs from the true sequence. given a read t, we refer to reads that have sufficient sequence similarity with t as the shadows of t. the results shown here are based on differences by up to two bases, though different definitions could be adopted depending on the application. among the shadows, there may be sequences that are legitimate and error-free. our method is based on the observation that the number of shadows due to sequencing errors increases linearly with the read count of t, while the number of legitimate shadows is independent of the read count of t. figure
 <dig> shows read-shadow relationships for samples from some of the data sets to which shadow regression was applied. the same plots for two dna sequencing runs of the bacteriophage phix are shown in figure
 <dig>  we see that as read count increases, shadow count also increases. infrequently occurring reads have wildly varying numbers of shadows; however, among frequently occurring reads, the relationship between read count and shadow count is clear and positive. we propose a linear model based on this observation to estimate error rates in sequencing pipelines, which we call shadow regression. even though there may be more than two errors in a read, as is the case for reads containing sequence-specific errors shown in nakamura et al.
 <cit> , we found that using reads that differ from t by up to two bases in shadow regression gives us accurate estimates of error rates without excessive computational cost. note that we present results with substitution errors only in this paper; application of this method to insertions and deletions differ only in the way shadows are defined and are implemented in the r package. insertions at the beginning of reads and deletions at the end of reads may result in genuine reads that are shifted by one base. therefore the resulting estimates of position-specific indel rates may be biased, so these estimates are not computed at the extremes. read-level indel rates are unlikely to be affected.

per-read error rates
let rt denote the true number of reads with sequence t in a given sample, and 

  rt=nt+et, 

 where nt is the number of reads with sequence t that have been sequenced correctly and et is the number of reads that come from sequence t, but contain sequencing errors and are therefore slightly different from t. we define the per-read error rate to be the proportion of reads containing sequencing errors among all the reads in a sample, which is the same as the proportion of reads containing errors per additional unit of reads sequenced: 

  error rateread=∑tet∑trt=ΔetΔrt. 

based on our observation of the linear relationship between the number of shadow reads due to sequencing errors and the number of true reads for a given sequence t, we propose the following linear model to estimate sample-specific error rates in sequencing runs. in the case of illumina genome analyzer , a sample corresponds to a lane in a flow-cell. our model is 

  st=α+βnt+ε, 

where st denotes the number of observed shadows of sequence t  in the sample, ε is independent of nt and approximately gaussian with mean  <dig> and variance σ <dig>  α is the intercept, and β is the parameter that represents the slope. because shadows can also come from legitimate reads that are error free, β needs to be estimated robustly so that they are not influenced by error-free shadows. shadow counts are computed by first enumerating all possible shadows of each observed read, and then identifying the shadows that are actually observed.

it is generally observed that in a given sample, a small number of reads have high frequencies while the majority of reads have very low frequencies. we find that the relationship between the number of reads and the number of shadows is captured in high frequency reads, and that it is enough to use the top  <dig> reads with highest frequencies to estimate β. we also regard the top  <dig> reads to be error free, and thus exclude them from shadow counts of any read.

the estimated slope
β^ is the number of additional error shadows we get for each additional unit of correctly sequenced read t, i.e.β^=Δet/Δnt. the per-read error rate we want to estimate can be obtained the following way: 

  error rateread=ΔetΔrt=ΔetΔnt+Δet=β^1+β^. 

thus, by examining the slope, we may obtain a sample-specific estimate of the sequencing error rate. the error due to substitutions, insertions or deletions may be estimated separately with this method. alternatively, the aggregate error from any source may be estimated.

position-dependent error rates
it has been observed that error rates in sequencing pipelines depend on the base position in the read
 <cit> , which can be estimated by stratifying shadow reads by position. we define the per-base error rate at position i to be the proportion of reads with sequencing errors at position i among all the reads in the sample, i.e., 

  error ratebasei=∑teti∑trt=ΔetiΔrti, 

 where
eti is the number of reads that should be t if error free, but are not because of at least a sequencing error at position i. the corresponding linear model is 

  sti=αi+βint+εi, 

 where
sti is the number of error shadows that differ from read t at least at position i, and εi is gaussian with mean  <dig> and variance σi <dig>  as with per-read error rates,
β^i/ is the per-base error rate at position i that we want to estimate.

application to different data types
our method, shadow regression can be applied to mrna-seq, sage, re-sequencing and whole genome sequencing data regardless of platform, as long as there is sufficient coverage in the input data. the current implementation requires the read lengths from a given sample to be the same. precautions need to be taken when working with whole genome sequencing data as some genomes are highly repetitive and may result in over estimation of the error rates. one way to assess whether a particular genome is too repetitive to apply shadow regression directly is to sample reads from the reference genome and see if shadow regression gives an error rate estimate that is very close to  <dig>  if this error rate is significantly greater than  <dig>  indicating a genome with repetitive regions, one can mask out reads from the repetitive regions or retain only reads from the coding regions before applying shadow regression. the test for repetitive genomes described here is implemented in the r package.

required coverage
shadow regression requires sufficient coverage to estimate the error rate accurately. for mrna-seq, samples shown in the results section for maqc and encode human data contain about  <dig> million reads, which is sufficient for shadow regression to work well. when using about  <dig>  million reads sampled from the  <dig> million reads as input, shadow regression still gives good estimates . therefore we are confident that our method works well with any mrna-seq data. in general, we would like the top  <dig> read counts, which is what we use for error estimation, to have a range of about  <dig> or more. therefore the maximum read count needs to reach about  <dig> or more.

RESULTS
simulation studies
in order to determine the accuracy of our proposed method, we performed two simulation studies. the first one assumes that errors in a read occur independently of each other, while the second study assumes that once an error occurs in a read, it is more likely to make another error in that read. for both studies, we start with u <dig> reads  of an maqc experiment  <dig> sample . these reads, which map to the reference genome perfectly, are assumed to be the error-free ones for the purpose of generating synthetic data. substitution errors are then added to these reads according to pre-specified position-specific error rates. for the second study where the errors do not occur independently of each other, the error rates for the rest of the read double once an error occurs in a read, i.e. if an error occurs at position i, the error rates for positions j > i become twice their pre-specified error rates. the pre-specified error rates are based on the estimated error rates of sample srr <dig> by counting the number of mismatches to the reference genome at each position. this set of position-specific error rates are then scaled to create a range of different error rates. the estimated error rates were calculated by transforming the slope from a robust linear regression  function in the r library mass). for each set of pre-specified error rates, we repeated the error simulation and estimation one hundred times.

figure
 <dig> shows the performance of shadow regression for estimating per-read error rates. under the independent error model, shadow regression gives estimates that are usually within 2% of the true error rates. when the errors are dependent, shadow regression is usually within 5% of the truth. note that as the error rate increases, there is a tendency for shadow regression to underestimate the error rate. this is because at higher error rates, more reads have more than two errors, which are not captured because we only use shadows that differ from the read of interest by two bases. this trend is more pronounced in the dependent case as it is easier to have multiple errors in a read if the first error induces later ones. figure
 <dig> shows the position-specific error rate estimates given by shadow regression, which are very similar to estimates from mismatch counting, and track the true error rates very closely.

the simulations presented this far assumed that the true genome sequence of the sample is exactly the same as that of the reference genome. in practice this is seldom the case. to assess the performance of shadow regression and mismatch counting when the sample genome sequence differs from the reference genome, we performed a simulation where we assumed that there is a single base pair difference between the sample genome and the reference genome every  <dig> base pairs on average, a realistic value for human polymorphisms. this only affected the error rate estimates produced by mismatch counting since shadow regression does not use the reference genome. the results are shown in figures
 <dig> and
 <dig>  as expected, mismatch counting overestimates the error rate in this case.

phix dna data
next, we evaluated our method using sequencing data of the bacteriophage phix 174rf <dig>  dna, whose complete sequence is known. dna from phix is sometimes sequenced in one lane of illumina flowcells to calibrate quality scores of the base caller
 <cit>  . we obtained illumina data for two phix samples from the center for cancer computational biology at dfci. figure
 <dig> shows that shadow regression fit reasonable lines to the phix samples and we would expect accurate error rate estimates from it. mismatch counting first gave much higher error rate estimates than shadow regression. on further inspection, we realized that this was caused by several mutations in the phix genome. because the coverages of phix samples were in the thousands, differences between the reference genome and the actual phix sequence in a few positions substantially inflated the error rates estimated by mismatch counting. this is shown clearly in figure
 <dig>  at five places in each sample, almost all the reads differed from the reference genome. closer examination of the data confirmed that at each of these places, almost all the mismatched reads had the same difference between the actual reads and the reference genome, leading us to conclude that the difference was due to real mutations rather than sequencing errors. once we incorporated these mutations into the reference genome, mismatch counting and shadow regression gave error rate estimates that are much closer to each other . the percentage of mismatched reads was much higher than the background at some other positions, although not nearly as high as 100%. these may be due to mixed phix species in the phix sample and other irregularities introduced in the sample processing steps, and explains the higher estimates given by mismatch counting compared to shadow regression. our findings here demonstrate the advantage of shadow regression over methods that depend on the reference genome. bullard and colleagues
 <cit>  found that phix calibration did not improve the detection of differentially expressed genes in mrna-seq experiments and yielded fewer high quality reads per lane. our analysis showed that this may be due to mutations in phix and that the reference sequence used in the calibration step can be different from the actual sequence of phix used. this is corroborated by the estimate given by
 <cit> , indicating that phix undergoes  <dig>  × 10− <dig> substitutions per base per round of copying.

the intervals in parentheses for shadow regression estimates are the 95% confidence intervals of the estimates. the column “mm” gives the mismatch counting estimates using the standard phix reference genome. the column “mm / new genome” gives the mismatch counting estimates using the phix genome corrected for mutations shown in figure
 <dig> 

mrna-seq: maqc brain experiment  <dig> using auto calibration
we applied shadow regression to illumina mrna-seq data from the maqc project
 <cit> . a scatter plot of read and shadow counts for one of the samples is shown in figure
 <dig>  specifically, we used shadow regression to estimate the per-read and position-specific error rates for fourteen samples on two flow-cells  run on the illumina 1g genome analyzer, and results are shown in table
 <dig> and figure
 <dig> respectively. most per-read error rates fell between 15% and 20%. for the two samples with higher than 20% per-read error rates, their corresponding position-specific error rates were not as smooth as other samples and they had substantial differences in neighboring positions. in all fourteen samples, mismatch counting gave higher error rate estimates than shadow regression, which is expected because mismatch counting classifies genuine differences between the sample of interest and the reference genome as errors.

shadow regression is abbreviated “sr”. mismatch-counting is abbreviated “mm”.

mrna-seq: encode transcriptome
we applied shadow regression to a second illumina mrna-seq data set, this time five samples of human cell line k <dig> from the encode project 
 <cit> , also run on the illumina 1g genome analyzer. a scatter plot of read and shadow counts for one of the samples is shown in figure
 <dig>  results are shown in table
 <dig> and figure
 <dig>  we found much higher error rates in these samples with per-read estimates around 40% to 50% compared to around 20% for the maqc samples. the position-specific error rates were similar to maqc samples in early cycles but increased dramatically after cycle  <dig>  thus inflating the per-read error rates.

shadow regression is abbreviated “sr”. mismatch-counting is abbreviated “mm”.

mutation screening: re-sequencing
in addition to mrna-seq, we also applied shadow regression to re-sequencing data from  <dig> samples as described in hu et al.
 <cit> . a novel multiplex pcr method and next generation sequencing were combined to screen patients with x-linked mental retardation for mutations in  <dig> genes. sequencing was done using illumina genome analyzer ii. a scatter plot of read and shadow counts for one of the samples is shown in figure
 <dig>  we used shadow regression to estimate the error rates in these samples, and results are shown in figure
 <dig> and table
 <dig>  the error rates in this data set are in general lower than the two mrna-seq data sets, possibly due to improvements in the genome analyzer ii. shadow regression gave lower per-read estimates than mismatch counting for most samples as seen in the two mrna-seq data sets. in about half the samples, shadow regression estimated much higher error rates in the last few cycles than mismatch counting.

shadow regression is abbreviated “sr”. mismatch-counting is abbreviated “mm”.

application to serial analysis of gene expression 
sage is a powerful technique for the examination of genome-wide expression levels that involves considerable sequencing of concatenated ten base pair long tags corresponding to transcripts
 <cit> . velculescu and colleagues
 <cit>  estimated the magnitude of sequencing errors in a sage library using error estimates obtained from studies in yeast. previous work by the same group compared the  <dig>  transcripts in the sage yeast library to the known yeast genome, and determined that  <dig>  tags match the tags predicted by the sequence of the yeast genome,  <dig> of the tags match the mitochondrial genome, and an additional  <dig> tags match a plasmid present in yeast
 <cit> . the remaining  <dig>  tags did not match the yeast genome and were therefore considered to be the result of sequencing errors. as these  <dig>  tags represent  <dig> % of the total library, velculescu reports that  <dig> % of all tags are thought to have a sequencing error. this estimate may be conservative because it only considers novel tags introduced by sequencing errors. sequencing errors which create additional copies of tags already present in the library rather than novel tags have not been considered in this calculation of the error rate. additionally, this error rate may include legitimate tags not matching the yeast genome databases because of single nucleotide differences between the yeast strain analyzed by sage and those used for genome sequencing, or because of incomplete genome sequencing. we applied shadow regression to sixteen human samples of pancreatic and colorectal tissue available from the ncbi sagemap website. a scatter plot of read and shadow counts for one of the samples is shown in figure
 <dig>  estimated error rates are shown in table
 <dig>  these error rates are slightly higher than the reported  <dig> %, as expected, confirming the accuracy of the shadow regression method. these error rates are lower than in previous data sets as conventional sequencing was used in these data sets instead of next generation sequencing.

per-read error rate estimates and standard errors from shadow regression.

CONCLUSIONS
we established a simple, general, flexible and robust methodology to estimate error rates for any of the existing second-generation sequencing technologies producing short read sequences. the fundamental advance behind the proposed methodology is our observation that there is a linear relationship between the frequency of short reads and the frequencies of their ‘neighboring’ reads, where neighbors are defined by sequence similarity. this linear increase reflects sequencing errors, as frequently occurring tags cast larger “shadow” of errors on neighboring tags. this observation holds true of sage libraries and seems to hold universally across second-generation sequencing platforms with moderate or high sequencing depths as well. because shadow regression estimates the slope robustly, the error rate estimates are not influenced by shadows that are error-free.

the shadow regression method does not require mapping reads to a reference genome. this has significant computational advantages, but more importantly it can address critical biological needs. for example, the ability to measure error rates independent of a reference genome can be critical in experiments designed to detect unknown species, as in threat detection, and in experiments investigating many species simultaneously, as when studying the microbiome. when the reference genome is prone to errors, for example because of a relatively high mutation rate of the system studied, we showed that the method of using the differences between the sample of interest and the reference genome as proxy for sequencing errors can produce estimates that are substantially inflated, while shadow regression is not affected by such differences.

we also showed the accuracy of shadow regression through simulation studies and analyses of the phix and sage data. we applied shadow regression to mrna-seq, dna sequencing, mutation screening and sage, and demonstrated that this approach can be immediately used to evaluate sequencing error rates in different applications as they are generated. even though our next-generation sequencing examples are all from the illumina platform, shadow regression can be applied to other sequencing platforms as well.

we hope that the availability of a simple and computationally effective way of computing error rates at the level of single sequencing experiments will contribute significantly to quality control, proper analysis and experimental design of second-generation sequencing efforts.

competing interests
the authors declare that they have no competing interests.

authors’ contributions
xvw co-developed the statistical methods, wrote the shadowregression r package, performed data analysis, and drafted the manuscript. nb co-developed the statistical methods and edited the manuscript. jd co-developed the statistical methods. rs designed the phix experiment and edited the manuscript. gp co-developed the statistical methods, edited the manuscript, and coordinated the research. all authors read and approved the final manuscript.

