BACKGROUND
mendelian disorders are inherited diseases caused by inborn defects in the dna sequence of one or few genes. most inherited genetic disorders are rare, although if taken collectively, they are estimated to affect ~4% of newborns. there are ~ <dig> disease phenotypes described in the online mendelian inheritance in man  database  <cit>  but the cause of about half of the described diseases is still unknown  <cit> . whole exome sequencing  of patients allows to find causative mutations of genetic diseases thanks to high-throughput sequencing  technologies  <cit> . wes is an effective alternative to standard genetic screenings to find causative mutations of genetic diseases when only few patients are available, as it is often the case for mendelian disorders  <cit> . when compared to whole genome sequencing , wes is still to be preferred because the targeted region comprises only 1-2% of the genome sequence and thus much less reads are required to get the sequencing depth necessary to reliably identify mutations. furthermore, the potentially damaging effect of a coding-region mutation on the gene product activity can be predicted with good accuracy  <cit> , but this is much more difficult in the case of a non-coding region mutation  <cit> .

wes has been successfully used to find candidate causative mutations with as low as one affected individual  <cit> . one limitation of wes is that the percentage of samples where a candidate causative mutation is not found is still high  <cit> . this may happen when the causative mutation lies outside the targeted region or in a position difficult to sequence, or may be due to incomplete penetrance and the presence of modifier genes  <cit> . another factor affecting the outcome of the analysis is the bioinformatic analysis pipeline  <cit>  and its stringency level, since no standard operating procedure is currently available. this means that in order to compare results of different wes samples, it is important to use a uniform analysis pipeline and a common reference databases to prioritise the detected variants.

indeed, despite the ever decreasing cost of sequencing experiments, the bioinformatic analysis of wes data requires high computational resources, trained experts and a reference variant database to select and prioritise the best candidate pathogenic variants.

our aim was to build a community-based resource providing a disease-oriented allele variant frequency repository for mendelian disorders populated by means of an automatic exome-sequencing analysis pipeline. the expansion and usefulness of this resource will be driven by user-submitted wes samples collected from mendelian disorder patients.

implementation
website
the website is implemented in php. after user registration, a new analysis can be started through the create new submission page . the user has to provide the presumptive  mendelian disorder associated to the sample, the mode of inheritance and the platform used for exome target enrichment. the disease has to be chosen using a fixed vocabulary implementing the medic hierarchical disease ontology  <cit>  including all child terms to mesh id d009358: "congenital, hereditary, and neonatal diseases and abnormalities". the disease list can be searched by directly typing the specific omim id  <cit>  or a keyword and the auto-completion function will automatically retreive all the available matching terms. the user should choose the definition that best describes the patient phenotype. the disease association can be later edited, for example when an initially presumptive diagnosis is then confirmed following the wes analysis. in such cases, the user will initially choose a less specific disease definition, using the controlled vocabulary, and can then change it to a more specific one after receiving the analysis results. ideally, the user should confirm the diagnosis only after having validated the mutations found. the user can submit multiple samples at once, if the samples correspond to related individuals. each sample has to be uploaded as a pair of sequence files in fastq format  <cit> . the user can follow the analysis progression online and retrieve the results upon analysis completion .

pipeline implementation
the analysis pipeline is fully automated and it has a modular structure, as detailed below and in additional file  <dig>  each module performs its task using custom scripts and state-of-the-art tools . the pipeline was designed to run on a high-performance computing cluster using the torque resource manager, but can easily be ported to any other job manager. the exome.tigem.it website uses a cluster with  <dig> computing nodes equipped with dual xeon e5- <dig> for a total amount of  <dig> computing cores and 376gb of ram.

read quality assessment and trimming module
read sequences are submitted by the user in fastq format  <cit>  and are initially assessed for the general quality using fastqc  <cit> . reads are then trimmed to remove the illumina adapter sequence and low quality ends  using trim galore  <cit>  and cutadapt  <cit> ; a fastqc report is generated also on the trimmed sequences.

alignment on reference, post-alignment processing and summary statistics modules
paired sequencing reads are aligned to the reference genome   <cit>  using bwa  <cit> . post-alignment process, including sam conversion, sorting and duplicate removal are performed using picard  <cit>  and samtools  <cit> . the genome analysis toolkit   <cit>  is then used to prepare the raw alignment for the variation calling with local realignment around small insertions-deletions  and base quality score recalibration. this module is followed by a small module computing the read summary, target enrichment and target coverage statistics with samtools and bedtools  <cit> .

snvs and indels calling and annotation module
the identification of single nucleotide variants  and indels are separately performed using gatk unifiedgenotyper, followed by variant quality score recalibration  <cit>  when applicable. the snv and indel calls are then merged and annotated using annovar  <cit>  to add the following information: the position in genes and amino acid change relative to the refseq gene model  <cit> , presence in dbsnp  <cit> , omim  <cit> , frequency in nhlbi exome variant server  <cit>  and  <dig> genomes project stratified by population  <cit> , prediction of the potential damaging effect on protein activity with different algorithms  <cit>  and evolutionary conservation scores  <cit> . the annotated results are then imported into the variation database.

variation database and report generation module
the variation database is implemented in postgresql and its structure with the main tables and relationships is shown in additional file  <dig>  a variations table contains an entry for each variation progressively collected in the database, each uniquely identified by genomic coordinates, reference and alternative alleles. separate tables collect the statistics of the analysis calls, the annotation, the analysis and samples details. finally, the diseases table contains the medic hierarchical disease terms  <cit> . once all the detected variants have been imported, the report generation module creates a report including all the variations found in the samples accompanied by the available annotations. importantly, this module also dynamically computes allele frequencies stratified by disease groups, using the hierarchical disease ontology. in this way, even if no or few samples are available in the database for a specific mendelian disorder, a sufficient number of samples can be reached by grouping samples at the higher levels of the disease ontology. the variation reports of all the archived analysis are periodically refreshed to update allele frequencies on the analyses gradually added to the database.

RESULTS
we developed a variation database for mendelian disorders and associated wes analysis pipeline, in order annotate and store insertions, deletions and single nucleotide variants found in targeted resequencing projects, with a focus on patients affected by mendelian disorders. the pipeline automates the analysis workflow using state-of-the-art tools, starting with raw sequences and providing the final list of annotated variants found in the sample. the pipeline allows for the simultaneous analysis of multiple samples of related individuals. this option is recommended when analysing members of the same family, who are expected to share the same causative mutation. in this case, the variant calling algorithm uses a multi-sample model that takes into account the global allele count in calling the individual genotypes, which can highly improve sensitivity  <cit> . it is also possible to analyse unaffected members of the family indicating them as controls. in this case the variants called in the unaffected members can be directly used to filter out all shared mutations that are not relevant in causing the proband phenotype.

this resource is complementary to free and commercial databases of known mutations associated to specific diseases or phenotype, such as the hgmd  <cit>  or the clinvar  <cit>  databases or locus specific databases   <cit> , since it focuses on patients affected by mendelian disorder. it is also different from the other large scale databases providing population frequencies because the collected samples are not phenotypically normal. moreover, the associated wes analysis pipelines here presented has to be considered only as an accompanying tool to uniformly populate the database and cannot be considered a general purpose exome analysis pipeline, such as those recently presented in the literature  <cit> .

the aim of this resource is to provide a standardised analysis of wes samples by providing state-ofthe-art pipeline and a standardised output of the variant calls and annotations, including the relative allele frequency in the anonymised samples already analysed in the database, stratified by disease.

uniformity of the calling quality is ensured by analysing all samples with the same pipeline. the analysis was implemented to have a low stringency for the initial variant calling, in order to minimise the false negatives, but it relies heavily on intersection filters for controls and general population frequency to rule out non-causative mutations.

submission of whole exome sequencing samples
whole exome sequencing samples are submitted through a webpage http://exome.tigem.it shown in figure  <dig>  the user has to provide the required information about the analysis and the samples to be analysed and upload the sequences . samples are required to be annotated with omim id or, if a clear diagnosis is not available, with a mesh term  <cit> . the analysis pipeline uses this annotation to group samples by disease and to calculate allele frequencies within disease groups . the analysis can be run on multiple samples provided they are from the same family and associated to the same disease . the user can check the analysis progress through the analysis section where all the submitted analyses are archived. in the same section the results page becomes available after the analysis was successfully completed. the results page includes the files produces at several steps: the quality reports, the processed alignment in bam format  <cit> , reads and target coverage statics, the complete call results in vcf format  <cit>  and the annotated table of variants . the user will find on the website notification of every annotation database updated or a major analysis pipeline improvement and can choose to download updated results. importantly, the sequence data  will never be made public, and on request these files will be deleted from the servers . in this case, however, the user will not be able to get updated results.

automated analysis workflow
as detailed in the implementation section, the pipeline workflow follows a state-of-the-art implementation of the exome sequencing analysis  <cit>  . the analysis is initialized by a master script that configures and submits the modules performing the actual analysis steps on the computing cluster. the modules are configured with pre-defined sets of parameters to ensure uniformity of sensitivity across analyses. the user can only choose the number of samples to analyze, either as a single case or as a group analysis by selecting the family option. in this latter case, also control samples are allowed, but these are analyzed separately.

the first module in the pipeline performs a quality assessment of reads and trimming of read ends to remove the adapter sequence or trailing low quality bases. then reads are aligned to the reference genome  and the alignment is prepared for variation calling trough a series of steps: format conversion, sorting, local realignment around indels and base quality score recalibration. the local realignment around indels is an important step. it finds a consensus alignment among all the reads spanning a deletion or an insertion to both improve indel detection sensitivity and accuracy and to reduce snv false calls due to misalignment of the flanking bases. the base quality score recalibration is a procedure through which the raw quality scores provided by the instrument are recalibrated according an empirical error model derived by the sequences  <cit> . the snv and indel variant calling are then performed and the calls are merged and annotated with information collected from several sources . the pipeline is designed to run on a cluster and can submit jobs in parallel to analyse several samples simultaneously. the annotated variant calls are then imported into the variant database.

variant annotation and reporting
the variation database is used to store the annotated exonic/splicing variants and to calculate allele frequencies stratified by groups of patients presenting the same, or similar, disease or phenotype according to the omim identifiers and mesh terms, implementing the medic hierarchical disease ontology  <cit> . importantly, the internal allele frequency among samples progressively collected in the database itself, stratified by mendelian disorder, is estimated, thus leading to a better selection of putative disease-specific causative variations.

the database includes also annotations of variants from external sources , which are stored in a separate table and are periodically updated upon release of a new version of one or more external source database.

the final report of the analysis, which will be available to the user, is a microsoft excel file including a table with all the relevant information useful to filter the selected variants and to prioritise them in order to choose the best possible candidates for subsequent validation . specifically, in order to help the user in the filtering process, the table classifies variants in five classes, as shown in table  <dig>  on the basis of three factors: frequency in the general population, in unrelated diseases, and in the same or related disease, quality of the call and predicted impact on the gene product activity.

variants are automatically classified by the pipeline to help the user in detecting causative mutations . a "+" sign means that the criterion indicated in the column is satisfied. frequency criterion: the frequency in  <dig> genomes project, exome variant server and the tigem variant database  must be < 1%; quality criterion: the gatk variant calling tool must assign a "pass" value to the "filter" field and score >  <dig> to the genotype quality field. moreover, if the variant is homozygous, the percentage of reads supporting the call must be > 80%. if the variant is heterozygous, the percentage of reads supporting the call must be > 30% and < 80%); impact criterion: the mutation causes a gain or loss of a stop codon, a gain or loss of a splicing signal, or a frame-shift in the open reading frame. alternatively, the phylogenetic conservation must be significant  and  <dig> out of  <dig> prediction algorithms indicate a damaging effect .

we give priority to the frequency criterion since when dealing with rare mendelian disorders it is unlikely that the causative mutation may be common in the general population. these categories should be regarded as guides in prioritising the variant called in the analysis and can help in quickly highlighting the best candidate.

CONCLUSIONS
we developed a resource for the analysis of wes samples for researchers studying mendelian disorders. we believe this resource will be useful not only for those who do not have the hardware resources or the necessary expertise to run the analysis, but, more importantly, as a common reference for the community to collect and compare variants across patients with the same, or similar, disease.

each researcher by submitting data to the resource will enrich the database and thus leverage the frequency of the variations potentially associated to the mendelian diseases. for this reason, we require all samples to be annotated with the omim/mesh corresponding to the patient phenotype in order to update the corresponding group allele frequencies with the new samples variant calls.

the analysis report classifies variation by classes to help the user in prioritising candidate mutants. these classes should be regarded as prioritising guides and not as hard filters because it is possible that low-quality calls  are true mutations that can be validated and could be lost in a highly stringent analysis.

the resource provides variant frequencies according to disease groups, thus helping in detecting modifier or secondary mutations which tend to be more represented in the patients affected by the same phenotype. the estimation of statistically significant associations will improve with the number of patients with homogeneous phenotype collected in the resource.

the tigem exome mendelian disorder pipeline is a new community-based resource available to the mendelian diseases research community, built with the aim of help in dissecting the genotype underlying the disease phenotype in patients affected by rare diseases.

availability and requirements
• project name: tigem exome mendelian disorder pipeline

• project home page: http://exome.tigem.it

• operating system: platform independent

• programming language: bash, perl, r, sql, php

• license: terms of use are on the website

list of abbreviations
bam: binary alignment map; gatk: genome analysis toolkit; hts: high-throughput sequencing; indel: small insertion or deletion; ngs: next generation sequencing; snp: single nucleotide polymorphism; snv: single nucleotide variation; wes: whole exome sequencing; wgs: whole genome sequencing; vcf: variant call format.

competing interests
the authors declare that they have no competing interests.

authors' contributions
mm and vsm designed and developed the analysis pipeline. dc developed the web interface and built the variation database. rr contributed to the pipeline and building of the database. gd participated in the initial design of the analysis workflow. go helped in developing the pipeline and the web interface. mm and ddb supervised the project development. ddb conceived the idea. mm, vsm, dc and ddb drafted the manuscript. all authors read and approved the final manuscript.

supplementary material
additional file 1
additional figure  <dig>  pipeline workflow scheme. the analysis master represents the main wrapper script that reads input parameter and creates a new sample analysis in the configuration db. the parameters stored in the configuration db are then passed to the individual modules, represented in blue, here grouped according to different phases of analysis representing the main steps. the results are imported into the tigem variant db, which stores all variant and annotation information. the tigem variant db is then queried to generate the final report. the files delivered to the end user are marked with a red colored asterisk.

click here for file

 additional file 2
additional table  <dig>  analysis tools implemented in the pipeline. list and current version of the analysis tools used in the pipeline.

click here for file

 additional file 3
additional figure  <dig>  variation database structure. scheme of the main tables and relationships in the variation database.

click here for file

 additional file 4
additional table  <dig>  analysis report column legend. legend of the representative fields in the analysis report.

click here for file

 acknowledgements
this work was supported by the fondazione telethon, the italian national research center flagship project epigen, pona <dig>  <dig> and pon <dig>  <dig> . the authors would like to thank vincenzo nigro and sandro banfi for critical discussion.

declarations
the publication costs for this article were funded by the italian national research center .

this article has been published as part of bmc genomics volume  <dig> supplement  <dig>  2014: italian society of bioinformatics : annual meeting 2013: genomics. the full contents of the supplement are available online at http://www.biomedcentral.com/bmcgenomics/supplements/15/s3
