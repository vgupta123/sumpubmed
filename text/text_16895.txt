BACKGROUND
many industry and research projects require some form of model mapping. data from one clinic or research facility will not be readable by another unless they have the same data model or a method to translate between the two. the current process to allow such exchanges is costly and time consuming since it requires resources such as database specialists or knowledge engineers to communicate and manually map data elements from one facility to another or to a reference model. currently this is done manually in a labor-intensive and error-prone process without tools to automate the process  <cit> .

this problem promises to worsen in the future as biomedical data rapidly increase due to scientific advancements; particularly with the innovations made in genetic research and molecular biology. for example, uniprot, a universal protein resource that is referenced for many biomedical research projects, reports having to add many new terms and database cross-references  <cit> . this can result in frequent changes to its model. another example of changing vocabulary is the nci vocabulary services that are released monthly to keep information up to date  <cit> . manual identification of equivalent model elements consumes time and resources, and may often be the rate-limiting technological step in integrating disparate data sources  <cit> .

mapping of models is also common in the area of controlled medical vocabularies. several controlled medical vocabularies  are currently available. however, they usually cover diverse domains with different scopes and objectives. the absence of an accepted "standard" method for representing medical concepts, and the need to translate clinical data to existent cmvs has made automated vocabulary mapping an active area of medical informatics research  <cit> . an accepted method is to map vocabularies to a reference terminology. this eliminates the combinatorial explosion of mappings that would be required otherwise  <cit> . while the use of a reference terminology is helpful in reducing the cost of mappings by reducing the number of mappings, it is still expensive to map a local model to a reference model. this requires the selection of appropriate metadata components called common data elements  that are equivalent between resources that are destined to interoperate.

cabig™
cabig™  is designed as an open source infrastructure that connects resources to enable the sharing of data and tools for cancer research. the nci launched cabig™ in  <dig> and it includes the development of standards, policies, common applications, and middleware infrastructure to enable more effective sharing of data and research tools. while cabig™ is designed to provide the framework around use-cases in cancer research, this effort can benefit the entire biomedical informatics community where large-scale data integration becomes a necessity.

the systems developed in the cabig™ initiative are constructed using a model driven architecture . the mda approach is used for the construction of well-specified application program interfaces  that the grid middleware  <cit>  uses to pass semantically and syntactically meaningful data. all data transmitted by the grid is transformed to objects that are derived from models expressed in the unified modelling language   <cit> .

uml allows developers of resources such as data services and analytical services to describe their services in an abstract manner while constructing meaningful apis that the grid middleware uses to pass data. uml modelling is used to specify the classes and attributes of the system .

for systems to interoperate, it is necessary for these two components of the model  to be harmonized with identical components in other models across the systems. this paper is examining using lexical matching algorithms to identify the classes and attributes that are common between domain models by mapping to a reference cde repository.

harmonization scaling problem
currently developers go through a manual process of harmonizing new service elements  with those stored in the nci's cancer data standards resource  in order to achieve interoperability certification of a resource. the cadsr is nci's implementation of the metadata standard iso <dig> which consists of metadata binding object classes and properties within a data element to controlled terminologies in nci's enterprise vocabulary service . since the space of models within cabig™ is complex and getting more complex , the need for tooling to navigate the model space is urgent. in cabig™, uml models are bound to the components of a cde with uml classes being bound to object classes, uml attributes being bound to properties and uml data types being bound to value domains . consequently, the process of mapping uml models to cdes in the cadsr is arduous and currently requires an nci curator  to work one-on-one with the developer of the new data model to develop the mapping between the uml model class-attributes and the cdes.

a number of uml models have already gone through this manual mapping processes to cdes. the difficulties of cde mapping become even greater with the increasing amount of cdes available within cadsr and the size of this space is getting larger with every cabig™ data service or application that is developed.

proposed solution to improve scalability
the goal is to mitigate the work involved in reusing cdes through the reduction of the information an expert is required to examine in order to achieve interoperability and harmonization. in particular, this paper discusses a baseline comparison of two algorithms  used to map biomedical data models into cabig™'s cde space. the question is how close simple lexical algorithms can get to the selection of the appropriate mappings.

the ability of the two algorithms to select the appropriate mapping is also compare across two conditions: per project and combined project. in practice, developers constrain their uml model comparisons to similar models. this restricted model comparison, referred to as the per project condition, restricts the matching of uml class/attribute pairs to the cdes within the same model space. the combined project condition is searching the entire model space. these comparisons are used to explore the feasibility of deploying an open source tool that can be used to map models and enable the reuse of existing information objects and cdes in the development of new models for translational research applications.

methods
in order to map the uml model class-attributes to cdes, the uml models and the cdes must be converted to a format that the lexical algorithms can process . after the data are formatted, data are submitted to each algorithm: dice's coefficient with di-grams  <cit>  and dynamic programming using smith-waterman's algorithm  <cit>  the algorithms produce similarity ratings that are used to find the best match between the uml model class-attributes to cde class object-property pairs. to evaluate the goodness of the match, the algorithms' matches are compared to a "gold standard" – the matches established through nci cabig™ curators. we compare application mappings already in use and currently stored as metadata in the cabig™ infrastructure by extracting all application uml models and their corresponding cdes.

uml model class-attribute data
we tested the algorithms ability to map uml model class-attributes data available from  <dig> uml models  to cde class object-property pairs. in addition, only cabig™ cdes that are considered "released cde" are used in the mapping. "released cdes" are cdes that have gone through a series of reviews within cabig™.

per project
each of the  <dig> uml projects was mapped to a restricted collection of cdes to which it uses . this restriction of the search space to corresponding cdes is reasonable since typically a developer will compare their uml models/projects with similar projects within cabig™. this condition can be viewed as a curator guided algorithm to mapping models. it is possible to reduce the curator guidance by building an ontology for the models/projects.

combined project
each of the  <dig> uml project was mapped to the combined set of all the cdes in the  <dig> uml models. this condition is more computationally difficult  and can be viewed as an automated approach to mapping models.

matching uml model class-attributes to cdes
for both algorithms, the process of matching uml model class-attributes to cde class object-property pairs consists of two phases: formatting the data and mapping via similarity measures.

formatting data phase
the formatting data phase extracts the uml class-attribute pair names and tokenizes them into text strings of words. uml classes and attributes are converted from programming notation to space delimited words. for example the uml attribute "racedescription" would be converted to "race description."

next the umls lexical tools lvg <dig> api is used to normalize the uml class attribute pairs and the object class property pair of the cde . the normalization process includes removal of genitives, replacement of punctuation with spaces, removal of stop words, lowercasing words, un-inflection of each word, and word order sorting. this formatting data process produces tokenized strings of uml class/attribute pairs that can be matched to their corresponding object class/property pairs . note that only names of the classes and attributes along with the names of the object classes and properties are used.

mapping phase
the mapping phase is where dynamic and dice's algorithms are applied. the algorithms differ by the similarity measures. for each algorithm, the mapping consists of calculating all the similarity measures between the uml model class-attributes and the cdes. the similarity scores are rank ordered with the highest similarity scores listed first as likely candidates for the mapping. this is listed on the graphs as percentage of correctly matched cdes within a given ranking.

dice algorithm
dice's similarity coefficient is a similarity score to measure the lexical similarity  <cit> . this algorithm requires no knowledge about word formation or semantics and provides resilience to noise   <cit> . the algorithm breaks the strings into two letter pairs called di-grams  and then uses dice's similarity coefficient as follows:

dfc =  ÷  where:

m = number of common elements

s = number of elements from source

t = number of elements from target

dynamic algorithm
the dynamic algorithm is inspired by dna-sequencing algorithms such as smith-waterman  <cit> , a popular edit-distance algorithm. the power of the algorithm comes from its ability to account for gaps in strings where sequences of non-matching characters can be found. the process of comparing the similarity between two strings proceeds by creating a two dimensional matrix where the axes are the strings being compared. scores are calculated by scanning through each row in the matrix and comparing the letter for the row against the letters in the string at the top of the columns of the matrix. the weighting method gives unique matching score , mismatch score , and gap penalty . the point of the scoring process is to find consecutive sequence of similar substring within the strings being compared. this process is continued until all the scores are calculated in the matrix. then the algorithms backtrack through the matrix to find a path with the highest score. this score is used to rank the similarity of the two strings.

"gold standard"
the "gold standard" mappings have been constructed by nci curators who have created and validated mappings between uml models and cdes. these existing mappings, serving as our "gold standard," are stored in the cadsr and are publicly available for download through the uml model browser or by programmatic access via the cadsr api. the cadsr api allows runtime access to metadata, the uml models, and their corresponding mappings to cdes. this api can be found as part of the cacore sdk and is publicly available  <cit> .

RESULTS
the comparisons of the dice and dynamic algorithms to the "gold standard" are made by plotting the percentage of correct "gold standard" matches for each cde provided by the algorithms. the graphs depicted in figures  <dig>   <dig> are accumulative functions in which the first point corresponds to the percentage of correct matches  for a single cde and the second point corresponds to the total percentage of matches for both the first and second cde and so forth.

per project
combined project
discussion
notice the graphs start with a high percentage of "gold standard" matches within the first  <dig> returned results. this suggests that developers can use the results to help find an appropriate cde using these automated methods. the class-attribute pairs of the uml models that were analyzed are highly similar to the evs class-property pairs demonstrating that this could be a valid and effective approach and that mapping of different but similar model types  is feasible.

figures  <dig> and  <dig> illustrate this in terms of the 80- <dig> rule, where 80% of the gold standard cde matches are in the top  <dig> or  <dig> ranked matches for the dice and dynamic algorithm respectively. this would be equivalent of a google search returning the correct link 80% of the time in the top  <dig> or  <dig> listed links. since currently searching for cdes to reuse is very labor intensive this can reduce roughly 80% of that work simply by matching developer models against the correct project. since developers are aware of the domain they are developing systems within, it is reasonable to expect them to compare proteomic models against other proteomic models in the repository  instead of comparing them against tissue banking models or the entire set of models .

comparing against the combined models space, the performance of the algorithms degrade somewhat. given the simple nature of the lexical matching algorithms, they perform relatively well in the combined project condition. still the results suggest that a tool to help the developers navigate the model space would facilitate identifying a higher number of correct matches. the findings from the combined project comparison point to the need for an ontological space of models. this will help the developer navigate the space in order to identify the correct model to compare his or her uml class/attributes against or one that algorithms could utilize to constrain the comparison space.

both dice and dynamic algorithms have their own strengths. dice is relatively simple and not as computationally intensive as dynamic programming. dynamic programming requires tuning of the scoring variables such as gap scores and adjusting the gap penalty for large gaps in the strings where mismatches are found. it is capable of using longer sequences compared to di-grams; although for this task this feature does not appear to be necessary.

caveats
a look at the datasets in figure  <dig> shows that some uml model mappings performed better than others. as an example we look at catissue core, caarray and proteomics lims, with  <dig> and  <dig> uml class-attribute pairs respectively because they are similar in size with acceptable but differing mapping performances. catissue has  <dig> percent of the correct matches returned within the top  <dig> ranks while protlims has  <dig> percent . by looking at the mappings that performed poorly we can improve our algorithms as well as create guidelines for improving automated mapping.

the dice algorithm did have difficulty with some of the matches. table  <dig> shows a comparison of the uml class-attribute and its corresponding "gold standard" mapping for catissue core caarray and proteomics lims. these two were chosen to compare because their similarity in size. mapping performance of our implementation of the dice algorithm appears to be reduced when abbreviations and synonyms are used. for example protlims mapping of the uml class-attribute "sample.label" is pre-processed and converted to "label sample" while the cde class-property "specimen tracer"  is formatted and converted to "specimen tracer". the current implementation of the dice algorithm doesn't score this true mapping well when it should have the highest mapping score. the reason for this poor performance appears to be due to the inability to resolve synonyms and determine that specimen and sample are actually the same and that a tracer refers to a label. another challenge illustrated in table  <dig> is difficulty in resolving abbreviations involving numbers. the dice algorithm is unable to resolve the similarity between "gel2d id sample" to " <dig> dimensional electrophoresis gel identifier". the gel2d word is not broken down into three separate words as it should. also from table  <dig> we see in places where words are duplicated exacerbating the effects of the algorithms inability to resolve synonyms. protlims mapping of the uml class-attribute sampletype.sampletypeid is pre-processed and converted to "id sample sample type type" while the cde class-property type specimen identifier  is pre-processed and converted to "identifier specimen type".

with adjustments it is likely we will improve both the algorithms' performance. adjustments could be made to the parameters of each algorithm as well as modifying normalization techniques. normalization techniques can hurt or help each algorithm depending upon the properties of each model such as duplicate words and which stop words to remove. we chose to go with the default normalization method used in the umls api. while both algorithms have similar performance dynamic programming is considerably more computationally intensive, requiring more memory and time to execute, and therefore we would recommend using the faster method of dice over dynamic when comparing only names.

the results show that names of uml class-attributes match well with cde class-properties. it is possible that this is an artifact of the mapping process between the uml models and the evs concepts. due to the process and difficulty of the manual mapping the developers may have named their uml elements similar to the evs concepts.

we have shown the possibility of approaching this problem of mapping uml using lexical algorithms. given the simplicity of the approach taken, the number of matches is surprising. the mapping results suggest that the mapping processes could at least be partially automated. developers could iteratively identify reusable cdes and correctly identify around 80% with relatively small ranked sets when reducing the search space of cdes choosing a similar model space to work in. this would be an improvement over the current manual mapping process.

verification will still be need to be part of the cabig™ review process to ensure accurate mapping but this type of mapping tool could be used by developers as well as by reviewers to hasten the process. while this leads to a mapping process that is not entirely automated, researchers such as sheth and larson have assumed that automated mapping is not accurate enough to be used un-supervised by a human <cit> . thus, a tool that facilitates mapping uml models to cdes is a realistic approach to mapping models in the biomedical informatics domain.

future work
we believe that applying semantic techniques to this problem will further enhance the usefulness of this type of mapping tool as indicated by other mapping efforts  <cit> . future goals are to include semantic mapping tools of umls. umls have tools that can analyze text and return umls concepts. we plan to map uml model descriptions and names into umls concepts and then use the mapping stored in evs to convert to evs concepts. these concepts will be used to search the evs for cdes that contain them and then returned to the user as candidates. the challenge of mapping two models is commonly addressed by lexical methods, logical methods <cit> , and a hybrid of both  <cit> .

the dynamic scoring method performs well in our preliminary investigation, but it can potentially be improved by creating a substitution matrix for assigning different mismatch scores according to different substitution or assigning less of a penalty score when having continuous gaps.

the long-term goal of this research is to produce an open source tool that has a broad application for mapping ontologies, data models, and/or terminologies. this tool will implement the current state of the art mapping algorithms. in addition to developing this tool for comparing current mapping algorithms it will serve as at test bed for the development of new algorithms or hybrid algorithms that combine the techniques.

CONCLUSIONS
this effort contributes to the creation of interoperable systems within cabig™ and other similar frameworks. the dice and dynamic algorithms are compared and both algorithms have similar performance. results of this study demonstrate that the names of the uml elements  can be used effectively to map to existing cdes. the lexical matching algorithms can facilitate the reuse of cdes and reduce the work that needs to be done by a curator to identify pre-existing cdes that match developers uml class/attribute pairs. it suggests that automatic mapping of uml models and cdes are feasible within cabig™ as well as other metadata frameworks.

competing interests
this work was funded in part by the nci cabig™ initiative for which lf is the pi at the university of utah huntsman cancer institute. lf receives funding from the nci to participate in the following cabig™ workgroups: vocabulary and common data elements , population science  and documentation and training. lf is also funded to serve as a vcde guide to mentors. lf has used some of this funding to pay ik as a graduate research assistant.

authors' contributions
lf came up with the concept and design of the approach taken for mapping metadata. ik implemented the algorithms and collected data. ik drafted the manuscript, created tables and figures and participated in the revision. ml contributed the implementation and tuning of the dynamic algorithms. lf, ml, ik made many contributions to the analysis of the data and interpretation of the results. all authors read and approved the final manuscript.

