BACKGROUND
high-throughput experimental techniques provide objective views of the molecular changes that occur in cells during disease progression. a widely used tool when trying to understand the biological meaning of the observed changes is pathway analysis. in pathway analysis, the list of significantly altered genes or molecules is mapped onto usually pre-compiled pathways. a wide range of methods for finding pre-defined pathways overrepresented by significant genes have been developed and are steadily used, e.g.  <cit> . however, this strategy for identifying the important disease pathways is limited, as pathways are not fixed and change with context  <cit> . as a consequence, many of the significantly altered genes or molecules fall outside of the expected pathways  <cit> .

an alternative approach, which is fundamentally different from the pathway analysis just described, is a purely data-driven approach, in which the experimental data is used without any guidance from prior knowledge about molecular interactions. the goal is then to discover hidden patterns of correlation between genes reflecting the complex processes and pathways that underlie cellular metabolism and physiology  <cit> . the most common approach for this task is unsupervised clustering. this class of methods was of the first to be applied to microarray data  <cit> , and several approaches have been proposed, e.g hierarchical and k-means clustering, prediction around medoids   <cit> , model-based clustering via markov chain monte carlo , e.g  <cit> , tight clustering  <cit>  and clustering via networks  <cit> . another way of learning molecular relationships from microarray data is to use bayesian network  methodology. instead of finding groups of correlated molecules, bn methodology infers a network of  interacting molecules. bns were first proposed for microarray data in  <dig>  <cit> , and have also been much applied.

along with the development of such unsupervised methods, there has been a steady development of prior information about molecular interactions. in addition to the mentioned pathways, there are many databases containing pairwise connections, such as protein-protein interactions, transcription factors binding to genes and protein sequence similarities. such information is maybe a more reliable source of information than pathways, as the latter lack proper definitions, and are as already mentioned heavily context dependent.

bayes’ formula is well suited for taking prior information into account during inference, and says 

 pm|d=pd|mpmpd∝pd|mpm. 

 the goal of the analysis is the posterior probability p, i.e. the probability that the model  is correct given the data . in our setting, the model m represents a clustering or a network configuration, whereas d represents the microarray data. many methods using bn methodology to incorporate informative priors have been proposed quite recently, e.g  <cit> . however, even with the help of prior information, inferring bayesian networks for large numbers of genes remains computationally challenging, and the number of genes that can be included is usually smaller than one hundred. inference about groups or clusters of genes is a less daunting task, as there are fewer group/cluster configurations than network configurations. for cluster analysis, there has been some, but not many, suggestions for how to make use of prior knowledge, e.g  <cit> . many bayesian model-based clustering methods have been proposed, e.g.  <cit>  but common to all of these is that they use non-informative priors. bayesian clustering with truly informative priors has to our knowledge not previously been proposed.

in the present paper, we develop a novel method for clustering using bayesian statistics and informative priors making use of markov chain monte carlo  sampling. we name our method mcip . in our method, co-regulation patterns in the microarray data are used together with prior knowledge to find groups or modules of interacting genes. specifically, we propose a method which searches for an optimal partitioning of the genes into functional modules, where module assignment is based on both microarray data and prior knowledge. the prior value for assigning genes to the same module is retrieved from databases containing gene pairs with a previously reported interaction or connection. markov chain monte carlo  sampling is used to search for the most reliable modules. having found the modules, we generate subnetworks consisting of the prior pairs within each module, hypothesizing that these pairs represent the direct interactions. in the presented work we use prior information in forms of protein-protein interaction data, transcription factor binding predictions and protein sequence similarities. we apply our method to simulated data as well as two real-world microarray data sets, one in heart failure and one in melanoma cancer.

methods
assume we have a genomic dataset d, e.g. a microarray dataset, with measurements of n genes. we want to use d together with prior knowledge about molecular interactions to find the most likely partitioning into groups or modules of functionally related genes. now assume that the n genes represent k different modules, where k is not known in advance. let m={,m∈{ <dig> …,q}} be the collection of q gene pairs for which prior knowledge exist, where pm=pim,jm is the prior probability that gene i
m
 and gene j
m
 belong to the same module.

now let 
g
= be a representation of group/module membership for each of the n genes, where g
j
∈{ <dig> …,k}. we want to find the most likely division 
g
 into modules given the data as well as the prior knowledge, or formally, find the 
g
 maximizing p. using bayes’ formula, we have 

 pg∣d,m=pd∣gpg∣mpd∣m∝pd∣gpg∣m. 

marginal likelihood given grouping
we start by finding the marginal likelihood given the subdivision into different groups  and the prior information, i.e. p. assume the data in group k follow a multivariate normal distribution with covariance matrix Σ
k
, whose prior is inverse wishart f where Ψ
k
 describes the prior covariance matrix and m
k
 describes the sharpness of the prior. assume also that all prior information about the data is contained in m, and that genes belonging to different groups are independent of each other. consequently, we can let each group k have prior covariance matrix Ψ
k
=ρ
k
i
k
, where i
k
 is a n
k
×n
k
 identity matrix and n
k
 is the number of genes in group k. we thus have that 

  pd∣g=∏k=1k|Ψk|mk/2Γnkmk+n/2πn·nk/2|Ψk|+xktxkmk+n/2Γnkm/ <dig>  

where n is the number of rows in d , x
k
 is the data matrix for genes belonging to group k and Γ
i
() is the multivariate gamma function. if the gene expressions are standardized to have mean values equal to zero and variances equal to one, it is natural to choose ρ
k
= <dig> and m
k
=n
k
+ <dig>  as this yields expected values of  <dig> for the variances, i.e. for the diagonal elements. the expectancy of the inverse wishart distribution is defined only for m
k
>n
k
+ <dig>  so this is a minimalistic way of coding for the knowledge that the data has been standardized.

probability of grouping given prior information
next, we want to find p, i.e. the probability of grouping 
g
 given the prior information m. assume we have n genes and k∈{ <dig> …,n} groups. let n denote the number of possible subdivisions of n genes into k groups. a new gene can be inserted into one of the k existing groups, or as its own, single-membered, group, so n can be defined recursively by 

 nn,k=k·nn- <dig> k+nn- <dig> k- <dig>  

where n= <dig>  let n
i
j
=k·n+n=n be the number of subdivisions of n genes into k groups where i and j are in the same group. let nn=∑k=1nnn,k be the number of subdivisions of n genes in total and nijn=∑k=1nnijn,k=∑k=1nnn- <dig> k=nn- <dig> be the number of subdivisions of n genes where i and j are in the same group.

now let m={,m∈{ <dig> …,q}} be the set of q pairs for which prior knowledge exist, where we define p
m
 as the prior probability of forcing gene i
m
 and j
m
 to belong to the same group. consider first the situation where we have no prior knowledge, i.e. m0=∅. let  denote that we have k groups of n objects, and let p=1/n, i.e equal prior probability for the number of groups. for a particular grouping 
g
= that has a total of k
g
 groups, let p)=i/n, i.e. equal probability for all groupings for a given number of groups k
g
. this implies that the probability of grouping 
g
 given no prior knowledge is 

 pg∣m0=1n·nn,kg. 

we denote this probably measure pm <dig> and refer to it as the baseline prior.

we will now specify a probability measure which has the same structure as the baseline prior, except that i and j are forced to be in the same group and will thus be handled as a unit. to do this, consider the situation where we have one pair of genes that belong to the same group with probability one. the prior knowledge is then defined as m <dig> ={,p1=1}. we then have in total n
i
j
=n possible subdivisions and n- <dig> possible number of groups. the number of subdivisions into k groups is n
i
j
=n. this means that 

 pk∣m <dig> =1n-1ik≤n- <dig>  

 pg∣m <dig> ,k=1nijn,kigi=gj=1nn- <dig> kigi=gj, 

 where i is the indicator function, so 

 pg∣m <dig> =1n-1nn- <dig> kgikg≤n- <dig> gi=gj. 

call this probability measure pm <dig> .

then consider the situation where we have one pair of genes that belong to the same group with probability p1≠ <dig>  we now define the prior knowledge as m1={,p1}. the idea is that pm1=p1pm <dig> +1-p1pm <dig>  that is a mixture between a probability measure which forces i and j to be in the same group and a probability measure that treats all genes equally . following this idea, we have 

 pg∣m1=p1ikg≤n- <dig> gi=gjn-1nn- <dig> kg+1-p11n·nn,kg. 

now let’s generalize to the situation where we have q pairs of genes with existing prior knowledge, i.e. we have m={,m∈{ <dig> …,q}} with pm=pim,jm. since we have a probability for each pair, we need to introduce some notation specifying what pairs in the prior that are forced to be in the same group. this can be achieved by introducing x={x
m
},m∈ <dig> …,q, where x
m
∈{ <dig> } indicates whether the pair  is forced to be in the same group or not, and m
x
={|x
m
=1} are the pairs that are forced together. we also define the total number of forced pairs for such a combination xas x=∑m=1qxm. we have that 

 pk,∣mx=1n-xik≤n-x, 

 pg∣mx,k=ikg<n-x,gim=gjm∀m∣xm=1nn-x,kg, 

and thus 

 pg∣mx=ikg<n-x,gim=gjm∀m∣xm=1n-xnn-x,kg. 

since we have 

 pmx=∏m=1qpmxm1-pm1-xm, 

and pg∣m=∑xpg∣mxpmx, we arrive at 

  pg∣m=∑x∏m=1qpmxm1-pm1-xm×ikg≤n-x,gim=gjm∀m∣xm=1n-xnn-x,kg. 

note that this expression increases exponentially with the number of prior pairs q. in order to avoid computational cost increasing exponentially with the number of prior pairs, we developed a monte carlo estimation of p, described in additional file  <dig> 

for a given grouping, the baseline prior contributes to the overall probability of a grouping with an additive factor ⋯p ). this implies that the baseline prior will contribute to the probability of two genes being clustered. define p
b
 as the probability for two genes being in the same group given the baseline prior m <dig>  it is important that this probability is non-zero, in order to allow for the possibility of two arbitrary genes being in the same group whether they are in the set of prior pairs or not. if not, it would be impossible to group gene pairs that are not in the set of specified prior pairs. however, this implies that the probability of grouping two genes  in a prior pair will be be the mixture p
m
+p
b
, as there is a non-zero probability that the genes are connected, even if they should not be connected according to the prior information. for instance, if the baseline prior for two arbitrary genes to be connected is  <dig>  and pair number m has prior enforcement probability p
m
= <dig> , the total prior probability for the pair  to be connected will be  <dig> .

there will be a baseline probability for two arbitrary genes to be connected. we have become aware that with equal probability for all number of groups and equal probability for each grouping given the number of groups, the baseline for any two genes to be connected will be dependent on the total number of genes, n. in general, we get that the prior for groupings gives that the baseline probability, p
b
 for two genes to be connected when there are k groups will be p= n/n. the total probability will then be pb=1/n∑knn- <dig> k/nn,k, which depends on the number of genes in total, n. for n= <dig>  p
b
= <dig>  while for the extreme case n= <dig>  p
b
= <dig> . it might be seen as a weakness that there is any dependency on the number of genes in the dataset on the baseline probability. an alternative approach could be to specify the baseline prior according to a given baseline probability for any arbitrary pair of genes. this would make for a more consistent baseline prior, but has the disadvantage that the baseline prior has to be set manually. an alternative would be to make the baseline prior into a parameter to be estimated in a hierarchical bayesian model.

removing cycles
the set of priors might contain cycles, which can easily occur, e.g if both direct and indirect connections are included. we have developed an algorithm for detecting cycles, and if such are found, the prior pair with the smallest prior probability  is removed, as this connection is interpreted as a result of the rest of the cycle. the reason for excluding cycles in the prior is that with cycles, the pairwise specification of prior probabilities of pairs could be misleading. as an example, let us assume the prior is specified so that there is a  <dig>  prior probability of a pairing between gene a and b , between b and c  and between a and c . then the probability for a forced connection between a and b  will be p = p + ppp =  <dig>  +  <dig> * =  <dig> . thus in order for the pairwise prior probabilities to be interpreted as the probability for two pairs to be forced to be connected, cycles should be avoided.

markov chain monte carlo procedure for integrative networks
we use markov chain monte carlo  to sample from the posterior distribution p, as the analytical solution is not known. we will use the metropolis hastings algorithm, which is the most general version of mcmc. specifically, we propose the following algorithm: 

• start with a random grouping, called 
g
.

• sample n groupings 
g
 based on the following scheme: 

propose either  

∗ a partitioning of one of the groups 

∗ a merging of two of the groups 

∗ a transition of one of the genes to another group 

– call the new grouping 
g
new.

– accept 
g
new with the following probability: 

 pacceptgnew=min <dig> pd∣gnewpgnew∣mqgold∣gnewpd∣goldpgold∣mqgnew∣gold, 

 where p is given by , p is given by  and q is the probability of proposing the group configuration 
g
x from the configuration 
g
y, and is given by  in the next section.

in order to avoid convergence to local maxima, we implemented parallel tempering  <cit> , as described in additional file  <dig> 

inferring clusters from mcmc samples
the above mcmc procedure results in a series of samples 
g
. these samples can be used to calculate the posterior similarity matrix , in which each entry  gives the proportion p
i
j
 of samples gene i and gene j occur together in the same cluster. we infer clusters from the psm using the minbinder function in the mcclust r library  <cit> . specifically, minbinder makes use of hierarchical clustering with the psm as distance matrix together with the cuttree function to produce cluster configurations with the number of clusters ranging from  <dig> to l, where l is a user-specified maximum. now letting i
k
 be the indicator for whether gene i and j are in the same cluster for the configuration using k clusters , and using absolute difference as loss function, the posterior expected loss e
k
 for k clusters is calculated in minbinder as ek=∑i<j|iki,j-pij|. the inferred cluster configuration is the result of hierarchical clustering and cuttree for k^ clusters, where k^ is the k minimizing the posterior expected loss, i.e. k^=minkek.

proposal distribution
let n, as before, be the total number of genes, and let n
k
 be the number of genes in group k and n
s
 be the number of single-membered groups. if the number of groups k equals  <dig>  the only allowed option is splitting into two new groups. if k=n, we can only have a merging of two genes into a new group. if 1<k<n, all three types of moves are allowed . each type of move then has probability 1/ <dig> 

first, consider the situation where 
g
→
g
′ is due to a splitting of group k. for the configuration 
g
, we then either have 1<k<n, and a splitting is occurring with probability 1/ <dig>  or k= <dig>  and this type of move is occurring with probability  <dig>  the probability of getting the new grouping 
g
′ is then the product of the probability of having a split within group k, which is n
k
/, the probability of the actual splitting of j into two specific new subgroups, which is 1/n, and the probability of having a split , which is 1/3·i+i. that is, we have, 

  qg∣g′=nkn-ns·1nnk,20·ik=n+13i1<k<n+ik= <dig>  

next, consider the situation where 
g
→
g
′ is due to a merging of group k and l. a merging happens with probability one if the number of groups is equal to n and with probability 1/ <dig> if 1<k<n. two groups, l and k, are chosen by first sampling a random gene and finding which group the gene belongs to, then picking another random gene and re-sampling as long as that other gene belongs to the same group. the probability of merging group l and group j has thus a proposal probability p = pp =  p. that is, we have 

  qg∣g′=nkn·nln-nk+nln·nkn-nl×ik=1+13i1<k<n 

finally, consider the situation where 
g
→
g
′ is the result of moving a gene in group l to group k. a move of one gene from group l to group k is proposed by sampling a random gene and re-sampling if the gene itself constitutes a single-membered group. another random gene not belonging to group l is then sampled, defining another group k. a random element from group l is then assigned group identity k. the proposal probability thus becomes p = pp = pppp = ))i. thus, we have 

  qg∣g′=nkn-nsn-nl13i0<k<n. 

computational aspects
the likelihood estimation involves the determinant function, which is o in the number n of genes in each module. in our method, the most computationally expensive calculation is the exact calculation of the prior probability p. this calculation is exponential in the number of prior pairs. often, as is the case for the data used in this paper, the number of pairs for which there exist prior knowledge, can be substantial. to deal with such situations, we developed an approximate estimate of the prior probability based on monte carlo simulations. comparisons on moderately large number of priors suggested that although less accurate, a monte carlo estimate of the prior gives results close to the results obtained when calculating the prior exactly . for larger number of priors, this can not be tested, but experience shows stable results, suggesting that the stochastic nature of the algorithm do not seriously affect the results. with  <dig> genes and  <dig> samples and  <dig> priors, and using  <dig> for the monte carlo prior calculation, it took our method approximately  <dig> minutes to run  <dig> samples on an  <dig> gb ram,  <dig> physical cpu cores compute node.

prior information
we will use three sources of prior information: protein-protein interactions, transcription factor binding predictions as well as protein sequence similarity calculations. gene pairs in these databases have evidence of being functionally related. the strength of the evidence is represented by some type of score for each database. in our mcmc algorithm the prior information is formulated in terms of the prior probability of forcing two genes to belong to the same group. we will use the logit transformation to transform the scores into the unit interval, thus enabling them to be used as a probability measure. further details are given below for each prior type. there is very little overlap between the prior information databases. in cases where a gene pair is found in more than one database, the highest prior probability will be used.

protein interaction data
protein-protein interactions  are important for the majority of biological functions. ppi databases contain lists of proteins pairs for which there exist some evidence for interaction. the evidence comes from various types of studies, ranging from high-throughput methods, more traditional low-throughput proteomics studies, as well as in silico predictions based on known interactions  <cit> . irefindex  <cit>  is a consolidated protein interaction database comprising information from nine well-known interaction databases. one of the features of the database is the so-called lpr  score, which is the lowest number of unique interactions that are supported by one of the interaction’s pubmed identifiers . a low lpr indicates that the interaction is more likely to rely on low-throughput methods than on high-throughput methods. as the former is recognized as more reliable than the latter, the lpr score can be used as a measure of the reliability of the interaction. we will use a logit transformation taking x to 1/) of the inverse of the lpr score to obtain a probability measure . for example, if the lpr score is one, p
m
 becomes  <dig> , if the lpr score is zero, p
m
 becomes  <dig> .

transcription factor bindings
transcription factors  are proteins that bind to specific dna sequences, thereby controlling the expression levels of the corresponding genes. binding preferences of many transcription factors are known and characterized by a sequence binding motif. however, binding affinity does not depend entirely on the match of the sequence to the motif, but will rely also on sequence specific features. ernst et al. <cit>  developed tf binding predictions, where they first found a general binding preference of the sequences based on  <dig> local genomic features, including histone modifications, conservation and melting temperature. then, they combined this general binding preference score with motif information for specific transcription factors to improve prediction of genes bound by the factor. we will make use of these scores, and again, we will apply the logit transformation to transform the scores to values between  <dig> and  <dig> 

protein sequence similarity
proteins with similar sequences are likely to be functionally related as the proteins may be expressed by paralogous genes  or by genes that are selected to have the same function. for instance, two homologous proteins can be phosphorylated by the same kinase, thus playing roles in the same signaling pathway. one additional feature of using protein homology data in this setting is that the function of proteins for which the function is unknown can be learned by borrowing information from their protein homologs. we will calculate percent similarity between each of the human proteins in refseq using blast  <cit> .

RESULTS
simulated data
to evaluate the performance of our method we used simulated gene expression data generated according to  <cit> . in our study, we used a total of five clusters of genes c∗= with dimension n  samples. cluster sizes n
c
 were generated from n
c
∼2×poisson. expression values in cluster c
c
 were generated using a hierarchical log-normal model as in  <cit> :

 a vector of cluster template for cluster c
c
 was created with four periods of constant expression of size m <dig> m <dig> m <dig> and m <dig>  the sizes m
k
, k= <dig> …, <dig>  was from a uniform distribution such that ∑kmk=n and m
k
> <dig>  an initial template with constant pattern in four periods was simulated from logμkc∼nμ,σ <dig> 

 sample variability and gene variability: sample variability σs <dig> was introduced and the cluster template tjc, j= <dig> …,n, was generated from logtjc∼nlogμkc,σs <dig>  then for each gene vector i in sample j, gene variability was added and gene expression values generated as logxij∼nlogtjc,σ <dig> 

 we repeated steps  <dig> and  <dig> to generate five clusters. we used parameter values of μ= <dig>  σ= <dig>  σ
s
= <dig>  σ0= <dig>  and λ= <dig> 

as in  <cit> , extra variation was introduced to evaluate robustness of clustering methods against potential random errors introduced from experimental procedures, such as sample acquisition, labeling hybridization and scanning. to each element of the log-transformed expression matrix we added a a random error from a normal distribution with mean zero and standard deviation  equal to  <dig>   <dig> and  <dig>  in addition, the sample size was varied, using n =  <dig>  and  <dig>  for each of these nine scenarios,  <dig> datasets were generated.

for each dataset, three scenarios for the available prior information were used. in , we assumed that no prior information was used. in , we assumed priors pairs were available, where 20% where mis-specified, i.e. 20% of the gene pairs had members belonging to different groups. in the last scenario , all pairs were assumed to be correctly specified . prior values were generated from a uniform u distribution.

we compared our method with five well-known clustering methods for which a software already exist, namely hierarchical clustering, k-means clustering, partitioning around medoids   <cit> , model-based clustering   <cit>  and tight clustering  <cit> . for all methods except ours, the number of clusters were estimated using the gap index  <cit>  . for our method, clusters were inferred by minimizing the posterior expected loss based on the mcmc samples as described in the methods section. the number of clusters estimated by the gap index as well as our method is shown by boxplots in additional file 3: figure s <dig>  the rand index, defined as the proportion of concordant gene pairs in two partitions among all possible gene pairs, was used as evaluation measure. specifically, we used the adjusted rand index  <cit> , which is standardized to have expected value zero when the partitions are randomly generated and takes maximum value one if two partitions are perfectly identical. unlike the other methods, tight clustering produces clusters where some genes are not allocated to any cluster. in the calculation of the rand index, only the allocated genes are considered.

the results are shown in figure  <dig>  we see that when all pairs are correctly specified , our method  was at least as good as all other methods, and superior to the other methods for the smallest sample size . when 20% of the priors were mis-specified , the performance was better than our method without using priors , as well as hierarchical clustering, which was overall the second best method. we note that mclust had a very variable performance, and that tight clustering was performing very poorly for large sample sizes. in order to further investigate the effect of mis-specifications of the priors on model performance, we calculated the adjusted rand index for increasing proportion of mis-specifications. additional file 4: figure s <dig> shows that about 40% mis-specifications were allowed, in the sense that this corresponded to the use of no prior information. we also note that there was a correspondence between number of estimated clusters  and performance . especially for small sample sizes , the number of clusters found by maximizing the gap index, as well as with our method without the use of priors, quite often yielded many more clusters than the true number of clusters . this bias was much less evident for our method with the use of priors . additional file 5: figure s <dig> shows the performance after fixing the number of clusters to the true number of clusters  for all methods except our method, which inherently finds the number of clusters. the figure shows that poor performance, especially seen for tight clustering  and mclust , was not only due to bias in the estimation of number of clusters, as these methods also performed poorly after fixing the number of clusters.

heart failure data
we used the data described in  <cit> , consisting of microarray gene expression measurements from fourteen mice subjected to aortic banding and five sham operated mice. aortic banding leads to increased left ventricular pressure. to compensate for the increased load, gene expression changes occur resulting in myocardial remodeling, involving hypertrophy of cardiomyocytes. ultimately, the cardiac hypertrophy might lead to development of heart failure. we based our network analysis on the most differentially expressed genes between aortic banding and sham. to find differentially expressed genes we performed t-tests between the two groups, using log <dig> expression values, before multiple testing correction was performed using the method of  <cit> . we used a false discovery rate  cut-off of 5%, and among these genes we picked the  <dig> with largest fold change . we looked up connections between these genes and assigned prior probabilities for the pairs based on the prior databases described in the previous section. for each of the three prior databases, there were several hundred pairs where both genes were represented in our input-list. as the use of so many priors pairs was too computationally demanding for our method, we picked the  <dig> top scoring pairs for each of the prior types. we applied our mcmc algorithm using altogether  <dig> monte carlo samples, with the first  <dig> samples used for burn-in . we applied parallel tempering as described in additional file  <dig>  as we here had more than hundred prior pairs, we approximated p with the monte carlo estimator  defined in additional file  <dig>  using k= <dig>  as this value gave stable results within a reasonable computation time. clusters were inferred by minimizing the posterior expected loss based on the posterior similarity matrix, which was calculated from the collection of each of the 100th mcmc sample after the burn-in period.

size = number of genes in each cluster, upreg.  = percentage of upregulated genes, edges = number of edges, priors  = percentage of edges that were prior pairs, and top three go terms = the three most significant gene ontology terms found by gostats  <cit> .

melanoma cancer data
metastatic melanoma is a deadly disease while non-metastatic melanoma and other cutaneous tumor types are usually cured with surgical removal of the primary tumors. to find network of genes differentially expressed between metastatic and non-metastatic tumors we used data from  <cit> , which included microarray gene expressions from  <dig> metastatic and  <dig> non-metastatic tumor samples of patients with various cutaneous tumors. as for the heart failure data, we used the  <dig> most differentially expressed genes  for which benjamini hochberg fdr < <dig> , and found gene pairs in the ppi, the tf and the sequence similarity database where both genes were represented in our input list. we also here approximated p with the monte carlo estimator  of the additional file  <dig>  using k= samples. again, result clusters were inferred by minimizing the posterior expected loss based on the posterior similarity matrix calculated from each th of 150k mcmc samples generated after a burn-in period of 50k samples.

size = number of genes in each cluster, upreg.  = percentage of upregulated genes, edges = number of edges, priors  = percentage of edges that were prior pairs, and top three go terms = the three most significant gene ontology terms found by gostats  <cit> .

method evaluation
in order to evaluate our method we made use of literature reported interactions that occurred in abstracts of articles labeled with the medical subject headings  term left ventricular hypertrophy for the heart failure clusters  and the mesh term melanoma for the melanoma clusters . we applied gene pairs with p-values smaller than 5% only, using the method described in  <cit> . we will refer to these interactions as "true" interactions. the application of our method together with minimization of the posterior expected loss led to an inferred clustering. by considering whether the genes of each possible gene pair occurred in the same group or not in the inferred clustering, we were able to calculate the sensitivity , the specificity , the positive predictive value . from the sensitivities and specificities the area under curve  was also calculated. table  <dig> shows performance measures for the heart failure and the melanoma data, respectively, using our method both with and without priors, and compared to the results of k-means clustering. for k-means clustering the optimal number of clusters was found using the gap index.
k
-means clustering

k
k
the performances are obtained by evaluating the result clusters against a literature based reference network comprising pairs of genes co-cited in pubmed articles with the medical subject headings  left ventricular hypertrophy  and melanoma cancer . sens.=sensitivity, spec. = specificity, ppv = positive predictive value, auc = area under receiver operator curve, and k = number of clusters, which is automatically found by our method, and by using the gap index for k-means clustering.

discussion
using simulated data we compared our method to established clustering methods as k-means and hierarchical clustering. when no prior information is provided our method did not offer any gains over other standard approaches, except for the n =  <dig>  sd =  <dig> regime. when most priors were correctly specified , our method was as least as good as the best-performing established methods for large samples, and superior to the same methods for small sample sizes. we believe that the majority of the priors will be correctly specified in most cases. the reason for this is that there will usually exist so many prior pairs that one would restrict oneself to only those with the strongest evidence. of course, a previously shown connection might still not be real in the current situation, e.g. if the connection has been discovered in a different tissue type than the one under study. however, this problem will be limited if one is analyzing a set of genes differentially expressed between two conditions, as many of these will be co-expressed, and thus also correlated.

the gene ontology analysis of the heart failure network showed that many of the top ranked go categories for the larger module were related to the extracellular matrix. awareness has emerged regarding the extracellular matrix changes taking place in myocardial remodeling  <cit> . when investigating figure  <dig>  we see that the larger module contains many collagens , which are important structural components of the extracellular matrix. the figure shows that these molecules were primarily connected by protein sequence homology . moreover, other molecules thought to be parts of the extracellular matrix were identified in the same module . for example, fibronectin has been demonstrated to play a role in the organizing of collagen type i  <cit> . the module also contained enzymes and hormonal factors known to process the extracellular matrix structural proteins . for instance, matrix metallopeptidase  <dig> is known to be important for the breakdown of collagen type i  <cit> . finally, the extracellular matrix related transcription factor early growth response  <dig> was a hub in this module, indicating a particular importance in this pathological process. altered metabolism has been described in remodeled and failing hearts. e.g. reduced fatty acid oxidation and an increase in glucose utilization have been reported  <cit> . the smaller module contained several genes involved in carbohydrate metabolic processes . taken together, the two modules confirm regulatory and signaling events and structural alterations known to be involved in myocardial remodeling. we believe that the complete result network, shown in additional file 6: figure s <dig>  contains many other important, not yet discovered, interactions. however, a detailed investigation of all these connections is beyond the scope of this paper.

the melanoma network was derived from the data of riker et al. <cit> . as the present paper represents a reanalysis of the data, the outcome of an analysis with similar input data should be expected to generate somewhat similar output data. the main difference in approach is that while the riker paper primarily performs a direct gene ontology analysis, the current approach attempts to combine multiple sources of information prior to performing any functional analysis. in this way, the resultant network modules will represent subnets of relevance with respect to the combined prior information, thus presenting local information clusters with higher likelihood of coherence in function for each cluster. riker et al. observed differentially expressed genes involved in keratinocyte differentiation and epidermal development, including loricrin , involucrin , keratin  <dig>  and plakophilin  <dig> , suggesting a loss of epidermal characteristics, in highlighting the desquamation process. in our largest module  we found many genes related to keratinocyte differentiation and epidermal development . when looking at figure  <dig>  where gene pairs with prior information within each module were connected, we note that keratins and kallikreins were connected through a set of interacting genes that included desmocollin  <dig> and  <dig> , desmoglein  <dig> and  <dig> , desmoplakin  and corneodesmosin . many of the genes in this path are related to corneodesmosomes . corneodesmosomes are located at the junctional structures that mediate corneocyte cohesion  <cit> , underlining keratinocyte dedifferentiation. the individual connections in this path are supported by previous findings; caubet et al. <cit>  showed that klk <dig> and klk <dig> degrade the desmosomal proteins dsc <dig> and dsg <dig>  smith et al. <cit>  showed that when epidermal cells differentiate, dsc <dig> and dsg <dig> are bound by pkp <dig> and dsp, thereby enhancing anchorage to keratin intermediate filaments. interactions between plakophilins, desmoplakins and keratins have also been shown by other authors, e.g.  <cit> . interestingly, the transcription factor rar-related orphan receptor a  was downregulated, and placed as a hub in this module. rora has recently been indicated as a breast tumor suppressor  <cit> , as well as having a role in keratinocyte differentiation  <cit> . taken together, figure  <dig> suggests that the loss of epidermal characteristics seen in the metastatic individuals is mediated by a downregulation of the rora transcription factor.

when comparing the go analysis of the main clusters from our method with the use of priors  to the go analysis of the main clusters using our method without priors  and k-means clustering , we note that many of the same go categories were showing up. but the p-values were overall much smaller for our method with the use of priors, than the other two, indicating that our method has better sensitivity of finding functionally related gene groups. we note that the path found in the melanoma data linking the rora transcription factor to the keratins via the kallikreins and the desmosomal proteins, would not have been discovered by our method without priors or k-means clustering, as none of the these methods gave clusterings where all these gene subgroups were contained in one cluster.

method evaluation using the literature-derived network showed that adding prior knowledge yielded improved auc. the auc was improved from  <dig>  to  <dig>  for the heart failure data and from  <dig>  to  <dig>  for the melanoma data. the positive predicted values  were also improved . we note that these values are very small, which is because there are very few gene pairs with co-citation  compared to the number of gene pairs clustered together . it is important to be aware that the possibility of improvement is limited by the degree of overlap between the list of pairs in the prior interaction databases and list of pairs in the literature reference network. many of the pairs in the literature databases were not found in the interaction databases. in fact this was the case for about 90% for these data. such interactions are, when evaluated on the literature network, treated as false positives, but might of course be true positives. of the 90% of the pairs in the literature network that were not in the prior databases, the evidence for grouping the genes together was based solely on the correlation in the microarray data. another limitation of the literature network is that it itself might contain false positives. genes that are mentioned in the same pubmed abstract are not necessarily connected.

we have here focused on finding groups of connected genes, and not on discovering direct interactions. direct interactions are often inferred using bayesian networks . as mentioned in the background section, the bn formalism allows for incorporation of prior knowledge, and bn methods for genomic data has indeed been proposed. however, constructing large-scale networks using bn methodology is very difficult as the number of possible configurations is about exponential in the number of genes. formally this has been shown to be an np-complete problem. by instead focusing on groups, we heavily reduce the number of possible configurations. thus, our method can handle many more genes than bn methods. this is relevant, as microarray data may involve several hundred regulated genes. one way of using our method is to apply it as an initial step prior to a bn analysis; if the number of genes is too large to apply bn methodology to the full set, our method can be used to first find smaller-sized, independent sets of genes, followed by separate bn analysis on each of the subsets. the result of such an analysis will be similar to the networks shown in figures  <dig> and  <dig>  where prior pairs within each cluster are shown. we believe that the connections shown in figures  <dig> and  <dig> are reliable and robust, as they display connections between genes that are co-regulated and that have a previously shown connection. using bn on each cluster could lead to an improvement, as novel interactions can be detected based on strong correlations in the data, and is one possibility for future methodological development.

along with the development of the primarily data-driven methods, various methods focusing more on the prior information have been proposed, e.g.  <cit> . in these approaches, the authors made use of the observed changes in the experimental data, e.g. the most differentially regulated genes, while the interactions among these genes were derived from prior information only. for example, huang et al. <cit>  applied the so-called prize-collecting steiner tree to select nodes and interactions. as we speak, the prior knowledge about molecular interactions is rapidly increasing. for instance, the data generated by the large-scale consortium project encode  <cit>  represent huge possibilities for extending the source of prior knowledge about transcriptional regulation. obviously, methods enabling the use of prior knowledge when constructing genetic networks will increase their relevance in line with this development.

CONCLUSIONS
we have presented a novel method for finding modules of interacting molecules, representing biological pathways or processes, based on microarrays or other transcriptomic data. the method is a clustering approach, which is a commonly used technique for analyzing transcriptomic data. unlike previous approaches using bayesian statistics to infer clusters, e.g.  <cit> , we used informative  priors. the prior information was assumed to be in form of pairs of connected genes, along with a connection score, as this enabled us to capture a lot of relevant prior information, like protein-protein interactions, transcription factor binding information and protein sequence similarity measurements. using simulated data our method showed improved ability of identifying correct groups compared to traditional clustering, especially for small sample sizes, and for situations where most priors were correctly specified. when applying the method to real-world microarray data in heart failure and melanoma cancer we found clusters overlapping with known pathogenic processes, but where subnetworks of prior pairs within each cluster pointed to new connections extending beyond the classical disease pathways.

availability
the method is implemented in c++ and r and is available from: http://folk.uio.no/trondr/gene_corr, as well as a tool in the galaxy  <cit>  based genomic hyperbrowser  <cit> , see http://hyperbrowser.uio.no/dev <dig> under assorted tools →mcmc gene corr. the data sets supporting the results of this article are available from the gene expression omnibus repository: http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=gse <dig>  and http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=gse <dig> .

competing interests
the authors declare that they have no competing interests.

authors’ contributions
sn and tr developed the methodology. sn, tr and vn implemented the software. sn, tr, tc, vn, jb, bs and tt generated and collected data used in this paper. sn, tr, tc, jb, gc and eh analyzed the results. sn, tr, jb, gc and eh wrote the article. all authors participated in discussions, read and approved the final manuscript.

supplementary material
additional file 1
calculations and parallel tempering description. calculations of expressions used in the mcmc algorithm and description of the use of parallel tempering.

click here for file

 additional file 2
monte carlo estimation of prior. evaluation of the precision of the monte carlo estimates of the prior compared to the exact calculation.

click here for file

 additional file 3
figure s <dig>  number of estimated clusters. gap index is used for all methods except ours, which inherently finds the number of clusters. hclust = hierarchical clustering, kmeans = k-means clustering, pam = prediction around medoids, mclust = model-based clustering, tight = tight clustering, mcip-a, is our method , but with no priors used, mcip-b is our method using priors with 20% of the priors mis-specified, and mcip-c is our method with all prior pairs correctly specified.

click here for file

 additional file 4
figure s <dig>  investigation of the effect of mis-specified priors on model performance. the figure shows boxplots of adjusted rand index values for  <dig> simulated datasets using the simulation set-up described in the results section, using extra variation sd of  <dig>   <dig> and  <dig>  and number of individuals n of  <dig>  and  <dig> 

click here for file

 additional file 5
figure s <dig>  evaluation of performance in terms of adjusted rand index following the simulation scheme of  <cit> . the simulation setup is identical to the one generating figure  <dig>  except that for this figure the number of clusters where fixed to the true number of clusters . hclust = hierarchical clustering, kmeans = k-means clustering, pam = prediction around medoids, mclust = model-based clustering, tight = tight clustering, mcip-a, is our method , but with no priors used, mcip-b is our method using priors with 20% of the priors mis-specified, and mcip-c is our method with all prior pairs correctly specified.

click here for file

 additional file 6
figure s <dig>  the results of applying our method to the most differentially expressed genes between aorta banding and sham in the microarray heart failure data. red node color means upregulated in aorta banding vs sham, green color downregulated.

click here for file

 additional file 7
go results mcip with priors, heart failure data. results of gene ontology analysis using gostats  <cit>  of heart failure clusters found using our method with priors.

click here for file

 additional file 8
go results mcip without priors, main cluster, heart failure data. results of gene ontology analysis of main heart failure cluster found using our method without priors.

click here for file

 additional file 9
go results kmeans clustering, main cluster, heart failure data. results of gene ontology analysis of main heart failure cluster found using kmeans clustering.

click here for file

 additional file 10
figure s <dig>  the results of applying our method to the most differentially expressed genes between metastatic and non-metastatic melanoma cancer patients. red node color means upregulated in metastatic melanoma, green color downregulated.

click here for file

 additional file 11
go results mcip with priors, melanoma data. results of gene ontology analysis of melanoma clusters found using our method with priors.

click here for file

 additional file 12
go results mcip without priors, main cluster, melanoma cancer data. results of gene ontology analysis of main melanoma cluster found using our method without priors.

click here for file

 additional file 13
go results kmeans clustering, main cluster, melanoma cancer data. results of gene ontology analysis of main melanoma cluster found using kmeans clustering.

click here for file

 acknowledgements
we thank ian donaldson for help using the irefindex database, torbjørn rognes for providing sequence homology scores using blast, jason ernst for giving us tf binding predictions, kjetil klepper for providing mappings of pwm ids to gene symbols, kai trengereid and morten johansen for incorporating the software into the genomic hyperbrowser, and john quackenbush and his lab for hosting internship of sn during which the idea of this project was conceived. we also would like to thank the anonymous reviewers for their detailed and constructive comments. the work of sn was supported by the south-eastern norway regional health authority.
