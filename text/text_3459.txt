BACKGROUND
the use of mass spectrometry to search for proteins that are indicative of disease has greatly accelerated the "discovery" phase for biomarkers. however, this increase in initial discovery has resulted in very few biomarkers that survive subsequent testing using new data. one of the major causes of the high false positive rate of biomarker candidate discovery is the problem of overfitting classifiers built from small sample sets with many observed variables  <cit> . a mass spectrum of a biologic sample, such as those obtained via maldi-tof profiling of blood serum, may have tens or even hundreds of thousands of time points in the signal. even after signal processing to reduce noise and increase sensitivity, we still find up to hundreds of time positions that have molecular abundance "peaks" representing the existence of a concentration of some molecule, typically a protein in our application. our sample sets, unfortunately, consist of perhaps a few hundred samples of various disease states - on the order of the number of features found in the spectra. much of our group's other work has increased the efficiency of our signal processing  <cit> , resulting in ever more features--albeit with more precise abundance measurements--through which we must sort to find those that are diagnostic of a particular disease.

with such small sample sets , most typical statistical methods will find many features with correlations to the presence of disease--some likely to be strong, even through random chance. we seek to reduce the number of falsely diagnostic candidate features, and simultaneously determine relationships between features to provide additional information that may help identify proteins for further study. to this end, we have developed a relatively simple method of creating a bayesian belief network  that starts with the disease state  as the root node, and attempts to organize spectral features that impact knowledge of the disease state. we have chosen model-free criteria to assess relationships, and criteria on which to judge the stability of the resulting network, that is, our confidence that the result will apply to future data, and not lead to a diagnostic "dead end."

after briefly introducing the major mathematical tools necessary to perform the bayesian network analysis, we will describe our method of building the network structure and testing the stability of the links. we will then describe our application of the method to two sets of mass spectrometry data. the method is first tested on data that was artificially generated, with pre-chosen diagnostic features, specific relationships between features, and large variability carefully introduced to mimic common measurement errors and instrumental variability found in tof-ms systems  <cit> . the second set of data was derived from a  <dig> institutional review board-approved leukemia study conducted at the eastern virginia medical school . we will then compare our method's results to several traditional feature selection methods. we will show that the feature set selection using our method is more stable, and, in the case of the leukemia data, better at predicting the error rates achieved when previously withheld  data is classified.

mathematical tools
two primary mathematical tools were needed to implement the bn feature selection method. the bayesian network itself is a method of encoding the dependencies among random variables. in our application, the variables were the relative intensities of the peak signal at mass positions with significant abundances in at least a subset of sample spectra.

to build the bayesian network, we borrow from the information theorists a simple, but powerful, model-free test for independence--mutual information. mutual information is a measure of the information that knowledge of one variable's value  provides about another . for two variables x and y, the mutual information between them is, in the discrete case,   

where x represents all the possible values x can take, similarly with y, and p represents the joint probability that x takes on the value x and y takes on the value y. the mutual information ranges from zero, representing independence between x and y, to the log of the number of values that x or y can take. the base of the log is arbitrary, and we use  <dig> as is conventional in information theory. the maximal value is attained when knowledge of x always provides perfect prediction of the value of y .

a bayesian network is, at its most basic level, a formula for a joint probability distribution of a set of variables, such as p. this formula, which summarizes all the dependencies among the variables, can be represented graphically by use of a directed acyclic graph, or dag. when the joint probability distribution is determined by the structure of the bn, it can be rewritten in the form p, or "the probability of a given b and c and d...." when associated with the variables a = "disease class" and b,c,d,... = "data measurements," this represents a classifier. writing the joint probability distribution from the dag is straightforward; details can be found in jensen  <cit> .

the dag has two elements: nodes for each variable in the problem, which we will represent as ovals, and arcs, or lines between nodes. the arcs are directed, so that they point  from one node to the other. the graph is acyclic; there are no nodes where it is possible to start, and then return, by following a set of directed arcs . figure  <dig> represents a simple dag with five nodes.

the dag encodes a set of facts about the relationships between the variables in the distribution it models. arcs represent dependencies, so that, in the most basic case of only two nodes, an arc is drawn if they are dependent and no arc if they are independent. the dag is simply a way to represent all the dependency information in a particular system of variables; mathematical theorems about various dependencies are then represented as easily visualized operations on the dag  <cit> .

the general bn has no particular root node, although it will have one or more nodes that have no parents . one aspect of our problem allows us to simplify the intractable problem  <cit>  of exact "structure learning," or assembling, the correct bn for the data. since we wish to discover features diagnostic of the disease class, we can place the variable representing the class at the root of the bn and work downward.

to do this assumes that the presence of the disease , is causal to the variability in the ion abundance for a particular feature, and that the causality will emerge as a link in the bn. assumptions of this type underlie much of the work done with belief networks recently, a good discussion can be found in pearl  <cit> .

an important attribute of the bayesian network allows a further, and critical, simplification. connections between variables of the type we seek encode dependencies between the variables, as we have stated. a connection such as a→b→c  encodes the statement that "although a and c may be dependant, this dependency disappears when b is known." the equivalent joint probability distribution formula encoded by this dag is p = p p p.

thus, when the data is divided up into groups sorted by the possible values of b, we will find that mi =  <dig>  and deduce that they are independent. of course, building the bn goes the other way - such independencies are estimated from observations and built into the resulting dag.

if we consider b to be not a single variable, but instead the set of all variables whose knowledge isolates a from all other variables c, we have found the "markov blanket" of a. if we can find a markov blanket of the class variable, we have built a minimal classifier--knowledge of the variables in set b are sufficient to determine the probability of a, without using any of the variables in c. we have used this concept of the markov blanket of the disease class to perform feature set selection. we will look further, however, as variables which connect to the markov blanket might still be of biochemical importance in understanding the disease, even though they are not the primary "biomarkers" in the usual sense.

another important statistical technique we used is that of k-fold cross-validation . we desired to study the stability of the feature selection method, and this type of cross-validation was well suited for that purpose. we repeated the cross-validation a number of times, randomizing the groups each pass. using that protocol, each case is classified using a different training set. for 10-fold cv, for example, 90% of the cases are used to find classifier parameters to classify the other 10%. by choosing new groups each repetition, a different 90% of cases are used to create the parameters, and a different classification may result.

while "leave one out" cross-validation is intrinsically more stable, it cannot be used in this fashion. other methods such as bootstrap sampling were considered, but we chose k-fold cv  for its low bias and variance in this type of problem  <cit> . to further reduce variance, we used stratified cv, in which a training group is chosen to have approximately the same distribution of classes as the original population.

methods
using these two tools of a bayesian belief network and mutual information, we have taken the output of our advanced signal processing methods  <cit>  and attempted to find diagnostic features, as well as build a classifier that could be used to separate future samples. more detail on the method can be found in kuschner  <cit> .

the first step in our implementation is to determine all variables that show dependency with the class. we originally attempted to determine a threshold for mutual information significance by repeatedly and randomly permuting the class assignment of our data, computing the mutual information mi for each permutation, and finding the largest "random" mutual information which results. however, due to the mutual information maximization described below, strictly using this baseline mutual information value as a threshold to declare significance resulted in an unrealistic number of features with some connection to the class. the final methodology was empirical, increasing the threshold while monitoring the number of first level features, as well as the fraction of cases misclassified under cross-validation. feature set sizes uniformly decreased, while error rates had a local minimum, pointing to a stable threshold value. resource constraints prevented further investigation into a rule-based method of determining a significance threshold, and we hope to improve this aspect of our work at a later date. in the leukemia data described in the next section, a threshold of  <dig>  times the "randomized" baseline provided stable feature sets with a reasonable number of features and minimal error rates.

the abundance values for each feature were discretized into  <dig> bins - high, medium, and low - by maximizing the mutual information of that feature with the class. thus for each feature, bin boundaries are swept from the maximum to the minimum empirical values, the data is discretized, and mi is found. the bin boundaries that maximize this value are noted and the discrete values of the variables are used for all further calculations.

the three bin method was selected in order to isolate central values which provide little or no discrimination between groups. if a protein has higher abundance in disease samples, for instance, the high bin will have a large difference in the probability of occurrence given disease vs. normal, as will the low bin. the central bin will have nearly the same probability of occurrence regardless of disease state. diagnostic features will have few cases in the central bin, and the maximized mi will reflect this. figure  <dig> illustrates this technique.

with a significance threshold set, all features with mi greater than the threshold are initially considered to have connection to the class variable. graphically, directed arcs are created in the bn from the class node to each node representing a feature passing this test.

once a set of features having significant mutual information with the class is established , they are individually tested against all other features. the mi threshold and discrete values found previously are used  to determine if connections between features exist. if mi exceeds the significance threshold, an undirected arc is placed on the bayesian network to represent this dependency.

in the case where this test is between a first-level feature and a non-first-level feature, the arc can be directed immediately, given our simplification to the bn based on the causality assumption. however, if this feature-feature link occurs between two first-level features, an additional test is required.

to direct such arcs, we used conditional mutual information. this measurement determines the mutual information remaining between two variables when a third variable is known. in practice, the data is partitioned by the third variable's value, and mutual information is measured by   

if the connection to the class c is of the form c→v1→v <dig>  then the feature v <dig> will become independent of the class when the data is partitioned on the values of v <dig>  as discussed previously. in that case, the mutual information mi will drop to zero, indicating the independence and the initial link c→v <dig> is removed. if this connection accurately reflects the causal situation, however, it will not be true that mi drops to zero--and this link is kept.

this provides a means to organize first-level features with dependencies between them. we compute the conditional mi values and look for mi<<mi. if such a drop occurs, we conclude a serial connection c→v1→v <dig> exists. while we did not find that the conditional mutual information vanished, indicating pure independence, significant drops  were often observed. our results were relatively insensitive to the exact threshold used, but fewer expected connections  were organized correctly with this threshold above 90%.

first level feature pairs where such drops were not significant were maintained at the first level, but the arc between them was directed based on the greater of the conditional mutual information results.

these two simple tests resulted in a markov blanket of features around the class variable and information about correlations between these and other features. the resulting dag is recorded during each cross-validation trial and is used to classify the test cases. after k trials, all cases in the data are classified and an error rate for that trial is recorded. to find that error rate, the probabilistic classification given by the bn  is changed to a deterministic classification  using some value, which is  <dig>  in all of our results.

by randomizing the list of samples in each of the k-fold cross-validation groups n times, n*k bayesian networks are recorded, along with n cross-validated error rates. the stability of the bayesian network is examined by noting the frequency with which various links appear in this set of results, and the stability of the direction of the arcs between features. an "average" network of most frequent connections can be built, thus enabling the classification of new samples with the most stable connections and parameters found.

the matlab code which implements the algorithm described above can be obtained from the matlab central file exchange under the title "wmbat" http://www.mathworks.com/matlabcentral/fileexchange/ <dig>  or by contacting the authors.

data
two data sets are examined, one artificial and one real. the real data set used is from an eastern virginia medical school  study aimed at discriminating between subsets of patients infected with human t-cell leukemia virus type  <dig> . blood sera samples were collected under a protocol developed by the national institute of health and evms. the samples derived from three major clinical sites and were collected using centralized protocols and kept frozen until processed. the diagnosis and classification of adult t-cell leukemia  was made using the world health organization classification and shimoyama criteria. in addition to atl and healthy individuals the cohort included htlv-1-infected asymptomatic individuals from the same clinical sites. the acquisition of ms spectra was performed according to protocols described in  <cit> .

evms investigators employed an in-house program to assign samples in a randomized matrix pattern to prevent bias between replicates, or clinical status, and chip spot position. all samples were processed in triplicate and the arrayed chips were read in a 48-h period. the matrix codes were assigned by an individual separate from the team that processed the samples so that each phase of the study was blinded with respect to the operator. the code was broken during the classification stage.

before analysis, the data were divided into two sets. the training set consisted of  <dig> different patients, of which  <dig> were classified during the clinical portion as "normal," and  <dig> with various stages of atl. after removing spectra from the triplicate processing that had poor signal-to-noise due to instrument problems, we were left with  <dig> cases for the study. this constituted approximately two-thirds of the data taken; the remaining one-third  was withheld for validation until a final classifier was created. the data are available at proteomecommons.org, under the title "leukemia' <dig> tof spectra parsed into rdata files."

signal processing of the spectra was performed using tools created by our group and its collaborators and reported elsewhere  <cit> . the procedure followed several steps:  removal of an exponentially decaying pedestal  presumably created by the low mass matrix products;  peak location and amplitude fitting for each spectra by using a gaussian line shape with a full-width at half maximum of  <dig> time steps. this fit weighted each data point's squared error by the inverse of the expected signal to simulate the expected poisson statistics. whenever a peak amplitude exceeded  <dig> times the root-mean-square  noise in the spectra, that location and amplitude were recorded.  all the recorded peaks were aligned across the spectra by shifting the start time of each spectrum to minimize the variation in peak positions found in the spectra. this typically required shifts of as large as ±  <dig> time steps.  a master peak list was generated by including peak locations found in at least 5% of the spectra.  fitted amplitudes were recorded for all spectra at the master peak locations, even those which did not exceed the earlier snr threshold of  <dig>   the remaining background was removed by smoothing and interpolating each spectrum, after excluding those regions that were within  <dig> fwmh of a peak or an expected peak.  the peak amplitudes were corrected for a systematic decay that was observed in the qc  spectra by increasing each spectrum's amplitude by  <dig> % in the order they were taken. this resulted in a net increase of approximately a factor of  <dig> by the end of the list of spectra. we believe that this was necessary to correct for a laser power decrease over the course of the experimental run. the final result was an array of abundance values for each case at a number of mass-to-charge positions . this processing of leukemia data set led to detection of  <dig> aligned peaks in all  <dig> spectra in m/z range from  <dig> to  <dig> kda.

the artificial data was created to test the ability of the method to reproduce known relationships. no signal processing is done, but the typical challenges associated with the analysis of real mass spectra are introduced, such as strong correlations between peaks, high variability, convolution of the values of nearby peaks, and the presence of many peaks that are non-diagnostic. data is generated from gaussian distributions with means and variances drawn from the leukemia data . specific features are chosen to be primary markers, and the mean values of the distributions the two groups are drawn from are one to two standard deviations apart, as was found in the leukemia data. the distribution between groups shown in figure  <dig> is from this data set, and simulates the most diagnostic feature found in the leukemia data set. several other features are chosen to be modifications of the primary features, and random, but bounded, amounts of the primary features are placed in the secondary features. this simulates protein modifications, multiple ionizations, and other systematic events maldi events  <cit> . the remaining features are drawn from a single distribution, regardless of class. other common tof-ms problems are introduced. for example, one feature has a portion of its values moved to a neighboring feature to replicate signal convolution of nearby peaks. detail of the creation of the generated data and the matlab code used to generate it is at http://kwkusc.people.wm.edu/dissertation/creategendata.html.

RESULTS
the leukemia data set was examined with several traditional feature selection methods, using a classifier as a wrapper, to create a baseline for our method's results. these methods were the naïve bayesian classifier , linear and quadratic discriminate analysis , and classification by mahalanobis distance. the wrapper method of feature selection uses the classifier result to choose which features to include. we used the forward selection method, which adds to the feature set whichever remaining feature best minimizes the error rate of the classifier, and stops when no better feature set can be found.

with this baseline established, the data was processed using the bayesian network algorithm. our primary objective was to maximize the stability of feature networks under randomized k-fold cross validation, with minimizing error rate a secondary goal.

traditional feature selection and classification methods
each of the traditional methods was repeated  <dig> times using the training data, with feature sets and resulting 10-fold cross-validated error rates recorded for each trial. the best error rate achieved was with qda. using an average of just over  <dig> features, the error rate averaged  <dig> %. the results from each method are presented in table  <dig>  for the nbc, we were able to achieve cross-validated error rates as low as 7% with about  <dig> features. figure  <dig> shows a typical error rate profile as features are systematically added to an nbc feature set.

four different methods of classification are used to select features from the leukemia data set.  <dig> trials were performed for each. features selected represents the average number of features in a feature set when the wrapper determined no better feature set was available. min error represents the average 10-fold stratified cross-validated error rate achieved by the final feature set. lockbox error is the average error achieved by using the final feature set  to classify the data which was withheld until the final classifier was built.

one common factor among all these methods was that, with each new trial and subsequent randomization of the group membership for the k-fold cross-validation, the features that were selected changed dramatically after the first several choices. two typical trials of the nbc are shown in table  <dig>  additionally, between the various methods, the primary features--those occurring in more than 50% of the trials--were often different. lda, for example, found features  <dig>   <dig>  and  <dig> in 63%, 100%, and 100% of the trials, respectively. mahalanobis, on the other hand, found only features  <dig>  and  <dig>  in more than half the trials.

two typical trials of a naïve bayesian classifier wrapper. after the first three features, selection is very unstable. similar results occurred for all the traditional classifiers.

in this form of feature selection, features that are highly correlated to features already selected are often not subsequently selected. to illustrate, if a new feature is a duplicate of one already chosen, the new feature will show no additional diagnostic power added to the feature set, and will be passed over in favor of another, less diagnostic, feature. we know that feature  <dig> and  <dig> are highly correlated, in fact, they represent modified forms of the same protein. in lda, feature  <dig> was chosen, but rarely  <dig>  the opposite was true for the mahalanobis method. since it is critical to the overall goal of biomarker discovery to understand how each of these modifications is related, this is a near-fatal weakness of these traditional approaches.

even more critically, the feature sets chosen using the training data failed to effectively predict the disease state of the withheld  data once it was released. the error rates in classifying the  <dig> cases from the withheld data far exceeded the cross-validated errors from the training data. qda, for example, had cv error rates of  <dig> +/- <dig> %, but was only able to classify the withheld data to about 38% error. all the methods had true errors far outside the predicted range, as shown in table  <dig>  such results have been common disappointments in our previous biomarker discovery work.

trials of the artificial data showed similar results. for example, use of an nbc to select features drove the error rate down to about 1%, but chose many "randomly diagnostic features"--those in which both disease classes were drawn from the same gaussian distribution and were only selected due to overfitting.

bayesian network approach
results using a bn approach with a mutual information score as a filter were more stable. to measure feature selection and error rate stability, a 10-fold stratified cross-validation was run  <dig> times, with each trial's cross-validation groups randomized.

the method was able to completely recreate the intended network for the artificial data, with two exceptions. one feature that was intended to simulate a multiply-charged ion of a protein modification of a primary diagnostic feature was found connected to the class in a small number of trials. the algorithm was not built to search for such "third-level" features, and the small number of times this feature was connected would have kept it from being added to the final classifier in our methodology. two features were intended to simulate fragments of a large protein outside the range of measurement , and one was found frequently connected to the disease class, with the other as its child. the algorithm is not built to detect such hidden variables. one of these features would have been added to the final classifier using our methodology. however, the existence of these fragments in the network may itself lead a researcher to discover the larger, non-measured protein.

all the intended primary diagnostic features were connected to the disease class in 95-100% of trials, showing excellent stability and a nearly perfect discrimination between "real" and "randomly" diagnostic features, unlike the conventional wrapper methods.

using a nominal 50% threshold, we can immediately build the first level of the bn below the root node, which represents the disease state. figure  <dig> shows the initial bn as thick solid arcs connected to the disease class node, "c." it is important to note that more features may have initially passed the significance test and been placed on the first level of the bn, but subsequent tests showed them to be children of these  <dig> remaining features.

in addition to the primary feature set, the method allows discovery of relationships between primary features and all other features. the thin arcs in figure  <dig> show additional relationships found by testing mutual information between features, and organized by testing for conditional mutual information with the disease class. figure  <dig> shows the selection rate of the  <dig> features most frequently selected as children of feature  <dig>  a first level feature. in previous leukemia data study, semmes et al.  <cit>  had found the cluster containing this feature  with very low p-values as a discriminator of disease state. table  <dig> lists the m/z values for the features found in figure  <dig> 

 <dig> features were found in the range of mass-to-charge values we used for this. the list of features that were found to be important and the corresponding m/z values are given in this table.

for this data set, families of features were discovered that allowed a preliminary identification of a primary feature based not only on its mass, but on the mass values of related features. feature  <dig>  for example, has a mass-to-charge ratio almost exactly 1/ <dig> of that of feature  <dig>  indicating that it is the same molecule in a doubly ionized state.

other features such as  <dig> and  <dig> have masses that differ from feature  <dig> by values that may indicate, for example, loss of an arginine residue. investigating each of these "children" allows more preliminary information about the "parent" ion and may lead to a more rapid chemical identification. this information is not readily obtainable by a more traditional feature selection method. in fact, we noticed consistent literature reports  <cit>  for a protein  with this family of modifications, and further experimental testing validated that identification and assignment to serum amyloid a. thus, the combination of better data processing and analysis improved biomarker id capabilities  <cit> 

as a final test of the technique, an approximate bayesian network  was created for this data set, using the most frequent results. the entire training set was discretized and probability parameters for the network were estimated empirically from the result. with the final classifier parameters "frozen," the lockbox of previously withheld data was opened, and the spectra pre-processed using the same techniques and parameters as the training data, including using the same global peak list as features.

the resulting list of observed variable values for each case was discretized using the boundaries determined from the training data and then classified using the final classifier. probabilistic results were converted to deterministic using  <dig>  as a threshold, as was done for the training set. the results were recorded and then assessed against medical diagnoses recorded in the database. the error rate for this classifier was  <dig> %, within the  <dig>  ±  <dig> % predicted by the cross-validation of the training data. roc curves for the classification of both the original training set, and the withheld data, are shown in figure  <dig>  the same feature lists, discretization, and probability tables were used for both sets of data.

the ability of the final classifier to classify the withheld data at a rate similar to the cross-validated error rates for the training data was an important improvement from the poor classification results of the conventional feature selection and classification methods.

discussion
the problems expected of more conventional feature selection methods were found in the leukemia data set when the classifier-wrapper methods were applied. correlated feature groups  had one feature selected, while the others in the group were overlooked. subsequent feature selection was unstable due to the high dimensionality of the data and small sample size. this problem is well documented, but often ignored  <cit> .

more problematically, resulting classifiers produced good results on the data they were derived from, but poor results when applied to new data. given the resources required to validate biomarker candidates, this approach is an inadequate technique for biomarker discovery.

the bayesian network/mutual information approach provided a much clearer partition between stable and unstable features. in the experiment using artificial data, the bn clearly identified all parent features. it also correctly showed the relationship of nearly all correlated features, including those that were designed to replicate ms-specific effects such as the convolution of peak shapes separated by less than the shape width.

most promisingly, error rates predicted by many trials of cross-validation were found to agree well with the results of the training data derived bn classifier used on withheld data. this was not true of the traditional methods. the nbc, for example, was not useful for finding diagnostic information past two or three features, even thought the error rate could be driven artificially low by overfitting.

CONCLUSIONS
the process of chemically validating the selected features in the search for biomarkers is costly and time-consuming. feature selection methods that prevent false positive results are critical to making progress in this field. feature selection methods using traditional classifiers as wrappers suffer from overfitting in small sample sets, and mishandle information about highly correlated variables. the bayesian network approach, combined with model-free mutual information scoring, appears to highlight stable features, as well as provide the opportunity to examine relationships between diagnostic features that may assist in identification.

authors' contributions
kwk applied the bayesian network framework, created the analysis software tools, and analyzed the data. ert provided the theoretical basis for the selection of mutual information as a scoring technique and other statistical methods. ojs led the team that developed the experimental clinical ms protocols, and lhc produced the raw spectra from the blood sera samples. dim and wec provided the code for the signal processing and creation of the peak list, and interpreted the results of the feature selection. all authors have read and approved the final manuscript.

